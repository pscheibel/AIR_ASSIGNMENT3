('emg', 22);('vesper', 13);('shehata', 11);('hpi', 8);('edwards', 7);('joint', 7);('figure', 6);('castellini', 6);('final typeset article', 6);('provisional file', 6);('joint action', 5);('pilarski', 5);('pattern recognition adaptive', 5);('pesquita', 4);('ieee trans biomed eng', 3);('scheme e j sensinger j', 3);('engels', 3);('partner machine partner', 3);('hallmarks joint action', 3);('scheme englehart', 3);('myoelectric', 3);('autonomous agents multiagent systems', 2);('international conference', 2);('jrrd', 2);('j neuroengineering rehabil', 2);('l f', 2);('sci rep', 2);('myoelectric control', 2);('scott phillips', 2);('gvfs', 2);('real time', 2);('pattern recognition', 2);('prosthesis user', 2);('proportional emg', 2);('prosthesis controller', 2);('joints prosthesis', 2);('adaptive', 2);('pattern', 2);('individual task', 2);('mathewson', 2);('kathleen', 2);('sebanz', 2);('social interaction', 2);('williams', 2);('micera', 2);('resnik', 2);('peerdeman', 2);('th', 2);('upper limb prostheses', 2);('alberta edmonton alberta canada', 2);('doi 101098rstb20021238', 1);('phil trans r soc lond', 1);('computational framework motor control', 1);('wolpert doya k kawato', 1);('oi 101109tbme20223140269', 1);('recurrent convolutional neural networks approach position aware myoelectric prosthesis', 1);('dawson scheme e hebert j pilarski p', 1);('williams h shehata', 1);('doi 101016jn eunet201006002', 1);('neural networks', 1);('minimal architecture joint action', 1);('butterfill knoblich g sebanz n', 1);('international foundation', 1);('richland sc', 1);('aam', 1);('architecture learning knowledge unsupervised sensorimotor interaction', 1);('real', 1);('horde', 1);('pilarski p', 1);('sutton r modayil j delp de', 1);('doi 101109tnsre20172712287', 1);('myoelectric prosthesis sensory feedback amputees ieee trans neural syst rehabil eng', 1);('term learning feedforward', 1);('short', 1);('strbac isakovic belic popovic simanic farina', 1);('doi 101109tbme20112155063', 1);('ramp minimizing effect misclassifications real', 1);('decision based v', 1);('kuiken', 1);('j lock', 1);('simon hargrove', 1);('doi 101109msp20213075931', 1);('process', 1);('electromyographic signals improved performance ieee', 1);('prosthetic', 1);('machine lea', 1);('williams h e hebert j pilarski p', 1);('doi 101109tnsre20182826981', 1);('strategies ieee trans neural syst rehabil eng', 1);('model strength performance myoelectric prosthesis', 1);('evaluating inte', 1);('w 2018c', 1);('audible feedback improves internal model strength performance myoelectric prosthesis', 1);('w 2018b', 1);('sensinger j', 1);('scheme e j', 1);('internal model strength performance prosthetic hands', 1);('improving', 1);('w 2018a', 1);('controzzi cipriani', 1);('topics cognitive', 1);('prediction joint', 1);('sebanz n knoblich g', 1);('doi 101016jtics200512009', 1);('trends cognitive', 1);('action bodies minds', 1);('sebanz n bekkering h knoblich g', 1);('available httpsbooksgooglecabooksidoj71oaeacaaj', 1);('bloomsbury academic', 1);('communication different language evolve', 1);('minds', 1);('doi 103389fnbot2021661603', 1);('promote forgiving interactions autonomous machines front neurorobot', 1);('embodied', 1);('marasco p', 1);('schofield j battraw parker r pilarski p sensinger j', 1);('doi 101682jrrd2010090177', 1);('clinical use', 1);('upper limb prostheses state art', 1);('pattern recognit ion control', 1);('electromyogram', 1);('scheme e englehart k', 1);('disability rehabilitation assistive', 1);('user experience', 1);('upper limb prosthesis', 1);('g multi degree freedom', 1);('controllin', 1);('etter k fantini', 1);('klinger', 1);('doi 101109tnsre20132279737', 1);('user training pattern recognition based myoelectric prostheses improving phantom limb movement consistency distinguishability ieee trans neural syst rehabil eng', 1);('powell kaliki r r thakor n v', 1);('accessed january', 1);('available httparxivorgabs171103676', 1);('arxiv171103676 cs', 1);('communicative capital prosthetic agents', 1);('rds l', 1);('parker r edwa', 1);('sherstan', 1);('pilarski p sutton r mathewson k', 1);('doi 101109biorob20126290309', 1);('biomedical robotics biomechatronics biorob rome italy ieee', 1);('ieee ras embs', 1);('human control assistive biomedical robots', 1);('time machine learning', 1);('dynamic', 1);('pilarski p dawson r degris carey j p sutton r', 1);('doi 101109mra20122229948', 1);('automat', 1);('ieee ro', 1);('real time approach prediction anticipation', 1);('artificial limbs', 1);('pilarski p dawson r degris carey j p chan k hebert j', 1);('psychon bull rev', 1);('joint action model hierarchical predictive approach human cooperati', 1);('predictive', 1);('enns j', 1);('pesquita whitwell r', 1);('doi 101682jrrd2010080161', 1);('forearm prostheses state art user', 1);('r hermens h stramigioli', 1);('boere witteveen h huis', 1);('doi 101016jjelekin200608006', 1);('electromyography kinesiology', 1);('limb prostheses journal', 1);('signal proces', 1);('parker p englehart k hudgins', 1);('doi 101109rbme20102085429', 1);('peripheral information ieee rev biomed eng', 1);('hand prostheses', 1);('micera carpaneto j raspopovic', 1);('neural comput applic', 1);('agency collaborative capacity', 1);('capital key resource human machine', 1);('communicative', 1);('sutton r pilarski p', 1);('parker r sherstan', 1);('math', 1);('eaao6990 doi 101126scitranslmedaao6990', 1);('sci transl med', 1);('movement perception improves motor control prosthetic hands', 1);('illusory', 1);('e schofield j thumser z', 1);('shell', 1);('marasco p hebert j sensinger j', 1);('upper body movements transradial prosthesis users', 1);('range ofmotion variability', 1);('comparison', 1);('fatone gard', 1);('c w', 1);('heckathorne', 1);('j stine r', 1);('res', 1);('exp', 1);('fragile object prosthetic limb', 1);('upper limb prosthesis users', 1);('internal', 1);('lum p black holley r j barth j dromerick', 1);('psychology learning motivation elsevier', 1);('psychological', 1);('g butterfill sebanz n', 1);('knoblic', 1);('doi 101016jactpsy2021103476', 1);('acta psychologica', 1);('psychology philosophy', 1);('hri insights', 1);('addressing', 1);('elisabeth p michle g', 1);('amandine aurlie', 1);('f c', 1);('vctor', 1);('doi press', 1);('robotics autonomous systems', 1);('communicate physical interaction annual review', 1);('embodied communication robots', 1);('kalinowska pilarski p murphey', 1);('muzumdar berlin heidelberg springer berlin heidelberg', 1);('clinical application', 1);('control implementation', 1);('paediatrics powered upper limb prostheses', 1);('powered upper limb prosthetic', 1);('naumann glasford montgomery g ramdial', 1);('hubbard heim', 1);('e1911197 doi 101001jamanetworkopen201911197', 1);('upper extremity prosthesis users jama netw', 1);('demands', 1);('quantitative eye gaze movement differences visuomotor adaptations varying', 1);('vette h', 1);('hebert j boser q valevicius tanikawa h lavoie e', 1);('doi 101016jconcog2019102820', 1);('consciousness cognition', 1);('sense agency human human vs human robot joint action', 1);('roche', 1);('grynszpan saha hamidi n pacherie e berberian', 1);('doi 101109tnsre20122196711', 1);('review ieee trans neural syst rehabil eng', 1);('yoelectric control', 1);('upper limb prostheses terminology proportional', 1);('fougner stavdahl kyberd p j losier g parker p', 1);('doi 101109tbme2003813539', 1);('real time control scheme multifunction myoelectric control', 1);('englehart k hudgins', 1);('doi 103389fnins201900578', 1);('feedback dominates continuous audio biofeedback integrated percept controlling myoelectric prosthetic hand front neurosci', 1);('less discrete tacti', 1);('cipriani', 1);('doi 101109biorob20167523678', 1);('biomedical robotics biomechatronics biorob singapore singapore ieee', 1);('con', 1);('ieee', 1);('switch functions myoelectric arm', 1);('machine', 1);('hebert j pilarski p', 1);('prosthetics ortho', 1);('real time machine learning myoelectric prosthesis control case series adaptive', 1);('application', 1);('sutton r chan k', 1);('dawson r hebert j sherstan', 1);('front neurorobot', 1);('traditional surface electromyography', 1);('peripheral machine interfaces', 1);('proceedings', 1);('artemiadis p wininger ajoudani alimusaj bicchi', 1);('crossmodal congruency task', 1);('quality supplementary sensory feedback', 1);('assessing', 1);('blustein wilson sensinger j', 1);('doi 101016jhumov201008012', 1);('vement science', 1);('mo', 1);('cognitive mechanisms decision making joint action human robot interaction study', 1);('neuro', 1);('silva e', 1);('costa', 1);('louro', 1);('bicho e erlhagen', 1);('university press doi', 1);('cambridge', 1);('context', 1);('perception actio', 1);('references azaad knoblich g sebanz n', 1);('amii canada cifar ai chairs', 1);('smart network alberta machine intelligence', 1);('adaptive rehabilitation', 1);('canada nserc alberta innovates sensory', 1);('research council', 1);('engineering', 1);('acknowledgments', 1);('gaze movement analysis inc', 1);('cofounder company', 1);('deepmind csc', 1);('pmp', 1);('potential conflict interest note', 1);('financial relationships', 1);('absence commercial', 1);('interest', 1);('manuscript revision', 1);('figure authors', 1);('mrd', 1);('conception manuscript', 1);('pmp mrd', 1);('author', 1);('assistive rehabilitation technologies', 1);('significant impact design use', 1);('field neuroprosthetic control', 1);('study impact joint action ideas', 1);('based', 1);('strengthening foundations human machine partners form leverage predictive knowledge ongoin g interactions', 1);('capacity coordination', 1);('conventional myoelectric control batch machine learning continual machine learning method', 1);('representative examples', 1);('analysis hallmarks joint action', 1);('agents article', 1);('human prosthesis dyad', 1);('useful framework', 1);('multiple limb position', 1);('upper limb device control', 1);('prosthesis movements', 1);('facilitate precise classification user', 1);('multiple sensors', 1);('recent example data', 1);('additional sensors describe task human partner', 1);('contextual awareness classifier use', 1);('predictions pattern recognition', 1);('furthermore', 1);('different computation', 1);('resemble behavior pattern recognition controllers', 1);('prediction process autonomous', 1);('switch controller guesses', 1);('minimum level confidence', 1);('2016b method autonomous', 1);('swit ch movements', 1);('predicts movement prosthesis user', 1);('predictive enhancement', 1);('prediction learning', 1);('comprehensive representations', 1);('additional sensors communication channels facilitate', 1);('control solutions', 1);('strengthening predictive capabilities', 1);('predictions e ach', 1);('ability th e partners', 1);('kalinowska', 1);('emergent conventions pre', 1);('human machine partner', 1);('subtle ostensive cues', 1);('mental effort information processing costs opportunitie', 1);('overall system performance', 1);('specific feedback key', 1);('prosthetic device task', 1);('rich feedback machine partner', 1);('optimal balance', 1);('achieving', 1);('overall system integration', 1);('h uman understanding prosthetic device', 1);('feedback machine partner control states signals human partner', 1);('specific feedback human', 1);('2018b task', 1);('adapt changes task prosthetic device', 1);('strong internal model', 1);('auditory visual cutaneous sensory cues', 1);('feedbac k partner', 1);('specifically', 1);('human brain prosthetic device control system', 1);('internal model', 1);('feedback control system human partner', 1);('signals partner monitors task suggestion', 1);('additional coordination smoothers', 1);('internal models human prosthesis controller', 1);('powerful way', 1);('ideas field joint action', 1);('important analysis reveals terms recommendations', 1);('present different candidate human prosthesis partnerships', 1);('previ ous section', 1);('prosthesis interaction', 1);('recommendations improving', 1);('displays movements', 1);('training phase human sends retrain signal pattern recognition', 1);('machine partner coordination signals pattern recognition', 1);('explicit coordin', 1);('feedback human', 1);('hallmark coordination signals', 1);('adap tive', 1);('regular operation', 1);('adapting', 1);('classifier pattern recognition occurs', 1);('parameters proportional', 1);('cases human part learning process', 1);('adapting predictions', 1);('continuously', 1);('list human partner', 1);('predictable b', 1);('critical moments', 1);('simon', 1);('englehart hudgins', 1);('velocity ramps', 1);('techniques maj ority', 1);('incorrect predictions', 1);('pattern recognition controllers', 1);('additionally', 1);('powell', 1);('signals types controllers', 1);('generate distinct', 1);('evidence hu mans', 1);('goal regard coordination smoothers', 1);('movement intent human partner', 1);('aspects actions', 1);('evidence controller', 1);('predictions coordination smoothers', 1);('x x', 1);('x coordination signals x x continuously adapt', 1);('actions', 1);('x shared goal x predict actions x x x partner actions x coordination smoothers', 1);('partner actions partner', 1);('x monitor actions', 1);('x shared goal x partner', 1);('proportional emg pattern recognition adaptive switching representation', 1);('hallmarks joint', 1);('yellow question mark', 1);('myoelectric controllers thr ough joint action lens green checkmark', 1);('evaluation', 1);('decisions wi th respect goal', 1);('machine partners', 1);('reward signal', 1);('present work reinforcement learning algorithms', 1);('representations note candidate analysis', 1);('towel controller', 1);('level task eg', 1);('goals controller', 1);('infer location object environment kinds', 1);('access position sensors load sensor gripper', 1);('classifi er access type information', 1);('environment eg', 1);('complex involves', 1);('signals controller', 1);('patt ern', 1);('particular position', 1);('goal partners task pattern recognition', 1);('representations tasks', 1);('howeve', 1);('explicit representation tasks goals', 1);('direct mappings inputs outputs controllers', 1);('controllers employ', 1);('full environment eg partner goals', 1);('complete r', 1);('prominent things', 1);('operation inputs outputs state', 1);('partner eg machine partner', 1);('observable space', 1);('prominent regard signals states', 1);('consistent element control engineering human motor control', 1);('representations monitoring tasks goals monitoring', 1);('independent capacity representations', 1);('component machine learning processes', 1);('n ot', 1);('scope representations joint action', 1);('way human partner use', 1);('likely joint action', 1);('controllers representations', 1);('red goal', 1);('standard human tool use sha', 1);('common conception prosthesis', 1);('necessary representation predicti processes case analogous', 1);('controller lacks', 1);('controller human', 1);('action proportional', 1);('complete definition joint action', 1);('inadequ ate', 1);('hallmarks joint action cases key hallmarks', 1);('prosthesis controllers exhibit', 1);('respect machine partner analysis suggests', 1);('marasco', 1);('blustein', 1);('strbac', 1);('lum', 1);('internal models', 1);('prosthesis users adapt', 1);('predictions humans', 1);('control schemes human partner', 1);('results analysis prosthesis controllers joint ac tion lens', 1);('analysis discussion', 1);('joint resumes', 1);('list human', 1);('signal adaptive', 1);('explicit training period', 1);('regular use', 1);('improvement adaptive', 1);('predictions joint human', 1);('monitors joint feedback prosthesis', 1);('controllers adaptive', 1);('key difference', 1);('forecasts prosthesis mode function use cf', 1);('sutton', 1);('stream observations', 1);('accumulations signals interest', 1);('tempo rally', 1);('reinforcement learning methods', 1);('learning predictio n approach', 1);('gvf', 1);('adapt order', 1);('gvf sutton', 1);('general value functions', 1);('uses magnitude collection', 1);('list adaptive', 1);('similar structure proportional', 1);('analysis adaptive', 1);('example continual online machine learning', 1);('adaptive switching', 1);('con trol', 1);('real time prosthesis user', 1);('classifier training pattern recognition controller', 1);('predictions training process', 1);('samples compute parameters classifier llow', 1);('signal pattern movement demonstration period classifier use', 1);('manner human demonstrates', 1);('physical virtual representation prosthesis', 1);('phone application', 1);('1b button prosthesis', 1);('fig', 1);('retrain signal', 1);('train retrain classifier', 1);('joint th e prosthesis time prosthesis user', 1);('contemporary clinical use', 1);('control pattern recognition controllers', 1);('similar proportional', 1);('multiple features time frequency domains', 1);('recognition controllers extract', 1);('signal stre ngth', 1);('muscles r esidual limb', 1);('controllers pattern recognition controllers', 1);('signals contrast proportional', 1);('b offline batch machine learning classifier predicts movement intent prosthesis user', 1);('pattern recognition controller', 1);('cable switch', 1);('antagonistic muscles', 1);('huma n machine partner co', 1);('different joints arm eg hand openclose wrist rotation elbow flexion', 1);('signal sequential', 1);('motor speeds', 1);('threshold proportionality', 1);('velocity joint eg hand openclose prosthesis', 1);('residual antago nistic muscles eg bicepstriceps', 1);('fougner', 1);('emg hubbard', 1);('state proportional controller sequential', 1);('specific type proportional', 1);('current state eg position velocity multi joint prosthesis', 1);('actuation', 1);('feet trunk joints residual limb', 1);('position prosthesis space', 1);('signals prosthesis controller prosthesis user', 1);('socket residual muscles', 1);('prosthetic socket', 1);('physical connection prosthesis user multi joint prosthesis', 1);('adjusts order sequential', 1);('continual learning method', 1);('offline training c', 1);('recognition controller single class output episodic', 1);('myoelectric control proportional', 1);('conventional', 1);('different prosthesis controllers interact prosthesis user', 1);('block diagrams', 1);('continualonline machine learning', 1);('machine learning pattern recognition batchoffline machine learning adaptive', 1);('control sequential', 1);('main ca tegories control proportional', 1);('analysis joint action architecture representative case', 1);('prosthesis controllers', 1);('myoelectric controllers included analysis', 1);('continuous improvement predictions type coordination', 1);('complementary model', 1);('coordination signals', 1);('coordination smoothers', 1);('examples', 1);('hallmarks improves coordination partners', 1);('smoothers defi', 1);('coordination smoothers coordination', 1);('actions timing actions outcomes actions', 1);('predictions actions actions partner', 1);('multiple joint action architectures partner', 1);('prediction across', 1);('mo vements forces prosthesis', 1);('signals human', 1);('machine partner array sensors', 1);('conversely', 1);('visual feedback', 1);('monitors movement prosthesis', 1);('task human', 1);('monitor actions partners actions', 1);('note partner need', 1);('specific context', 1);('necessary processes', 1);('joint action architecture', 1);('individual tasks', 1);('actions partners actio ns', 1);('numerous perceptions states', 1);('monitoring', 1);('individual task list requirement', 1);('helpful partner representation others', 1);('goal eg portrayals human brain digita l storage', 1);('representation', 1);('control signals human', 1);('typical tasks machine partner', 1);('hebert', 1);('body residual limb movements major', 1);('control signals machine partner', 1);('typical tasks human', 1);('con figuration environment', 1);('specific user', 1);('particular position use interact environment', 1);('goal human machine partner', 1);('responsible combination', 1);('tasks goals', 1);('th e machine prosthesis control system', 1);('partner human partner machine partner case', 1);('task joint action', 1);('partners', 1);('h pi', 1);('terms relate', 1);('partners tasks goals', 1);('prediction coordination smoothers', 1);('present system', 1);('main hallmarks b e', 1);('basic framework', 1);('purpos es paper', 1);('knoblich', 1);('sebanz knoblich', 1);('wolpert', 1);('social interaction joint action', 1);('architectures collaborative', 1);('additional hallmarks joint action', 1);('fit framework', 1);('controllers represe ntative example continual machine learning', 1);('goal explore proportional', 1);('viewpoint joint action human prosthesis interaction', 1);('thes e trends', 1);('current article', 1);('relationship agency partner human prosthesis system capacity partnership', 1);('case studies examples', 1);('p rosthesis distinct agent communicative capital', 1);('grynszpan', 1);('bicho', 1);('interaction human robots', 1);('azaad', 1);('social sciences joint action', 1);('actions space time', 1);('movement object manipulation lens joint action', 1);('complex tasks', 1);('human prosthetic device', 1);('complex systems', 1);('schofield', 1);('complex behavior co adaptation human prosthesis controller', 1);('human prosthesis interaction single human', 1);('technology tradit ional approach', 1);('control approaches', 1);('autonomy prosthesis control system', 1);('machine learning methods', 1);('individual prosthesis users', 1);('life needs', 1);('device control signal patterns', 1);('continual learning methods', 1);('deep neural networks', 1);('machine learning methods pattern recognition', 1);('address user', 1);('small number control inputs', 1);('high number joints', 1);('report ch allenges frustration', 1);('actuation technology users', 1);('joints multi', 1);('capability complexity prostheses', 1);('standard example human tool', 1);('early systems prosthesis controller', 1);('parker', 1);('residual muscles', 1);('voluntary surface electromyography', 1);('degree offreedom', 1);('mid twentieth cent ury', 1);('development robotic', 1);('introduction', 1);('collaborative communication par tner', 1);('myoelectric systems relate', 1);('hallmarks joint action results comparison lead n ew perspective understanding', 1);('different prosthesis controllers proportional electromyography sequential', 1);('prediction others actions communication ability adapt work', 1);('others goal', 1);('interactions partners', 1);('joint action framework', 1);('human partners', 1);('e field joint action', 1);('understanding interfaces model collaborative multi agent systems lens joint action', 1);('possible approach', 1);('human machine interface human', 1);('traditional approac h', 1);('autonomy system', 1);('movement intent controllers', 1);('various machine learning controllers', 1);('challenging address issue', 1);('user generat', 1);('multiple degrees freedom', 1);('robotic limb', 1);('significant improvements number movements', 1);('abstract recent', 1);('pattern recognition reinforcement learning machine learning prediction artificial intellige', 1);('keywords prosthesis joint', 1);('alberta edmonton alberta canada correspondence michael r dawson', 1);('kinesiology sport recreation', 1);('biomedical engineering', 1);('rehabilitation medicine edmonton alberta canada', 1);('canada', 1);('amii edmonton albe', 1);('machine intelligence', 1);('medicine', 1);('physical medicine rehabilitation', 1);('shehata1 jacqueline hebert14 craig chapman5 patrick pilarski12', 1);('framework understanding partnerships humans upper limb prostheses michael r dawson12 adam r parker23 heather e williams24 ahmed', 1);