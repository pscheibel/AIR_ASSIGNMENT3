('grn', 31);('fcmae', 27);('convnext', 22);('cvpr', 20);('imagenet1k', 13);('convnets', 11);('mae', 11);('convnext v2', 11);('figure', 9);('coco', 8);('simmim', 8);('iclr', 7);('imagenet', 6);('huge', 6);('v1', 6);('v2b fcmae', 6);('v2l fcmae', 6);('v2h fcmae', 6);('ade20k', 6);('bl', 6);('eccv', 6);('l2norm', 5);('adamwbase', 5);('2090999layerwise lr decay', 5);('rate schedule cosine decaywarmup epochs', 5);('iccv', 5);('icml', 5);('neurips', 5);('convnext v1', 4);('v2', 4);('method', 4);('flops val', 4);('v2b supervised', 4);('89m 154g', 4);('v1l supervised', 4);('v2l supervised', 4);('198m 344g', 4);('swin', 4);('v2h', 4);('imagenet22k', 4);('endtoend in1k', 4);('convolutional neural networks', 4);('global', 3);('top1 accuracy', 3);('mlp', 3);('sparse', 3);('vit', 3);('v2h simmim', 3);('v1xl', 3);('\x00 \x00 \x00 \x00 \x00convnext', 3);('gpu', 3);('pytorch', 3);('randaug', 3);('10drop path', 3);('ssl', 3);('convnextv2', 2);('ade20ksegmentation', 2);('various sizes', 2);('atto', 2);('convnext v2model', 2);('additionally', 2);('sparse convolutions', 2);('block decoder', 2);('overall', 2);('convnextbase', 2);('in1k', 2);('unet', 2);('feature', 2);('specically', 2);('sup', 2);('model exhibits', 2);('xi', 2);('nal proposal', 2);('v1b supervised', 2);('89m 154g 838convnext', 2);('v1b fcmae', 2);('89m 154g 837convnext', 2);('198m 344g 843convnext', 2);('v1l fcmae', 2);('198m 344g 844convnext', 2);('convnext v2 huge', 2);('similarly', 2);('beit', 2);('large', 2);('presentimagenet22k intermediate', 2);('thetraining', 2);('new stateoftheart accuracy', 2);('ourresults', 2);('122m 1170gconvnext', 2);('component analysis', 2);('moco v3', 2);('tiny', 2);('base', 2);('sparse convolution', 2);('minkowskiengine', 2);('adamw', 2);('09batch size', 2);('fp', 2);('modelscong valueoptimizer', 2);('hhead', 2);('blh', 2);('ntbatch', 2);('v1 v2', 2);('37m 055g', 2);('52m 078g', 2);('91m 137g', 2);('156m 245g', 2);('286m 447g', 2);('v2n', 2);('v1t', 2);('v2t', 2);('v1b', 2);('v2b', 2);('v1l', 2);('v2l', 2);('convnext v2base', 2);('image transformers', 2);('vision transformers', 2);('iniccv', 2);('van der', 2);('ineccv', 2);('mingxing tan quoc', 2);('convnext v2 codesigning scaling convnets masked autoencoderssanghyun woo1shoubhik debnath2ronghang hu2xinlei chen2zhuang liu2in kweon1saining xie3y1kaist2meta ai fair3new york universityabstractdriven', 1);('representation learning frameworks eld visual recognition', 1);('rapid modernization performance boost', 1);('2020s example', 1);('strong performancein', 1);('various scenarios models', 1);('learning techniques', 1);('subpar performance paper wepropose', 1);('autoencoder framework', 1);('normalization grnlayer', 1);('architecture toenhance interchannel', 1);('competition codesignof', 1);('learning techniques architectural improvement results', 1);('new model family', 1);('improves performance pureconvnets', 1);('various recognition benchmarks includingimagenet classication', 1);('convnext v2models', 1);('efcient 37mparameter', 1);('public training datacode httpsgithubcomfacebookresearchconvnextv21', 1);('introductionbuilding', 1);('research breakthroughs', 1);('decades3444476068 eld visual recognition usheredin', 1);('new era largescale visual representation', 1);('largescale vision models', 1);('essential tools', 1);('wide range ofvision applications performance visual representation learning system', 1);('mainfactors neural network architecture', 1);('fairycorresponding', 1);('femto pico nano tiny base large huge740760780800820840860imagenet top1 accuracy', 1);('v1 supconvnext v2 selfsupconvnext v1 selfsupfigure', 1);('autoencoder framework performs', 1);('previous version', 1);('wide range model', 1);('training network data', 1);('trainingin eld visual recognition progress theseareas contributes overall improvements performanceinnovation neural network architecture design', 1);('major role eld representation learning', 1);('convolutional', 1);('neural network architecturesconvnets', 1);('signicant impact oncomputer vision research', 1);('genericfeature learning methods variety visual recognitiontasks', 1);('recent years transformer architecture', 1);('natural language processing hasalso', 1);('behaviorwith respect model dataset size', 1);('pure convolutionalmodels', 1);('scalable architectures', 1);('common method', 1);('design space forneural network architectures', 1);('learning performance', 1);('imagenet1arxiv230100808v1', 1);('jan', 1);('separate line research focus visual representation learning', 1);('learning labels', 1);('pretext objectives', 1);('recentlybrought success', 1);('popular approach visualrepresentation learning', 1);('common practice', 1);('learning use', 1);('thevision transformer', 1);('design elements architectures', 1);('learning frameworks', 1);('specicencodedecoder design', 1);('capabilities transformers', 1);('thecomputeheavy encoder focus', 1);('visible patches thusreduce', 1);('cost design', 1);('dense slidingwindows', 1);('relationship architecture training objective', 1);('optimal performancecan', 1);('previous research', 1);('learning difcult', 1);('empirical evidence suggeststhat transformers', 1);('representation qualityto end', 1);('codesign network architecture', 1);('autoencoder framework aim making', 1);('sparse patches', 1);('visible parts ideais', 1);('sparse convolutions processinglargescale 3d point clouds', 1);('standard denselayers', 1);('transformerdecoder single', 1);('block making entiredesign', 1);('resultswith changes', 1);('baseline results', 1);('modelwe conduct', 1);('space analysis', 1);('identify potential issue', 1);('layer trainingconvnext', 1);('input address issuewe', 1);('normalization', 1);('layerto enhance interchannel', 1);('competition changeis', 1);('effective model', 1);('suboptimalin summary introduce', 1);('improves performance', 1);('convnetsacross', 1);('object detection', 1);('models usedin variety compute regimes', 1);('complexity efcient 37mparameter', 1);('attomodel', 1);('toa 650m', 1);('stateoftheart 889accuracy', 1);('in22k', 1);('related workconvnets', 1);('numerous improvements terms optimization accuracy efciency years', 1);('recent years efforts beenmade', 1);('architecture search', 1);('selfsupervisedpretext tasks rotation prediction colorizationas case', 1);('unnas', 1);('recently convnext', 1);('comprehensive review design space', 1);('scalable vision transformers', 1);('dominant architecture', 1);('simple way toupgrade', 1);('signicant boost inperformance', 1);('wide range use', 1);('autoencoders masked', 1);('learning strategies neural', 1);('autoencoders showna', 1);('broad impact visual recognition', 1);('due asymmetric encoderdecoder design', 1);('alternative', 1);('adaptthe approach use', 1);('uses convolutional blocks input tokenizers', 1);('fully convolutional masked autoencoderour', 1);('simple runs fullyconvolutional manner learning signals generatedby', 1);('raw input visuals', 1);('context framework', 1);('describe maincomponents', 1);('convolutional model hierarchical design', 1);('differentstages mask', 1);('nest resolution implementthis practice', 1);('original input image use minimal dataaugmentation', 1);('croppingencoder design use', 1);('model encoder approach', 1);('challenge making maskedimage', 1);('copy paste information', 1);('visible patches input encoder', 1);('itis difcult', 1);('2dimage structure', 1);('naive solutionsinvolve', 1);('tokens inputside', 1);('result train test time inconsistency asthere mask tokens test time', 1);('ratio highto tackle issue', 1);('new insight view', 1);('image sparse data perspective whichwas', 1);('sparse point clouds 3dtasks', 1);('key observation', 1);('2d sparse array pixels', 1);('based', 1);('onthis insight', 1);('natural incorporate sparse convolutioninto framework facilitate', 1);('maskedautoencoder practice', 1);('standard convolution layer encoderwith submanifold sparse convolution', 1);('visible data points 152728we note sparse convolution layers convertedback', 1);('standard convolution', 1);('alternative isalso', 1);('operation beforeand', 1);('dense convolution operation operationhas', 1);('effect sparse convolutions', 1);('intensive bemore', 1);('ai', 1);('tpudecoder', 1);('design use lightweight', 1);('convnextblock', 1);('decoder forms asymmetric encoderdecoder architecture overall encoder', 1);('framework introduce', 1);('encoder lightweight', 1);('architecture autoencoderis asymmetric encoder processes', 1);('visible pixels andthe decoder reconstructs image', 1);('pixels andmask tokens loss', 1);('regionhas hierarchy', 1);('complex decoders hierarchical decoders', 1);('simpler single', 1);('dimension decoder 512reconstruction target compute', 1);('mse', 1);('target imagessimilar', 1);('target patchwise normalizedimage', 1);('original input loss', 1);('fully convolutional maskedautoencoder fcmae', 1);('effectiveness framework use', 1);('model encoder andconduct series ablation studies', 1);('throughout', 1);('paper focus endtoend', 1);('practical relevance', 1);('learning anduse assess quality', 1);('representationwe pretrain netune', 1);('imagenet1k in1k', 1);('reportthe top1', 1);('validation accuracy single 224224center crop', 1);('additional', 1);('experimental setupcan', 1);('sparse convolution inour', 1);('framework rst', 1);('affectsthe quality', 1);('empirical ndings', 1);('information leakage', 1);('region order', 1);('good resultswo', 1);('conv w', 1);('conv793 8373dec type ft hours speedupunet w', 1);('transformer', 1);('\x02convnext block', 1);('17\x02adecoder design', 1);('simple convolutional block outperforms', 1);('complex decoder designsblocks ft1', 1);('833bdecoder depth single block yieldscompetitive', 1);('performancedim ft128', 1);('835cdecoder width decoder width of256', 1);('decoder ablation experiments', 1);('convnextbase imagenet1k', 1);('ft accuracy', 1);('epochs decoder design exploration wallclock time', 1);('tpuv3', 1);('pod usingjax speedup', 1);('decoder baseline nal design choices', 1);('activation visualization visualize activation map', 1);('small squares clarity wedisplay', 1);('channels visualization', 1);('model suffers', 1);('collapse issue', 1);('thepresence redundant activations', 1);('channels x problem introduce', 1);('new method promotefeature diversity training', 1);('global response normalization', 1);('layer technique', 1);('inevery block', 1);('experimental results', 1);('epoch baseline', 1);('thesame recipe', 1);('nd thatour', 1);('initialization thanthe random baseline ie', 1);('needsto catch', 1);('setupsup 100ep', 1);('fcmae827', 1);('837this contrast', 1);('recent success', 1);('counterparts motivates', 1);('normalizationin', 1);('section introduce', 1);('global responsenormalization grn', 1);('effective conjunction', 1);('convnextarchitecture', 1);('rst motivate approach bothqualitative quantitative', 1);('analysesfeature collapse gain insight learningbehavior rst', 1);('qualitative analysis featurespace visualize activations', 1);('pretrainedconvnextbase model notice', 1);('featurecollapse phenomenon', 1);('dead saturatedfeature maps activation', 1);('redundant acrosschannels', 1);('figure3', 1);('block 52feature cosine distance analysis validate ourobservation', 1);('cosine distance analysis', 1);('activation tensor', 1);('x2rh\x02w\x02c4collapsefigure', 1);('cosine distance analysis number oftotal layers varies', 1);('different architectures plot distancevalues', 1);('layer indexes observe theconvnext', 1);('v1 fcmae', 1);('severe featurecollapse behavior', 1);('shows reductionin', 1);('diversity nal layers', 1);('likely due use thecrossentropy loss encourages model focus classdiscriminative', 1);('map ith channel', 1);('wereshape hw', 1);('dimensional vector compute theaverage pairwise cosine distance', 1);('channels by1c2pcipcj1\x00cosxixj2', 1);('distance value', 1);('value indicatesfeature redundancyto', 1);('different classes', 1);('validationset extract highdimensional', 1);('different models', 1);('compute distance perlayer image average values', 1);('images results', 1);('clear tendency towardsfeature collapse consistent observations theprevious activation visualizations motivates', 1);('ways diversify', 1);('mechanisms brain thatpromote neuron diversity example lateral inhibition', 1);('sharpen response', 1);('neuron increase contrast selectivity', 1);('individual neurons stimulus', 1);('thediversity responses', 1);('population neurons', 1);('indeep', 1);('learning form lateral inhibition', 1);('response normalization', 1);('work weintroduce', 1);('new response normalization layer', 1);('globalresponse normalization', 1);('aims increase thecontrast selectivity channels', 1);('input featurex2rh\x02w\x02c', 1);('pseudocode grn pytorchlike', 1);('style gamma beta', 1);('learnable affine transform parameters', 1);('input shape', 1);('nhwcgx', 1);('torchnormx p2 dim12 keepdimtruenx gx gxmeandim1 keepdimtrue1e6return gamma', 1);('xnx', 1);('xfirst', 1);('aggregate spatial', 1);('xiinto', 1);('global function', 1);('g\x01gx x2rh\x02w\x02cgx2rc', 1);('different functions', 1);('table 2a', 1);('interestingly', 1);('global average', 1);('gx', 1);('gxfjjx1jjjjx2jjjjxcjjg2rcwheregxijjxijjis scalar aggregates statistics ith channelnext', 1);('response normalization function', 1);('n\x01to', 1);('concretely', 1);('standard divisive normalization followsnjjxijj jjxijj2rjjxijjpj1cjjxjjj2r2wherejjxijjis', 1);('ith channel', 1);('eqn', 1);('computes relativeimportance', 1);('similar toother forms normalization', 1);('step createsa', 1);('mutual inhibitionin', 1);('table 2b', 1);('normalizationfunctions nd', 1);('simple divisive normalizationworks', 1);('standardization jjxijj\x00\x16\x1byieldssimilar results', 1);('original input responses usingthe', 1);('normalization scoresxixi\x03ngxi2rh\x02w3the core', 1);('lines code', 1);('learnable parametersthe pseudocode', 1);('algorithm', 1);('additional learnableparameters', 1);('initialize zero alsoadd residual connection input output ofthe', 1);('layer1to account', 1);('number channels', 1);('layers inpractice', 1);('value channel', 1);('c5case', 1);('846aglobal aggregation', 1);('g\x01 l2 normbasedaggregation', 1);('resultcase ftjjxijj\x00\x16\x1b 8451pjjxijj 838jjxijjpjjxijj 846bnormalization operator', 1);('n\x01 divisive', 1);('effective channel importance calibratorcase ftwo', 1);('846cresidual connection', 1);('performancecase ftbaseline 837lrn', 1);('838grn 846dfeature normalization', 1);('outperformsother normalizations', 1);('global contrastingcase ft parambaseline', 1);('effective efcient', 1);('parameter overheadcase ftbaseline 837drop ft 788add ft 806both 846fgrn', 1);('identity function', 1);('training importance residual connection', 1);('table 2cconvnext', 1);('layerscale', 1);('newblock design', 1);('various models', 1);('efciency capacity', 1);('family models range lightweight egatto', 1);('computeintensive eg', 1);('detailedmodel', 1);('grnfrom', 1);('cosine distance analysisin', 1);('collapse issue cosine distancevalues', 1);('layers behavior', 1);('similar tothat', 1);('learning behavior resemblevit', 1);('v1 fcmae v2 fcmae838', 1);('grn fcmae', 1);('improves representation quality', 1);('absent inthe', 1);('addingadditional parameter overhead', 1);('flops2relation', 1);('normalization methods othernormalization layers', 1);('additional afne parameters', 1);('convnext block', 1);('layer dimensionexpansion', 1);('layer droplayerscale', 1);('redundantglobal response normalization', 1);('table 2dwe', 1);('normalization layers', 1);('local response', 1);('normalization lrn', 1);('normalization bn', 1);('layer normalizationln', 1);('lrn', 1);('global contextas contrasts channels', 1);('nearby neighbors', 1);('bnnormalizes', 1);('batch axis', 1);('ln', 1);('encourages featurecompetition', 1);('variance standardization work', 1);('grnrelation', 1);('way enhance competition', 1);('table 2e', 1);('layers squeezeandexcite se', 1);('convolutional block attention modulecbam', 1);('se focuses channel', 1);('cbamfocuses', 1);('modules increase the6backbone', 1);('codesign', 1);('matters architecture learning framework', 1);('relative improvement', 1);('individual channels', 1);('simpler efcient', 1);('additional parameter layers', 1);('mlpsthe', 1);('weexamine importance', 1);('present results', 1);('table 2f', 1);('grnonly', 1);('either', 1);('way observe asignicant performance degradation', 1);('imagenet experimentsin', 1);('present analyze', 1);('key proposals', 1);('convnext v2architecture', 1);('successful show designs synergize', 1);('strong foundation', 1);('approaches experiments', 1);('furthermore', 1);('show thatour', 1);('theimagenet22k dataset', 1);('new stateoftheartof', 1);('available datacodesign matters paper conduct uniquestudy involves', 1);('model architectureimprovement', 1);('layer empirical study oftheir learning behavior results', 1);('table 3demonstrate importance approachwe', 1);('model architecture', 1);('impact onrepresentation learning quality', 1);('grnlayer', 1);('small effect performance', 1);('combination tworesults signicant improvement', 1);('pt', 1);('ft', 1);('comparisons', 1);('image modelingapproaches', 1);('allselfsupervised', 1);('performance image size', 1);('underline thehighest accuracy model size bold', 1);('resultsmance supports idea model learning framework', 1);('range of8 models', 1);('different sizes lowcapacity 37matto model highcapacity 650m', 1);('counterpartsthe results', 1);('model sizesthis rst time benet', 1);('broad model spectrumboth terms effectiveness efciency', 1);('previous methods', 1);('autoencoder methods', 1);('models results', 1);('model sizes', 1);('compared', 1);('vitpretrained mae', 1);('approach performs', 1);('model regime', 1);('muchfewer parameters 198m vs 307m', 1);('hugemodel regime approach', 1);('thismight', 1);('model benet', 1);('additional intermediate netuningimagenet22k intermediate', 1);('process involves', 1);('backbone', 1);('size param', 1);('v2xl', 1);('4802208m 940g 873convnext', 1);('3842350m 1790g 878hybridcoatnet4 5122275m 3609g 881maxvitxl 3842475m 2937g 885maxvitxl 5122475m 5352g 887transmvitv2h 3842667m 3885g 886mvitv2h 5122667m 7635g 888convnext', 1);('3842659m 3379g 887convconvnext', 1);('5122659m 6007g', 1);('in21k', 1);('outperforms architectures', 1);('public data', 1);('3842resolution images', 1);('results thestateoftheart architecture designs', 1);('hybrid designs', 1);('labels results', 1);('availabledata ie', 1);('imagenet1k imagenet22k6 transfer learning experimentswe', 1);('learning performancefirst', 1);('impact codesign ie', 1);('v2 fcmae', 1);('swintransformer', 1);('appendixobject detection segmentation', 1);('mask rcnn', 1);('detection mapboxand segmentation mapmaskon', 1);('gradual improvement proposals', 1);('v1 v2 grn', 1);('introducedand enhances performance', 1);('upon', 1);('model furtherbenets', 1);('fcmaebased', 1);('learning bestperformances', 1);('transformer counterpartsacross model sizes', 1);('thehuge model regimesemantic segmentation', 1);('summarize weconduct experiments', 1);('semantic segmentation task', 1);('upernet', 1);('similar trend object detection experiments nal model', 1);('improves thev1', 1);('performs par withbackbone', 1);('method flops apboxapbox50apbox75apmaskapmask50apmask75convnext v1b supervised', 1);('object detection instance segmentationresults', 1);('maskrcnn flops', 1);('image size1280', 1);('swins', 1);('input miou param', 1);('flopsconvnext v1b supervised', 1);('122m 1170gswinb', 1);('121m 1181gconvnext', 1);('235m 1573gconvnext', 1);('235m 1573gswinl', 1);('234m 1601gconvnext', 1);('235m 1573gswin', 1);('5122542\x00 \x00convnext', 1);('707m 3272gconvnext', 1);('22k ft', 1);('semantic segmentation results', 1);('upernet swins', 1);('flops', 1);('input sizesof', 1);('fcmae22k', 1);('ft case', 1);('transformer base', 1);('large model regimesbut outperforms', 1);('huge model regime7', 1);('conclusionin', 1);('paper introduce', 1);('convnet', 1);('broader range complexity architecture minimal changes', 1);('object detectionand', 1);('ross wightman', 1);('initial design smallcompute', 1);('model variantsand', 1);('training recipe', 1);('thehelpful discussions feedback', 1);('kaiming he8appendixthis', 1);('implementation details', 1);('model congurations', 1);('netuningrecipes sparse', 1);('accuracy comparisons', 1);('convnext v1and v2 imagenet', 1);('1k 22k c', 1);('analyses efciency sparse', 1);('class selectivity index', 1);('ind conduct', 1);('additional ablation studies', 1);('contrastive learninga implementation', 1);('detailsa1 convnext v2', 1);('model congurationsthe', 1);('basic models ie', 1);('89m andlarge 198m', 1);('congurations stageblock b channel c settings', 1);('convnextv1', 1);('convnext v2t c96b3', 1);('convnext v2b c128b3', 1);('convnext v2l c192b3', 1);('3given denitions scale modelto', 1);('broad model size spectrum', 1);('efcient models scale downas', 1);('convnext v2a c40b2', 1);('convnext v2f c48b2', 1);('convnext v2p c64b2', 1);('convnext v2n c80b2', 1);('2a f', 1);('p n', 1);('femto', 1);('pico91m nano', 1);('156m models', 1);('introduce largecapacity variant wescale', 1);('convnext v2h c352b3', 1);('3h denotes', 1);('659m model', 1);('imagenet experimentspretraining', 1);('rule 26lrbase lr\x02batchsize 256imagenet1k', 1);('learning capacity variesby model size', 1);('recipes foreach model summarize', 1);('small models', 1);('weadopt', 1);('different learningrate layer decay strategies inthis work groupwise', 1);('layer use', 1);('valuefor layerwise', 1);('distinctvalue layer', 1);('standard decayingrule default layerwise strategy', 1);('base large', 1);('modelsimagenet22k intermediate', 1);('conductimagenet22k intermediate', 1);('fcmaepretrained convnext', 1);('tiny baselarge', 1);('huge models setups', 1);('layerwise learningrate decay values', 1);('small models helpfulsparse', 1);('possible implementations', 1);('external libraries', 1);('dense convolution whichcan', 1);('binary masks', 1);('standard convolution operation', 1);('asthey', 1);('identical outputs', 1);('different use cases workwe', 1);('environment wherewe use', 1);('ontpu accelerators', 1);('jax', 1);('experiments themain paper', 1);('tpu', 1);('v3256 pods andwe release', 1);('object', 1);('detection segmentation', 1);('cocofor coco', 1);('mmdetection', 1);('10toolbox nal model weights', 1);('network initializations models trainedwith 3x schedule', 1);('epochs batch size', 1);('weutilize adamw', 1);('learning rate of1e4 weight decay', 1);('sweep layerwise learningrate decay inf09 095g stochastic depth rate f02', 1);('05g employ largescale', 1);('resolution scale range', 1);('semantic', 1);('ade20kfor ade20k', 1);('mmsegmentation17', 1);('toolbox use', 1);('hyperparameters weight decay', 1);('sweep layerwise decay rate f08 09g learning ratef1e4', 1);('3e4g stochastic depth rate f01', 1);('04g models', 1);('160k iterations with9cong valueoptimizer', 1);('54base learning rate 15e4weight decay 005optimizer momentum', 1);('20909511batch size', 1);('rate schedule cosine decay 53warmup epochs', 1);('pretraining', 1);('settingcong valueoptimizer', 1);('learning rate 2e4weight decay', 1);('apnoptimizer', 1);('epochs 600augmentation', 1);('ncutmix', 1);('ndrop', 1);('fphead', 1);('atto afemto', 1);('pico p nano n', 1);('learning rate 8e4weight decay 005optimizer momentum', 1);('epochs 300augmentation', 1);('02head init', 1);('modelcong valueoptimizer', 1);('learning rate', 1);('hweight', 1);('decay 005optimizer momentum', 1);('hbatch', 1);('htraining', 1);('haugmentation randaug', 1);('base blarge', 1);('huge h', 1);('learning rate 25e4weight decay 005optimizer momentum', 1);('epochs 90augmentation', 1);('endtoend in22k', 1);('settingscong valueoptimizer', 1);('learning rate 25e5weight decay 1e8optimizer momentum', 1);('nonetraining', 1);('ntaugmentation randaug', 1);('nonecutmix', 1);('nonedrop', 1);('l 05hhead init', 1);('ntbl', 1);('in22kintermediate', 1);('netuningan input resolution', 1);('\x02512 inference multiscaletest', 1);('of512\x022048 employedsimilar', 1);('segmentation models', 1);('model weights', 1);('weights directlyb', 1);('complete', 1);('v1in tables', 1);('experimentlevel comparisons', 1);('v2in', 1);('atto femto nano pico tinybase large huge', 1);('range lowcomputeatto 37m largecapacity models', 1);('wesee', 1);('consistent signicant improvement', 1);('theeffectiveness codesign', 1);('steps 1fcmae', 1);('v1a supervised', 1);('37m 055g 757convnext', 1);('v2a supervised', 1);('v2a fcmae', 1);('v1f supervised', 1);('52m 078g 775convnext', 1);('v2f supervised', 1);('v2f fcmae', 1);('v1p supervised', 1);('91m 137g 795convnext', 1);('v2p supervised', 1);('v2p fcmae', 1);('v1n supervised', 1);('156m 245g 808convnext', 1);('v2n supervised', 1);('v2n fcmae', 1);('v1t supervised', 1);('286m 447g 821convnext', 1);('v2t supervised', 1);('v2t fcmae', 1);('660m 115g', 1);('results single224\x02224 crop improvement', 1);('parenthesesbackbone image size param', 1);('2242156m 245g 821convnext', 1);('3842156m 721g 834convnext', 1);('2242286m 447g 829convnext', 1);('2242286m 447g 83910convnext', 1);('3842286m 131g 841convnext', 1);('3842286m 131g 85110convnext', 1);('224289m 154g 858convnext', 1);('224289m 154g 86810convnext', 1);('384289m 452g 868convnext', 1);('384289m 452g 87709convnext', 1);('2242198m 344g 866convnext', 1);('2242198m 344g 87307convnext', 1);('3842198m 1011g 875convnext', 1);('3842198m 1011g 88207convnext', 1);('2242350m 609g 870convnext', 1);('3842350m 1790g 878convnext', 1);('3842660m 3379g 887convnext', 1);('5122660m 6008g', 1);('results witha single', 1);('\x02224 crop improvement', 1);('nano tiny base large huge', 1);('particular theatto', 1);('femto pico nano tiny base large100200300400500600throughput', 1);('convsparse convatto', 1);('femto pico nano tiny base large1020304050max memory gfigure', 1);('efciency pretrainingsetup measure training throughput images max', 1);('gpumemory', 1);('batch size', 1);('throughput values', 1);('backward steps', 1);('show sparse', 1);('modelsoutperform nextlevel model sizes', 1);('xlarge', 1);('v2 huge', 1);('new stateoftheartwith performance', 1);('proposal demonstratesthat', 1);('pure convolutional models', 1);('strong scalable vision learners', 1);('analysessparse', 1);('key design choicesin', 1);('framework use sparse convolution', 1);('primary purposeis block ow information', 1);('region facilitate', 1);('computational memory efciency', 1);('kernels applyto', 1);('visible pixels', 1);('note sparse convolution libraries', 1);('modern hardware efciency', 1);('dependson frameworks', 1);('benchmark experiments', 1);('input image size', 1);('ratio11stage1layer0 stage1layer1 stage1layer2 stage2layer0 stage2layer1 stage2layer2 stage3layer0 stage3layer1 stage3layer2stage3layer3 stage3layer4 stage3layer5 stage3layer6 stage3layer7 stage3layer8 stage3layer9 stage3layer10 stage3layer11stage3layer12 stage3layer13 stage3layer14 stage3layer15 stage3layer16 stage3layer17 stage3layer18 stage3layer19 stage3layer2000', 1);('selectivity index000001002003004005pdfstage3layer21v1 fcmaev2 fcmaestage3layer22', 1);('stage3layer23 stage3layer24 stage3layer25 stage3layer26 stage4layer0 stage4layer1 stage4layer2figure', 1);('class selectivity index distribution xaxis yaxis', 1);('class selectivity index density', 1);('pdf', 1);('validation dataset', 1);('class selectivity index distribution', 1);('convnext v1red v2', 1);('early stages distribution', 1);('different deep layers', 1);('tends toinclude classgeneric', 1);('stages06 mask size', 1);('training throughput images max', 1);('memory usage', 1);('encoders results', 1);('experimental environment', 1);('pytorch v180cuda', 1);('cudnn', 1);('nvidia rtx a6000 gpuwe', 1);('moderate increase', 1);('efciencywith average', 1);('\x02increase throughput', 1);('\x02decrease max memory usage', 1);('models gapbecomes salient model size increasesclass', 1);('selectivity index fcmae', 1);('v1we', 1);('class selectivity index analysis', 1);('convnext v1 v2', 1);('tounderstand class selectivity index metricthat measures difference', 1);('activity classconditionalmean activities nal', 1);('lter activates', 1);('lter activates uniformlyfor classes', 1);('plot class selectivityindex distribution intermediate layers', 1);('residual block distributionis', 1);('early stagesbut', 1);('layers stage3 layer', 1);('plot showsthat', 1);('bimodal tends', 1);('pergrn functionscase aggregation normalization', 1);('val', 1);('accbase 837a', 1);('x x', 1);('component analysis report netuningperformance', 1);('hereafne', 1);('parameters residual connection', 1);('claritythe base denotes', 1);('theaggregation', 1);('andnormalization spatial', 1);('andchannelwise divisive normalization', 1);('casea', 1);('simple baseline channelwise', 1);('withafne parameters', 1);('explorationsas future studyd', 1);('additional experimentsgrn', 1);('global relation network grn', 1);('global featureaggregation', 1);('main paper demonstrates combination', 1);('aggregation divisive normalization workswell practice', 1);('individual contribution components', 1);('decreases training', 1);('unstable if1201', 1);('ratio 825830835840845850figure', 1);('masking', 1);('ratio observe', 1);('ratio 06provides', 1);('result yaxis', 1);('global aggregationthis supports idea operations work', 1);('ratios conduct hyperparameter analysis onthe', 1);('ratio mask size', 1);('ratio rangeof', 1);('performance models performance', 1);('input information', 1);('morerobust information retainedcomparison contrastive', 1);('approaches contrastive learning', 1);('mocov3', 1);('current stateoftheart', 1);('encoder followthe default', 1);('recipes approach', 1);('present results belowsup 300ep', 1);('moco v3 fcmae843', 1);('849we use 300epoch', 1);('learning baseline reference table shows', 1);('betterrepresentation quality', 1);('baseline consistent recentobservations', 1);('superiorresults contrastive', 1);('work success', 1);('convnetsreferences1 mart', 1);('abadi paul barham jianmin chen zhifeng chenandy davis jeffrey dean matthieu devin sanjay ghemawat geoffrey irving michael isard', 1);('tensorow asystem', 1);('largescale machine learning', 1);('systems', 1);('design implementation', 1);('jimmy lei ba jamie ryan kiros geoffrey e hinton layer', 1);('normalization arxiv preprint arxiv160706450', 1);('hangbo bao li dong furu wei beit bert', 1);('navaneeth bodla bharat singh rama chellappa', 1);('davis softnmsimproving', 1);('object detection withone line code', 1);('james bradbury roy frostig peter hawkinsmatthew james johnson chris leary dougal maclaurin george necula adam paszke jake vanderplas skyewandermanmilne qiao zhang jax', 1);('pythonnumpy', 1);('fergus', 1);('campbell john g robson application', 1);('offourier analysis visibility gratings journal ofphysiology', 1);('thomas capelle finding', 1);('resnet18https', 1);('wandb ai fastai', 1);('fine tune timmreportsfindingthenewresnet18vmlldzoymdi0mju3', 1);('mathilde caron ishan misra julien mairal priya goyal piotr bojanowski armand joulin unsupervised', 1);('learning visual', 1);('cluster assignments', 1);('inneurips', 1);('mathilde caron hugo touvron ishan misra herv', 1);('jegoujulien mairal piotr bojanowski armand joulin emerging', 1);('kai chen jiaqi wang jiangmiao pang yuhang cao yuxiong xiaoxiao li shuyang sun wansen feng ziweiliu jiarui xu zheng zhang dazhi cheng chenchen zhutianheng cheng qijie zhao buyu li xin lu rui zhuyue wu jifeng dai jingdong wang jianping shi wanliouyang chen', 1);('loy dahua lin mmdetection', 1);('open mmlab detection toolbox benchmarkarxiv190607155', 1);('mark chen alec radford rewon child jeffrey wu heewoo jun david luan ilya sutskever generative', 1);('ting chen simon kornblith mohammad norouzi geoffrey hinton', 1);('simple framework contrastive learningof visual representations', 1);('xinlei chen kaiming exploring', 1);('siameserepresentation', 1);('xinlei chen saining xie kaiming', 1);('empiricalstudy training', 1);('vision transformers iniccv', 1);('christopher choy junyoung gwak silvio savarese', 1);('4dspatiotemporal convnets', 1);('minkowski', 1);('convolutional neuralnetworks', 1);('kevin clark minhthang luong quoc v', 1);('christopher manning electra pretraining', 1);('text encoders asdiscriminators', 1);('mmsegmentation', 1);('mmsegmentationopenmmlab', 1);('semantic segmentation toolbox andbenchmark https github com', 1);('open mmlabmmsegmentation', 1);('spconv contributors spconv spatially', 1);('sparse convolution library httpsgithubcomtraveller59spconv', 1);('ekin cubuk barret zoph jonathon shlens quoc vle randaugment practical', 1);('data augmentationwith', 1);('search space', 1);('cvprw', 1);('zihang dai hanxiao liu quoc v', 1);('mingxing tancoatnet marrying', 1);('convolution attention datasizes', 1);('alexey dosovitskiy lucas beyer alexander kolesnikovdirk weissenborn xiaohua zhai thomas unterthinermostafa dehghani matthias minderer georg heigold sylvain gelly jakob uszkoreit neil houlsby', 1);('image isworth', 1);('transformers', 1);('image recognition atscale', 1);('haoqi fan bo xiong karttikeya mangalam yanghao lizhicheng yan jitendra malik christoph feichtenhofermultiscale', 1);('peng gao teli hongsheng li jifeng dai yuqiao mcmae masked convolution meets masked autoencoders neurips', 1);('golnaz ghiasi yin cui aravind srinivas rui qian tsungyi lin ekin cubuk quoc v', 1);('barret zoph simplecopypaste', 1);('strong data augmentation method instancesegmentation', 1);('ross girshick jeff donahue trevor darrell jitendramalik rich', 1);('accurate object detectionand semantic segmentation', 1);('priya goyal piotr doll', 1);('ross girshick pieter noordhuis lukasz wesolowski aapo kyrola andrew tullochyangqing jia kaiming accurate', 1);('large minibatchsgd', 1);('training imagenet', 1);('hour arxiv170602677', 1);('benjamin graham martin engelcke laurens vander maaten', 1);('3d semantic segmentation submanifoldsparse convolutional networks', 1);('benjamin graham laurens', 1);('maaten submanifold', 1);('sparse convolutional networks arxiv preprintarxiv170601307', 1);('jeanbastien grill florian strub florent altch', 1);('corentintallec pierre richemond elena buchatskaya carl doerschbernardo avila pires zhaohan guo mohammad gheshlaghi azar bilal piot', 1);('koray kavukcuoglu', 1);('remi munos', 1);('valko bootstrap', 1);('new approachto', 1);('h k hartline henry g wagner floyd ratliff inhibitionin', 1);('eye limulus journal', 1);('general physiology', 1);('kaiming xinlei chen saining xie yanghao li piotrdollar ross girshick masked', 1);('autoencoders scalablevision learners', 1);('kaiming haoqi fan yuxin wu saining xie rossgirshick momentum', 1);('visual representation learning', 1);('kaiming georgia gkioxari piotr doll', 1);('ross girshick mask rcnn iccv', 1);('kaiming xiangyu zhang shaoqing ren jian sundelving', 1);('deep rectiers', 1);('surpassing', 1);('humanlevel performance imagenet classication', 1);('kaiming xiangyu zhang shaoqing ren jian sundeep', 1);('residual learning image recognition', 1);('andrew g howard menglong zhu bo chen dmitrykalenichenko weijun wang tobias weyand marco andreetto hartwig adam mobilenets efcient', 1);('mobile vision applicationsarxiv170404861', 1);('jie hu li shen gang sun squeezeandexcitation', 1);('ronghang hu shoubhik debnath saining xie xinleichen exploring', 1);('autoencoders arxivpreprint arxiv221007224', 1);('gao huang zhuang liu laurens', 1);('maaten kilian q weinberger densely', 1);('convolutional networks', 1);('gao huang yu sun zhuang liu daniel sedra kilian qweinberger deep', 1);('networks stochastic depth', 1);('sergey ioffe', 1);('szegedy batch', 1);('deep network training', 1);('internal covariate', 1);('kevin jarrett koray kavukcuoglu marcaurelio ranzatoand yann lecun', 1);('multistage architecturefor object recognition', 1);('li jing jiachen zhu yann lecun masked', 1);('siameseconvnets arxiv preprint arxiv220607700', 1);('alex krizhevsky ilya sutskever geoff hinton imagenet', 1);('convolutional neural networksinneurips', 1);('alex krizhevsky ilya sutskever geoffrey e hintonimagenet', 1);('communications acm', 1);('yann lecun bernhard boser john denker donniehenderson richard e howard wayne hubbard', 1);('jackel backpropagation', 1);('handwritten zip code recognition', 1);('neural', 1);('yann lecun', 1);('l eon', 1);('bottou yoshua bengio patrick haffneret', 1);('gradientbased', 1);('document recognition', 1);('proceedings ieee', 1);('tsungyi lin piotr doll', 1);('ross girshick kaiming hebharath hariharan serge belongie feature', 1);('pyramidnetworks object detection', 1);('tsungyi lin michael maire serge belongie james hayspietro perona deva ramanan piotr doll', 1);('ar c', 1);('lawrencezitnick microsoft', 1);('common objects context', 1);('chenxi liu piotr doll', 1);('kaiming ross girshick alanyuille saining xie', 1);('necessary neural architecture search', 1);('ze liu yutong lin yue cao han hu yixuan wei zhengzhang stephen lin baining guo swin', 1);('transformerhierarchical vision transformer', 1);('zhuang liu hanzi mao chaoyuan wu christoph feichtenhofer trevor darrell saining xie', 1);('convnet the2020s', 1);('ilya loshchilov frank hutter sgdr stochastic', 1);('gradient descent', 1);('warm restarts', 1);('ilya loshchilov frank hutter decoupled', 1);('weight decayregularization', 1);('ari morcos david gt barrett neil', 1);('rabinowitz', 1);('botvinick', 1);('importance single directionsfor generalization', 1);('jongchan', 1);('sanghyun woo joonyoung lee sokweon bam bottleneck', 1);('attention module', 1);('bmvc', 1);('adam paszke sam gross soumith chintala gregorychanan edward yang zachary devito zeming lin alban desmaison luca antiga adam lerer automaticdifferentiation', 1);('ilija radosavovic raj prateek kosaraju ross girshickkaiming piotr doll', 1);('designing', 1);('network designspaces', 1);('olaf ronneberger philipp fischer thomas brox unetconvolutional', 1);('networks biomedical image segmentationinmiccai', 1);('olga russakovsky jia deng hao su jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathyaditya khosla michael bernstein alexander', 1);('berg', 1);('feifei imagenet large scale visual recognition challenge ijcv', 1);('szegedy wei liu yangqing jia pierre sermanetscott reed dragomir anguelov dumitru erhan vincentvanhoucke andrew rabinovich going', 1);('szegedy vincent vanhoucke sergey ioffejonathon shlens zbigniew wojna rethinking', 1);('inception architecture computer vision', 1);('efcientnet rethinking', 1);('efcientnetv2 smaller', 1);('hugo touvron matthieu cord alexandre sablayrollesgabriel synnaeve herv', 1);('jegou going', 1);('zhengzhong tu hossein talebi han zhang feng yangpeyman milanfar alan bovik yinxiao li maxvitmultiaxis', 1);('vision transformer', 1);('dmitry ulyanov andrea vedaldi victor lempitsky instance', 1);('fast stylization arxiv160708022', 1);('ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez', 1);('kaiser illiapolosukhin attention', 1);('qilong wang banggu wu pengfei zhu peihua li wangmeng zuo qinghua hu ecanet efcient', 1);('channel attention', 1);('ross wightman pytorch', 1);('image models https github com rwightman pytorch image models', 1);('ross wightman jeremy howard', 1);('image models', 1);('sanghyun woo jongchan', 1);('joonyoung lee sokweon cbam convolutional', 1);('block attention module', 1);('yuxin wu kaiming', 1);('group normalization', 1);('tete xiao yingcheng liu bolei zhou yuning jiang', 1);('sun unied', 1);('scene understanding', 1);('saining xie ross girshick piotr doll', 1);('zhuowen tu', 1);('aggregated', 1);('residual transformations deepneural networks', 1);('saining xie jiatao gu demi guo charles r qi leonidasguibas litany pointcontrast unsupervised', 1);('3d point cloud understanding', 1);('zhenda xie zheng zhang yue cao yutong lin jianminbao zhuliang yao qi dai han hu simmim', 1);('zongxin yang linchao zhu yu wu yi yang gatedchannel', 1);('transformation visual recognition', 1);('sangdoo yun dongyoon han seong joon oh sanghyukchun junsuk choe youngjoon yoo cutmix regularization', 1);('strategy train', 1);('strong classiers localizablefeatures', 1);('hongyi zhang moustapha cisse yann n dauphin', 1);('lopezpaz', 1);('empirical risk minimization', 1);('bolei zhou agata lapedriza jianxiong xiao antonio torralba aude oliva learning', 1);('deep features scenerecognition', 1);('places', 1);('bolei zhou hang zhao xavier puig tete xiao sanja fidler adela barriuso antonio torralba semantic', 1);('understanding scenes', 1);('ijcv', 1);