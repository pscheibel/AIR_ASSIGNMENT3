('fdsc', 35);('ieee', 23);('figure', 21);('dgfont', 17);('international conference', 12);('fid', 10);('computer vision', 10);('font generation', 9);('ieee computer', 9);('springer', 9);('l1', 8);('european conference', 8);('computer vision eccv', 8);('frnres', 7);('mxfont', 6);('fdscattn', 6);('funit', 6);('imagetoimage translation', 6);('dgfont dgfont', 6);('corr', 6);('neural information processing systems', 6);('proceedings', 6);('maxpool', 5);('avgpool', 5);('lecture notes computer', 5);('ieeecvf', 4);('computer vision iccv', 4);('long beach', 4);('ieeecomputer', 4);('imagetoimage translation methods', 3);('experiments', 3);('rewrite', 3);('deformation skipconnection', 3);('cyclegan', 3);('ivc2', 3);('offset normalization', 3);('zi2zi', 3);('256res block', 3);('upsample', 3);('computer vision patternrecognition cvpr', 3);('july', 3);('aaai', 3);('glasgow uk august', 3);('annual', 3);('science vol', 3);('x chen', 3);('existing', 2);('dgfontwe', 2);('automatic font generation', 2);('sav ae', 2);('dmfont', 2);('recently', 2);('unsupervised', 2);('different', 2);('gan', 2);('radical decomposition', 2);('ganimorph', 2);('deformable convolution', 2);('overview', 2);('moco', 2);('icand', 2);('generative network', 2);('specically', 2);('f0cis', 2);('fdscmodule', 2);('ffn', 2);('extensive', 2);('fdsc fdscattn', 2);('convolution layers', 2);('eq', 2);('imagetoimage translation method', 2);('shape deformation', 2);('unseen font', 2);('rmse', 2);('iv', 2);('challenging cases', 2);('easy cases', 2);('convolution layers content encoder', 2);('conduct ablationstudies incremental modules losses', 2);('full model', 2);('size reference', 2);('style', 2);('ut usa june', 2);('seattle wa usa june', 2);('salt lake city', 2);('articial intelligence aaai', 2);('vision eccv', 2);('ca usa', 2);('venice italy october', 2);('october', 2);('november', 2);('computer vision pattern recognition', 2);('bmvc', 2);('munichgermany september', 2);('lecturenotes computer', 2);('wang', 2);('z chen', 2);('hiusa july', 2);('hi usa july', 2);('computer vision pattern recognitioncvpr', 2);('li', 2);('munich germany september', 2);('recognition cvpr', 2);('ieeecvfconference computer vision pattern recognition cvpr', 2);('wa usa june', 2);('machine learning icml', 2);('proceedings machinelearning', 2);('virtual event', 2);('pmlr', 2);('recognition', 2);('robust', 1);('generativenetworks unsupervised font generationxinyuan chen yangchen xie li sun yue luabstract automatic', 1);('human experts isa', 1);('practical signicant problem', 1);('languagesthat consist', 1);('large number characters', 1);('methodsfor font generation', 1);('learning requirea', 1);('large number', 1);('data laborintensive andexpensive', 1);('applicable font generationas', 1);('dene style', 1);('textures colors', 1);('inthis', 1);('deformable generative networkfor', 1);('tolearn local patterns geometric transformations fontsthe', 1);('predicts pairs displacement maps', 1);('deformable convolution lowlevelcontent', 1);('maps outputs', 1);('mixerto generate nal results', 1);('robust style representationfor fonts understanding similarity dissimilarities offonts distinguish', 1);('different styles train model witha multitask discriminator ensures style canbe', 1);('addition adversarial lossanother', 1);('reconstruction losses', 1);('constrain thedomaininvariant characteristics', 1);('images andcontent images', 1);('adoptedloss functions model', 1);('spatial informationand generates highquality character images unsupervisedmanner', 1);('able togenerate character images', 1);('quality stateoftheartmethodsindex', 1);('terms font generation unsupervised imagetoimagetranslation imagetoimage translation image generationi ntroductionevery', 1);('day people consume', 1);('massive amount text forinformation', 1);('storage representation textsthe font', 1);('font', 1);('applications eg font library', 1);('historical handwriting imitationand data augmentation optical character recognition', 1);('traditional', 1);('font library creatingmethods', 1);('expert designers drawing eachglyph', 1);('expensive laborintensive logographic languages', 1);('chinese morethan', 1);('korean', 1);('chen shanghai articial intelligence laboratory shanghaichina', 1);('xie', 1);('sun lu shanghai keylaboratory multidimensional information processing eastchina normal', 1);('shanghai', 1);('china', 1);('development convolutional neural networksenables', 1);('human expertsthere attempts explore font generation andachieve', 1);('promising results', 1);('neural networksto generate', 1);('certain alphabet languagestwo', 1);('notable projects', 1);('generatelogographic language characters learning', 1);('fromone style', 1);('afterthat emd', 1);('design neural networks toseparate content style representation extendto generate character', 1);('new styles contents', 1);('howeverthese', 1);('training samplessome methods', 1);('auxiliary annotationseg strokes radicals facilitate highquality fontgeneration example', 1);('utilizes labels stroke togenerate glyphs', 1);('trajectories synthesis', 1);('radical decomposition eg radicals subglyphs ofcharacters', 1);('certain logographiclanguage', 1);('lffont11', 1);('disentanglement strategies disentanglecomplex glyph structures', 1);('local detailsin', 1);('rich text design', 1);('featuresfor fewshot font generation', 1);('subglyph andcomponents characters', 1);('methods relyon', 1);('specic writingsystems labels stroke skeleton', 1);('algorithms estimation error woulddecrease', 1);('methods stillrequire thousands', 1);('introduces novel modulethat transfers', 1);('densenet', 1);('fast skeleton extraction method toobtain skeleton characters utilize', 1);('skeleton facilitate font generationin eld imagetoimage translation series', 1);('generative models', 1);('combiningadversarial training', 1);('font generation tasks imagetoimage translationthe style images', 1);('texturesand colors contrast', 1);('different fonts localpatterns stroke thickness tips brushes joinedup', 1);('methods imagetoimagetranslation', 1);('extract style', 1);('target classimages employ adaptive instance normalization', 1);('adainarxiv221214742v1', 1);('dec', 1);('font generation results', 1);('content images style reference images model aims togenerate imitations example reference images calligraphic font imitation result', 1);('fromour model22', 1);('content style featuresthe', 1);('adainbased', 1);('featurestatics tends transform texture color isnot', 1);('suitable transform local style patterns eg geometricdeformation', 1);('robustdeformable generative model', 1);('font generationdgfont', 1);('deform andtransform character', 1);('images target font', 1);('shows scenario font generation', 1);('style reference imageseg calligraphy artist model', 1);('able generate imitations', 1);('content reference characterimages', 1);('separates style', 1);('representations generatetarget characters introduce', 1);('pairs displacement maps andemploy', 1);('deformable convolutionto lowlevel', 1);('maps content encoder', 1);('theoutputs fdsc', 1);('mixer generate nalresults', 1);('robust representation fonts usecontrastive learning style encoder', 1);('thesimilarity dissimilarities fonts end deneseveral data augmentation operations construct positivecounterparts fonts model', 1);('afeature space characters', 1);('positive counterpartsare', 1);('similar point distinguish', 1);('different styles trainour model multitask discriminator ensures thateach style', 1);('addition toadversarial loss', 1);('reconstruction losses adoptedto constrain domaininvariant characteristics', 1);('images content imagesthe', 1);('transform lowlevel', 1);('content imageswhich preserves pattern character eg strokes radicals', 1);('imagetoimage translation problemthat denes style', 1);('textures colors style offont', 1);('geometric transformation strokethickness tips brushes joinedup', 1);('twofonts', 1);('correspondence foreach stroke', 1);('advantage spatial relationship offonts', 1);('usedto conduct spatial deformation', 1);('complete structures', 1);('furtherimprove quality', 1);('localspatial attention', 1);('module predicts thelocal relationship encoder mixer featuresthe local spatial attention model predicts similarity scores forfeatures position', 1);('positionsthis work', 1);('extensive version conference paper24', 1);('compared', 1);('previous version paper includesthe', 1);('additional contributions', 1);('extraction approach', 1);('introducedata augmentation operations fonts construct positivecounterparts characters introduce contrastive loss tohelp model', 1);('integratelocal spatial attention', 1);('module ie', 1);('fdscattnexperiments', 1);('additional', 1);('toablate analyze function', 1);('weconduct', 1);('comprehensive experiments', 1);('different imagesizes comparisons stateoftheart methods', 1);('extensiveexperiments', 1);('model outperforms stateoftheart font generation methods', 1);('generate unseen style characterii', 1);('r elated worka font generationfont', 1);('generation aims', 1);('generate charactersin specic font', 1);('font library', 1);('recent', 1);('image translation methods font generationzi2zi', 1);('font generation onthe basis', 1);('thousands character pairsfor', 1);('strong supervision series models', 1);('pegan', 1);('multiscale image pyramid topass information renement connections', 1);('han', 1);('27improves zi2zi', 1);('hierarchical loss skipconnection', 1);('aegg', 1);('additional network renethe training process', 1);('dcfont', 1);('introduces style classierto', 1);('style representation', 1);('large numberof', 1);('font generation learning mappingbetween', 1);('ignore geometricdeformation font results satisfyinglots methods employ auxiliary annotations eg strokeand', 1);('disentangles style content astwo irrelevant domains', 1);('chinese characters intohighfrequency character structure congurations radicalscalligan', 1);('decomposes characters components', 1);('lowlevel structure information includingthe order strokes', 1);('generation process', 1);('rdgan', 1);('radical extraction module extractrough radicals', 1);('performance thediscriminator', 1);('chinese font generation', 1);('lffont', 1);('11propose disentanglement strategies disentangle complexglyph structures', 1);('local details', 1);('rich textdesign', 1);('fewshotfont generation', 1);('subglyph components ofcharacters attempts', 1);('chinesecharacter', 1);('skeletonstroke extractionalgorithm', 1);('extra annotations oralgorithms', 1);('font generation estimation errorwould', 1);('generation performance work ourmodel', 1);('aims generate highquality characterimages', 1);('imagetoimage translationthe', 1);('purpose imagetoimage translation', 1);('image source domain target domainimagetoimage translation', 1);('artistic style', 1);('semantic segmentation33', 1);('image animation', 1);('object transguration38 video frames generation', 1);('pix2pix42', 1);('rst model', 1);('unsupervisedimagetoimage translation lot', 1);('introduces cycleconsistency source target domain', 1);('therelationship samples', 1);('specic domain tackle problem recentworks', 1);('multiple style outputs', 1);('gatedgan', 1);('encodes content imageand class image', 1);('adain22 tunit', 1);('network asan', 1);('domain classier', 1);('adomain label', 1);('dunit', 1);('extracts separaterepresentations', 1);('global image instances topreserve', 1);('content object instances learnthe', 1);('geometry variations', 1);('introduces adiscriminator', 1);('multiscale perceptual loss', 1);('shape objects', 1);('disentangles image space acartesian product appearance geometry latentspacesour task', 1);('image translation', 1);('shares aim', 1);('reference images thetarget domain', 1);('focus images wildanimals style', 1);('poses setof textures colors', 1);('works improvingshape deformation', 1);('generatehighquality font images contrast characteristics fontlie local patterns stroke thickness tips brushesgeometric deformation joinedup', 1);('theunique', 1);('characteristics font motivate design', 1);('robustdeformable networks font generationc', 1);('convolution attention mechanismcnns', 1);('inherent limitations', 1);('kernel conguration', 1);('toenhance', 1);('cnns52', 1);('deformable convolutional layer augmentsthe spatial', 1);('locations modules additionaloffsets', 1);('highlevel vision tasks object detection5254 video object detection', 1);('semantic segmentation', 1);('human pose estimation', 1);('recentlysome', 1);('methods attempt', 1);('deformable convolution inimage generation tasks', 1);('tdan', 1);('addresses video superresolution tasks', 1);('deformable convolution align twocontinuous frames output highresolution frame', 1);('novel view images', 1);('deformable convolutiongiven view condition vectors', 1);('dgfontoffsets', 1);('latent style codefurthermore attention modules', 1);('deformable convolutioncan', 1);('deformable convolution attention moduleachieves', 1);('tasksof object detection semantic segmentation', 1);('hard conditional deformation modules', 1);('deformable convolution attention', 1);('special skipconnection way', 1);('image synthesis tasks', 1);('theyshow', 1);('model shows combination deformableconvolution spatial attention', 1);('unsupervisedfont generation tasksd', 1);('unsupervised representation learningin', 1);('study utilize', 1);('arobust style', 1);('representation learning aims extract meaningful representations fordownstream tasks', 1);('human supervision', 1);('contrastive learning methods', 1);('maximizingmutual information', 1);('noise contrastive estimation', 1);('incontrast samples dataset design choices ofthe contrastive loss number negatives how4fig', 1);('generative network stylecontent encoder maps stylecontentimage stylecontent representation', 1);('zszc fdsc fdscattn', 1);('transformation convolution lowlevel featurefrom content encoder', 1);('results mixer mixer generates output image b', 1);('module c', 1);('moduleto sample data augmentation play', 1);('critical roleand need', 1);('dictionaryas queue', 1);('negative data samples', 1);('dataaugmentation images', 1);('positive samples', 1);('tasks undera', 1);('reasonable minibatch size', 1);('imagenet', 1);('dueto', 1);('natural images font images dataaugmentation', 1);('contrastive learning frameworkand design', 1);('data augmentations font imagesiii', 1);('ethodsa overviewgiven', 1);('content image', 1);('style image modelaims generate character content image withthe font style image', 1);('style encoder acontent encoder mixer', 1);('modules architecture styleencoder discriminator', 1);('thedetailed', 1);('architecture section', 1);('iva1', 1);('style encoder', 1);('style representation input imagesthe style encoder', 1);('style image input andmaps style latent vector', 1);('zsthe', 1);('content encoderis', 1);('extract structure', 1);('contentimages content encoder maps content image aspatial', 1);('zc', 1);('content encoder module', 1);('deformable convolution layers', 1);('geometric deformation', 1);('fonts acharacter correspondence stroke betweentwo fonts characterblocks', 1);('deformable convolution layer enablesthe content encoder', 1);('forimages content mixer aims outputcharacters', 1);('zcand', 1);('zs adain', 1);('content encoder themixer', 1);('details', 1);('sec iiib5b feature deformation skip connectionas', 1);('geometric deformationof', 1);('fonts character exists correspondencefor stroke', 1);('compelling', 1);('afeature deformation', 1);('module applygeometric deformation convolution content image inthe', 1);('deformation lowlevel', 1);('module predictsoffsets', 1);('guidance code instruct deformableconvolution layer', 1);('geometric transformation onthe lowlevel', 1);('module concatenation', 1);('fcextracted', 1);('content image styleguidance map', 1);('fsfsis', 1);('mixer injectingthe style code', 1);('fs', 1);('module estimates', 1);('convolution concatenation', 1);('fsandfc\x02', 1);('f\x12fsfc 1heref\x12refers', 1);('deformable convolution layer \x02f\x01pk\x01mkjk 1\x01\x01\x01jrjg refers offsets andmask convolution kernel', 1);('rf1', 1);('regular grid', 1);('\x023 kernelunder guidance', 1);('parameter \x02', 1);('deformable convolution fdc\x01f0cfdcfc\x02', 1);('position pon output', 1);('f0c', 1);('deformable convolution fdc\x01is', 1);('rxk1wpk\x01xppk', 1);('\x01pk\x01\x01mk 3where thewpkindicates weight', 1);('deformable convolution kernel kth location convolution operatedon irregular positions pk\x01pk \x01pkmay befractional', 1);('followed', 1);('bilinear interpolation', 1);('71deformable convolution introduces 2d offsets regulargrid', 1);('standard convolution enablesfreeform deformation', 1);('grid lotsof areas color character images asbackground color character color', 1);('deformableconvolution area', 1);('area thesame color difcult optimize nonunique solutionto', 1);('module impose constrainton offsets \x01p introduce constraint detail insubsection', 1);('iiid', 1);('visualization theoffsets \x01pin section', 1);('ivd2our fdsc', 1);('module aims deform spatial structure ofthe content image', 1);('crucial selectwhich level', 1);('lowlevel featurescontain structure spatial information highlevelfeatures', 1);('ivd', 1);('analysisof performance model', 1);('different numbers thefdsc modulefig', 1);('illustration', 1);('contrastive representation learningthe model', 1);('style reference image', 1);('positive pair image samples ofthe dataset', 1);('negative samplesfdscattn', 1);('thelocal spatial attention model', 1);('explore local relationships', 1);('weights position regard thefeatures', 1);('fdscattnis', 1);('f0c2rh\x02w\x02cproduced fdsc', 1);('latent space asquery key value', 1);('qf0ckf0cvf0c2rh\x02w\x02cby', 1);('using1\x021convolution layers location ijwithin thespatial dimensions extract patch size', 1);('k2rs\x02s\x02c weightw2rs\x02s\x02cis', 1);('estimation afeedforward network', 1);('ffnwreshape ffn', 1);('concat flatten kq 4the', 1);('patch query flatten kand', 1);('corresponding queryvector q2r1\x021\x02catij', 1);('fc', 1);('relu', 1);('linearfc layer wplays', 1);('equivalent role thesoftmax attention map', 1);('traditional key query aggregation83', 1);('output vector o2r1\x021\x02catijis', 1);('elementwise multiplication', 1);('wand value patch size', 1);('vcentered', 1);('v2rs\x02s\x02coij w v loopover ijto constitute output', 1);('oaas', 1);('deformable convolution additionalattention module', 1);('heat map', 1);('certain location context patch', 1);('modelto look local attention information generates asoft', 1);('current position featureand contextc', 1);('unsupervised feature representation style encoderto', 1);('robust representation', 1);('font hopeto', 1);('consistent style', 1);('regardless content6to end dene', 1);('data augmentation operationsto construct', 1);('positive counterparts fonts adoptcontrastive learning force', 1);('positive pairs similarin latent space contrastive representation learns thevisual styles images', 1);('mutual informationbetween image', 1);('version contrast toother', 1);('negative images', 1);('contrastive representation learning', 1);('style encoder aimsto', 1);('robust map style image', 1);('isto', 1);('style code', 1);('zssimilar moco', 1);('momentum style encoder usedto map', 1);('positive counterpart', 1);('isas', 1);('positive codes', 1);('zswe', 1);('construct queue data samples', 1);('contrastive loss unitize thesimilarity', 1);('positive pair', 1);('zszsand', 1);('negative pairs', 1);('zszi\x00slsty\x00logexpzs\x01zs', 1);('pni1expzs\x01zi\x00s', 1);('temperature hyperparameter', 1);('sum isover', 1);('nnegative', 1);('sample loss thelog loss', 1);('n1way', 1);('toclassifyzsaszs momentum style encoder', 1);('contrastive representation facilitates thestyle encoder', 1);('robust style', 1);('alleviatesthe impact', 1);('different content images', 1);('certain styleexperiments section', 1);('number reference style imagesd', 1);('loss functionour', 1);('model aims', 1);('method addition contrastive loss', 1);('eq5', 1);('adversarial loss', 1);('producerealistic images', 1);('content consistent loss', 1);('toencourage content', 1);('image consistentwith content image', 1);('image reconstruction loss', 1);('tomaintain domaininvariant', 1);('deformation offsetnormalization', 1);('excessive offsets thefdsc module introduce formula loss thefull objective sectionadversarial loss character images generatedfrom generative network multitask discriminator', 1);('conduct discrimination style', 1);('style output discriminator binaryclassication', 1);('input image', 1);('real image', 1);('different styles fontsin training', 1);('discriminator outputs binary vectorwhose length number styles model aims togenerate plausible images', 1);('minimax optimizationproblem generative network', 1);('gtries', 1);('fool discriminatordby', 1);('fake images adversarial loss penalty isthe', 1);('wrong judgment', 1);('images input tothe discriminatorladv maxdsmingeis2psic2pclogdsis log1\x00dsgisic6whereds\x01 denotes logit', 1);('corresponding style ofthe discriminators outputcontent consistent loss adversarial loss', 1);('tohelp model generate', 1);('realistic style ignoringthe correctness content', 1);('mode collapse andensure', 1);('content canbe content consistent content encoder fc imposea content consistent loss herelcnteis2psic2pckzc\x00fcgisick1 7lcntensures', 1);('source content image', 1);('maps consistentafter content encoder fcimage reconstruction loss ensure generatorcan reconstruct source image', 1);('icwhen', 1);('origin stylewe impose reconstruction losslimgeic2pckic\x00gicick1 8the objective', 1);('domaininvariant characteristicseg content input image', 1);('icdeformation', 1);('deformable offsets', 1);('enable freeform deformation', 1);('asthere', 1);('lots areas color input imagesand', 1);('images background color charactercolor', 1);('nonunique solution difcult tooptimize', 1);('font generation focus strokerelationship content character image targetcharacter image thickness tips strokehowever', 1);('images content differentstyle position stroke', 1);('deformable convolutionalnetwork impose constrain offsets \x01ploffset 1jrjk\x01pk1 9where \x01pdenotes offsets', 1);('deformable convolutionkerneljrjdenotes number convolution kerneloverall objective loss', 1);('combining', 1);('abovementionedlosses overall loss function training', 1);('frameworklladv\x15imglimg\x15cntlcnt\x15stylsty\x15offsetnxiloffsetn10where\x15adv\x15img\x15cnt\x15sty and\x15offset hyperparameters control weight loss', 1);('nindicatesthe', 1);('modules model generativenetwork aims minimize overall object loss thediscriminator aims maximize itiv', 1);('e xperimentsin', 1);('model thechinese font generation task rst introduce implementation details experiments', 1);('experimentsdemonstrate superiority model', 1);('provideablation studies', 1);('andobjective function7a implementation', 1);('detail1 network architecturethe', 1);('style encoder contentencoder mixer', 1);('modules style encoder', 1);('fclayer', 1);('convolution layer 3\x023kernel nonlinearactivation', 1);('relu fc', 1);('layer maps style', 1);('mapsinto style representation vector', 1);('thearchitecture', 1);('content encoder mixer symmetrical', 1);('architectures style encoder contentencoder mixer', 1);('fdscmodules', 1);('thefdsc', 1);('deformable convolution layer with3\x023kernel', 1);('deformable convolutionlayer local spatial attention module patch sizes', 1);('discriminator contains', 1);('residual blocksand', 1);('information thediscriminator', 1);('ii frn', 1);('lter responsenormalization', 1);('training strategywe', 1);('initial weights convolutional layers', 1);('heinitialization', 1);('zero andthe weights linear layers', 1);('n0001we', 1);('adam', 1);('forstyle encoder', 1);('rmsprop', 1);('thecontent encoder mixer train', 1);('whole framework with200000 iterations learning rate', 1);('aweight decay', 1);('train model hinge versionadversarial loss', 1);('r1', 1);('\x15img 01\x15cnt 01\x15sty 01\x15offset', 1);('temperature hyperparameterin', 1);('007by default', 1);('reference images compute averagestyle code generation process3', 1);('data', 1);('augmentationwe use', 1);('data augmentation operations spatial andgeometric transformation construct', 1);('positive counterparts forfonts', 1);('style reference image conduct', 1);('data augmentation operations', 1);('rotation degree 20to', 1);('horizontal vertical translation', 1);('value rangefrom', 1);('image size random', 1);('compared methodswe', 1);('methods forchinese font generation\x0fcyclegan', 1);('generative networks', 1);('cycle consistency loss\x0femd', 1);('emd', 1);('font generation methodthat', 1);('distance loss groundtruth', 1);('encoderdecoder architecture separates stylecontent representations\x0fzi2zi', 1);('font generation andoperation', 1);('kernel resample padding featuresstyle', 1);('512fc 128contentencoderdeform conv', 1);('32deform conv', 1);('64deform conv', 1);('256mixerres block', 1);('architecture', 1);('generative networkoperation', 1);('kernel resample features normalizationconvolution', 1);('res', 1);('frnleakyrelu convolution', 1);('leakyrelu convolution', 1);('avgpool average pooling leakyrelu slope', 1);('ii architecture', 1);('discriminative networkuses', 1);('gaussian noise', 1);('achievemultistyle transfer\x0fganimorph', 1);('discriminator dilatedconvolutions', 1);('contextaware generator\x0ffunit', 1);('imagetoimage translation model separates content andstyle', 1);('natural animal images', 1);('withadaptive instance normalization', 1);('adain', 1);('stateoftheart fewshotfont generation method', 1);('decomposable glyphs5', 1);('dataset evaluation metricswe', 1);('fonts styles', 1);('handwriting fonts', 1);('chinese characters content dataset', 1);('thetraining', 1);('fonts font contains 800characters', 1);('anotherpart', 1);('generalization for8methods onetomany training', 1);('rmse ssim lpips fidseen', 1);('3583unseen fontsemd', 1);('iii quantitative', 1);('whole dataset', 1);('rst column', 1);('image sizeunseen fonts image size', 1);('consistentwith mainstream methods', 1);('order comparewith', 1);('font generation methods iemxfont', 1);('dataset conference version 80\x0280resolution characters conference versioncannot', 1);('fair comparison experiments', 1);('datasetand experiments 80\x0280images', 1);('dataset theconference versionwe employ metrics', 1);('root mean', 1);('errorrmse ssim lpips', 1);('l1loss rsme structural similarity ssim', 1);('usedin font generation task', 1);('ground truths', 1);('l1loss', 1);('l1norm', 1);('distance generatedimage groundtruth', 1);('square errorto', 1);('overall evaluation', 1);('ssim', 1);('global meanand variance assess structural similarity', 1);('meanwhilelearned perceptual image patch similarity lpips', 1);('anothermetric compute distance generations andground truths perceptual domain', 1);('fr', 1);('distance fid', 1);('measure realismof', 1);('betweenthe distributions', 1);('real data styleb', 1);('comparison stateofart methods1 quantitative', 1);('comparisonthe quantitative results', 1);('iii', 1);('\x0280 images asour', 1);('previous version', 1);('adapt model generate128\x02128', 1);('recent work', 1);('forthe image', 1);('\x02128 onetoone image translation models ie', 1);('cyclegan ganimorph', 1);('target style experimentof', 1);('\x0280 size results', 1);('thatour methods ie', 1);('methods pixellevel evaluation metricseg', 1);('rmse ssim', 1);('metricsfocus pixelwise comparison', 1);('imageand groundtruth', 1);('pixelwise', 1);('scores blur images thatare consistent human perception', 1);('perceptuallevel metrics ie', 1);('lpips', 1);('font andunseen fontin experiment', 1);('funit mxfont weobserve mxfont', 1);('rmse ssim lpips funitoutperforms mxfont', 1);('score becausemxfont uses pixelwise loss', 1);('training themodel', 1);('measuresthe realism quality', 1);('images contrast ourmethods ie', 1);('funitand mxfont', 1);('stateoftheart performance', 1);('dgfont detailed', 1);('explore generality ourmodel', 1);('generate imitations unseen styles whoseresults', 1);('demonstrates modeloutperforms', 1);('fewshotfont generation method', 1);('mxfont2 qualitative', 1);('demonstrates qualitative comparison betweenour method stateoftheart methods explore thecapability', 1);('source characterpatterns eg stroke skeleton display visual comparisons', 1);('easy cases challenge cases', 1);('characters9a easy cases', 1);('eg calligraphy wordartfig', 1);('comparisons', 1);('model stateoftheart methods', 1);('red boxes highlight failures structurepreservation', 1);('blue boxes highlight failures style', 1);('orange boxes highlight blur noisy outputsin', 1);('typefaces havecursive', 1);('challenge cases characters ofwordart calligraphy fonts hollow joinedup', 1);('observe results', 1);('zi2zi emd ganimorph', 1);('acomplete structure', 1);('vague challengingcases generate parts characters', 1);('sometimesunreasonable structures', 1);('generate characters witha', 1);('clear background', 1);('theirstructure degree', 1);('figure5b funit', 1);('generates characters', 1);('incomplete structurewhen target font cursive', 1);('style case', 1);('hollow font', 1);('generate characterof reference style', 1);('mxfontis', 1);('stateoftheart fewshot font generation method mostcases', 1);('method generate images comparablequality', 1);('notably mxfont', 1);('datasets ourmethods', 1);('hollow font contrast', 1);('onlygenerate characters', 1);('complete structure', 1);('complete images', 1);('ablation study10fig', 1);('effect', 1);('different components', 1);('dgfont weadd', 1);('different parts baseline', 1);('replacethe', 1);('withdeformable convolution layers b', 1);('modulewithout normalization c impose normalization thefdsc module', 1);('module iedgfontfor', 1);('ablation studyin', 1);('part conduct ablation studies modelwe', 1);('baseline model', 1);('normal encoderdecodermodel', 1);('style encoder content encoder andmixer', 1);('deformable convolution layer', 1);('moduleand contrastive loss section', 1);('ivc1', 1);('dgfontand', 1);('baseline model section', 1);('dgfontand dgfont1 baseline', 1);('model vs', 1);('deformable offset normalization successivelyon baseline model', 1);('dgfont theexperiments', 1);('challenging cases explore thefunctionality component', 1);('dgfont qualitative', 1);('andquantitative comparisons', 1);('deformable convolution content encoder', 1);('6a shows results', 1);('withdeformable convolution layers', 1);('deformable convolution layers inthe content encoder', 1);('performanceof model2the inuence', 1);('module part addan', 1);('rst layer penultimate layerresults', 1);('comparing figure6a', 1);('morestructure information', 1);('able reconstruct completestructure characters3effectiveness', 1);('deformable offset constraint', 1);('weinvestigate', 1);('deformable offset normalizationby', 1);('6b c', 1);('model generate images', 1);('similar target4effectiveness', 1);('6d showsthe results', 1);('modules notedthat', 1);('noise andachieve', 1);('quantitative results2', 1);('dgfontbased dgfont', 1);('fdsc fdscattnin', 1);('dgfontattnand', 1);('contrastive learning', 1);('ablation study', 1);('iv figure', 1);('image size', 1);('\x02128 analyze resultsand effectiveness follows1effectiveness', 1);('module partwe', 1);('quantitative', 1);('ivindicated dgfontattn dgfontattn', 1);('close score pixelwise metrics ie', 1);('rmsessim', 1);('terms perceptualmetrics ie', 1);('fid lpips', 1);('qualitative results forfdscattn', 1);('compared dgfont', 1);('target style', 1);('example inthe', 1);('fth columns', 1);('stylewhose results', 1);('style source style themodel', 1);('images thetarget style2effectiveness contrastive loss', 1);('theimpact style contrastive loss', 1);('observe thatthe model contrastive loss', 1);('results highestscore metrics', 1);('dgfontattn lsty', 1);('shows qualitative results forcontrastive loss', 1);('ableto generate highquality images', 1);('strokes ornoisy points', 1);('contrastive learninghelps', 1);('robust contentinvariant style representationwhich', 1);('complete structure strokes', 1);('glyph images analysis contrastive representation learning', 1);('analysis', 1);('subsection investigatethe robustness model', 1);('size stylereference images', 1);('times results', 1);('box plotswe use yaxis interval', 1);('figure8b', 1);('dgfontachieves', 1);('times inference numberof references', 1);('8c shows variance offid scores', 1);('small number reference images observethat variance', 1);('visual', 1);('samples ablation study', 1);('dgfontmethods l1', 1);('rmse ssim lpips fiddgfont', 1);('iv ablation', 1);('dgfont dgfontattnlsty', 1);('dgfontin', 1);('reference images number contrastive representation model tends', 1);('robust contentinvariantstyle representation alleviates inuence thevariation reference style imagesd', 1);('analysis fdsc module1 fdsc', 1);('vs skipconnectionwe', 1);('skipconnection', 1);('different resolutions', 1);('fromthe encoder decoder', 1);('effective semanticsegmentation', 1);('content inputs outputsshare structure', 1);('font generation requiresa geometric deformation content inputs', 1);('images structure comparethe', 1);('module skipconnection', 1);('twofdsc modules skipconnection', 1);('dgfontnetwork', 1);('comparison results', 1);('canobserve models', 1);('modules outperform modelswith skipconnection proves effectiveness', 1);('fdsc2 visualizationin', 1);('order show effectiveness', 1);('f0cpreserve', 1);('pattern characterswell', 1);('generate character', 1);('complete structureon hand observe', 1);('contentencoderin addition visualize', 1);('optical ow character ow', 1);('tovisualize', 1);('offsets kernel', 1);('deformable convolution inthe', 1);('10we observe', 1);('characterregion offset value background tends zeromethod', 1);('rmse ssim lpips fidsc', 1);('v comparison', 1);('sc', 1);('unet', 1);('modules withskipconnections', 1);('new model thefull model', 1);('dgfontwhich', 1);('proves usefulness', 1);('offset loss', 1);('eq9', 1);('character ow', 1);('offset vectorspoint stroke target characters correspondingsource stroke results', 1);('convolution processthe', 1);('locations target characters', 1);('locations source character learnedoffsetse', 1);('style representations', 1);('style interpolation results infigure', 1);('rst extract style', 1);('interpolate style factors', 1);('zsto', 1);('dgfontproduces', 1);('smooth transition', 1);('thicknessstroke joinedup', 1);('user studyto', 1);('quality images', 1);('withother methods conduct experiment human studyby pairwise', 1);('ab', 1);('methods comparison', 1);('select100 characters test', 1);('theparticipants', 1);('chinese characters', 1);('everyday participants', 1);('groundtruth pair', 1);('secondsfor pair', 1);('image votes thejudgment result', 1);('shows participants preferenceamong', 1);('tasks observe', 1);('resultsof methods outperform results', 1);('method generates realisticcharacters', 1);('compared funit', 1);('impressive resultsin imagetoimage translation tasks method', 1);('recent method forfont generation', 1);('results method', 1);('thanmxfont validates superiority model overthese stateoftheart methodsv c', 1);('onclusionthis', 1);('font generation model', 1);('capable generate', 1);('realistic characterswithout', 1);('wepropose feature deformation skip', 1);('dgfontfig', 1);('performance', 1);('report performance', 1);('size ofthe reference style images case calculate', 1);('score random', 1);('style images', 1);('figuresa', 1);('b show statistics', 1);('score box plots', 1);('c shows variance', 1);('feature', 1);('visualization visualize', 1);('f0cgenerated fdsc', 1);('module case leftto', 1);('content reference characters', 1);('characters visualization', 1);('forfeature', 1);('map images whiter area', 1);('largeractivation valuefdscattn module', 1);('global local deformablelowlevel spatial information mixer', 1);('employdeformable convolution layers content encoder learnstyleinvariant', 1);('experimentson font generation', 1);('effectiveness proposedmodelreferences1', 1);('p upchurch n snavely k bala z', 1);('transferof style content', 1);('deep neural network generators', 1);('azadi fisher v g kim z wang e shechtman darrellmulticontent gan', 1);('fewshot font style', 1);('ieeeconference computer vision pattern recognition cvpr', 1);('2018salt lake city', 1);('ieee computer society2018', 1);('fogel h averbuchelor cohen mazor r litmanscrabblegan semisupervised', 1);('length handwritten text generation', 1);('ieee2020', 1);('zhang zhang', 1);('cai separating', 1);('style content', 1);('computer visionand pattern recognition cvpr', 1);('ut usa june1822', 1);('sun ren', 1);('li h su j zhu learning', 1);('stylizedchinese characters reading handful examples', 1);('proceedingsfig', 1);('columnsource images', 1);('column deformation ows', 1);('offsets \x01p', 1);('offsets \x01pby quiver plot', 1);('fourthcolumn', 1);('zoomedin details source', 1);('blue green respectivelyfig', 1);('generated', 1);('glyphs rowcorrespond', 1);('identical content representations leftmostand rightmost images', 1);('imagesin', 1);('middle convex combinations', 1);('twentyseventh', 1);('joint', 1);('articial intelligence ijcai', 1);('stockholm sweden', 1);('ijcaiorg2018 pp', 1);('jiang z lian tang j xiao scfont structureguidedchinese', 1);('thirtythirdaaai', 1);('thirtyfirstinnovative applications articial intelligence', 1);('honoluluhawaii usa january', 1);('february', 1);('user study', 1);('images participantspreferences test', 1);('number imagesthat participants', 1);('indicatesthe number images participants', 1);('results fromthe', 1);('numberof images', 1);('equal votes401540229', 1);('huang', 1);('jin wang rdgan', 1);('fewzeroshot chinesecharacter style', 1);('glasgowuk august', 1);('proceedings part vi', 1);('lecture notes', 1);('incomputer science', 1);('vedaldi h bischof brox j frahm edsvol', 1);('j cha chun g lee', 1);('lee kim h lee fewshotcompositional', 1);('font generation dual memory', 1);('proceedings part xix', 1);('lecture notes computer sciencea vedaldi h bischof brox j frahm eds', 1);('vol 12364springer', 1);('chun j cha', 1);('lee h shim fewshot', 1);('style representations factorization', 1);('vol abs200911042', 1);('multiple', 1);('fewshot', 1);('font generationwith', 1);('proceedings ieeecvfinternational', 1);('computer vision iccv october', 1);('gao j wu ganbased', 1);('chinese character imagetranslation', 1);('skeleton transformation stroke', 1);('thethirtyfourth aaai', 1);('york ny usa february', 1);('pp64665314 b', 1);('chang q zhang pan', 1);('meng generating', 1);('handwrittenchinese characters', 1);('ieee winter', 1);('conference onapplications', 1);('computer vision wacv', 1);('tahoe nv usamarch', 1);('g huang z liu', 1);('l van der', 1);('maaten k q weinberger denselyconnected', 1);('convolutional networks', 1);('computer vision pattern recognition cvpr', 1);('hi usajuly', 1);('kim cha h kim j k lee j kim learning', 1);('todiscover crossdomain relations generative adversarial networks inproceedings 34th', 1);('machine learningicml', 1);('sydney nsw australia', 1);('august', 1);('z yi h zhang p tan gong dualgan unsupervised', 1);('ieee internationalconference computer vision iccv oct', 1);('j zhu', 1);('p isola efros unpaired', 1);('cycleconsistent adversarial networks', 1);('venice italyoctober', 1);('taigman polyak', 1);('wolf unsupervised', 1);('crossdomain imagegeneration', 1);('vol abs161102200', 1);('benaim', 1);('wolf onesided', 1);('december2017', 1);('k baek choi uh j yoo h shim rethinking', 1);('x huang j belongie arbitrary', 1);('realtime withadaptive instance normalization', 1);('international conference oncomputer', 1);('vision iccv', 1);('liu x huang mallya karras aila j lehtinen', 1);('kautz fewshot', 1);('imagetoimage translation 2019ieeecvf', 1);('korea', 1);('xie x chen', 1);('sun lu dgfont', 1);('deformable generativenetworks', 1);('theieeecvf conference', 1);('j goodfellow j pougetabadie mirza', 1);('xu wardefarleys ozair', 1);('courville bengio generative', 1);('adversarial netsinadvances', 1);('annualconference neural information processing systems', 1);('december813', 1);('montreal quebec canada', 1);('sun q zhang j yang pyramid', 1);('generative adversarial network', 1);('internationalconference pattern recognition icpr', 1);('beijing china august2024', 1);('j chang gu zhang wang', 1);('chinese handwriting imitationwith hierarchical generative adversarial network', 1);('machinevision', 1);('newcastle uk september', 1);('bmv', 1);('p lyu x bai', 1);('yao z zhu huang', 1);('liu autoencoderguided gan', 1);('chinese calligraphy synthesis', 1);('iapr', 1);('document analysis recognition icdar', 1);('japan november', 1);('jiang z lian tang j xiao dcfont', 1);('endtoend deepchinese font generation system', 1);('siggraph asia', 1);('technicalbriefs bangkok thailand november', 1);('acm', 1);('sj wu cy yang j hsu calligan style', 1);('structureawarechinese calligraphy character generator', 1);('arxiv', 1);('vol abs200512500202031', 1);('j johnson alahi', 1);('feifei perceptual', 1);('losses realtimestyle', 1);('amsterdam netherlands october', 1);('proceedings part ii', 1);('lecture notes computer sciencevol', 1);('h zhang k j dana multistyle', 1);('generative network realtime', 1);('proceedings part iv', 1);('shukla', 1);('v gool r timofte extremely', 1);('imagetoimage translation semantic segmentation 2019ieeecvf', 1);('computer vision workshopsiccv', 1);('seoul korea', 1);('musto zinelli semantically', 1);('adaptive imagetoimage translation domain adaptation semantic segmentation', 1);('xu tao selfsupervised', 1);('pose adaptation crossdomain image animation', 1);('ieee transactions articial intelligence', 1);('e yang', 1);('deng', 1);('liu x liu tao x gao pairwiserelationship', 1);('crossmodal retrieval', 1);('yuan tao puppeteergan arbitraryportrait', 1);('animation semanticaware appearance transformation inproceedings', 1);('recognition cvpr june', 1);('xu x yang tao attentiongan', 1);('object transguration', 1);('wild images', 1);('conferenceon computer vision eccv', 1);('chan ginosar zhou efros', 1);('dance nowinproceedings', 1);('computervision', 1);('xu x yang tao longterm', 1);('video prediction viacriticization retrospection', 1);('ieee transactions image processing', 1);('j dong x li', 1);('xu x yang g yang x wang wang dualencoding', 1);('video retrieval text', 1);('ieee transactions patternanalysis machine intelligence', 1);('p isola j zhu zhou efros imagetoimage', 1);('translationwith conditional adversarial networks', 1);('conference oncomputer', 1);('vision pattern recognition cvpr', 1);('mirza osindero conditional', 1);('generative adversarial netscorr vol abs14111784', 1);('liu tuzel coupled', 1);('generative adversarial networks inadvances', 1);('december', 1);('barcelona spain', 1);('k bousmalis n silberman dohan erhan krishnanunsupervised', 1);('pixellevel domain adaptation generative adversarialnetworks', 1);('shrivastava pster tuzel j susskind', 1);('wang r webblearning', 1);('xu x yang', 1);('l song', 1);('tao gatedgan adversarialgated', 1);('networks multicollection style', 1);('ieee trans imageprocess', 1);('bhattacharjee kim g vizier salzmann dunitdetectionbased', 1);('imagetoimage translation 2020ieeecvf conference', 1);('gokaslan v ramanujan ritchie k kim j tompkin improving', 1);('imagetoimage translationincomputer', 1);('proceedings part xii', 1);('v ferrari hebert', 1);('sminchisescuand weiss eds', 1);('wu k cao', 1);('qian', 1);('c c', 1);('loy transgaga geometryaware', 1);('ieee conferenceon computer vision pattern recognition cvpr', 1);('beachca usa june', 1);('ieee2019', 1);('x huang liu j belongie j kautz multimodal', 1);('part iii', 1);('v ferrarim hebert', 1);('sminchisescu weiss eds', 1);('springer2018', 1);('j dai h qi xiong li g zhang h hu wei deformableconvolutional', 1);('computervision iccv', 1);('ieee computersociety', 1);('g bertasius', 1);('torresani j shi object', 1);('detection video withspatiotemporal', 1);('part xii', 1);('science vol11216', 1);('x zhu h hu lin j dai', 1);('deformable convnets', 1);('v2', 1);('ca usa june', 1);('fei', 1);('liu n yu spatialtemporal', 1);('featureaggregation network video object detection', 1);('acoustics speech', 1);('processing icassp2020 barcelona spain may', 1);('x sun', 1);('xiao', 1);('wei liang wei integral', 1);('humanpose regression', 1);('europeanconference munich germany september', 1);('proceedings partvi', 1);('tian zhang fu', 1);('xu tdan', 1);('temporallydeformablealignment network video superresolution', 1);('yin', 1);('sun q li novel', 1);('view synthesis', 1);('data byconditional', 1);('deformable variational autoencoder', 1);('proceedings part xxviii', 1);('lecture notes computerscience', 1);('idunet iterative', 1);('soft hard deformation view synthesisinieee conference', 1);('computer vision pattern recognition cvpr2021', 1);('june', 1);('ieee2021', 1);('x zhu cheng z zhang lin j dai', 1);('empirical studyof spatial attention mechanisms', 1);('ieeecvfinternational', 1);('seoul koreasouth october', 1);('h zhang j goodfellow n metaxas odena selfattention', 1);('generative adversarial networks', 1);('36thinternational conference', 1);('june2019', 1);('california usa', 1);('k chaudhuri r salakhutdinov eds', 1);('vol 97pmlr', 1);('n yu g liu dundar tao', 1);('catanzaro', 1);('davis', 1);('fritz dual', 1);('contrastive loss attention gans', 1);('chen kornblith norouzi g e hinton', 1);('simple framework contrastive learning visual representations', 1);('proceedingsof', 1);('proceedings machine learningresearch', 1);('chen kornblith k swersky norouzi g e hinton bigselfsupervised', 1);('advancesin neural information processing systems', 1);('conference onneural', 1);('information processing systems', 1);('neurips', 1);('december612', 1);('h larochelle ranzato r hadsell balcanand h lin eds', 1);('k h fan wu xie r', 1);('girshick momentum', 1);('visual representation learning', 1);('x chen h fan r', 1);('girshick k improved', 1);('baselines withmomentum contrastive learning', 1);('vol abs200304297', 1);('j h', 1);('dataefcient', 1);('image recognition contrastive predictive', 1);('international conference onmachine', 1);('learning icml', 1);('machine learning', 1);('research vol', 1);('r hjelm fedorov lavoiemarchildon k grewal p bachman trischler bengio learning', 1);('deep representations bymutual information estimation maximization 7th', 1);('internationalconference learning representations iclr', 1);('orleans lausa may', 1);('openreviewnet', 1);('efros r zhang j zhu contrastive', 1);('proceedings part ix', 1);('vedaldih bischof brox j frahm eds', 1);('gutmann hyv', 1);('noisecontrastive', 1);('estimation newestimation principle', 1);('statistical models', 1);('proceedingsof thirteenth', 1);('articial intelligence', 1);('aistats', 1);('chia laguna resort sardinia italy may', 1);('jmlr proceedings', 1);('teh titteringtoneds', 1);('jmlrorg', 1);('ronneberger p fischer brox unet convolutional', 1);('networksfor biomedical image segmentation', 1);('image computing', 1);('intervention miccai', 1);('internationalconference munich germany october', 1);('proceedings partiii', 1);('z wu xiong x yu lin unsupervised', 1);('learningvia nonparametric instance discrimination', 1);('proceedings ieeeconference', 1);('singh krishnan filter', 1);('response normalization layer', 1);('eliminating', 1);('batch dependence training', 1);('neural networks inproceedings', 1);('k x zhang ren j sun delving', 1);('humanlevel performance imagenet classication in2015', 1);('chile december', 1);('society 2015pp', 1);('tran r ranganath blei deep', 1);('hierarchical implicitmodels', 1);('vol abs170208896', 1);('mescheder geiger nowozin', 1);('training methodsfor gans', 1);('internationalconference machine learning icml', 1);('stockholmsm', 1);('sweden july', 1);('j g dy krause eds', 1);('pmlr2018', 1);('r zhang p isola efros e shechtman wang', 1);('theunreasonable effectiveness', 1);('perceptual metric in2018', 1);('heusel h ramsauer unterthiner', 1);('nessler hochreitergans', 1);('timescale update rule converge local nashequilibrium', 1);('advances neural information processing systems', 1);('30annual conference', 1);('drozdzal v', 1);('romero bengio theone', 1);('layers tiramisu', 1);('fully', 1);('convolutional densenets semanticsegmentation', 1);('cvpr', 1);('e shelhamer darrell fully', 1);('convolutional networks forsemantic segmentation', 1);('boston usa june', 1);