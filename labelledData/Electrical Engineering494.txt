('intruder', 16);('agent', 9);('rl', 6);('ros', 6);('rlcas', 5);('surrogate', 4);('ieee', 4);('safe distance', 3);('original task', 3);('runner', 3);('call', 3);('horizontal separation', 2);('reinforcement learning rl', 2);('waypoints airplane', 2);('robot', 2);('evaluation', 2);('atc', 2);('avoidance trajectory', 2);('figure', 2);('original route', 2);('markovian', 2);('avoidance policy', 2);('policy model', 2);('boeing', 2);('python', 2);('rel', 2);('system diagram', 2);('geometric trajectory', 2);('surrogate policy', 2);('detailed', 2);('appendix', 2);('intruders', 2);('physical demonstrator', 2);('grant', 2);('aviation', 2);('airspeed', 2);('control signal vehicle', 2);('vehicle update', 2);('reinforcement learningbased', 1);('trafcdeconictiondenis osipychevboeing', 1);('technologyhuntsville aldenisosipychevboeingcomdragos margineantuboeing', 1);('technologyseattle wadragosmargineantuboeingcomgirish chowdharyuniversity illinois urbanachampaigngirishcillinoiscomabstractremain well clear', 1);('hazards appropriateseparation distance', 1);('essential technology', 1);('safe operation uncrewedaerial vehicles', 1);('airspace work focuses', 1);('obstacle avoidance problem a2d surrogate optimization task design surrogate task', 1);('execution solution primary', 1);('optimize avoidance policy modelthe dynamics interactions', 1);('policy surrogate transitions system', 1);('complete avoidance trajectory solver', 1);('systemros', 1);('system generates', 1);('quick achievable avoidance trajectory thatsatises safety requirements', 1);('highdelity simulation fullscale airplane demonstration', 1);('enormous integration effort', 1);('reallife demonstrationof', 1);('rlbased', 1);('introductionan', 1);('conict resolution', 1);('crucial safe operation', 1);('aerial vehicles', 1);('ua vsand', 1);('trafc', 1);('aviationadministration faa', 1);('species requirements', 1);('ua v', 1);('concepts 3detect', 1);('avoid daa', 1);('executionphases ightremain', 1);('well clear', 1);('appropriateseparation distancethe regulator', 1);('verticalor horizontal separation', 1);('common way vertical separation', 1);('different ightthis research', 1);('advanced', 1);('projects', 1);('darpathe', 1);('views opinions andor ndings', 1);('representingthe ofcial', 1);('policies department defense us', 1);('government36th', 1);('neural information processing systems neurips', 1);('2022arxiv230101861v1 csro', 1);('jan', 1);('2023levels approach', 1);('heavy trafc congestion aircraft', 1);('reaction time horizontal separation', 1);('complex requiressynchronization actions', 1);('specic behavior', 1);('type position aircraftin work focus horizontal separation', 1);('solution case thattodays methods', 1);('uncontrolled airspace proceduralseparationa', 1);('horizontal', 1);('aircraft formulatedas 2d carlike obstacle avoidance problemb', 1);('singleengine', 1);('cessna', 1);('caravan', 1);('demonstration platformfigure', 1);('air trafc conicts', 1);('asafe distance airplanesthis work poses deconiction problem 2d', 1);('problem optimizationis datadriven', 1);('reinforcementlearning rl', 1);('stochastic nature problem', 1);('trajectory methods', 1);('amount work inthe deconiction collision avoidance areas autonomous car', 1);('work stands', 1);('aerial application', 1);('automobile applications solution spaceis', 1);('dynamics aircraft increases search spaceas', 1);('1a goal alternate', 1);('agentprovide', 1);('thiswork', 1);('strong assumptions', 1);('future research', 1);('passive trajectory', 1);('agents intruders', 1);('observable andassume', 1);('perfect knowledge', 1);('narrow set', 1);('markov decision processes mdp', 1);('systemthis work', 1);('surrogate task improveresponse time', 1);('runtime solution surrogate problem', 1);('feasibility solution', 1);('actual task output systemprovides', 1);('complete avoidance trajectory', 1);('aerospace industry', 1);('endtoend policy', 1);('ailerons rudder throttle approach wouldprovide', 1);('explainable solution', 1);('quick feasible avoidance trajectory satisesthe safety requirements', 1);('uncertainty transitions', 1);('efciency ourreinforcement', 1);('learning', 1);('conict avoidance system', 1);('actual task inhighdelity simulation fullscale airplane demonstration', 1);('cessna caravan', 1);('methodology21 technical approachin', 1);('work corrective action avoidance', 1);('sequential policy optimization methodthat', 1);('continuous datarich interaction environment', 1);('policy asurrogate', 1);('number interactions surrogateenvironment', 1);('openai gymframework', 1);('11adsbstate parserlat', 1);('heading airspeedlat', 1);('heading airspeedglobal localstate converterlat longheadingairspeedsurrogate policymodelpositionsheadingsspeedsrel', 1);('rateaccelerationpredicted', 1);('headings speedsrel', 1);('globalstate converterfull', 1);('trajectoryin local framefull trajectoryin', 1);('global framefigure', 1);('conict resolverthe', 1);('model minimizes risk', 1);('continuous control commands surrogateenvironment commands', 1);('surrogate environment surrogate policy \x19is datadriven endtoend', 1);('policy surrogate task thatshares', 1);('similar transition dynamics', 1);('tand', 1);('rules engagement', 1);('similarity transitions conditions surrogate moreconservative approximation', 1);('actual task guarantees solution', 1);('feasible realsystem\x19true\x19rtruettrue 1\x19\x19\x03rt 2\x19true\x19\x19 ifrtruettrue2r\x0ft\x0f', 1);('surrogate environmentparam surrogate c208 true unitsx', 1);('mslong accel', 1);('ms2yaw rate', 1);('true dynamic parameters ranges3our surrogate environment', 1);('2d obstacle avoidance problem mimics actualtask air trafc conict resolution aircraft control differs 2d carlike dynamics doesnot', 1);('conventional brakes acceleration', 1);('dependson aircrafts altitude', 1);('etc parameters', 1);('turning rates longitudinalaccelerations', 1);('longitudinal accelerations', 1);('slight deviations aircrafts altitude', 1);('desiredight levelthe turning rates', 1);('turning radius', 1);('outlines difference', 1);('main dynamic parameters', 1);('vehicle highdelity simulation specic airframe', 1);('thesurrogate policy performance', 1);('vehicle response', 1);('appendix figures', 1);('observation control values', 1);('forthe convenience', 1);('trainingthe environment simulates movements', 1);('kilometers area controlledagent', 1);('minimal horizontal separation', 1);('safe waypoint', 1);('original route simulation ends', 1);('sparse rewardfeedback interactions', 1);('table 3the simulation update step', 1);('openai gym', 1);('commands input values', 1);('inputs vehicles step vehiclesdynamics', 1);('appendix algorithm', 1);('1a simplistic', 1);('dynamic model', 1);('vehicles surrogate', 1);('dubins', 1);('vehicle model', 1);('massless', 1);('kinematic modelto facilitate training', 1);('pidbased', 1);('waypoint controller', 1);('intrudervehicle', 1);('beginning anticipate', 1);('direction speed', 1);('thewaypoint', 1);('facilitate training generate conicts training scenarioshowever', 1);('future work23', 1);('rl trainingthe', 1);('training wrapper', 1);('certain environment methods parameters introduces', 1);('certain important changes environment making policy training', 1);('efcientthis wrapper includes1 scoring2 initialization vehicles', 1);('observationsto ensure', 1);('generalizes problem rewrap observations focus relativepositions', 1);('absolute ones addition normalize values', 1);('repackedobservations', 1);('agentheading', 1);('intruder airspeeddistance goal distance', 1);('angle goal', 1);('angle intruderto', 1);('conguration space', 1);('routine initial positionsare', 1);('imaginary circle vehicles', 1);('circles center', 1);('thisguarantees', 1);('paths intersect vehicles', 1);('collisionsurrogategradient basedpolicy optimizationsurrogate rewardoptional', 1);('positions headings speedsrel', 1);('truefalseobservationrewardcompletionturning rate accelerationintruderupdateagentupdateevaluationa reinforcement learning rl', 1);('tooptimize surrogate policy', 1);('headingsspeedsrel', 1);('distancesrel anglesleakyreluleakyrelutanhaction', 1);('accelerationsteeringb neural', 1);('network function approximation usedfor policy model', 1);('layers256 neurons eachfigure', 1);('reinforcement learning', 1);('rl policy agentthe rl', 1);('policy agent learns task', 1);('updatingthe parameters policy model', 1);('stochastic gradient descent sgd', 1);('weapproximate', 1);('optimization problem', 1);('markov decision problem mdp', 1);('system refactor intomarkovian states transitions', 1);('ts0jsa', 1);('transition reward', 1);('rs0jsa', 1);('agent intruder', 1);('observable assumes', 1);('perfect knowledge isenough describe', 1);('mdp', 1);('system state agent', 1);('assfva avi i idi gdggwhereva', 1);('i angle tointruderdi distance', 1);('g angle goal dg distance goalthe optimization', 1);('nd optimal policy \x19\x03sas', 1);('stateaction mappings thatmaximizes', 1);('vs10\x19s pajs', 1);('4\x19\x03s arg max\x19v\x19s', 1);('arg maxarsa', 1);('ts0jsavs0', 1);('6value state', 1);('future reward', 1);('bybellman function asvs', 1);('erjs\x19', 1);('rs0jsa vs0', 1);('xs0ts0jsav\x19s0', 1);('9v\x03s maxa', 1);('rsa xs0ts0jsav\x03s010the rl', 1);('actorcritic', 1);('stability ofthe training', 1);('sgdbased', 1);('actor', 1);('criticwnetworks\x0ert1 vst1w\x00vstw', 1);('11w w \x0ervsw 12\x12 \x12 \x0erln\x19ajs\x12 135the core functionality', 1);('agent incorporates', 1);('baselines', 1);('reputable forkof', 1);('openai baselines', 1);('exploration policy update steps work', 1);('proximalpolicy optimization ppo', 1);('state art continuousaction agents', 1);('integration31 training resultsto', 1);('quick efcient runtime precompute solutionsbeforehand store neural network model', 1);('library solutions neuralnet', 1);('thorough training', 1);('expensive process', 1);('thetraining', 1);('surrogate environment simplies dynamics ofthe vehicles 2d geometric problem', 1);('policy result', 1);('simulation for108steps', 1);('years sim timea', 1);('average', 1);('episode reward b', 1);('training lossc entropy loss neglog probabilityfigure', 1);('agent training resultsthe policy converges average score 750on surrogate task', 1);('parameters model', 1);('run ourrosagent', 1);('integration tool incorporates', 1);('interface communicate thesimulations hardware32', 1);('evaluation demonstratoradopting', 1);('thorough investigation', 1);('mismatchin vehicle dynamics', 1);('policy output vehicle controller', 1);('unreliable causesoscillations contributes system instability effect', 1);('policy itselfsince', 1);('successful policy', 1);('smooth consistent actions', 1);('additionthe difference dynamics', 1);('internal controller contribute', 1);('trajectorythis deciency', 1);('vehicle controllerthe trajectory', 1);('arrival time allowsthe vehicle controller compensate potential discrepancy transitionswe', 1);('different demonstration platforms', 1);('policy canbe', 1);('gazebo', 1);('simulation lowdelity dynamics', 1);('proprietary highdelity simulation', 1);('real', 1);('airplane demonstrator33', 1);('ros integrationcas', 1);('system integration', 1);('interfaces highdelity simulation', 1);('rosagent6ros lec runnerinput', 1);('reinforcementlearning policy agentadapter', 1);('localcoordinatesoutputof lecmodulerosadapter', 1);('globalcoordinatesdynamicssurrogateconversiontransitionsangle distheadingairspeedintr headinggoal angle distintr airspeedx yairspeedheadingintr x yintr headingturn rateintr airspeedaccellat lonairspeedheadingintr lat lonintr headingoriginal routeintr airspeedlat lonairspeedheadingaccumulatoraggregate waypointsx yairspeedheadingxyairspeedheadingfigure', 1);('roslec rosagent', 1);('runner integration', 1);('lec', 1);('interfaceroslec runner', 1);('fig', 1);('aggregates data', 1);('different domains providesimportant utilities system job', 1);('followsreceive accumulate', 1);('ownship state', 1);('state trafcalerts', 1);('gpssrs', 1);('transformation data', 1);('adsb gpsnovatel', 1);('data local', 1);('frame extract goal location', 1);('original route rewrap observations', 1);('agentspecic', 1);('input format', 1);('corrective actions', 1);('surrogate environment', 1);('transitions form corrective trajectory check trajectory good', 1);('trajectory local', 1);('global latlong waypoints publish trajectory', 1);('messageon external request', 1);('rosmessage', 1);('waypoints total', 1);('waypoints uniqueindex', 1);('original routethese waypoints', 1);('400second planning horizon', 1);('becauseof', 1);('large time step waypoints policy surrogate', 1);('waypoint total response time system', 1);('msec acomplete trajectorythis architecture', 1);('closedloop corrections external runtime assurance monitor', 1);('themonitor', 1);('transition error', 1);('avoidance planor denies operation', 1);('backup mode', 1);('resultswe', 1);('evaluation results', 1);('complete systems performance', 1);('therst', 1);('statistical evaluation run batch simulation compute total number ofsuccessful deconiction events', 1);('part trajectory performance analysis', 1);('thenumerical error', 1);('surrogate policy700', 1);('statistical', 1);('initial conditions systems performancein failures', 1);('relative angle distance', 1);('presume conict inevitable41', 1);('statistical resultsto', 1);('performance avoidance policy', 1);('batch simulation ofover104random conditions', 1);('avoidingthe trafc conicts', 1);('totalnumber simulations', 1);('fig6', 1);('cases resolvedwith', 1);('high number failures system', 1);('work standalonesystem', 1);('safety layer', 1);('trajectory evaluationthis', 1);('section evaluates demonstrator', 1);('trajectory setfour experiments', 1);('different behaviors experimentsinclude', 1);('right right toleft', 1);('headon course', 1);('coursein scenarios vehicles controller', 1);('physical capabilities surrogate assumptions', 1);('figures', 1);('7a 7b', 1);('distance error time arrival error846875', 1);('47075lat1195511950119451194011935lonsurrogate vs', 1);('true trajectorysurrtrueintra intruder', 1);('cross course46875', 1);('47075lat119500119475119450119425119400119375119350lonsurrogate vs', 1);('true trajectorysurrtrueintr', 1);('headon course500005000', 1);('xsxt10000010000ysyt4020hsht7100', 1);('7350time sec50556065', 1);('vsvtsurrogate', 1);('true trajectoryc accumulation', 1);('error trajectory500005000', 1);('xsxt10000010000ysyt4020hsht5550', 1);('5800time sec50556065vsvtsurrogate vs', 1);('true trajectory accumulation', 1);('error trajectoryfigure', 1);('transition', 1);('mismatch surrogate ground truth transitions5', 1);('conclusionthis', 1);('conict resolution system', 1);('reinforcement learningframework', 1);('ofine surrogate task', 1);('neuralnetwork model runtime', 1);('solution library providesa', 1);('quick efcient avoidance route mitigate potential trafc conict optimization doneofine board', 1);('lowpower node', 1);('thissystem', 1);('excellent smallscale', 1);('ua vs', 1);('solverthe system', 1);('simulations physicaldemonstrator', 1);('international airport', 1);('moses', 1);('washington', 1);('ight data', 1);('separate paper', 1);('high number failures', 1);('rlcasrequires', 1);('assurance monitor', 1);('prospective assurance methods forthe', 1);('internal surrogate validation external runtime', 1);('ndadditional information assurance', 1);('separate paper 17most', 1);('alternative methodology', 1);('dynamic trajectorygeneration task', 1);('diversication', 1);('critical components', 1);('essential concept risk mitigationfor', 1);('entire system9acknowledgmentthe authors', 1);('alex chen michael mcgivern boeing', 1);('data collectioneffortsreferences1steve', 1);('calandrillo jason oh ari webb', 1);('drones faa regulations', 1);('markon drone safety', 1);('stan tech', 1);('rev', 1);('ewen macpherson', 1);('ready drones air space law', 1);('faa ajv115 emerging technologies team unmannedaircraft', 1);('national airspace system nas', 1);('faa jo', 1);('kuwata gaston fiore justin teo emilio frazzoli jonathan p motionplanning', 1);('urban driving', 1);('ieeersj', 1);('international conference', 1);('intelligentrobots systems', 1);('20085charles w', 1);('warren global', 1);('path planning', 1);('articial potential elds', 1);('ieeeinternational', 1);('robotics automation', 1);('ieee computer society19896joohyun woo nakwan kim collision', 1);('surface vehicle usingdeep reinforcement learning ocean', 1);('engineering', 1);('kaushik vignesh prasad k madhava krishna balaraman ravindran overtakingmaneuvers', 1);('deep reinforcement learning', 1);('ieeeintelligent vehicles symposium iv pages', 1);('zhao myungil roh sungjun lee', 1);('control method path', 1);('collisionavoidance autonomous ship', 1);('deep reinforcement learning journal marine', 1);('scienceand', 1);('osipychev duy tran weihua sheng girish chowdhary', 1);('human intentionbasedcollision avoidance autonomous cars', 1);('american control conference', 1);('acc', 1);('richard sutton andrew g barto reinforcement', 1);('learning introduction', 1);('mit', 1);('greg brockman vicki cheung ludwig pettersson jonas schneider john schulman jie tangand wojciech zaremba openai', 1);('gym arxiv preprint arxiv160601540', 1);('ashley', 1);('antonin rafn maximilian ernestus adam gleave anssi kanervisto renetraore prafulla dhariwal christopher hesse oleg klimov alex nichol', 1);('stable baselines201813', 1);('john schulman filip wolski prafulla dhariwal alec radford oleg klimov proximalpolicy', 1);('optimization algorithms arxiv preprint arxiv170706347', 1);('siddharth mysore bassel mabsout renato mancuso kate saenko regularizing', 1);('smooth control reinforcement learning arxiv preprint arxiv201206644', 1);('richard cheng abhinav verma gabor orosz swarat chaudhuri yisong yue joel burdickcontrol', 1);('variance reinforcement learning', 1);('conferenceon machine learning', 1);('pmlr', 1);('morgan quigley ken conley brian gerkey josh faust tully foote jeremy leibs robwheeler andrew ng ros', 1);('opensource robot', 1);('icra', 1);('open source software volume', 1);('kobe japan', 1);('darren cofer ramachandra sattigeri isaac amundson junaid babar saqib hasan eric wsmith karthik nukala denis osipychev matthew moser james', 1);('paunicka', 1);('flighttest', 1);('collision avoidance neural network runtime assurance', 1);('ieeeaiaa', 1);('avionics systems', 1);('dasc', 1);('appendixfigure', 1);('longitudinal acceleration response demonstrator commandedstepinputsparameter range', 1);('unitstime', 1);('secmax timetmax', 1);('secdistance range', 1);('mhorizontal separation', 1);('environment simulation parameters11figure', 1);('longitudinal deceleration response demonstrator commandedstepinputscondition', 1);('rewarddistance', 1);('violation 100no violation', 1);('original path 10no violation', 1);('original path', 1);('environment reward function12algorithm', 1);('simulation updatereset random initialswhilettmax doupdate', 1);('vehicle controller compute control', 1);('set', 1);('vehicleupdate agent vehicle', 1);('pass', 1);('vehicleevaluate state', 1);('conict termination scorereturn observation reward terminationend13', 1);