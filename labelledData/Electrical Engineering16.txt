('peas', 26);('pea', 20);('sstam', 16);('ieee transactions', 13);('video quality', 9);('saliency regions', 9);('image processing', 9);('ssim', 7);('saam', 7);('a. c. bovik', 7);('video quality assessment', 6);('vqa', 6);('mos', 6);('video frame', 6);('atex class files', 5);('vol', 5);('no', 5);('september', 5);('visual saliency model', 5);('quality assessment', 5);('fig', 5);('video', 5);('tlvqm', 5);('international conference', 5);('proceedings', 5);('computer vision', 5);('china', 4);('grant', 4);('fuzhou', 4);('strred', 4);('speed-qa', 4);('viideo', 4);('saliency model', 4);('detection model', 4);('saliency objects', 4);('eq', 4);('base learners', 4);('ferit-rtrk', 4);('systems', 4);('subjective', 3);('human visual perception', 3);('timesformer', 3);('l. lin', 3);('fujian', 3);('blocking', 3);('blurring', 3);('color', 3);('ringing', 3);('flickering', 3);('floating', 3);('structural similarity', 3);('nr-vqa', 3);('of', 3);('loss function', 3);('bce', 3);('iou', 3);('spatial pea detection', 3);('total number', 3);('plcc', 3);('ms-ssim', 3);('brisque', 3);('niqe', 3);('performance comparison', 3);('ablation experiments', 3);('processing', 3);('r. soundararajan', 3);('circuits', 3);('a. mittal', 3);('ieee/cvf', 3);('pattern recognition', 3);('journal of', 2);('saliency-aware spatio-temporal artifact detection', 2);('encoding artifacts', 2);('temporal artifacts', 2);('based', 2);('saliency-aware spatio-temporal artifacts measurement', 2);('visual experience', 2);('reference', 2);('fr', 2);('rr', 2);('natural science foundation', 2);('t. zhao', 2);('fujian key lab', 2);('intelligent processing', 2);('wireless transmission', 2);('media information', 2);('physics', 2);('information engineering', 2);('zheng', 2);('w. chen', 2);('original videos', 2);('psnr', 2);('video quality evaluation', 2);('mlp', 2);('compression artifacts', 2);('detection module', 2);('ii', 2);('visual', 2);('cbam', 2);('u-net', 2);('u2-net', 2);('u2-cpnet', 2);('adjacent pixels', 2);('saliency map', 2);('densenet- pr', 2);('iij', 2);('pea265', 2);('ln', 2);('subjective quality scores', 2);('bagging', 2);('iii', 2);('live', 2);('csiq', 2);('ivp', 2);('srcc', 2);('methods live csiq ivp ferit-rtrk overall psnr', 2);('aclnet', 2);('saam2.0', 2);('telecommunication', 2);('m. vranje', 2);('z. wang', 2);('image', 2);('no-reference', 2);('iccv', 2);('convolutional', 2);('q. xue', 2);('z. zi', 2);('h. chen', 2);('salient object detection', 2);('cvpr', 2);('h. wang', 2);('machine learning', 2);('compressed video quality assessment liqun lin', 1);('yang zheng', 1);('weiling chen', 1);('chengdong lan', 1);('tiesong zhao abstract compressed', 1);('degrade video visual quality', 1);('ob- jective measures', 1);('various types', 1);('visual quality', 1);('spatial artifacts', 1);('low computational cost', 1);('detect temporal artifacts', 1);('quality metric', 1);('experimental', 1);('re- sults', 1);('method outperforms state- of-the-art metrics', 1);('index terms video', 1);('saliency detection', 1);('compression artifact', 1);('i.', 1);('ntroduction with', 1);('high-denition', 1);('hd', 1);('uhd', 1);('large amount', 1);('hd/uhd', 1);('transmission bandwidth', 1);('storage space', 1);('en-', 1);('artifacts', 1);('visual quality degra- dation [', 1);('objective meth- ods', 1);('mean opinion score', 1);('different mean opinion score', 1);('dmos', 1);('telecommunications', 1);('itu', 1);('reect video subjective quality', 1);('labor- intensive', 1);('reduced reference', 1);('fujian province', 1);('corresponding', 1);('lan', 1);('innovation laboratory', 1);('opto-', 1);('information', 1);('t.zhao g @ fzu.edu.cn', 1);('c. lan', 1);('lancd g @ fzu.edu.cn', 1);('examples', 1);('popular', 1);('compression processes', 1);('spurious discontinuities', 1);('block boundaries', 1);('visual appearance', 1);('visual discontinuity [', 1);('signal reconstruction results', 1);('signicant loss', 1);('high frequency energy', 1);('perceptually', 1);('spatial detail', 1);('texture areas', 1);('image [', 1);('color [', 1);('sharp edges [', 1);('frequent changes', 1);('time dimension', 1);('illusory movement', 1);('certain areas', 1);('visually', 1);('nr', 1);('fr-vqa', 1);('methods measure video quality', 1);('peak', 1);('noise ratio', 1);('original video', 1);('rr-vqa', 1);('spatial-temporal rr entropy differences', 1);('spatial effective entropy dif-', 1);('positive performance', 1);('original video data', 1);('popular quality assessment scheme', 1);('end users', 1);('nr-vqas', 1);('video intrinsic integrity', 1);('distortion evaluation oracle', 1);('two-level video qual-', 1);('model', 1);('different perspectives', 1);('recently', 1);('compression ar- tifacts', 1);('bovik', 1);('account video', 1);('specic classication', 1);('saliency-arxiv:2301.01069v1', 1);('[ eess.iv ]', 1);('jan', 1);('overall framework', 1);('transformer', 1);('encoder block l2 [', 1);('l ]', 1);('temporal attention module', 1);('spatial attention module', 1);('aware artifact measurement', 1);('specic detection', 1);('account compression artifacts', 1);('intensive [', 1);('great impact', 1);('video quality [', 1);('main contributions', 1);('de- tection', 1);('typical types', 1);('leverages visual saliency', 1);('quality evaluation', 1);('lit- tle impact', 1);('video visual quality', 1);('computational consumption', 1);('comprehensive validation', 1);('available databases', 1);('promising performance', 1);('pea-b ased video quality index', 1);('overall structure', 1);('video quality prediction model', 1);('a. spatial pea detection model', 1);('visual saliency model extracts', 1);('saliency areas', 1);('exclude areas', 1);('computational complexity', 1);('detection part', 1);('essential component', 1);('hu-', 1);('hvs', 1);('visual saliency', 1);('saliency', 1);('object detection identies', 1);('distinctive objects', 1);('focusing', 1);('computational burden', 1);('existing', 1);('saliency models', 1);('specic class', 1);('targets [', 1);('] [', 1);('target mo- tion', 1);('appearance contrast', 1);('saliency targets', 1);('such regions [', 1);('channel attention', 1);('channel linkage', 1);('spatial attention', 1);('complement channel attention', 1);('convolutional block attention module', 1);('semantic information', 1);('identify saliency regions', 1);('high-level semantic', 1);('essential local details', 1);('low-level semantic information', 1);('top-down process', 1);('local in- formation', 1);('drawing', 1);('extract multi-level', 1);('global guiding flows', 1);('ggfs', 1);('global guidance information', 1);('top-down path', 1);('pyramid pooling module', 1);('ppm', 1);('feature maps', 1);('top-down pathway output', 1);('inspired', 1);('u2-convolutional pyramid network', 1);('attention mechanism', 1);('global guidance', 1);('binary', 1);('entropy', 1);('adjacent regions', 1);('equal weights', 1);('loss function aims', 1);('loss', 1);('global aspect', 1);('pixel- level data', 1);('global background', 1);('local information', 1);('global context', 1);('foreground targets [', 1);('lbce=\x00', 1);('liou=hp', 1);('a=1wp b=1s', 1);('hp', 1);('a=1wp b=1 [ s', 1);('horizontal coordinates', 1);('handwindicate', 1);('real label', 1);('saliency object', 1);('structural relationships', 1);('image content', 1);('structural information', 1);('lssim=', 1);('g+\x162 p+c2', 1);('g+\x1b2 p+c2', 1);('gdenotes', 1);('binary ground truth mask', 1);('pis', 1);('probabilistic map mask', 1);('the\x16gand\x16prefer', 1);('standard deviation', 1);('c1andc2are', 1);('zero error', 1);('model training', 1);('lis', 1);('l=lbce+liou+lssim', 1);('densenet', 1);('pea recognition', 1);('gradient disappearance', 1);('pa- rameters', 1);('siextracted', 1);('bi', 1);('bibackto', 1);('recognition models', 1);('probability list', 1);('whole video sequence', 1);('nfnpnfx', 1);('i=1npx j=1iij', 1);('nfdenotes', 1);('video frames.is vrepresents', 1);('intensity value', 1);('72\x0272patch.iis thei-th frame', 1);('jis thej-th patch', 1);('b. temporal pea detection model video-specic', 1);('temporal in- formation', 1);('compared', 1);('video understanding tasks', 1);('tem- poral', 1);('cap- ture', 1);('great lack', 1);('self-attention', 1);('global dependencies', 1);('long range', 1);('hence', 1);('insigni- cant', 1);('training', 1);('temporal pea', 1);('softmax', 1);('ncx', 1);('j=1ntx i=1tsf j', 1);('fi', 1);('ntframes', 1);('ncis', 1);('tsf', 1);('layer norm', 1);('c. video quality prediction predicting', 1);('previous sections', 1);('bootstrap aggregating', 1);('] method', 1);('multiple', 1);('different parts', 1);('generaliza- tion performance', 1);('complete dataset', 1);('jdmos values', 1);('d.', 1);('d=f', 1);('iv1', 1);('ivk', 1);('mjdmos m', 1);('mjdmos mdenotes', 1);('subjective quality score', 1);('ivkis', 1);('support vector regression', 1);('svr', 1);('pearson linear correlation coefcient', 1);('true quality scores', 1);('video qualityqv', 1);('qvis', 1);('qv=nx', 1);('nx i=1', 1);('i2 [', 1);('prediction output', 1);('thei-th base learner', 1);('i-th base learner', 1);('e xperiments and discussions experiments', 1);('video quality databases', 1);('vqds', 1);('compression artifacts intensities', 1);('complete datasets', 1);('popular quality assessment methods', 1);('spearman rank correlation coefcient', 1);('tables', 1);('result corresponds', 1);('weighing', 1);('overall per- formance', 1);('total performance', 1);('high improvement', 1);('strong correlation', 1);('performance comparison in terms of plcc', 1);('table ii performance comparison in terms of srcc', 1);('table iii ablation experiments', 1);('indicators saam saam2.0 sstam plcc', 1);('accordingly', 1);('saliency regions contributes', 1);('attentive cnn-lstm network', 1);('u2- cpnet', 1);('saliency network', 1);('saliency model performs', 1);('iv', 1);('onclusions', 1);('video quality index', 1);('ex- perimental results', 1);('references', 1);('j. xia', 1);('shi', 1);('k. teunissen', 1);('i. heynderickx', 1);('perceivable artifacts', 1);('image communication', 1);('methodology', 1);('subjective assessment', 1);('quality', 1);('pictures', 1);('recommendation itu-r bt', 1);('geneva', 1);('switzerland', 1);('b. xie', 1);('h. zhang', 1);('c. jung', 1);('wcdgan', 1);('weakly connected dense generative adversarial network', 1);('artifact removal', 1);('highly com-', 1);('images', 1);('ieee access', 1);('x. sheng', 1);('l. li', 1);('d. liu', 1);('z. xiong', 1);('attribute artifacts removal', 1);('geometry-based', 1);('cloud compression', 1);('q. zhang', 1);('nie', 1);('l. zhu', 1);('c. xiao', 1);('w.', 1);('blind color separation model', 1);('faithful palette-based image recoloring', 1);('multimedia', 1);('m. k. rohil', 1);('n. gupta', 1);('p. yadav', 1);('no- reference image quality assessment', 1);('no-reference video quality assessment model', 1);('frame analysis', 1);('image video processing', 1);('j. vlaovi', 1);('d. grabi', 1);('d. samard', 1);('comparison', 1);('objective video quality assessment methods', 1);('videos', 1);('different spatial resolutions', 1);('signals', 1);('iwssip', 1);('h. r. sheikh', 1);('e. p. simoncelli', 1);('error visibility', 1);('reduced reference spatio-temporal entropic differencing', 1);('c. g. bampis', 1);('p. gupta', 1);('speed- qa', 1);('spatial efcient entropic differencing', 1);('inieee signal', 1);('m. a. saad', 1);('completely blind video integrity oracle', 1);('j. korhonen', 1);('two-level approach', 1);('t. r. goodall', 1);('detecting', 1);('video impair- ments', 1);('jing', 1);('w. zheng', 1);('compressed video quality index based', 1);('saliency-aware artifact detection', 1);('sensors', 1);('art', 1);('c. jin', 1);('z. peng', 1);('f. chen', 1);('g. jiang', 1);('objective video quality assessment', 1);('windowed-6dof synthesized videos', 1);('broadcasting', 1);('s. yu', 1);('l. zhou', 1);('perceptual assessment', 1);('video compression artifacts', 1);('ieee trans-', 1);('peng', 1);('l. guan', 1);('x. yuan', 1);('semi-supervised', 1);('video salient object detection', 1);('ieee cvf', 1);('j. guo', 1);('luo', 1);('omnidirectional video quality assessment', 1);('generative adversarial networks', 1);('multimedia tools', 1);('applications', 1);('zhao', 1);('j. zhao', 1);('j. li', 1);('x. chen', 1);('rgb-d salient object detection', 1);('ubiquitous target awareness', 1);('n. liu', 1);('n. zhang', 1);('k. wan', 1);('l. shao', 1);('j. han', 1);('visual saliency transformer', 1);('w. sanghyun', 1);('p. jong', 1);('l. joon', 1);('block atten- tion module', 1);('european conference', 1);('eccv', 1);('o. ronneberger', 1);('p. fischer', 1);('t. brox', 1);('biomedical image segmentation', 1);('med-', 1);('image computing', 1);('computer-assisted intervention', 1);('miccai', 1);('going', 1);('u-', 1);('l. jiang', 1);('h. qi', 1);('c. ming', 1);('real-time salient object detection', 1);('m. rahman', 1);('wang', 1);('optimizing', 1);('deep neural networks', 1);('image segmentation', 1);('symposium', 1);('visual computing', 1);('isvc', 1);('basnet', 1);('boundary-aware', 1);('b. gedas', 1);('l. torresani', 1);('space-time attention', 1);('video understanding', 1);('icml', 1);('l. breiman', 1);('s. hu', 1);('l. jin', 1);('zhang', 1);('s. kwong', 1);('c.-c. j. kuo', 1);('objective video quality assessment based', 1);('perceptually weighted mean squared error', 1);('p. v', 1);('vu', 1);('d. m. chandler', 1);('vis3', 1);('spatiotemporal slices', 1);('electronic imaging', 1);('f. zhang', 1);('s. li', 1);('l. ma', 1);('wong', 1);('k. ngan', 1);('ivp subjective quality video database', 1);('available online', 1);('baj', 1);('d.babi', 1);('b.kova', 1);('sub-', 1);('objective quality assessment', 1);('mpeg-2', 1);('h.264', 1);('h.265', 1);('symposium elmar', 1);('w. sun', 1);('q. liao', 1);('j. xue', 1);('f. zhou', 1);('spsim', 1);('superpixel-based similarity index', 1);('full-reference image quality assessment', 1);('a. k. moorthy', 1);('no-reference image quality assessment', 1);('spatial domain', 1);('making', 1);('completely blind image quality analyzer', 1);('ieee', 1);('w. wang', 1);('j. shen', 1);('j. xie', 1);('revisiting', 1);('video saliency prediction', 1);('deep learning era', 1);('pattern analysis', 1);('machine intelligence', 1);