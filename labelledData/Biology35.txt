('serial dependence', 57);('markovian and memoryless properties of visual system', 33);('two-trait condition', 31);('markov', 30);('facial trait', 30);('markov chain', 27);('markovian', 19);('d.', 19);('facial traits', 18);('previous trial', 18);('yu', 15);('ying', 15);('facial trait judgment', 14);('todorov', 14);('previous inputs', 14);('gaussian', 13);('dog', 13);('m.', 13);('previous stimuli', 12);('previous input', 11);('derivative', 11);('whitney', 11);('current trial', 11);('different facial traits', 11);('current stimuli', 11);('one-trait condition', 10);('sutherland', 10);('serial', 10);('attractiveness-dominance block', 10);('a.', 10);('social characteristics', 9);('liberman', 9);('kramer', 9);('lmm', 9);('visual system', 8);('fischer', 8);('facial attractiveness', 8);('specifically', 8);('current face', 8);('current outputs', 8);('s.', 8);('l.', 8);('current stimulus', 7);('different facets', 7);('cicchini', 7);('jones', 7);('previous study', 7);('attractiveness-trustworthiness block', 7);('diagonal matrix', 7);('linear mixed-effect model', 7);('trustworthiness-dominance block', 7);('g.', 7);('j.', 7);('current output', 6);('computational task', 6);('pustelnik', 6);('present study', 6);('previous stimulus', 6);('memoryless property', 6);('previous face', 6);('figure', 6);('previous faces', 6);('two-trait conditions', 6);('baseline ratings', 6);('att', 6);('output', 6);('vision', 6);('e.', 6);('memoryless properties', 5);('burr', 5);('fritsche', 5);('serial perception', 5);('visual perception', 5);('high-level vision', 5);('anns', 5);('xu', 5);('face stimuli', 5);('current trials', 5);('f.', 5);('k.', 5);('c.', 5);('p.', 5);('information processing', 4);('fried', 4);('oppenheim', 4);('bergen', 4);('yao', 4);('zhou', 4);('wang', 4);('oosterhof', 4);('participants need', 4);('mathematical properties', 4);('three-dimensional model', 4);('mathematical property', 4);('baseline blocks', 4);('facial trait evaluation', 4);('according', 4);('manassi', 4);('current inputs', 4);('two-trait trials', 4);('transitional matrices', 4);('dom_incon input', 4);('h.', 4);('neuroscience', 4);('cognition', 4);('r.', 4);('current biology', 4);('nature', 4);('oxford', 4);('evidence', 3);('soochow', 3);('memoryless system', 3);('linear mixed', 3);('marr', 3);('computational mechanisms', 3);('krakauer', 3);('may', 3);('visual processing', 3);('mikellidou', 3);('kim', 3);('lange', 3);('watson', 3);('serial dependency', 3);('current states', 3);('transitional probability matrix', 3);('previous ones', 3);('jehee', 3);('system property', 3);('serial visual perception', 3);('freeman', 3);('mende-siedlecki', 3);('ajina', 3);('ann', 3);('zhang', 3);('perceptual learning', 3);('pascucci', 3);('trait judgment', 3);('representation input', 3);('judgment output', 3);('calve', 3);('facial dominance', 3);('burns', 3);('chen', 3);('two-trait block', 3);('participants ratings', 3);('different conditions', 3);('adjacent trials', 3);('current ratings', 3);('previous outputs', 3);('accordingly', 3);('transition matrix', 3);('previous trials', 3);('facial trait judgments', 3);('linear', 3);('current stimuli baseline ratings', 3);('significant serial dependence', 3);('transitional probabilities', 3);('tru', 3);('current faces', 3);('input', 3);('current', 3);('stein', 3);('engell', 3);('trustworthiness judgment', 3);('b.', 3);('cognitive', 3);('g. m.', 3);('experimental psychology', 3);('psychological', 3);('y.', 3);('visual', 2);('psychology', 2);('suzhou', 2);('china', 2);('number', 2);('convergent results', 2);('lorenz', 2);('signal processing system', 2);('dennett', 2);('temporal stability', 2);('webster', 2);('recent past', 2);('glasauer', 2);('shi', 2);('low-level visual processing', 2);('spaak', 2);('cont', 2);('zimmermann', 2);('clifford', 2);('fornaciai', 2);('algorithm level', 2);('previous states', 2);('various facial traits', 2);('information processing perspective', 2);('physical property', 2);('multiple facets', 2);('good candidate', 2);('ambady', 2);('vuilleumier', 2);('righart', 2);('processing task', 2);('computational mechanism', 2);('kanwisher', 2);('mcdermott', 2);('chun', 2);('gobbini', 2);('evans', 2);('haxby', 2);('oldmeadow', 2);('santos', 2);('towler', 2);('michael burt', 2);('pollard', 2);('bridge', 2);('investigating', 2);('different facial trait judgment', 2);('artificial neural networks', 2);('niles', 2);('silverman', 2);('convolutional neural networks', 2);('random fields', 2);('qu', 2);('bengio', 2);('tang', 2);('han', 2);('wan', 2);('hou', 2);('cao', 2);('meng', 2);('paisley', 2);('image segmentation', 2);('duan', 2);('liu', 2);('jiao', 2);('zhao', 2);('human cognition', 2);('human vision system', 2);('basic emotions', 2);('gilbert', 2);('sigman', 2);('crist', 2);('ceylan', 2);('herzog', 2);('inner representations', 2);('experimental design', 2);('neta', 2);('methods', 2);('previous studies', 2);('yang', 2);('n-fee', 2);('yap', 2);('chan', 2);('christopoulos', 2);('taiwanese facial expression image database', 2);('yen', 2);('faces', 2);('shine', 2);('willenbockel', 2);('mathworks', 2);('brainard', 2);('pelli', 2);('likert', 2);('one-trait block', 2);('two-trait blocks', 2);('one-trait conditions', 2);('facial trustworthiness', 2);('baseline block', 2);('facial trait instructions', 2);('effect model', 2);('bates', 2);('kuznetsova', 2);('judgment errors', 2);('1-back stimuli', 2);('participants judgment', 2);('state space', 2);('social characteristic', 2);('kampen', 2);('participants baseline ratings', 2);('previous output', 2);('previous face stimuli', 2);('previous trait instructions', 2);('previous response', 2);('consistent', 2);('perceptual bias', 2);('successive trials', 2);('serial dependence exists', 2);('present face', 2);('p <', 2);('mixed-effect models', 2);('parameter', 2);('general linear mixed-effect models', 2);('fixed', 2);('estimate', 2);('se t p', 2);('tru_incon input', 2);('dom_con input', 2);('significant effect', 2);('current responses', 2);('previous facial trait', 2);('current facial trait', 2);('representation inputs', 2);('divergent results', 2);('previous representation inputs', 2);('basic factors', 2);('different mathematical properties', 2);('awad', 2);('gayet', 2);('peelen', 2);('bzdok', 2);('social evaluation', 2);('mathematical principles', 2);('j.m', 2);('data analysis', 2);('data visualization', 2);('writing', 2);('jiangsu province', 2);('vol', 2);('statistical software', 2);('r. s.', 2);('spatial vision', 2);('w.', 2);('z.', 2);('convolutional neural network', 2);('d. c.', 2);('proceedings', 2);('t.', 2);('n.', 2);('f. p.', 2);('neuron', 2);('r. s. s.', 2);('sequential', 2);('facial attractiveness judgments', 2);('response biases', 2);('perception', 2);('j. w.', 2);('kreiman', 2);('koch', 2);('human brain', 2);('affective neuroscience', 2);('murai', 2);('international conference', 2);('plos biology', 2);('perceptual', 2);('university press', 2);('serial face processing jun-ming yu1,2', 1);('haojiang ying1', 1);('nanyang technological', 1);('singapore', 1);('correspondence', 1);('haojiang ying', 1);('psychology soochow', 1);('china email', 1);('@ suda.edu.cn', 1);('figures', 1);('tables', 1);('abstract', 1);('information processing system', 1);('specific fundamental properties', 1);('previous', 1);('asymmetrical system properties', 1);('effective technique', 1);('different computation tasks', 1);('keywords', 1);('face perception', 1);('characteristics', 1);('markov process', 1);('computational vision markovian and memoryless properties of visual system', 1);('introduction throughout', 1);('past decades', 1);('human visual perception', 1);('computational view', 1);('scientific theories', 1);('micro-level reductionism investigation', 1);('individual phenomena', 1);('macro-level investigation', 1);('complex system', 1);('studying', 1);('individual phenomenon', 1);('complex nature', 1);('whole system', 1);('linear combination', 1);('human vision computation', 1);('certain principles', 1);('individuals', 1);('unstable information', 1);('ever-changing environment', 1);('human visual system', 1);('current processing', 1);('alias', 1);('typical phenomena', 1);('perceptual judgment', 1);('serial dependence occurs', 1);('high-level processing', 1);('general visual mechanism', 1);('processing stage serial dependence occurs', 1);('computational principles', 1);('recently', 1);('stochastic process', 1);('participants response states', 1);('response states transit', 1);('transition patterns', 1);('response states', 1);('matrix analysis', 1);('researchers', 1);('general mechanism', 1);('effective tool', 1);('open question', 1);('strong markov', 1);('judgment response', 1);('future trial', 1);('disentangling', 1);('previous representation input', 1);('perceptual output taps', 1);('fundamental processing principle', 1);('basic principle', 1);('cognitive science', 1);('current input', 1);('future input', 1);('visual processing system violates', 1);('neural circuits', 1);('visual information', 1);('early visual cortex', 1);('processing area', 1);('multiple dimensions', 1);('different social evaluations', 1);('different neural circuits', 1);('specific time point', 1);('serial dependence framework', 1);('trivial mathematical', 1);('mathematical precondition', 1);('forward-backward algorithm', 1);('hidden markov model', 1);('model states', 1);('back propagation algorithm', 1);('fundamental elements', 1);('graph network', 1);('image crowd', 1);('hyperspectral image classification', 1);('computational neural models', 1);('information processing system properties', 1);('human cognition system', 1);('neural models', 1);('behavioral experiment', 1);('high-level vision system', 1);('neural base', 1);('seitz', 1);('complex physical structure', 1);('perceptual learning method', 1);('macro-level system structure', 1);('recent study', 1);('spatial frequency', 1);('orientation judgment tasks', 1);('different stimuli', 1);('different tasks', 1);('current inner representation', 1);('facial', 1);('different computational', 1);('neural mechanisms', 1);('facial trait perception', 1);('trait perception', 1);('stimuli input', 1);('different judgments', 1);('different trials', 1);('different effect', 1);('current facial judgment', 1);('previous representation', 1);('current judgment task', 1);('judgment task', 1);('mixed-condition trials', 1);('common characteristics', 1);('different stimulus types', 1);('stimulus type', 1);('different task instructions', 1);('mixed-condition blocks', 1);('trait judgment output', 1);('properties occurs', 1);('facial trait violates', 1);('different algorithms', 1);('mixed-condition design', 1);('different social characteristics', 1);('main characteristic dimensions', 1);('significant social functions', 1);('notably', 1);('valence-dominance model', 1);('face evaluations', 1);('social dimensions', 1);('whether', 1);('separate dimension', 1);('trustworthiness/valence axis', 1);('potential study', 1);('neural processing time course', 1);('gutierrez-garcia', 1);('beltran', 1);('attractiveness impressions', 1);('prime trustworthiness inferences', 1);('important social trait', 1);('computation importance', 1);('mate selection', 1);('facial trustworthiness shows', 1);('persons willingness', 1);('good indicator', 1);('persons ability', 1);('helpful behaviors', 1);('cognitive scientists', 1);('computational question', 1);('following', 1);('neural processing', 1);('facial trait instruction', 1);('minimum exposure', 1);('linz', 1);('willis', 1);('inner representation', 1);('perceptual output', 1);('retinal input', 1);('current perception', 1);('age =', 1);('corrected-to-normal vision', 1);('ethics', 1);('sample size', 1);('power analysis', 1);('power', 1);('social trait', 1);('stimuli adapted', 1);('ethnic chinese faces', 1);('nanyang facial emotional expression database', 1);('tfeid', 1);('oval mask', 1);('internal region', 1);('apparatus', 1);('matlab r2016a', 1);('psychtoolbox', 1);('lcd', 1);('macbook pro', 1);('spatial resolution', 1);('refresh rate', 1);('hz', 1);('.025 degree', 1);('visual angle', 1);('procedure', 1);('general procedure', 1);('central fixational cross', 1);('s presentation', 1);('face stimulus', 1);('discrete-time finite-space system', 1);('possible response bias', 1);('different lines', 1);('qwertyu keys', 1);('asdfghj keys', 1);('zxcvbnm keys', 1);('inter-stimulus interval', 1);('inter trial interval', 1);('participants reaction time', 1);('experimental procedure', 1);('illustrative example', 1);('trial n-1', 1);('trial n', 1);('facial trait judgment instruction', 1);('one-trait blocks', 1);('participants output', 1);('participants outputs', 1);('high-level visual processing', 1);('different facial trait', 1);('input values', 1);('particular facial trait', 1);('signal processing', 1);('term input', 1);('method', 1);('result section', 1);('attractiveness baseline block', 1);('trustworthiness instructions', 1);('instruction requirements', 1);('different participants', 1);('formal experiment', 1);('analysis', 1);('general logic', 1);('serial dependency occurs', 1);('social characteristic judgements', 1);('one-trait condition v.s', 1);('linear mixed-effect', 1);('aforementioned findings', 1);('reaction time', 1);('current ones', 1);('matlab r2018a', 1);('lme4 package', 1);('satterthwaites', 1);('freedom estimation method', 1);('imertest package', 1);('faces perceptual inputs', 1);('two-trait inter-trial conditions', 1);('output trait', 1);('effect models', 1);('research question', 1);('such details', 1);('mathematical relationship', 1);('conventional method', 1);('conventional serial dependence effect', 1);('judgment', 1);('previous responses', 1);('function y=xawce-', 1);('parameter x', 1);('peak-to-trough amplitude', 1);('w scales', 1);('peak amplitude', 1);('amplitude parameter', 1);('serial dependence bias', 1);('participants judgments', 1);('negative value', 1);('width parameter w', 1);('free parameter', 1);('plausible value', 1);('facial trait value', 1);('nonlinear minimization', 1);('residual sum', 1);('analyze serial dependence', 1);('advantageous tool', 1);('states transit', 1);('transitional pattern', 1);('time-series model', 1);('expresses transition', 1);('finite states', 1);('certain transition probabilities', 1);('k }', 1);('k-order transition probability matrix', 1);('transition probabilities', 1);('right-stochastic transition matrix', 1);('discrete state-space', 1);('time-series data', 1);('range {', 1);('transition information', 1);('participants data', 1);('transition probability matrices', 1);('classic serial dependence', 1);('powerful mathematical method', 1);('mixed-effect model', 1);('previous stimulis perceptual inputs', 1);('two-trait inter-trial condition', 1);('similar results', 1);('average baseline', 1);('average baseline ratings', 1);('accurate variables', 1);('typical serial dependence', 1);('previous response output', 1);('previous input analysis', 1);('participants baseline', 1);('current face stimuli', 1);('effective indicator', 1);('inter-trial difference', 1);('similar amplitude', 1);('general pattern', 1);('various facial trait', 1);('new question', 1);('previous reports', 1);('response bias', 1);('pure perceptual input', 1);('output attribute', 1);('previous facial trait instruction', 1);('data', 1);('one-trait trials', 1);('response errors', 1);('hollow-black dots', 1);('individual responses', 1);('bold-green line', 1);('markov chain modeling', 1);('transitional patterns', 1);('different trait ratings', 1);('matrix', 1);('correlation analysis', 1);('diagonal direction', 1);('complete transition', 1);('rs > .47', 1);('ps < .001', 1);('ratt-tru =', 1);('rtru-dom =', 1);('ratt-dom =', 1);('p =', 1);('transitional', 1);('probability matrices', 1);('current response', 1);('general linear mixed-effect model', 1);('previous ratings', 1);('tru_con input', 1);('models regardless', 1);('inter-trial consistency', 1);('positive predictor', 1);('linear mixed-effect model demonstrates', 1);('output attributes', 1);('facial trait requirement', 1);('trustworthiness-dominance blocks', 1);('two-trait attractiveness-dominance block', 1);('potential serial dependence', 1);('defines serial dependence', 1);('perceptual inputs', 1);('important factor', 1);('specific facial trait', 1);('facial trait information', 1);('current response outputs', 1);('two-trait trial', 1);('specific facial traits', 1);('discussion', 1);('system properties', 1);('human vision perception', 1);('memoryless process', 1);('various facial trait judgments', 1);('inconsistent condition', 1);('different trait', 1);('previous face stimulus', 1);('facial trait dimension', 1);('serial dependence effect', 1);('non-markov property', 1);('memoryless system refers', 1);('future inputs', 1);('perception output', 1);('process system', 1);('perceptual representation inputs', 1);('general perceptual representation', 1);('perceptual representation', 1);('linear mixed-effect model suggests', 1);('high-level visual system', 1);('different results', 1);('different way', 1);('dissociable computational mechanisms', 1);('various facial trait judgment', 1);('dominance-trustworthiness blocks', 1);('dominance', 1);('major dimensions/axes', 1);('significant social signals', 1);('continuous flash suppression', 1);('social-emotional meanings', 1);('similar subcortical pathways', 1);('trustworthiness', 1);('facial trait dimensions', 1);('general valance', 1);('common neural', 1);('superior temporal sulcus', 1);('medial orbitofrontal cortex', 1);('neural time course advantage', 1);('erp', 1);('special relationship', 1);('disparate algorithm', 1);('basic trait factors', 1);('facial evaluation', 1);('social traits', 1);('evaluation', 1);('facial traits judgments', 1);('separable properties', 1);('mathematical', 1);('simple mathematical', 1);('current practice', 1);('brain/cognitive models', 1);('artificial neural markovian and memoryless properties of visual system', 1);('networks', 1);('certain facets', 1);('basic properties', 1);('cognitive tasks', 1);('cognitive science perspective', 1);('mathematical perspective', 1);('attractive-dominance condition', 1);('social trait pairs', 1);('mathematical principle', 1);('social characteristics processing', 1);('cognitive processing task', 1);('mathematical computation', 1);('asymmetry processing', 1);('neural system', 1);('conclusion', 1);('asymmetry mathematical properties', 1);('internal representation', 1);('authors', 1);('h. ying', 1);('conceptualization', 1);('funding', 1);('resources acquisition', 1);('acknowledgement h. ying', 1);('national natural science foundation', 1);('natural science foundation', 1);('bk20200867', 1);('entrepreneurship', 1);('innovation', 1);('undergraduate', 1);('advising project', 1);('references adelson', 1);('e. h.', 1);('j. r.', 1);('plenoptic function', 1);('early vision', 1);('modeling', 1);('media laboratory', 1);('massachusetts', 1);('colliculus', 1);('amygdala support evaluation', 1);('face trait', 1);('blindsight', 1);('frontiers', 1);('neurology', 1);('769. https', 1);('//doi.org/10.3389/fneur.2020.00769 bar', 1);('linz h.', 1);('emotion', 1);('washington', 1);('dc', 1);('maechler', 1);('bolker', 1);('walker', 1);('fitting', 1);('linear mixed-effects models', 1);('//doi.org/10.18637/ jss.v067.i01 van', 1);('j. f.', 1);('probabilistic', 1);('human visual cortex reflects uncertainty', 1);('serial decisions', 1);('d. h.', 1);('psychophysics toolbox', 1);('e. j.', 1);('friend', 1);('contrastive', 1);('hierarchical processing', 1);('langner', 1);('caspers', 1);('kurth', 1);('habel', 1);('u.', 1);('zilles', 1);('laird', 1);('eickhoff', 1);('ale', 1);('facial judgments', 1);('brain structure', 1);('209223. https', 1);('calvo', 1);('m. g.', 1);('gutirrez-garca', 1);('beltrn', 1);('neural', 1);('time course', 1);('brain sources', 1);('affective', 1);('behavioral neuroscience', 1);('x.', 1);('hyperspectral', 1);('image classification', 1);('ieee transactions', 1);('image processing', 1);('m. h.', 1);('104709. https', 1);('l. f.', 1);('y. s.', 1);('mapping laboratory', 1);('science.taipei', 1);('yang-ming', 1);('functional role', 1);('royal society b', 1);('biological', 1);('20181722. https', 1);('//doi.org/10.1098/rspb.2018.1722 inlar', 1);('probability', 1);('york', 1);('springer', 1);('c. w. g.', 1);('t. l.', 1);('facial age estimation', 1);('royal society open science', 1);('180841. https', 1);('collins', 1);('dependence occurs', 1);('object representations', 1);('18211832. https', 1);('representation', 1);('sensory experience', 1);('logical geography', 1);('computational approaches', 1);('pole', 1);('presentation', 1);('knowledge', 1);('belief', 1);('theson', 1);('univ', 1);('arizona pr', 1);('sar', 1);('convolutional-wavelet neural network', 1);('random field', 1);('pattern recognition', 1);('nature neuroscience', 1);('attractive serial dependence', 1);('absence', 1);('explicit', 1);('437446. https', 1);('dynamic interactive theory', 1);('person construal', 1);('psychological review', 1);('studying mental', 1);('problems', 1);('systems', 1);('syndromes', 1);('current directions', 1);('mostert', 1);('opposite', 1);('recent history', 1);('bayesian', 1);('efficient observer model', 1);('repulsive history biases', 1);('elife', 1);('c.d.', 1);('r.e', 1);('neural basis', 1);('temporal continuity', 1);('perceptual biases', 1);('scientific', 1);('10746. https', 1);('image', 1);('markov random field', 1);('advanced computational intelligence', 1);('intelligent informatics', 1);('b. c.', 1);('debruine', 1);('l. m.', 1);('flake', 1);('j. k.', 1);('liuzza', 1);('m. t.', 1);('antfolk', 1);('arinze', 1);('n. c.', 1);('sirota', 1);('world regions', 1);('valencedominance model', 1);('social perception', 1);('human behaviour', 1);('159-169. https', 1);('//doi.org/10.1038/s41562-020-01007-2 van', 1);('n. g.', 1);('remarks', 1);('non-markov processes', 1);('brazilian', 1);('physics', 1);('m. m.', 1);('human extrastriate cortex', 1);('43024311. https', 1);('//doi.org/ 10.1523/jneurosci.17-11-04302.1997', 1);('alais', 1);('conscious awareness', 1);('r257r258', 1);('a. l.', 1);('performance', 1);('14761489. https', 1);('//doi.org/10.1037/ xhp0000869', 1);('l. r.', 1);('separating', 1);('visual cognition', 1);('679688. https', 1);('ghazanfar', 1);('gomez-marin', 1);('maciver', 1);('m. a.', 1);('poeppel', 1);('needs behavior', 1);('reductionist bias', 1);('480-490. https', 1);('imagery', 1);('357361. https', 1);('brockhoff', 1);('p. b.', 1);('christensen', 1);('r. h.', 1);('lmertest', 1);('tests', 1);('//doi.org/ 10.18637/jss.v082.i13', 1);('25692574. https', 1);('e. n.', 1);('deterministic', 1);('nonperiodic flow', 1);('atmospheric sciences', 1);('kosovicheva', 1);('position occurs', 1);('psychonomic bulletin', 1);('review', 1);('san francisco', 1);('simple', 1);('mathematical models', 1);('459467. https', 1);('c. p.', 1);('285299. https', 1);('history-dependent perceptual templates', 1);('l. t.', 1);('h. f.', 1);('april', 1);('combining', 1);('neural network classifiers', 1);('acoustics', 1);('speech', 1);('processing', 1);('ieee', 1);('a. v.', 1);('willsky', 1);('a. s.', 1);('nawab', 1);('s. h.', 1);('hernndez', 1);('signals', 1);('pearson', 1);('n. n.', 1);('functional basis', 1);('national academy', 1);('america', 1);('mancuso', 1);('santandrea', 1);('della libera', 1);('plomp', 1);('chelazzi', 1);('laws', 1);('article', 1);('d. g.', 1);('videotoolbox', 1);('visual psychophysics', 1);('transforming', 1);('gmnn', 1);('graph', 1);('markov neural networks', 1);('machine learning', 1);('pmlr', 1);('quiroga', 1);('r. q.', 1);('reddy', 1);('invariant', 1);('visual representation', 1);('11021107. https', 1);('seitz a. r.', 1);('r631r636', 1);('m. v', 1);('unconscious', 1);('low-level factors', 1);('c. a. m.', 1);('i. m.', 1);('a. w.', 1);('social inferences', 1);('ambient', 1);('images generate', 1);('105118. https', 1);('a. d.', 1);('implicit evaluation', 1);('neutral faces', 1);('m. i.', 1);('k. k.', 1);('j. v.', 1);('spontaneous', 1);('affective person knowledge', 1);('neuropsychologia', 1);('turbett', 1);('palermo', 1);('bell', 1);('hanran-smith', 1);('d. a.', 1);('jeffery', 1);('facial identity reflects high-level', 1);('919. https', 1);('attention', 1);('processing facial expressions', 1);('calder aj', 1);('rhodes g', 1);('johnson mh', 1);('haxby jv', 1);('personality labels', 1);('womens mate preference', 1);('acta psychologica sinica', 1);('zhu', 1);('fang', 1);('recognition confusion', 1);('754767. https', 1);('annual review', 1);('searching', 1);('serial dependencies', 1);('v.', 1);('sadr', 1);('fiset', 1);('horne', 1);('g. o.', 1);('gosselin', 1);('tanaka', 1);('controlling', 1);('low-level image properties', 1);('behavior', 1);('willis j', 1);('making', 1);('ms exposure', 1);('w. j.', 1);('july', 1);('nanyang', 1);('facial emotional expression [', 1);('] database', 1);('poster', 1);('congress', 1);('international association', 1);('cross-cultural psychology', 1);('nagoya', 1);('japan', 1);('j.-m.', 1);('general serial dependence', 1);('4. https', 1);('zeki', 1);('j. d.', 1);('lueck', 1);('c. j.', 1);('friston', 1);('k. j.', 1);('kennard', 1);('frackowiak', 1);('direct demonstration', 1);('functional specialization', 1);('human visual cortex', 1);('zhaoping', 1);('understanding', 1);('usa', 1);