('cme', 27);('pt', 15);('input sequence', 14);('variable model', 11);('ds', 11);('assumption', 10);('attention mechanism', 9);('proposition', 9);('figure', 9);('pzjx', 9);('gaussian', 9);('theorem', 9);('wvi', 9);('xt', 9);('neural networks', 7);('theorem c4', 7);('vaswani', 6);('edelman', 6);('speci', 6);('approximation error', 6);('ssl', 6);('ptmsk ds', 6);('international conference', 6);('conclude proof', 6);('dosovitskiy', 5);('devlin', 5);('lipschitz', 5);('generalization error', 5);('rkhs', 5);('kernel function', 5);('mle', 5);('recall', 5);('function class', 5);('machine learning', 5);('iv', 5);('fldntrans', 5);('rademacher', 5);('xt\x00bxt', 5);('latent', 4);('input tokens', 4);('intuitively', 4);('bert devlin', 4);('vit dosovitskiy', 4);('xie', 4);('malladi', 4);('zhang', 4);('input mask msk', 4);('learnable parameter', 4);('similarly', 4);('gaussian rbf', 4);('evjk', 4);('b2', 4);('relu', 4);('lxyf', 4);('eapprox', 4);('learning', 4);('a\x1bt', 4);('wki', 4);('xwvisoftmax', 4);('xwki', 4);('long sequences', 3);('desirable representation', 3);('finetti', 3);('bayesian', 3);('markov', 3);('transformers', 3);('tsai', 3);('yang', 3);('jacot', 3);('data distribution', 3);('vallep\x13', 3);('bartlett', 3);('hilbert', 3);('model', 3);('positional encodings', 3);('latent posterior bzx', 3);('variable z', 3);('independent input sequence', 3);('bert', 3);('corresponding', 3);('data point', 3);('learnable parameters', 3);('attention attn', 3);('propositions', 3);('lemma', 3);('kltvzz0msk', 3);('eyjx', 3);('error \x0fsslmsk', 3);('eptapprox', 3);('gradient', 3);('generalization', 3);('mean', 3);('cvkckk\x15i\x001kq\x01\x00cvkc\x001kkkq\x01', 3);('ckk\x15i\x001', 3);('axt', 3);('c6', 3);('empirical function class', 3);('c9', 3);('number empirical function class', 3);('lemma c7', 3);('ax', 3);('a\x1b', 3);('lemma g3', 3);('wqi', 3);('ds\x00f\x03dsx', 3);('pt\x00fywdsxmsk ds', 3);('pt\x00f\x03ptx\x01', 3);('output labels', 2);('b inference', 2);('c learning', 2);('independent input sizes', 2);('particularly', 2);('computer vision', 2);('valuegiven key', 2);('kernel conditional', 2);('global minimizer', 2);('stationary point', 2);('function classes', 2);('brown', 2);('chen', 2);('vuckovic', 2);('hron', 2);('yang littwin', 2);('garg', 2);('turing', 2);('xieet', 2);('deep neural networks', 2);('louis', 2);('zhu', 2);('mendelson', 2);('scarselli', 2);('xfxg2lwith', 2);('krdp\x02rdpris', 2);('kexpqk', 2);('nlp', 2);('cv', 2);('exchangeable sequence', 2);('representation input sequence', 2);('pz\x01jx', 2);('xconditioning', 2);('variable yis', 2);('vit', 2);('unknown label', 2);('xfory', 2);('generative distribution', 2);('pyjz', 2);('latent posterior', 2);('dnfxiyigi2n', 2);('inthe', 2);('n0\x15i', 2);('suppose', 2);('rbf', 2);('rd', 2);('random variables', 2);('lgoes', 2);('kde', 2);('softmax attention', 2);('l1', 2);('softmax attention attn', 2);('cmehave', 2);('capability diverse', 2);('characterization generalization error', 2);('zmsk z0msk', 2);('ltv', 2);('e1', 2);('attention fywxmsk', 2);('rkhs hltv', 2);('gap', 2);('ntkbased', 2);('attentionneural network bfdsxmsk', 2);('latenttovalue mappings', 2);('attention mechanism frozen', 2);('input masks msk', 2);('rkhss', 2);('pt\x01', 2);('ds2h ds', 2);('latenttotarget mappingg\x03dszmsk', 2);('rkhs hds', 2);('thatdxi1 g\x03pti\x01msk', 2);('ds\x00gywdsi\x01msk ds', 2);('subsequent analysis', 2);('bis', 2);('aggregation layer', 2);('ptto', 2);('attention neural networks', 2);('recovery gap \x0fgmsk', 2);('previous arguments', 2);('kernel', 2);('cambridge', 2);('song l', 2);('attention', 2);('tensor', 2);('joint distribution', 2);('covariance operator', 2);('a2', 2);('gp', 2);('zis', 2);('assumption b1', 2);('righthand side', 2);('su\x0ecient statistic', 2);('ux', 2);('b4it', 2);('ckk\x15i\x001ckkckk\x15i\x001ckkiii\x11e\x02v\x16v', 2);('complete proof', 2);('r 1s', 2);('complete setup', 2);('kqk', 2);('fltrans', 2);('c2', 2);('c1', 2);('conjugate pair rs', 2);('wkti', 2);('wvti', 2);('tof', 2);('letfbe', 2);('lemma c8', 2);('lemma g4', 2);('a\x1b\x00ba\x1b', 2);('xax', 2);('corollary c9', 2);('mha', 2);('wvi\x00cwvi', 2);('c14', 2);('c11proof', 2);('xt1\x00bxt1', 2);('ezjx\x02g\x03zmsk\x00gywzmsk\x03', 2);('f3', 2);('qk', 2);('c8', 2);('analysis attention', 1);('lens', 1);('modelsyufeng zhang boyi liu qi cai lingxiao wang zhaoran wanguni2016abstractwith', 1);('attention mechanism transformers', 1);('signi cant empiricalsuccesses', 1);('natural language processing computer vision', 1);('theintuitive understanding transformers', 1);('relational inference inductive reasoning', 1);('desirable representationswe lack rigorous theory attention mechanism', 1);('desirablerepresentation b attention mechanism infer', 1);('procedurelearn infer', 1);('desirable representation backward passwe aim', 1);('lens exchangeability', 1);('specifically', 1);('observe case', 1);('bert vit', 1);('positional encodings notion ofexchangeability induces latent', 1);('variable model invariant input sizeswhich', 1);('theoretical analysis', 1);('existence su\x0ecient andminimal representation input tokens', 1);('particular representationinstantiates posterior distribution latent', 1);('variable conceptgiven input tokens plays', 1);('central role', 1);('parameter infers latent posterior approximation error decreasingin input sizes', 1);('quantify attention approximates conditional', 1);('key characterizes performsrelational inference', 1);('long sequencesequal contributionnorthwestern university yufengzhang2023unorthwesternedunorthwestern university boyiliu2018unorthwesternedunorthwestern university qicai2022unorthwesternedunorthwestern university lingxiaowang2022unorthwesterneduuni2016northwestern university zhaoranwanggmailcom1arxiv221214852v1 cslg', 1);('dec', 1);('empirical risk minimization', 1);('parameter upto generalization error', 1);('setting identify condition number', 1);('tasksour theoretical analysis', 1);('complete characterization attentionmechanism greybox design uni es', 1);('variable model whitebox', 1);('data blackbox', 1);('provable approximation generalizationand optimization guarantees1', 1);('introductiontransformers', 1);('stateoftheart architecture variety tasks', 1);('ramesh', 1);('core signi cant empirical', 1);('theattention mechanism', 1);('computation graph', 1);('inparticular', 1);('computation graph performs speci c form message', 1);('bronstein', 1);('attention mechanismis', 1);('relational inference', 1);('key advantage transformers', 1);('lacks quantitative justi cation leaves', 1);('questions opena', 1);('desirable representation inputtokens su\x0ecient minimal sense preserves relevant information', 1);('tasks su\x0eciency neglects irreverent information minimality', 1);('lack quantitative', 1);('nition su\x0eciency andminimality', 1);('probabilistic modelb attention mechanism infer', 1);('computation graph resembleskernel', 1);('kernel regression', 1);('shawetaylor', 1);('formal characterization function class attentionmechanism parameterizes approximates', 1);('unclear speci c formof message', 1);('desirable representation input tokens', 1);('withsu\x0eciency minimalityc', 1);('desirable representation backward pass', 1);('empirically', 1);('procedure minimizes empirical risks', 1);('lack theoretical justi cationof', 1);('objective attains', 1);('desirable estima2tor generalizes generalization error', 1);('degrade longsequences', 1);('unclear degree', 1);('tasksin paper', 1);('lens exchangeability keyobservation case', 1);('vit dosovitskiyet', 1);('positional encodings otherwords joint distribution input tokens eg vector embeddings words paragraphor patches image positional encodings', 1);('attention mechanism entrywise feedforward neural networkspreserve notion exchangeability', 1);('transformer layers', 1);('finettitheorem', 1);('notion exchangeability induces latent', 1);('variable modelthat invariant input sizes', 1);('settings latent variablemodel', 1);('data points', 1);('datapoint incontext manner captures', 1);('structure interactionsas relational inductive biases', 1);('battaglia', 1);('ourtheoretical analysis', 1);('existence su\x0ecient minimalrepresentation input tokens', 1);('particular leverage latent', 1);('ne su\x0eciencyand minimality', 1);('factorization theorem su\x0eciency principle', 1);('fisher1922', 1);('posterior distribution latent', 1);('inputtokens su\x0ecient minimal representation plays', 1);('central role predictingoutput labels', 1);('variable instantiates theconcept paragraph image', 1);('words patches', 1);('indetail', 1);('summarization process', 1);('input tokens theposterior distribution latent', 1);('bayesianmanner', 1);('desirable representation latent posterior itremains unclear parameterize approximate latent posterior addressedby', 1);('parameter infers latent posterior approximation error', 1);('speci c parameterization latent posterior yieldsa variant attention mechanism', 1);('cmenamely cme', 1);('attention infers conditional', 1);('keyhere value key query', 1);('transformationof input tokens', 1);('unknown parameter', 1);('attention recovers latent posterior input sizes di ers fromthe', 1);('softmax attention normalization matrix end', 1);('attention softmax attention', 1);('nite limit inputsizes drawing connection nonparametric conditional density estimation otherwords softmax attention recovers latent posterior approximation errorthat', 1);('input sizes characterizes performs relational inferenceover', 1);('long sequences byproducts', 1);('multiple attention headsin transformers', 1);('causal interpretation', 1);('representation throughinstrumental variablesgiven', 1);('b quanti es approximation error latent posteriorit', 1);('parameter attention mechanism', 1);('objectivesallow empirical risk minimization', 1);('parameter generalization errorwhich', 1);('particular maximum likelihood estimationwe', 1);('connection latent posterior', 1);('objective isde', 1);('empirical risk', 1);('objective attains generalizationerror', 1);('independent input sizes justi es transformers', 1);('sequencesour proof exploits invariance equivariance attention mechanism entrywisefeedforward neural networks deviates', 1);('analyses generalizationerror', 1);('setting eg', 1);('mae', 1);('identifya condition number', 1);('conditionnumber quanti es amount information', 1);('new taskmeanwhile', 1);('optimal attention mechanism entrywisefeedforward neural networks su\x0ecient expressive power result stochastic gradientdescent nds', 1);('objective generalizes', 1);('analysis approximation generalization optimization errorsin', 1);('complete characterization attention mechanismcontribution summary theoretical contribution threefoldi identify general principle', 1);('learning objectives', 1);('latent posterior inference', 1);('minimal assumption ofdata contrast', 1);('classical learning paradigms latent', 1);('overinput tokens', 1);('data point captures relational inductive biasesii', 1);('attention mechanism speci c parameterization latent posteriorinference', 1);('nonparametric conditional density estimation', 1);('latent posterior inference learnable4parameter determines kernel functioniii characterize approximation generalization optimization errors', 1);('learnable parameter attention mechanism', 1);('input sizes degrade approximation andgeneralization errors justi es transformers', 1);('sequencesdiscussion theoretical analysis casts attention mechanism greybox approach', 1);('aprobabilistic model input tokens', 1);('data point whitebox learnableparameter', 1);('endtoend manner empirical risk minimization blackbox', 1);('theoretical analysis studies class oftransformers', 1);('autoregressive structure', 1);('gpt brown', 1);('hand general principle identi', 1);('applicable toother probabilistic models', 1);('general graphical models treesand grids motivates', 1);('attention mechanismwe', 1);('workstransformers attention', 1);('transformers rst time highlights key role attention mechanism', 1);('subsequently', 1);('vast body', 1);('various transformer architectures anddi erent', 1);('radford', 1);('references therein', 1);('signi cant empirical', 1);('wolf', 1);('protein structureprediction', 1);('jumper', 1);('sequential decision making', 1);('ourwork', 1);('theoretical justi cation transformers attention mechanism thatis latent', 1);('transformers attention', 1);('recent line worksthat analyze transformers attention mechanism', 1);('weiet', 1);('continuityof transformers', 1);('particle systems', 1);('littwin', 1);('nitewidth limit transformers framework neural tangent kernels', 1);('neural tangent kernels', 1);('parameter update', 1);('asparse function input tokens', 1);('sample complexity scales logarithmicallyin input sizes', 1);('wei', 1);('characterize approximation generalization errorsfor learning', 1);('machine transformers', 1);('transformerscan infer latent', 1);('variable concept', 1);('data distribution mixtureof', 1);('toperform linear predictions', 1);('data point incontext manner', 1);('empirical performance transformers learning equality groupoperationsour work', 1);('complete characterization representation inference learning aspects attention mechanism', 1);('lens exchangeability latent variablemodels', 1);('minimal assumption data distribution exchangeabilityspeci', 1);('attention mechanism parameterizes nonparametric conditional density estimation', 1);('approximates kernel conditional', 1);('infers conditional', 1);('invoke latent', 1);('exchangeability tojustify attention mechanism speci c parameterization latent posterior inferencemeanwhile leverage latent', 1);('common choice', 1);('objectives eg', 1);('objective comparison', 1);('speci c form mixture ofhidden', 1);('models latent posterior', 1);('priori speci c parameter', 1);('latent posterior inference approximation error', 1);('objective allowsus', 1);('infer latent posterior generalization optimization errorsalso', 1);('focus class transformers likegpt', 1);('focus class transformers likebert', 1);('invariance equivariance transformersand', 1);('independent input sizesgeneralization', 1);('vast body ofworks analyze generalization error', 1);('jiang', 1);('comprehensive introduction', 1);('invariance equivariance result', 1);('direct application suchresults yields vacuous', 1);('input sizes increase hand', 1);('sokolic', 1);('sannai', 1);('elesedy', 1);('generalizationerror captures improvement invariance equivariance', 1);('applicable attention mechanism theoretical analysis generalizationerror', 1);('addition concurrent work', 1);('pacbayes', 1);('analysis generalization error attention mechanism thecontext multiagent reinforcement learningoptimization', 1);('vast body worksthat analyze optimization error', 1);('allenzhu', 1);('zou', 1);('zou gu2019 allenzhu', 1);('cao gu', 1);('li liang', 1);('chizat', 1);('rotsko vandeneijnden', 1);('nguyen', 1);('sirignano', 1);('neural networks neuraltangent kernel', 1);('eld regime', 1);('mei', 1);('work analyzesthe optimization error neural tangent kernel regime', 1);('theoretical analysis approximationand generalization errors', 1);('neural tangent kernel regimeinvariance', 1);('equivariance deep neural networks', 1);('arecent line', 1);('deep neural networks invariance equivariance respectto permutations group operations', 1);('zaheer', 1);('lee', 1);('keriven peyr\x13', 1);('romero cordonnier', 1);('bloemreddy teh', 1);('hutchinson', 1);('satorras', 1);('kossen', 1);('2021and references therein', 1);('han', 1);('survey comparison', 1);('complete characterization representation inference learningaspects attention mechanism2', 1);('preliminarynotations', 1);('l index setf12lgfor anyl2n vector v2rl', 1);('softmax v expvpl01expv02l2rlthe softmax functionwe', 1);('byk\x01k 2the spectral norm', 1);('fthe frobenius', 1);('norm d2n', 1);('sd\x001fx2rdjkxk2', 1);('1gthe d\x001dimensional unit', 1);('kernel hilbert', 1);('lethxbe hilbert', 1);('space domain', 1);('whichcontains functions fxrand', 1);('inner product h\x01\x01ihx', 1);('kx\x02xrifwe', 1);('property hfkx\x01ihxfx anyf2hxandx2xanrkhshxis', 1);('x2such kxx0', 1);('x x0for anyxx02xmuandet', 1);('2the space', 1);('squaresummable seriesattention', 1);('mechanism', 1);('input tokens x27rd', 1);('key matrix', 1);('k2rl\x02dpand', 1);('value matrix', 1);('v2rl\x02dde', 1);('ask k1kl\x00k\x12x1k\x12xl\x012rl\x02dpv v1vl\x00v\x12x1v\x12xl\x012rl\x02dherek\x12rdrdpandv\x12rdrdmap theth input', 1);('token xto key kand thevaluev', 1);('learnable parameter query q2rdpwe', 1);('ne attention mechanism followsattn qkv', 1);('vnorm\x00kkq\x012rd', 1);('kkq kkq2l2rlhere', 1);('rlrla', 1);('normalization mappinga', 1);('common example attention mechanism softmax attention', 1);('al2017 kernel function exponential kernel', 1);('softmax normalizationnorm', 1);('sm\x00kkq\x01\x001kkq\x01\x001\x01kkqthe', 1);('exponential kernel softmax normalizationis softmax attention', 1);('smqkv vnorm sm\x00kexpkq\x01softmax kq', 1);('representation inference estimationvia latent', 1);('modelfrom exchangeability latent', 1);('input sequencexfxg2l wherex2rdis input', 1);('l2nis', 1);('sequence length', 1);('innatural', 1);('language processing', 1);('embeddings words aparagraph computer vision', 1);('embeddings patchesin imageas case', 1);('variable sequence fxg2nis', 1);('sequencelengthl2nand index permutation \x19 thatpx1x2xl', 1);('px\x191x\x192x\x19lin', 1);('index order', 1);('variable sequence nota ect joint distribution', 1);('proposition states exchangeability arandom', 1);('variable sequence induces latent variable8proposition', 1);('finetti representation theorem', 1);('letfxg2nbean', 1);('exchangeable sequence exists latent', 1);('variable zsuch sequencelengthl2npx1xl', 1);('zly1pxjz\x01pzdzpxjx1x\x001x1xl zpxjz\x01pzjx1x\x001x1xldz82lwe', 1);('exchangeable sequence toan approximation error nitelength', 1);('induces latent variablediaconis', 1);('freedman', 1);('case theinput sequence', 1);('illustration exchangeabilityx1xlx2uni22efuni22efxuni2113raw', 1);('inputx1xlx2uni22efuni22efxuni2113e1ele2euni2113exchangeable inputeuni2113positional encodingele1e2figure', 1);('raw version', 1);('exchangeable positional encodings practice positional', 1);('incorporatedin additive manner', 1);('guarantees existence latent', 1);('variable forms basis ofour theoretical analysis', 1);('2a illustration', 1);('latent variablecan', 1);('concept input sequence', 1);('words orpatches instance', 1);('variable instantiates meaning paragraphwhile', 1);('variable instantiates theme image', 1);('particular thelatent posterior', 1);('plays key role', 1);('tasks song', 1);('2b anillustration', 1);('pz\x01jxis', 1);('minimal su\x0ecient statistic', 1);('fisher', 1);('minimal su\x0eciency latent posterior letzbe', 1);('variable inducedby exchangeability input sequence', 1);('isa minimal su\x0ecient statistic input sequence', 1);('xfor', 1);('meanwhilefor', 1);('variable ythat', 1);('invertibility operator', 1);('tde', 1);('zpyjzfzdzthen', 1);('minimal su\x0ecient statistic inputsequencexfor target', 1);('variable yproof', 1);('seeb3', 1);('model learning objectives', 1);('considerthe prediction task', 1);('ybethe target', 1);('xfxg2lis', 1);('token input sequence', 1);('corresponding class', 1);('weremark vit', 1);('unknown label ycorresponds', 1);('whilethe input class', 1);('corresponds mask', 1);('cases concatenationfyx1xlgis', 1);('zpyjz\x01pzjxdz', 1);('31wherezis latent', 1);('yas target', 1);('variable satis es', 1);('speci es thatyis', 1);('lemma32', 1);('latent posterior bzx minimal su\x0ecient statistic', 1);('wordsthe latent posterior bzx', 1);('x according', 1);('to31 prediction target', 1);('variable yfrom input sequence', 1);('xforward', 1);('implicit steps inference latent posterior', 1);('ii prediction', 1);('pzjxto', 1);('construct learning objective', 1);('distribution target', 1);('xand', 1);('p\x12yjx', 1);('thelearnable parameter', 1);('wherexiis theith input sequenceandyiis theith target', 1);('variable maximum likelihood estimation', 1);('objective takesthe', 1);('nebexy\x18dn\x01 empirical expectation respect dataset', 1);('dn10x1xlzmaskx2xa prediction', 1);('maskedtoken xx1xlzx2uni22efuni22efxuni2113yb', 1);('prediction', 1);('token xand target variabley prediction ytakes', 1);('steps inference latent posterior', 1);('andii prediction', 1);('pzjx31 preliminary finitedimensional examplelatent', 1);('gaussiandistributed', 1);('xfxg2land', 1);('variable wherex2rdandy2rd input sequence', 1);('example latent variablemodel 31rzc\x0f wherecc\x03x rr\x03x82l 33herez2rdr\x02dcis latent', 1);('exchangeability input sequencec2rdcandr2rdrare covariate response', 1);('unknown functions c\x03rdrdcandr\x03rdrdr and\x0f\x18n0\x1b2i thenoise', 1);('independent c practice covariate cinstantiates contextualinformation response rinstantiates semantic information', 1);('unknown target', 1);('token input sequencewhile mskis positional', 1);('yis label input sequence mskis class', 1);('prediction model yrmsk wherermskis', 1);('covariate cmskof input mask thatyrmskzcmsk\x0f wherecmskcm\x03msk 34herecm\x03rdrdcis', 1);('unknown function \x0f\x18n0\x1b2i noise isindependent cmsk example', 1);('xfx1xlgcmskcl1', 1);('variable yrmskrl1', 1);('nitedimensional example show cmskc andrcorrespond querythe key value attention mechanism respectivelynote regression model', 1);('conditional model', 1);('theconditional distribution ygivenxas', 1);('model conditional distribution ygivenxandmsk', 1);('generative distributiontakes', 1);('formpyjmskzexp\x10\x00 y\x00zcm\x03msk 22\x0e2\x1b2\x11 35we', 1);('latent posteriorpzjx', 1);('formpzjxexp\x10\x00 z\x00\x16zx 22\x0e2\x132\x11 36here covariance latent posterior', 1);('\x16 zx thelatent posterior', 1);('ezjx rcc\x15i\x001cwhere', 1);('ne c c1cl2rl\x02dcandr r1rl2rl\x02dr', 1);('combining', 1);('zpyjmskz\x01pzjxdzexp\x10\x00', 1);('y\x00\x16zxcm\x03msk 22\x0e2e\x1b2\x1137which corresponds', 1);('approximate covariance', 1);('xandmskbye\x1b2i', 1);('bayesianmodel', 1);('wasserman', 1);('data pointparameterization', 1);('model recall', 1);('c\x03r\x03 andcm\x03in', 1);('unknown parameterize c\x12r\x12 andcm\x12 where\x122\x02 learnableparameter', 1);('ideal parameter \x12\x032\x02', 1);('2l thatc\x12\x03x c\x03x c r\x12\x03x r\x03x r cm\x12\x03msk cm\x03msk cmsk 38by', 1);('parameterize latent posterior', 1);('followsp\x12zjxexp\x10\x00 z\x00\x16z\x12x 22\x0e2\x132\x11 39where \x16z\x12x', 1);('follows\x16z\x12x r\x12x\x00c\x12xc\x12x\x15i\x01\x001c\x12x12herec\x12x c\x12x1c\x12xl2rl\x02dcandr\x12x r\x12x1r\x12xl2rl\x02dr', 1);('by35', 1);('parameterize generative distribution', 1);('pyjmskz', 1);('followsp\x12yjmskzexp\x10\x00 y\x00zcm\x12msk 22\x0e2\x1b2\x11by', 1);('ne conditional likelihood', 1);('pyjmskx', 1);('followsp\x12yjmskxexp\x10\x00 y\x00\x16z\x12xcm\x12msk 22\x0e2e\x1b2\x11', 1);('testing', 1);('training phase', 1);('weaim maximize', 1);('objective isequivalent', 1);('error followsmin\x12bexy\x18dnh y\x00\x16z\x12xcm\x12msk 22i 311note', 1);('learnable parameter \x12is', 1);('di erent data points datasetdnthrough backward pass latent', 1);('variable zis', 1);('data pointxiyi', 1);('remark learning \x12 model learns performbayesian model', 1);('estimator b\x12', 1);('xyand', 1);('input mask msky', 1);('posterior yby argmaxypb\x12yjmskyxy', 1);('ermskjmskyxy', 1);('\x16zb\x12xycmb\x12msky 312we remark learning process attention mechanism involves', 1);('data point infer latent posterior', 1);('predictthe target', 1);('variable backward pass estimate', 1);('learnable parameter \x12acrossdi erent data points', 1);('pass predict', 1);('pass estimate', 1);('forward', 1);('xy', 1);('infer latent posterior', 1);('p\x12zjxby', 1);('backward', 1);('di erent data points thedatasetdn estimate', 1);('learnable parameter \x12by 311the nitedimensional example illustrates greybox approach', 1);('learnable parameterin', 1);('endtoend manner empirical risk minimizationblackbox', 1);('rst infers latent', 1);('variable zandthen utilizes latent', 1);('variable zto', 1);('backward pass estimatessthe', 1);('nitedimensional exampleto', 1);('nitedimensional setting recovers attention mechanism particularwe', 1);('attention mechanism infers latent posterior', 1);('data pointalso show covariate corresponds query key responsecorresponds value attention mechanism14inputinputtolatentx1xlzlatenttotargetyexchangeablesupervisedselfsuperviseddownstreammaskfigure', 1);('dotted', 1);('arrows stand forwardpasses inputlatenttarget', 1);('arrows stand backward', 1);('masksgrey', 1);('yellow box4', 1);('attention latent posterior inferencein', 1);('attention mechanism performs latent posteriorinference latent', 1);('exchangeability inputsequence', 1);('nitedimensional example', 1);('avariant softmax attention', 1);('infers latent posterior', 1);('weprove softmax attention limit', 1);('attention sequencelength', 1);('nity implies softmax attention', 1);('infers thelatent posterior41', 1);('attention kernel conditional mean embeddingadvanced', 1);('example', 1);('nitedimensional version ofthe', 1);('preliminary example', 1);('similarlyto', 1);('model input sequence', 1);('inputtokenx2rdrz c \x0f wherecc\x03x rr\x03x82l 41herec2rdpandr2rdare covariate response', 1);('unknown functions c\x03rdrdpandr\x03rdrd', 1);('rdphcis', 1);('rkhs hczhcrdis', 1);('exchangeability input sequence', 1);('independent covariate c', 1);('that15 c1 c2', 1);('kc1c2', 1);('kernel functionof', 1);('rkhshc', 1);('common example', 1);('radial basis function', 1);('kernelkrbfqk exp\x00kq\x00kk222', 1);('unknown target variableyis', 1);('input mask msk satis esyrmskz cmsk \x0f wherecmskcm\x03msk 42here', 1);('cmskandrmskthe covariate response', 1);('corresponding inputmsk', 1);('unknown function \x0f\x18n0\x1b2i', 1);('gaussiannoise', 1);('independent cmsk simplify presentation view', 1);('rkhs hcasa', 1);('vector space', 1);('correspondingly', 1);('view latent', 1);('variable zas matrixinrd\x02d', 1);('present rigorous characterization zinb1', 1);('parameterize c\x03r\x03 andcm\x03byc\x12r\x12 andcm\x12 where\x122\x02is', 1);('viabrermskjmskxr\x12x\x10 \x00c\x12x\x01 \x00c\x12x\x01\x15i\x11\x001 \x00c\x12x\x01 \x00cm\x12msk\x01r\x12x\x10k\x00c\x12xc\x12x\x01\x15i\x11\x001k\x00c\x12xcm\x12msk\x01 43where', 1);('kc\x12xc\x12x kc\x12xic\x12xjij2l2rl\x02lkc\x12xcm\x12msk kc\x12xcm\x12msk2l2rl', 1);('c\x12x c\x12x1 c\x12xl2rl\x02d andr\x12x r\x12x1r\x12xl2rl\x02d remark', 1);('recovers empirical version thekernel conditional', 1);('prjcsong', 1);('prjcthe', 1);('conditional distribution rgivencas', 1);('data pointandhr', 1);('rd\x03rdis', 1);('dual space', 1);('rdequipped euclidean', 1);('kernel h\x01\x01ifrom', 1);('model attention recall', 1);('attention mechanism isde', 1);('q2rdpk k1kl2rl\x02dp andv v1vl2rl\x02dthe kernel conditional', 1);('cmenormalizationnorm cme\x00kkq\x01\x00kkk', 1);('\x15i\x01\x001kkq 44where', 1);('kkq kkq2l2rlandkkk kkikjij2l\x02l2rl\x02lwe', 1);('cmeqkv vnorm cme\x00kkq\x01v\x00kkk', 1);('\x15i\x01\x001kkq2rd 45we', 1);('attention recovers', 1);('whenqcm\x12msk kc\x12x vr\x12x82l 4616we remark', 1);('establishes connection latent', 1);('variable model theattention mechanism words covariate cmskof input mask mskcorrespondsto query q covariate cof input', 1);('token xcorresponds key kfor2land response rof input', 1);('token xcorresponds value vfor2l theattention mechanism', 1);('q\x12rdrdpk\x12rdrdp andv\x12rdrdthemappings input', 1);('token query key value', 1);('thelearnable parameter \x12', 1);('correspondenceq\x12cm\x12 k\x12c\x12 v\x12r\x12in', 1);('common example instantiate q\x12k\x12 andv\x12forx2rdas followsq\x12x', 1);('wqnnxa', 1);('wknnxa', 1);('wvnnxa47wherewqwk2rd\x02dpandwv2rd\x02dare', 1);('rdrdthe', 1);('feedforward neural network', 1);('aand', 1);('learnable parameter \x12', 1);('awqwkwv similarly', 1);('formmin\x12bexy\x18dn\x14 y\x00attn', 1);('cme\x00q\x12mskk\x12xv\x12x\x01', 1);('22\x15 48where', 1);('k\x12x k\x12x1k\x12xl2rl\x02dpandv\x12x v\x12x1v\x12xl2rl\x02dlimit', 1);('cme attention l1', 1);('xfxg2l', 1);('weconsider keyvalue pairs', 1);('kk\x12x andvv\x12x fora xed\x12 notational simplicity', 1);('kandvthe', 1);('random variables thesame distribution kv', 1);('attention approximates thekernel conditional', 1);('pvjkasl1', 1);('variable model 41proposition', 1);('cme attention converges kernel conditional mean embedding letkbe', 1);('nite kernel function', 1);('fxg2lin input sequence', 1);('xareindependent', 1);('1\x00\x0ethat attn', 1);('cmeqkv', 1);('\x00evjk q 2o\x00l\x0012\x01log1\x0e \x15\x018q2rdpproof', 1);('seeb4', 1);('cmeis', 1);('variant softmax attention', 1);('vaswaniet', 1);('di erent normalization', 1);('thesoftmax attention limit', 1);('attention sequence length', 1);('lgoesto', 1);('softmax attention infers latent posteriorin41', 1);('variable model motivates design', 1);('cmeattention recall', 1);('attention mechanism form', 1);('q2rdpk2rl\x02dp andv2rl\x02d practice', 1);('common normalization', 1);('smkkq', 1);('\x001lkkq\x01\x001\x01kkq 49where 1l2rlis theldimensional allone vector recall', 1);('kkq kkq2l2rl', 1);('smthe', 1);('attention mechanism normalization', 1);('whenthe', 1);('kernel function exponential kernel', 1);('expkq anyqk2rdpanda', 1);('smqkv vnorm sm\x00kexpkq\x01vsoftmax kq', 1);('410which recovers softmax attention', 1);('provethat sequence length', 1);('nity softmax attention attn', 1);('smhas', 1);('cmesoftmax attention limit cme attention l1first', 1);('wedemonstrate softmax attention', 1);('conditional kernel density estimator ofpvjk', 1);('ne conditional kernel density estimator', 1);('followsbpkvjkvjkpl1kkk\x01kvvpl1kkk 411a', 1);('common choice kernel function', 1);('krbfqk', 1);('exp\x00kq\x00kk222 remark', 1);('involves kernelfunction', 1);('k\x01\x01', 1);('normalize queryq keyk value vso thatqk2sdp\x001andv2sd\x001', 1);('sdp\x001andsd\x001are', 1);('dp\x001dimensional d\x001dimensional unit spheres', 1);('unitsphere exponential kernel', 1);('exp qk', 1);('c\x01exp\x00kq\x00kk222', 1);('proposition proves attentionmechanism', 1);('outputs conditional kernel density estimator', 1);('thesame limit', 1);('l1 proposition', 1);('softmax attention converges kernel conditional mean embedding recall', 1);('smqkv czsd\x001v\x01bpkvjkvjqdvwherec', 1);('condition bpkvjkvjkpvjkvjk', 1);('smqkv c\x01evjk', 1);('seeb5', 1);('proofwe remark uniform convergence bpkvjkvjkpvjkvjk', 1);('de gooijer zerom', 1);('smand cme', 1);('attention captures latent posterior', 1);('41we conclude softmax attention', 1);('captures latent posterior approximatelymoreover terms', 1);('q highlight impliesthe necessity', 1);('multiple heads connects attention mechanism causalinference', 1);('discussionu1d68au1d69du1d69du1d697u1d672u1d67cu1d674u1d68au1d69du1d69du1d697u1d682u1d67cu1d53cu1d4b1uni007cu1d4a6qproposition 42proposition 41figure', 1);('smand cmeattention', 1);('q asl1', 1);('excess risk analysisto', 1);('theoretical bene t', 1);('latent posterior inference thetransformer architecture', 1);('present compact version excess risk analysis onelayersinglehead softmax attention neural networks', 1);('c detailedanalysis', 1);('complete setup transformer architectureattention', 1);('neural network', 1);('specify feedforward neural network', 1);('relu ax1 relu', 1);('\x01 recti', 1);('linear unit', 1);('activation thatoperates elementwise rest paper', 1);('attention neural networkswith nal aggregation layer', 1);('function class attention neural networksfattnnagg\x120\x0eattn', 1);('sm\x00q\x12mskk\x12xv\x12x\x01\x12', 1);('\x120awqwkwv2\x02o51where agg\x120rdrdyis output layer', 1);('smis', 1);('awqwkwv', 1);('47to characterize excess risk specify parameter space', 1);('fattna', 1);('nite capacity1here', 1);('feedforward neural networks', 1);('bias terms19assumption', 1);('parameter', 1);('\x12 \x120awqwkwv2\x02 thatkwqk2\x14kwkk2\x14kwvk2\x14kak2\x14 kwqkf\x14rattnkwkkf\x14rattnkwvkf\x14rattnkakf\x14rnnwhere', 1);('rattnrnn0', 1);('absolute constantsexcess', 1);('risk following', 1);('learning objective', 1);('ky\x00fxk22forf2f attn whereyis target', 1);('training dataset', 1);('dnfxiyigi2nis', 1);('onthe product space', 1);('xl\x02y', 1);('wherexl\x08x2rl\x02d max2lkxk2\x14r', 1);('y\x08y2rdykyk2\x141', 1);('excess risk', 1);('eelxybf\x00elxyf\x03 e\x01', 1);('thepopulation expectation data distribution', 1);('herebf2f', 1);('attnis attention neuralnetwork', 1);('empirical risk belxyf training processwherebe\x01 empirical expectation training dataset', 1);('dn heref\x03x eyjxis', 1);('regression function aim approximate words f\x03is optimalmodel minimizes population risk', 1);('elxyfto', 1);('analyze excess risk', 1);('termseehl\x00xybf\x01i\x00behl\x00xybf\x01ibehl\x00xyef\x01i\x00minf2fattnehl\x00xyf\x01i z', 1);('egen generalization error53', 1);('minf2fattnehl\x00xyf\x01i\x00ehl\x00xyf\x03\x01i z', 1);('eapprox approximation errorbehl\x00xybf\x01i\x00behl\x00xyef\x01i', 1);('eopt optimization errorwhereef', 1);('argminf2fattnbelxyf attention neural network minimizes theempirical risk', 1);('fattnin5153', 1);('terms righthand side', 1);('analysis approximation error', 1);('generalization error analysisrecall', 1);('exponential kernel whichis', 1);('kernel qandkare unit sphere', 1);('sdp\x001 also20note', 1);('vector 2norm scales dimension dpat rate ofpdp rest thepaper', 1);('kernel inputs', 1);('pdp iekqk exp\x00\x00kqpdp\x00kpdpk222\x01 exp\x00\x00kq\x00kk222dp\x01 54under', 1);('ne maxf g\x14 maxfrnnrattnrattn2g and\x10rattn', 1);('thatfattnis family attention neural networks', 1);('weprovide', 1);('egentheorem', 1);('generalization error letd', 1);('suppose assumptions5152', 1);('agg\x120is 1lipschitz output range', 1);('\x0e 0it', 1);('\x00\x0ethategeno\x12dpn\x01\x02plog1 plog1 \x10r plog1 \x14\x10\x03rlog1\x0en\x13proof', 1);('seec', 1);('important implication', 1);('generalization error attentionneural networks degrade sequence length', 1);('rnnrattn', 1);('crucial roles theoreticalanalysis generalization error', 1);('architecture design', 1);('original transformer speci c observe', 1);('rnn', 1);('andrattnand ii layer normalizations', 1);('rwhen', 1);('multilayer composition manyattention mechanisms', 1);('analysis generalization error thecomplete setup transformer architecture', 1);('approximation error analysisin', 1);('characterize approximation error', 1);('target', 1);('aim approximate regression function f\x03x', 1);('eyjxwith', 1);('attention neural network f\x122f attn', 1);('regressionfunctionf\x03x optimal model sense minimizes population riskelxyf', 1);('input mask mskand latent', 1);('variable zaregiven target', 1);('eyjx ezjx\x02eyjmskz\x03zeyjmskzzg\x03zmsk', 1);('latenttotarget\x01pzjxdz 5521here latenttotarget', 1);('function whichmaps latent', 1);('variable zto target', 1);('variable ygiven input mask msk otherhand latent posterior', 1);('encodes input sequence', 1);('xinto', 1);('variable zwe note input mask mskdescribes prediction task', 1);('forexample', 1);('input mask mskcorresponds class', 1);('setting orthe positional', 1);('regression function f\x03x involves capturingi latent posterior', 1);('ii latenttotarget', 1);('variable zsummarizes concept input sequence', 1);('xwhile', 1);('corresponding ii target', 1);('variable yand input mask mskspecify prediction task', 1);('central role latenttotarget mappingg\x03zmsk attention neural networks aim approximateapproximation', 1);('surrogate', 1);('wattn cme\x00q\x03mskk\x03xv\x03x\x0156as', 1);('surrogate function', 1);('regression function f\x03x', 1);('w2rd\x02dysatis', 1);('eskwkf1 sequel demonstratethat latenttotarget function', 1);('fywxmsk approximates latenttotargetmappingg\x03zmsk key component regression function f\x03x 43and', 1);('cme\x00q\x03mskk\x03xv\x03x\x01wevmskjmskxwzevmskjmskzz', 1);('zmsk latenttovalue\x01pzjxdz57whereq\x03msk andvmskreplacecm\x03msk andrmskin', 1);('56we obtainfywxmsk', 1);('zw', 1);('zmskzgywxmsk\x01pzjxdzezjx\x02gywzmsk\x03 58wheregywzmsk latenttotarget function', 1);('w2rd\x02dyfollowing', 1);('nitedimensional counterpart', 1);('attentioncaptures latent posterior', 1);('gaussian comparing', 1);('cmeattentionfywxmsk', 1);('performs latenttotarget', 1);('gywzmsk plays thesame role latenttotarget', 1);('characterize theexpressity function classgy\x08gywzmsk w zmsk', 1);('w2rd\x02dykwkf1', 1);('5922in terms', 1);('g\x03zmsk 55to characterize function class', 1);('gyde', 1);('ne function classgyifgywizmsk wi zmsk wi2rdkwik21 510which', 1);('ith entry latenttotarget function gywzmsk2gy', 1);('herei2dy', 1);('andw w1wdy', 1);('gyiis rkhshltvinducedby', 1);('kernelhere latenttovalue', 1);('visualization construction', 1);('hltvu1d696u1d69cu1d694zzuni2032', 1);('reweighted', 1);('beliefgwizu1d696u1d69cu1d694uni03c8zuni2032 u1d696u1d69cu1d694uni2119zuni007cxzyiuni22efx1xlx2xu1d53cyiuni007cu1d696u1d69cu1d694zgizu1d696u1d69cu1d694uni03a0uni210bu1d67bu1d683u1d685uni221eprojectionlatent posteriorlatenttotargetfigure', 1);('rkhs hltvinduced', 1);('zmsk inputmask mskdescribes prediction task determines', 1);('rkhs hltvtherefore', 1);('ithentryg\x03izmsk latenttotarget', 1);('fundamental hardness recovery taskassumption', 1);('input mask msk letgywi\x01msk \x05hltv1\x00g\x03i\x01msk\x01 argmingi\x01msk2h', 1);('g\x03i\x01msk\x00gi\x01msk 1be the1norm projection ith entryg\x03izmsk latenttotarget mappingg\x03zmsk', 1);('exists \x0fgmsk201 thatdyxi1 g\x03i\x01msk\x00gywi\x01msk 21\x14\x0f2gmskhere the1norm', 1);('variable z23recall function class attention neural networks', 1);('fattnis', 1);('wehave', 1);('approximation error letfgywizmsk', 1);('wi zmskgi2dybe functionclass', 1);('ne w w1\x01\x01\x01wdy', 1);('existsf\x122f attnand\x0fattn201 thatsupx2xl f\x12xmsk\x00wattn', 1);('cme\x00q\x03mskk\x03xv\x03x\x01', 1);('2\x14\x0fattn 511wherexlis', 1);('haveeapprox\x142\x0f2gmsk 2\x0f2attnproof', 1);('seee2', 1);('proofthe approximation error', 1);('involves recovery gap \x0fgmsk andthe surrogate approximation error \x0fattn', 1);('attention recovery gap \x0fgmsk function class', 1);('gyin', 1);('central role theapproximation error', 1);('hand approximation error \x0fattnbetweenattention neural networks', 1);('fattnand', 1);('optimization error analysissince', 1);('learning objective attention neural networks nonconvex respect theparameter\x12', 1);('property stationary points', 1);('b\x12 b\x120bacwqcwkcwvbe stationary point empirical risk belxyf', 1);('r\x12behl\x00xyfb\x12\x01i\x12\x00b\x12 \x1508\x122\x02 512which', 1);('training process ie bffb\x12', 1);('theregression function f\x03x', 1);('minimizer population risk', 1);('elxyfwe', 1);('optimization error', 1);('eopt', 1);('nedin 53proposition', 1);('optimization error suppose assumption', 1);('holdsthateopt\x144\x01min\x122\x02beh fb\x12x r\x12fb\x12x\x12\x00b\x12\x00f\x03x 2i 513proof', 1);('seed', 1);('proof24the righthand side', 1);('quanti es expressity function class', 1);('bythe local linearization\x08fb\x12x r\x12fb\x12x\x12\x00b\x12 \x122\x02', 1);('neural tangent kernel', 1);('ntk', 1);('thatf\x03x fb\x12x r\x12fb\x12x\x12\x00b\x12 o18x2rl\x02dwhere theo1 error captures', 1);('local linearization error', 1);('analysis aconsequence optimization error satis es', 1);('eopto1', 1);('global optimal result shows theoretical bene t incorporatingfeedforward neural networks architecture design', 1);('analysis involvesa random initialization', 1);('ntkbasedanalysis', 1);('training transformer', 1);('initialization inthe', 1);('supervised learning selfsupervised learningan', 1);('important aspect attention mechanism', 1);('sequence embeddingby', 1);('capability fordiverse', 1);('learning anddownstream prediction', 1);('process followspt', 1);('pretraining', 1);('process train attention neural network bfptxmsk', 1);('pt2fptwith', 1);('parameter b\x12ptto', 1);('token xl2rd', 1);('xfxg2l\x001and', 1);('input maskmsk', 1);('function class attention neural networks', 1);('sm\x00q\x12msk ptk\x12xv\x12x\x01\x122\x02pto', 1);('61where aggpt\x12rdrdis aggregation layer', 1);('process inputmask msk', 1);('ptis', 1);('token xlds', 1);('downs', 1);('tream task', 1);('parameter b\x12ptand train', 1);('ds2f dswith', 1);('parameter b\x12dsto', 1);('variable yds2rdyfrom', 1);('x25fxg2l\x001and', 1);('function class attention neuralnetworks', 1);('sm\x00qb\x12ptmsk dskb\x12ptxvb\x12ptx\x01\x122\x02dso', 1);('aggregation layer aggdsb\x12dsrdrdyreplaces aggregationlayer', 1);('taskthe input mask msk', 1);('dsis', 1);('variable ydswith', 1);('full input sequence', 1);('xreplaced', 1);('process decomposition ofthe excess risk', 1);('risk decomposition', 1);('process havethe characterization generalization error optimization error thosein', 1);('input sequences', 1);('previous analysis thegeneralization error', 1);('process otherhand', 1);('independent set', 1);('inputsequences modify', 1);('previous analysis', 1);('generalization error onlyscales complexity measure eg', 1);('number function class faggds\x12\x122\x02dsgof aggregation layers', 1);('attention mechanism asb\x12ptis frozen', 1);('attention neural network bfptxmsk', 1);('pretrainingprocess approximation error', 1);('setting characterizethe approximation error', 1);('process analyze approximation error thedownstream task', 1);('error', 1);('ne regressionfunction latenttotarget', 1);('process followsf\x03ptx', 1);('eyptjx', 1);('pt eyptjmsk ptz', 1);('regression function latenttotarget', 1);('thedownstream task followsf\x03dsx', 1);('eydsjx', 1);('ds eydsjmsk dsz', 1);('64in parallel', 1);('surrogate functions', 1);('task followsfywptxmsk', 1);('pt wptattn cme\x00q\x03msk ptk\x03xv\x03x\x01fywdsxmsk ds wdsattn cme\x00q\x03msk dsk\x03xv\x03x\x01', 1);('surrogatefunction bridge regression function attention neural network', 1);('parallel latenttovalue', 1);('we26de ne latenttovalue mappings', 1);('task asfollows', 1);('ptzmsk pt evmsk ptjmsk ptz dszmsk ds evmsk dsjmsk dszwherevmsk ptandvmsk dsreplacermskin', 1);('kernelfunctions followskptzz0msk', 1);('pt ptzmsk pt ptz0msk ptkdszz0msk ds dszmsk ds dsz0msk dswhich', 1);('rkhss hptandhds corresponding', 1);('pt zwpt ptzmsk ptzgywptxmsk pt\x01pzjxdzezjx\x02gywptzmsk pt\x03fywdsxmsk ds zwds dszmsk dszgywdsxmsk ds\x01pzjxdzezjx\x02gywdszmsk ds\x03', 1);('66note thatfywptxmsk', 1);('share latent posterior', 1);('previous arguments following58510', 1);('recoverthe latenttotarget mappings', 1);('rkhss hptandhds', 1);('7for illustration construction', 1);('rkhss hptandhds27uni2119zuni007cxzyu1d67fu1d683iuni22efx1xl1x2xu1d53cyu1d67fu1d683iuni007cu1d696u1d69cu1d694u1d67fu1d683zgu1d67fu1d683izu1d696u1d69cu1d694u1d67fu1d683latent', 1);('rkhss hptandhdsinduced', 1);('ptzmsk ptand dszmsk ds', 1);('ptand', 1);('dsdescribe', 1);('correspondinglythe1norm projections \x05', 1);('hpt1and', 1);('61in parallel', 1);('assumption fundamentalhardness', 1);('latenttotarget mappings', 1);('rkhss hptandhdsassumption', 1);('ptandmsk ds', 1);('pt2h pt', 1);('pt\x00gi\x01msk pt', 1);('ds\x01', 1);('ds\x00gi\x01msk ds', 1);('pt\x00gi\x01msk ds', 1);('1be the1norm projections ith entryg\x03ptizmsk', 1);('latenttotarget mappingg\x03ptzmsk', 1);('rkhshpt', 1);('theith entryg\x03dsizmsk', 1);('theith entryg\x03ptizmsk', 1);('rkhshds', 1);('statementsholdpt exists \x0fgmsk', 1);('pt201', 1);('pt\x00gywpti\x01msk pt', 1);('6728ds exists \x0fgmsk', 1);('ds201', 1);('thatdyxi1 g\x03dsi\x01msk', 1);('68ssl exists \x0fsslmsk', 1);('ptmsk ds201', 1);('pt\x00gywssli\x01msk ds', 1);('69here the1norms', 1);('ptzmsk pt', 1);('dszmsk ds', 1);('characterizes thefundamental hardness', 1);('capability sequence', 1);('process thedownstream task words', 1);('thedownstream task', 1);('approximate theith entry latenttotarget', 1);('rkhs hdsupto', 1);('approximation error \x0fsslmsk', 1);('ptmsk dswe', 1);('assumption condition number characterizes thealignment', 1);('ssl condition number letfgywdsizmsk ds', 1);('dszmsk dsgi2dandfgywsslizmsk ds', 1);('dszmsk dsgi2dybe', 1);('wds', 1);('dsdy2rd\x02dywsslwssl1w ssld2rd\x02d', 1);('and2bwdswsslwssl\x001wssl2rdy\x02d 610we', 1);('exists \x16201 thatkbk22\x14\x16the condition number \x16plays', 1);('critical role', 1);('\x16 letwdswssl implies', 1);('projection matrix \x16', 1);('alsolet', 1);('row vectors', 1);('wsslbe', 1);('orthonormal basis', 1);('wsslwsslidpandbwdswssl', 1);('bmeasures', 1);('subspace alignment', 1);('wsslobtained2for', 1);('wsslwssl2rd\x02dis', 1);('wsslwsslis', 1);('wsslwssl29in', 1);('process general cases', 1);('wsslis', 1);('nonorthonormal similarinterpretation eigenvalue decomposition', 1);('wsslwsslrecall', 1);('attention neural network', 1);('u2rdy\x02d', 1);('quantity characterizes expressityof function class faggds\x12\x122\x02dsgof aggregation layers', 1);('task\x0faggu inffds2fdssupx2xl\x001 fdsxmsk', 1);('ds\x00ubfptxmsk pt', 1);('inf\x122\x02dssupx2xl\x001 aggds\x12\x0eattn', 1);('sm\x00qb\x12ptmsk dskb\x12ptxvb\x12ptx\x01\x00uaggptb\x12pt\x0eattn sm\x00qb\x12ptmsk ptkb\x12ptxvb\x12ptx\x01', 1);('attention mechanism frozen downstreamtask', 1);('trainable part attention neural network aggregation layer aggds\x12', 1);('thusthe', 1);('aggregation approximation error \x0faggu characterizes expressity function classfaggds\x12\x122\x02dsgof aggregation layers terms', 1);('composition thelinear transformation', 1);('uaggptb\x12ptof', 1);('processand ii output variation', 1);('inputmask msk', 1);('dsin', 1);('implies \x0faggu', 1);('long function class aggregationlayers', 1);('form faggds\x12uaggptb\x12pt\x12u2rdy\x02dg case \x0faggu characterizes compatibility aggds\x12andaggptb\x12ptunder linear transformation parameterizedby\x12 general cases msk', 1);('pt6msk ds\x0faggu', 1);('characterizes capabilityofaggds\x12to', 1);('output variation', 1);('input maskrecall function class', 1);('fptof', 1);('leteptapprox', 1);('ptf\x01i\x00ehl\x00xy ptf\x03pt\x01i612be', 1);('theorem55 recall', 1);('fdsof', 1);('task approximation error', 1);('formeapprox minf2fdsehl\x00xy', 1);('dsf\x01i\x00ehl\x00xy dsf\x03ds\x01i', 1);('theorem characterizes approximation error', 1);('eapprox ssl', 1);('ssl approximation error assumptions', 1);('o\x10\x16\x01\x00eptapprox', 1);('ptmsk ds\x01\x0f2gmsk ds', 1);('\x0f2aggb\x11whereeptapprox \x0fsslmsk', 1);('ptmsk ds\x0fgmsk ds', 1);('seee3', 1);('demonstrates attention neural network', 1);('tasks approximation error subsume inthe', 1);('extra error terms', 1);('approximation errorin', 1);('followsi condition number \x16characterizes alignment', 1);('wsslobtained', 1);('wdswssl', 1);('have\x16 1ii approximation error', 1);('theorem55 speci', 1);('in67 characterizes', 1);('fundamental hardness', 1);('ith entryg\x03ptizmsk', 1);('therkhshpt attention approximation error \x0fattnde', 1);('characterizes fundamentalhardness', 1);('ith entryg\x03dsizmsk', 1);('rkhs hdsv', 1);('aggregation approximation error \x0faggb measures expressity functionclass aggregation layers', 1);('aggregation layer aggds\x12for downstreamtask approximate composition linear transformation', 1);('baggptb\x12ptof', 1);('process variation', 1);('switchingthe input mask msk', 1);('ds7 conclusionthe', 1);('attention mechanism transformers demonstrates signi cant empirical', 1);('innatural language processing computer vision lack understanding abouthow', 1);('e ective end', 1);('questions attention mechanism', 1);('good representation ii attention mechanismproduces representation', 1);('iii attention mechanism learns', 1);('representation backward pass lens of31exchangeability', 1);('theoretical characterization attention mechanism acombination whitebox design', 1);('variable model blackbox design', 1);('approximation generalizationand optimization guarantees attention mechanism', 1);('challenging questions', 1);('open eg theoretical bene t multilayer composition', 1);('ects approximation guarantee32referencesallenzhu', 1);('z li liang', 1);('neural information processing systems allenzhu z li', 1);('2019b convergence theory', 1);('learning viaoverparameterization', 1);('machine learning allenzhu z li', 1);('2019c convergence rate training recurrentneural networks', 1);('neural information processing systems arora', 1);('hu', 1);('li z wang r', 1);('finegrained', 1);('analysis optimization generalization', 1);('twolayer neural networks', 1);('internationalconference machine learning bartlett p', 1);('valid generalization size weights', 1);('important thanthe size network', 1);('neural information processing systems bartlett p helmbold', 1);('descent identity', 1);('nite linear transformations', 1);('residual networks', 1);('ininternational', 1);('machine learning bartlett p', 1);('evans n', 1);('representing', 1);('smooth functions ascompositions nearidentity functions implications', 1);('network optimizationarxiv preprint arxiv180405012', 1);('bartlett p', 1);('foster j telgarsky j', 1);('spectrallynormalized', 1);('marginbounds neural networks', 1);('neural information processing systems bartlett p', 1);('rademacher gaussian', 1);('riskbounds', 1);('structural results journal', 1);('battaglia p', 1);('hamrick j', 1);('bapst v sanchezgonzalez zambaldi vmalinowski tacchetti raposo santoro faulkner r', 1);('2018relational inductive biases', 1);('learning graph networks arxiv preprintarxiv180601261', 1);('bloemreddy', 1);('teh', 1);('probabilistic', 1);('symmetries invariant neuralnetworks journal', 1);('bronstein bruna j cohen veli\x14', 1);('ckovi\x13 c', 1);('geometric', 1);('deep learninggrids groups graphs geodesics gauges arxiv preprint arxiv210413478 33brown', 1);('mann', 1);('ryder n subbiah kaplan j dhariwal pneelakantan shyam p sastry g askell', 1);('language', 1);('modelsare fewshot learners', 1);('neural information processing systems cao gu q', 1);('bounds stochastic gradient descent wideand', 1);('neural information processing systems caponnetto de vito e', 1);('optimal', 1);('foundations computational mathematics chen', 1);('lu k rajeswaran lee k grover laskin abbeel p srinivas aand mordatch', 1);('decision', 1);('reinforcement', 1);('neural information processing systems chizat', 1);('oyallon e bach', 1);('lazy training di', 1);('erentiable programmingneural', 1);('information processing systems dai z yang z yang carbonell j', 1);('q v salakhutdinov r', 1);('attentive', 1);('language models', 1);('xedlength context arxiv preprintarxiv190102860', 1);('pr\x13 evision ses lois logiques ses sources subjectives', 1);('annales', 1);('henri poincar\x13', 1);('de gooijer j g zerom', 1);('conditional density estimation', 1);('statistica neerlandica devlin j chang mw lee k toutanova k', 1);('bert pretraining', 1);('deepbidirectional transformers language understanding arxiv preprint arxiv181004805', 1);('diaconis p freedman', 1);('finite', 1);('exchangeable sequences', 1);('annals probability dosovitskiy beyer', 1);('kolesnikov weissenborn zhai x unterthiner tdehghani minderer heigold g gelly', 1);('image recognition scale arxiv preprint arxiv201011929', 1);('lee j li h wang', 1);('zhai x', 1);('descent nds', 1);('global minimaof', 1);('zhai x poczos', 1);('singh', 1);('neural networks arxiv preprint arxiv181002054', 1);('b l', 1);('goel kakade zhang', 1);('inductive', 1);('biases variablecreation selfattention mechanisms arxiv preprint arxiv211010090 34elesedy b', 1);('provably', 1);('strict generalisation bene t invariance kernel methodsneural', 1);('information processing systems fisher r', 1);('mathematical foundations theoretical statistics', 1);('philosophicaltransactions', 1);('royal society 222309368garg', 1);('tsipras liang p valiant g', 1);('incontext case study', 1);('simple function classes arxiv preprint arxiv220801066', 1);('han j rong xu huang', 1);('geometrically', 1);('equivariant graph neuralnetworks survey arxiv preprint arxiv220207230', 1);('hardt', 1);('identity', 1);('learning arxiv preprintarxiv161104231', 1);('k chen x xie li doll\x13', 1);('p girshick r', 1);('masked', 1);('scalable vision learners', 1);('computer vision pattern recognition hron j bahri sohldickstein j novak r', 1);('nite attention', 1);('nngp', 1);('attention networks', 1);('machine learning hutchinson j', 1);('lan', 1);('zaidi dupont e teh', 1);('kim h', 1);('lietransformer equivariant', 1);('lie', 1);('international conference onmachine', 1);('learning jacot gabriel', 1);('hongler', 1);('neural', 1);('tangent kernel', 1);('convergence', 1);('andgeneralization neural networks', 1);('neural information processing systems jiang neyshabur', 1);('mobahi h krishnan bengio', 1);('fantastic', 1);('generalization measures nd arxiv preprint arxiv191202178', 1);('jumper j evans r pritzel', 1);('figurnov ronneberger otunyasuvunakool k bates r', 1);('\x14z\x13 \x10dek', 1);('potapenko', 1);('highly', 1);('accurate protein structure prediction', 1);('alphafold nature keriven n peyr\x13', 1);('universal', 1);('invariant equivariant graph neural networksneural', 1);('information processing systems kossen j', 1);('n lyle', 1);('gomez n rainforth gal', 1);('selfattention', 1);('going', 1);('individual inputoutput pairs', 1);('neural information processing systems lee j lee kim j kosiorek choi teh', 1);('set', 1);('transformera framework', 1);('permutationinvariant neural networks', 1);('internationalconference machine learning', 1);('liang', 1);('stochasticgradient descent', 1);('neural information processing systems malladi wettig yu chen arora', 1);('view oflanguage model', 1);('arxiv preprint arxiv221005643', 1);('mei misiakiewicz montanari', 1);('eld theory twolayers neuralnetworks', 1);('dimensionfree', 1);('bounds kernel limit', 1);('annual', 1);('learningtheory mei montanari nguyen pm', 1);('eld view landscape oftwolayer neural networks', 1);('proceedings', 1);('national academy', 1);('mohri rostamizadeh talwalkar', 1);('foundations', 1);('mit', 1);('k fukumizu k sriperumbudur', 1);('sch\x7f', 1);('olkopf b', 1);('distributions review', 1);('arxiv preprint arxiv160509522', 1);('nguyen pm', 1);('eld limit learning dynamics multilayer neural networks arxiv preprint arxiv190202880', 1);('pearl j', 1);('causality cambridge', 1);('university pressradford', 1);('narasimhan k salimans sutskever', 1);('improving', 1);('technical', 1);('radford wu j child r luan amodei sutskever', 1);('languagemodels', 1);('multitask learners', 1);('openai', 1);('ramesh pavlov goh g', 1);('voss', 1);('radford chen', 1);('zeroshot', 1);('texttoimage generation', 1);('conferenceon machine learning romero', 1);('cordonnier jb', 1);('group equivariant standalone selfattentionfor vision arxiv preprint arxiv201000977', 1);('rotsko g vandeneijnden e', 1);('parameters', 1);('long timeconvergence asymptotic error', 1);('neural information processing systems sannai imaizumi kawano', 1);('improved', 1);('generalization bounds groupinvariantequivariant', 1);('uncertainty arti', 1);('intelligence', 1);('v g hoogeboom e fuchs', 1);('f b', 1);('posner welling', 1);('enequivariant', 1);('ows arxiv preprint arxiv210509016', 1);('gori tsoi', 1);('hagenbuchner monfardini g', 1);('graphneural network model', 1);('ieee transactions neural networks schulz e speekenbrink krause', 1);('process regression', 1);('modelling', 1);('functions journal', 1);('mathematical psychology shawetaylor j cristianini n', 1);('methods pattern analysis', 1);('presssirignano j spiliopoulos k', 1);('eld analysis neural networks centrallimit theorem', 1);('stochastic processes applications sokolic j giryes r sapiro g rodrigues', 1);('error invariantclassi ers', 1);('arti', 1);('intelligence statistics', 1);('anandkumar dai', 1);('nonparametric', 1);('estimation multiview latent', 1);('variable models', 1);('huang j smola fukumizu k', 1);('space embeddings conditional distributions applications dynamical systems', 1);('conferenceon machine learning tsai yh h bai yamada morency lp salakhutdinov r', 1);('transformer', 1);('dissection uni', 1);('understanding transformers attention', 1);('lens kernelarxiv preprint arxiv190811775', 1);('g louis', 1);('learning arxivpreprint arxiv201204115', 1);('vaswani shazeer n parmar n uszkoreit j jones', 1);('gomez n kaiser', 1);('l andpolosukhin', 1);('neural information processing systems vuckovic j baratin combes r', 1);('mathematical theory attentionarxiv preprint arxiv200702876', 1);('wainwright j', 1);('highdimensional', 1);('statistics nonasymptotic viewpoint', 1);('presswasserman', 1);('model selection model', 1);('mathematical psychology', 1);('449210737wei c', 1);('statistically', 1);('meaningful approximation case studyon', 1);('machines transformers arxiv preprint arxiv210713163', 1);('wolf debut', 1);('sanh v chaumond j delangue', 1);('moi cistac p rault tlouf r funtowicz', 1);('transformers stateoftheart', 1);('empirical methods', 1);('language processing xie raghunathan liang p', 1);('inference arxiv preprint arxiv211102080', 1);('yang g', 1);('ii neural', 1);('tangent kernel architecture arxivpreprint arxiv200614548', 1);('yang g littwin e', 1);('iib architectural', 1);('universality neuraltangent kernel training dynamics', 1);('machine learning zaheer kottur ravanbakhsh poczos', 1);('salakhutdinov r r smola j2017 deep', 1);('neural information processing systems zhang', 1);('liu', 1);('wang k tan v yang z wang z', 1);('relational', 1);('provable e\x0eciency applications', 1);('marl', 1);('arxiv preprintarxiv220909845', 1);('zhang x yu wang', 1);('gu q', 1);('networksvia gradient descent', 1);('machine learning zhang backurs bubeck eldan r gunasekar wagner', 1);('lego', 1);('synthetic reasoning task arxiv preprintarxiv220604301', 1);('huang', 1);('understanding', 1);('generalization bene t modelinvariance data perspective', 1);('neural information processing systems zou cao zhou gu q', 1);('stochastic', 1);('gradient descent optimizes', 1);('networks arxiv preprint arxiv181108888', 1);('zou gu q', 1);('analysis training', 1);('neural information processing systems', 1);('conditional mean embeddingwe', 1);('introduce conditional', 1);('embeds conditional distribution tothe element', 1);('hxandhybe', 1);('xandywith', 1);('pxybe', 1);('xandytaking', 1);('xandy', 1);('cmexpxy2hyof', 1);('conditional distribution', 1);('pyjxis', 1);('e\x02ly\x01 xx\x03then', 1);('function g2hyandx2x', 1);('xx\x03gcmexpxy hywhich', 1);('shows conditional', 1);('representation conditionaldistribution', 1);('rkhs correspondingly', 1);('cyjxhxhyis', 1);('operator thatcyjxkx\x01', 1);('cmexpxyfor', 1);('cxxhxhxand', 1);('thecrosscovariance operator', 1);('cyxhxhyas', 1);('followscxxe\x02kx\x01kx\x01\x03cyxe\x02ly\x01kx\x01\x03hereis tensor product', 1);('cyjxcyxc\x001xx', 1);('squares problemminchxhye\x15c', 1);('eh ly\x01\x00ckx\x01', 1);('a1wherek\x01khsdenotes hilbertschmidt', 1);('norm \x15', 1);('regularization parameterthe solution', 1);('a1', 1);('c\x15yjxcyxcxx\x15i\x001', 1);('ihxhxis', 1);('squares problembeu 1llx1', 1);('ly\x01\x00ckx\x01', 1);('a2wherefxyg2lare', 1);('pxy', 1);('present solution', 1);('sxhxrlandsyhyrlassxf', 1);('fx1f xlandsyg gy1g yl f2hxandg2hy', 1);('bys\x03xands\x03ythe adjoints', 1);('sxandsy', 1);('l\x001s\x03xsxandbcyxl\x001pl1ly\x01kx\x01 s\x03ysx39the', 1);('bydcme\x15xpxy2hythe empirical conditional', 1);('following', 1);('sxs\x03xl\x15il\x001sx', 1);('thatdcme\x15xpxy bc\x15yjxkx\x01', 1);('a3bcyxbcxx\x15\x001kx\x01 s\x03ykxx l\x15il\x001kxxherekxx sxs\x03x kxixjij2l2rl\x02lis gram', 1);('kxx kx1xkxlx2rlb attention recovers latent posteriorb1 gaussian process regressiongaussian process regression', 1);('gp gp\x16\x01k\x01\x01onrdif', 1);('forx1xl fx1f xl', 1);('\x16x1\x16 xland covariance', 1);('kxixjij2l here\x16x efx', 1);('kxx0 efx\x00\x16xfx0\x00\x16x0', 1);('covariance kernel function', 1);('gp0kxx0as', 1);('noisy samples fxyg2l whereyfx\x0fwith\x0f\x18n0\x15iiid', 1);('noise posterior fis', 1);('\x16px covariancekpxx0', 1);('schulz', 1);('kxxkxx', 1);('kxx0\x00kxxkxx', 1);('kxx2l2r1\x02lkxx kxixjij2l2rl\x02l', 1);('kxx02l2rlrigorous characterization latent', 1);('nitedimensional example latent', 1);('variable model in41', 1);('modelrfc \x0frmskfcmsk \x0f', 1);('b1heref', 1);('f1fd fi\x18gp0k\x01\x01 fori2d and\x0fand\x0fare independentgaussian noise', 1);('implication limiting expectationnecessity multiple heads based', 1);('nition attention mechanism attnin', 1);('ne multihead attention asmhaqxw hxi1headi2rd', 1);('b2hereh2nis', 1);('number heads', 1);('wfwqiwkiwvighi1is', 1);('learnable parameterandheadiattn qkivi2rd wherekixwki', 1);('v xwviwe', 1);('remark multihead attention', 1);('summation formwhich', 1);('equivalent concatenation form', 1);('multihead attentionswe', 1);('ddp\x01h wherehis number headswe remark limit', 1);('q shows necessity', 1);('multiple headsin multihead attention', 1);('key value', 1);('wkx', 1);('wvxwherex2rdis', 1);('wk2rd\x02dpwv2rd\x02dare', 1);('learnable parametersin singlehead attentions h', 1);('anddpd matrix', 1);('wk2rd\x02dis', 1);('invertible ahigh probability', 1);('kv', 1);('andxthe random', 1);('variable distributionaskv andx', 1);('thatattn qkv \x19evjk q', 1);('e\x02wvx wkxq\x03\x00wk\x001wv\x01qwhich', 1);('interaction query qand input sequencex', 1);('singlehead attention mechanism', 1);('limit whenl', 1);('comparison number heads h', 1);('anddp matriceswk2rd\x02dare invertible', 1);('incorporate nonlinearity attention isnecessary use', 1);('multiple heads h1instrumental', 1);('variable limit', 1);('shows attention e ective sense ofcausal inference rst introduce instrumental', 1);('variable causal inference', 1);('instrumental', 1);('estimate causal relationship inputxand outputy', 1);('measurements pair random variablesxy', 1);('e ective', 1);('causal relationship', 1);('intuitively zis iv', 1);('ythroughx', 1);('thecausal assumption', 1);('b1 iv model', 1);('xyz', 1);('variable space', 1);('x\x02y\x02zwith', 1);('pxyz', 1);('thatiygx \x0fande\x0fjz 0iipxjzxjz', 1);('constant zin', 1);('assumption b1 zis iv assumption b1', 1);('exclusionrestriction function gis', 1);('true structural function error term \x0fis confoundingnoise', 1);('ii relevance condition ensures', 1);('informativewe remark', 1);('causal inference general contexts', 1);('thiswhenxz estimation hreduces', 1);('standard regression', 1);('inputs andit', 1);('e\x02gxjz\x03 b3the', 1);('b3', 1);('twostage method', 1);('function gat rst stage estimate conditional', 1);('xjz', 1);('stage weestimate function gvia regressingyonxjz', 1);('qk andv', 1);('mappingg\x12\x0eattn qkv 2rdwhereg\x12is function approximation parameter \x12 example g\x12can', 1);('thatg\x12\x0eattn qkv 2rd\x19g\x12\x00evjk q\x01asl1let target learning problem', 1);('q\x01thus keykis instrumental', 1);('pearl', 1);('mappings input sequence', 1);('xtoqk', 1);('parameter \x12', 1);('attention e ective relational reasoning', 1);('instrumental variableb3', 1);('32proof rst', 1);('statement bx minimal su\x0ecient statistic', 1);('xforzthe', 1);('su\x0eciency bx straightforward show minimal', 1);('suppose uxis', 1);('xforz', 1);('pzjux', 1);('z2z42which implies bx function', 1);('bx minimalwe', 1);('statement bx minimal su\x0ecient statistics', 1);('xfory suppose ux', 1);('pyjuxzpyjz\x01pzjuxdzwhich', 1);('t\x001\x10zzpy\x01jz\x01pzjuxdz\x11which', 1);('means bx function', 1);('bx minimalb4', 1);('according a3', 1);('cmerecovers', 1);('empirical conditional', 1);('euclidean', 1);('lyy0', 1);('cmeqpkv evjk', 1);('nition attention conditional', 1);('attn qkv \x00cmeqpkv 2\x14 bcvkbckk\x15i\x001kq\x01\x00cvkckk\x15i\x001kq\x01', 1);('z term i', 1);('z term ii', 1);('b4upper', 1);('bcvkbckk\x15i\x001\x00cvkckk\x15i\x001 \x14 bcvk\x00bckk\x15i\x001\x00ckk\x15i\x001\x01 bcvk\x00cvkckk\x15i\x001 bcvkbckk\x15i\x001bckk\x00ckkckk\x15i\x001 bcvk\x00cvkckk\x15i\x001', 1);('b5for', 1);('rst term fact kbcvkk\x14kvvk12\x01kbckkk12', 1);('bcvkbckk\x15i\x001bckk\x00ckkckk\x15i\x001 \x14kvvk12\x01 bc12kkbckk\x15i\x0012 \x01 bckk\x15i\x0012 \x01 bckk\x00ckkckk\x15i\x001 \x14\x15\x0012\x01 bckk\x00ckkckk\x15i\x001', 1);('b643plugging b6 b5', 1);('bcvkbckk\x15i\x001\x00cvkckk\x15i\x001 \x14\x15\x0012\x01 bckk\x00ckkckk\x15i\x001 bcvk\x00cvkckk\x15i\x001', 1);('b7in', 1);('term righthand side', 1);('b7', 1);('g2', 1);('\x14\x15\x001 thatk\x18kvk', 1);('\x01kvkhv\x01k kkhk\x14c\x01\x15\x001wherec', 1);('absolute constant addition thate\x02k\x18kvk2\x03eh kckk\x15i\x001 2hk\x01kvk2hvi\x14eh', 1);('k 2hkiehckk\x15i\x002 k k', 1);('hkiusing', 1);('trace operator thate\x02k\x18kvk2\x03ehtr\x00ckk\x15i\x002 k k\x01i tr\x00ckk\x15i\x002ckk\x01\x14\x15\x001tr\x00ckk\x15i\x001ckk\x01\x15\x001\x01 \x15where \x15 e ective dimension', 1);('ckkde', 1);('applying lemma g2withbc\x15\x001and\x1b2\x15\x001\x01', 1);('\x15 probability', 1);('\x00\x0ethat bcvkckk\x15i\x001\x00cvkckk\x15i\x001 \x14c\x01\x122\x15lr \x15\x15l\x13log2\x0e', 1);('b8wherec', 1);('\x00\x0ethat bckkckk\x15i\x001\x00ckkckk\x15i\x001 \x14c\x01\x122\x15lr \x15\x15l\x13log2\x0e', 1);('b9plugging b8 b9 b7', 1);('\x00\x0ethat bcvkbckk\x15i\x001\x00cvkckk\x15i\x001 \x14c\x01\x15\x0012\x122\x15lr \x15\x15l\x13log2\x0e', 1);('b1044upper', 1);('term ii', 1);('hk', 1);('hkhknote ev\x16vjk\x01\x16ky', 1);('ckkckkby', 1);('ckkckk\x001ev\x16vjk\x01\x16ky letf\x15ig1i1andf', 1);('ig1i1be eigenvalues andeigenvectors ofckk', 1);('k\x01\x16ky\x03 2xij\x12\x152i\x15i\x15\x152j\x15j\x15\x00\x152i\x15j\x15i\x15\x00\x152j\x15i\x15j\x15\x15i\x15j\x132h jeci2hkhkxij\x12\x15i\x15j\x152\x15i\x15\x15j\x15\x132h jeci2hkhk\x14\x154\x01keck2hkhkthus', 1);('b11wherec', 1);('b10 b11 b4', 1);('42proof condition bpkvjqpvjq', 1);('thatzvbpkvjkvjqdvevjk q45asl1', 1);('b12wheresd\x001is', 1);('d\x001dimensional unit sphere su\x0eces calculate integrationtermzsd\x001v\x01kvvdvto end utilize', 1);('b2 letkab', 1);('expab exponential kernel', 1);('itholds', 1);('followsc1zsd\x001ab\x01kabda8b2sd\x001here remark', 1);('c1is', 1);('due symmetry unit sphere', 1);('sd\x001proof seeb51', 1);('lemma b2', 1);('b12', 1);('kq c0\x01c1\x01attn smqkv', 1);('k1kl andv v1v keys queries andc0zsd\x001kabda c 1zsd\x001ab\x01kabda8b2sd\x001thus setting', 1);('cc0\x01c1', 1);('lemma b2proof letabbe', 1);('vectors d\x001dimensional unit sphere', 1);('sd\x001', 1);('vectorc ab\x01b\x00\x00a\x00ab\x01b\x012sd\x001', 1);('b13by', 1);('direct calculation', 1);('property cde', 1);('b13cb', 1);('ab\x01kbk22\x00ab ab\x01kbk22ab', 1);('b14thus', 1);('symmetry propertyc 2ab\x00a 2cb\x00c', 1);('b15we', 1);('ready calculate', 1);('thatzsd\x001a\x01expabdab\x01zsd\x001ab expabdazsd\x001\x00a\x00ab\x01b\x01\x01expabdab16meanwhile', 1);('nition cin', 1);('b13', 1);('b14', 1);('andb15 thatzsd\x001\x00a\x00ab\x01b\x01\x01expabda\x00zsd\x001\x00c\x00cb\x01b\x01\x01expcbda\x00zsd\x001\x00c\x00cb\x01b\x01\x01expcbdc', 1);('b17where', 1);('fact thatdc 2kbk22da\x00da dathus', 1);('variable righthand side', 1);('b17', 1);('b18finally', 1);('b18 b16', 1);('thatzsd\x001a\x01expabdab\x01zsd\x001ab expabdathus settingc1zsd\x001ab expabda8b2sd\x001we conclude proof', 1);('lemma b247c generalization error analysisin', 1);('section analyze generalization error', 1);('complete setup transformerarchitecture involves', 1);('multiple layers', 1);('connections multihead attention', 1);('wecollect', 1);('section followsnotations', 1);('letr\x151', 1);('typical rnorm', 1);('vectoralso lets\x151 andm m1md22rd1\x02d2 wheremi2rd1\x021fori2d2', 1);('nethe matrix rsnorm askmkrs', 1);('pd2i1kmiksr12', 1);('ne matrix rs operatornormk\x01krsaskmkrs supu2rd2\x021kmukskukrand writek\x01krk\x01krrwhen normoperates matrix', 1);('positive reals randssuch', 1);('rs aconjugate pairc1', 1);('complete setup transformer architecturein', 1);('tlayer', 1);('by\x12 \x120\x120\x12t\x001 tth layer', 1);('atwt', 1);('theaggregation layer', 1);('ne twolayer feedforward network ffnwith', 1);('bias terms followsxtffnxtat', 1);('relu xtaxta\x1btxt axta\x1btwhich', 1);('hereazt2rd\x02d\x1ba\x1bt2rd\x1b\x02dandrelu', 1);('\x01 recti edlinear unit', 1);('softmax attention mechanism', 1);('ne sequence sequence softmax attention mechanismfor matrices followsattn', 1);('smqkv', 1);('softmax\x00kqk \x01v2rl\x02d', 1);('c1whereqk2rl\x02dpv2rl\x02d', 1);('kkq2l2rl\x02lwith', 1);('slight abuse notations', 1);('ne sequence sequence counterpart mhade', 1);('followsmhaxw hxi1headihxi1attn', 1);('smqikiviwhereqixwqikixwki', 1);('ne multihead attentionwith', 1);('connection followsext1 mhaxtwt', 1);('xt wt\x08wqtiwktiwvti', 1);('wt48empirical function', 1);('construct function class', 1);('oftransformers rst specify base case', 1);('fl0wfx0gfxg', 1);('ne function classes asfollowsflta\x08ffnxtatat2atxt2fltw', 1);('flt1w', 1);('xtwt2wtxt2flta', 1);('wtandatare', 1);('parameter spaces layer', 1);('ne functionclass oftlayer transformers empirical counterpart followsfltrans faggtrans\x120\x0eff2fltagfldntrans n\x00fx1f', 1);('xn\x01f2fltransoc2note', 1);('aggregation layer aggtrans\x120in', 1);('involves input mask msk describesthe prediction task example', 1);('aggregation layer aggtrans\x120is composition function extracts output', 1);('corresponding input mask mskfrom sequence sequence softmax attention mechanism', 1);('anotherfunction computes prediction target', 1);('variable yeg linear', 1);('netuningassumptions parallel', 1);('assumption kernel', 1);('multihead attention mhaassumption', 1);('c1 rbf kernel', 1);('multihead attention mhaadopts thegaussian', 1);('exp\x00kq\x00kk222\x1b2 with\x1b 2dp1snote kernel function', 1);('assumption c1', 1);('general version', 1);('rbfkernel', 1);('assumption aggregation layer aggtrans\x120assumption', 1);('c2 aggregation layer', 1);('function aggregation functionaggtrans\x120rl\x02dyis 1lipschitz', 1);('continuous respect k\x01kr1norm', 1);('yisde', 1);('52in parallel', 1);('assumption parameter spacefor layer', 1);('complete setup transformerassumption', 1);('c3 parameter', 1);('parameter spaces tth composite layer transformer49areatnaxta\x1bt2rd\x02d\x1b\x02rd\x1b\x02d', 1);('r\x14 xt', 1);('r\x14 \x1bt', 1);('c3wtn\x08wqtiwktiwvti', 1);('wqtiwktiwvti2rd\x02dp\x02rd\x02dp\x02rd\x02d wqti', 1);('c4 wqti', 1);('generalization error analysis transformerfor', 1);('parameter boundsacross thehheads layer tas followsvthxi1vtiqkt maxi2hfqtiktigrvthxi1rvti', 1);('rqkthxi1rqtirkti c5where', 1);('nee t', 1);('xt \x1btevt', 1);('rtr0\x01t\x001y', 1);('0ev e', 1);('c6which', 1);('characterize magnitude intermediate input sequences', 1);('ne\x14t max\x1a xtr\x1bt \x1btrxte trvtevtrqktqktvt\x1b \x10tqkt2rvtevtc7we simplify quantities', 1);('c6 c7', 1);('ne max0\x14t\x14t\x001f xt \x1btvtg \x14 max0\x14t\x14t\x001\x14t \x10 max0\x14t\x14t\x001\x10t', 1);('c8recall', 1);('egenis', 1);('complete setup transformertheorem', 1);('c4 generalization error transformer suppose assumptions c1c3and assumption', 1);('\x00\x0ethategen\x14o\x12dphtpn\x01htplog2 ptqlog1 \x10r0 plog1 \x14\x10irlog1\x0en\x13whered maxfdd\x1bdpgandbe\x01 empirical expectation dataset', 1);('dn50proof seec4', 1);('highlight', 1);('key di erence analysis', 1);('exploitation bene t', 1);('invarianceequivariance property transformer', 1);('due invarianceequivariance property thetransformer dimensions parameters', 1);('wtandatcan', 1);('constant levelsregardless l', 1);('parameter space', 1);('propagation consequence', 1);('number scaleswith dimension', 1);('dof', 1);('parameters number', 1);('layers transformer', 1);('incontrast', 1);('results generalization error', 1);('hasi logarithmic dependency l ii assumption intermediate input sequencesxthas', 1);('low norminterpretation', 1);('thedependencies oplog1\x0en', 1);('ando1pn size nof datasetdnare standardin generalization analysis hand', 1);('odh12t32', 1);('implies thetransformer needs data generalize parameter dimensions number layersor number heads', 1);('withthe number layers', 1);('typical exponential scalingwith number layers', 1);('note dependency \x14 and\x10are alllogarithmic implies generalization error', 1);('long thesequantities scale', 1);('dh', 1);('architecture theorem c4', 1);('\x14\x10andrxplaycrucial roles generalization error transformer speci c observe iskip connections', 1);('identity maps', 1);('\x14and\x10 ii layer normalizations', 1);('rxtof', 1);('intermediate input sequences', 1);('xtsimpli', 1);('characterizes generalization error forthe', 1);('complete setup transformer general result', 1);('theorem53', 1);('53single layer signlehead attention', 1);('h 1t', 1);('andrr0skip connections', 1);('connections wereplacee tandevtwith xt ztandvtin', 1);('andreplace log2 log1', 1);('feedforward', 1);('neural network nn', 1);('linear transformation secondlayer we51remove \x1b0andr\x1b0remove intermediate output dimension d\x1b andset x0andrnnrx0correspondinglysoftmax', 1);('sm', 1);('maxfqk0v0gandrattn maxfrqk0rv0gaggregation layer aggtrans\x12 view aggregation layer', 1);('partsa aggregation function aggtrans\x120de', 1);('andb function', 1);('sequence sequence softmax attention mechanism', 1);('dpdimensional output', 1);('corresponding thequeryq\x12mskwith factors', 1);('c5c8', 1);('sketch', 1);('followsc3 introduce framework', 1);('fldntransof', 1);('transformers sketch proof', 1);('mhaandffnand ii', 1);('propagation coveringsof themf clarity presentation', 1);('proofs intermediatelemmas', 1);('fc3 fundation generalizationin', 1);('section introduce', 1);('fundamental building blocks analysis generalization error52c31', 1);('rademacher complexitywe', 1);('dnfxiyigni1is', 1);('fromthe data distribution characterize generalization error learning', 1);('thefunction classfvia empirical', 1);('e\x0f2f\x0011gn\x14supf2f1nnxi1\x0fi\x01l\x00xiyif\x01\x15 c9herelis', 1);('learning objective generalization error', 1);('egende', 1);('connectedto empirical', 1);('classic resulttheorem', 1);('c5 mohri', 1);('family functions', 1);('datadistributiondto output range', 1);('1lipschitz objective function', 1);('lthen', 1);('\x0e0 probability', 1);('independent identical drawof datasetdnfxiyigi2n', 1);('f2fehl\x00xyf\x01i\x00behl\x00xyf\x01i\x142brdnf 3rlog2\x0e2nwherebe\x01 empirical expectation', 1);('dnand', 1);('rademachercomplexitybrdnf', 1);('c9c32', 1);('covering numberin', 1);('present connection', 1);('dnfxiyigi2nand', 1);('function class f', 1);('corresponding empirical function classasfdnffx1f', 1);('xn', 1);('number followsde nition', 1);('c6 proper covering number letnsk\x01k', 1);('cardinalityof subsett \x12s coverssat resolution respect norm k\x01k', 1);('formally', 1);('wede nen\x00sk\x01k\x01 infncardt sups2sinft2tks\x00tk\x14t \x12sowhere cardt cardinality', 1);('tthe', 1);('complexity brdnf', 1);('fdn speci', 1);('dudley', 1);('entropy integral lemma', 1);('c7 dudley entropy integral', 1);('2f havebrdnf\x14inf\x18201\x124\x1812pnz1\x18qlogn\x00fdnk\x01kr1\x01d\x1353proof', 1);('seef1', 1);('standard version', 1);('dudleyentropy', 1);('integral lemma', 1);('mohri', 1);('considers k\x01k', 1);('fcovering', 1);('technical di erence', 1);('standard version ofdudley entropy integral lemma', 1);('k\x01k 2norm ork\x01k', 1);('fnormto', 1);('number empirical function classfldntrans', 1);('transformers respect k\x01kr1normc4', 1);('generalization error boundrecall wtandatare', 1);('c4 c3', 1);('characterize ofthe', 1);('transformers followinglemmalemma', 1);('c8 covering transformer letd', 1);('maxfdd\x1bdpgandr0 supi2nkxikr1we havelogn\x00fldntransk\x01kr1\x01\x144 hd2t\x01log\x121 2rtranstrt\x13wherertranstt\x001xt0\x14\x12rmhate\x1at xtr\x1bt \x1btrxte t\x13\x01t\x001y t1e\x1a ev \x15', 1);('c10heree\x1atevt', 1);('rmhatrvtqktrqkt\x01rt2c11wherertis', 1);('c5proof seec53', 1);('generalization error transformer', 1);('theoremc4', 1);('rd\x14z1\x18\x02plog1 r', 1);('plog1 1\x03d\x141\x00\x18\x01plog1', 1);('r z1\x181pd', 1);('2\x002p\x1854where rst inequality', 1);('inequality followsfrom log1 a\x14afora\x001', 1);('havebrdnfltrans\x14inf\x18201\x124\x1812pnz1\x18qlogn\x00fldntransk\x01kr1\x01d\x13\x1412dp4 ht\x012 plog1 2rtranstrtpn inf\x18201\x14\x124\x0012dp4 ht\x01plog1 2rtranstrtpn\x13\x01\x18\x0024dp4 ht\x01p\x18\x15for', 1);('mum righthand side inequality', 1);('\x180 obtainbrdnfltrans\x1412dp4 ht\x012 plog1 2rtranstrtpno\x12dpht\x011 plog1', 1);('rtranstrtpn\x13where', 1);('theoremc5', 1);('obtainehl\x00xyf\x01\x0e4i\x00behl\x00xyf\x01\x0e4i\x14o\x12dpht\x011 plog1', 1);('rtrtranstpnrlog1\x0en\x13 c12for', 1);('c12', 1);('lemma g5', 1);('obtainehl\x00xyf\x01i\x00behl\x00xyf\x01ic13\x14o\x12dphtpn\x01htplog2 ptqlog1 \x10r0 plog1 \x14\x10irlog1\x0en\x13for anyf2', 1);('fltrans recall', 1);('regression function efminimizes empirical riskbelxyf', 1);('letf', 1);('nition generalization55erroregenin', 1);('haveegenehl\x00xybf\x01i\x00behl\x00xybf\x01ibehl\x00xyef\x01i\x00minf2fltransehl\x00xyf\x01iehl\x00xybf\x01i\x00behl\x00xybf\x01i minf2fltransbehl\x00xyf\x01i\x00ehl\x00xyf\x01iehl\x00xybf\x01i\x00behl\x00xybf\x01i minf2fltransbehl\x00xyf\x01i\x00behl\x00xyf\x01ibehl\x00xyf\x01i\x00ehl\x00xyf\x01i\x14ehl\x00xybf\x01i\x00behl\x00xybf\x01ibehl\x00xyf\x01i\x00ehl\x00xyf\x01i\x14o\x12dphtpn\x01htplog2 ptqlog1 \x10r0 plog1 \x14\x10irlog1\x0en\x13where', 1);('c13', 1);('theorem c4c5', 1);('lemma c8in', 1);('number bounds mhaand ffnas building blocks coveringthe empirical function class', 1);('fdntrans', 1);('coverings mhaand ffnpropagate', 1);('layers thetransformerc53', 1);('c51 c52', 1);('forthe empirical function class', 1);('block coveringin', 1);('numbers mhaand ffnblock', 1);('fundamental tool', 1);('coveringbound transformerlemma', 1);('havelogn\x10\x08m2rd2\x02d1kmkrs\x14rm k\x01krs\x11\x14d1d2\x01log\x121 2rm\x13proof', 1);('seef11', 1);('ffn', 1);('number residual feedforward network ffn', 1);('letanaxa\x1b2rd\x02d\x1b\x02rd\x1b\x02d ax', 1);('r\x14 x', 1);('r\x14 \x1b', 1);('rs\x14r\x1bowe characterize', 1);('number function class fffnxaa2agof', 1);('ffnas', 1);('c10 ffn covering', 1);('positive reals x \x1brxr\x1b', 1);('positive integersdd\x1b', 1);('x2rl\x02dbe', 1);('havelogn\x10\x08ffnxaa2a k\x01kr1\x11\x142dd\x1b\x01log\x121', 1);('xr\x1b \x1brx\x01kxkr1\x13proof anya', 1);('axa\x1b2a', 1);('letba baxba\x1b2abe', 1);('ax\x00bax', 1);('ffnxa\x00ffnxba r1 \x00relu', 1);('xaxa\x1b\x01x\x00\x00relu xbaxba\x1b\x01\x00x', 1);('r1\x14 \x00a\x1b\x00ba\x1b\x01relu', 1);('r1 ba\x1b\x00relu', 1);('xbax\x00relu xax\x01', 1);('r1 ba\x1b r\x01 bax\x00axx r1\x14\x1b\x01', 1);('r\x01kxkr1r\x1b\x01 bax\x00ax rs\x01kxkr1\x14\x1b xx \x1b\x01kxkr1where', 1);('settingxrx xr\x1b \x1brx\x01kxkr1 \x1br\x1b xr\x1b \x1brx\x01kxkr1we obtainkffnxa\x00ffnxbakr1\x14', 1);('havelogn\x10\x08ffnxaa2a k\x01kr1\x11\x14logn\x10\x08ax2rd\x1b\x02d', 1);('rs\x14rx xk\x01kr1\x11 logn\x10\x08a\x1b2rd\x02d\x1b', 1);('rs\x14r\x1b \x1bk\x01kr1\x11\x142dd\x1b\x01log\x121', 1);('xr\x1b \x1brx\x01kxkr1\x13therefore conclude proof', 1);('lemma c1057covering mha', 1);('feasible weightswn\x08wqiwkiwvi i2h', 1);('wqiwkiwvi2rd\x02dp\x02rd\x02dp\x02rd\x02d c14 wqi', 1);('rs\x14rvi8i2howe rst', 1);('respect theparameters', 1);('wlemma c11 lipschitz continuous mha parameter', 1);('rs conjugate pairwith 1\x14r', 1);('suppose x2rl\x02dsatis', 1);('wfwqiwkiwvigi2h2w', 1);('letcwfcwqicwkicwvigi2h2wbe i2h', 1);('wqi\x00cwqi', 1);('wki\x00cwki', 1);('mhaxw\x00mhaxcw r1\x14r\x01hxi1vir3\x01hxi1qiki\x01qikiproof', 1);('seef21', 1);('number functionclassfmhaxww2wgof', 1);('mhalemma c12 mha covering', 1);('positive reals', 1);('positive integersddkdp', 1);('wbe', 1);('x2rl\x02dsuchthatkxkr1\x14r', 1);('havelogn\x10\x08mhaxww2w k\x01kr1\x11\x142 h\x01d2\x01log\x121 2rrmhaw\x13wherermhaw hxi1rvir2\x01hxi1qikirqirki', 1);('c15proof', 1);('alli2h setrqiqirkikirvivirrmhaw58wherermhaw', 1);('c15 lemma c11', 1);('mhaxw\x00mhaxcw r1\x14r\x01hxi1vir3\x01hxi1qiki\x01qiki', 1);('obtainlogn\x10\x08mhaxww2w k\x01kr1\x11\x14hxi1\x12logn\x12nwqi2rd\x02dp', 1);('rs\x14rqioqik\x01kr1\x13 logn\x12nwki2rd\x02dp', 1);('rs\x14rkiokik\x01kr1\x13 logn\x12nwvi2rd\x02d', 1);('rs\x14rviovik\x01kr1\x13\x13\x14ddp\x01hxi1\x12log\x121 2rqiqi\x13 log\x121 2rkiki\x13\x13d2\x01hxi1log\x121 2rvivi\x13', 1);('h\x01d2\x01log\x121 2rrmhaw\x13where', 1);('lemmac12c52 covering number propagationrecall wis', 1);('thelipschitz continuity', 1);('respect input sequence', 1);('xlemma c13 lipschitz continuous mha input sequence', 1);('rs conjugatepair 1\x14r1', 1);('suppose xbx2rl\x02dsatisfyingkxkr1\x14randkbxkr1\x14rare', 1);('wfwqiwkiwvigi2n2wbe', 1);('mhaxw\x00mhabxw r1\x14\x1aw\x01kx\x00bxkr1where\x1aw hxi1vir2\x01hxi1qiki2vi', 1);('c16proof seef22', 1);('fltrans59lemma c14 covering propagation', 1);('2w \x02a g0\x14 \x14tnlogn\x00fltwtwk\x01kr1\x01 logn\x00fltatak\x01kr1\x01ohere conventionqt\x001', 1);('t\x01\x111', 1);('ast\x001xt0\x14e\x1at\x01tatw\x01t\x001y t1e\x1a e \x15', 1);('c17wheree', 1);('anyf2flta letfaggtrans\x120\x0ef exists bf', 1);('xn\x01\x00\x00bfx1bfxn\x01', 1);('maxi2n fxi\x00bfxi maxi2n aggtrans\x120\x00fxi\x01\x00aggtrans\x120\x00bfxi\x01 \x14maxi2n', 1);('fxi\x00bfxi', 1);('r1\x14where rst inequality', 1);('1lipschitz continuity aggtrans\x120', 1);('nfltak\x01kr1throughout', 1);('proof x parameters fwtatg0\x14t\x14t\x001', 1);('intermediate input sequences bxtand output sequences bxt', 1);('startingfrombx0x0x', 1);('constructions followsbxt2nx ffnbxtat\x00x r1\x14tax2fltaobxt12nx mhabxtwt bxt\x00x r1\x14twx2flt1wo', 1);('c18for', 1);('inductive constructions', 1);('r1 ffnxtat\x00bxt r1\x14 ffnxtat\x00ffnbxtat r1 ffnbxtat\x00bxt r1\x14 ffnxtat\x00ffnbxtat r1ta', 1);('c1960where', 1);('nition bxt1in', 1);('c18', 1);('rst termon righthand side', 1);('c19', 1);('ffnxtat\x00ffnbxtat r1c20', 1);('a\x1btrelu xtaxt xt\x00a\x1btrelu', 1);('bxtaxt\x00bxt r1\x14', 1);('relu xtaxt\x00relu', 1);('bxtaxt r1', 1);('r1\x14e t\x01', 1);('r1where rst', 1);('axta\x1bt2aand', 1);('nition e tin', 1);('c6 lemma c13', 1);('r1\x14 mhaxtat', 1);('xt\x00mhabxtat\x00bxt', 1);('r1 mhabxtat bxt\x00bxt r1\x14\x00\x1awt 1\x01\x01kxt\x00bxt r1tw\x14e\x1at\x01', 1);('c21where', 1);('lemma c13', 1);('g4', 1);('c21 c20 c19', 1);('r1\x14e\x1ate t\x01', 1);('xt\x00bxtkr1e\x1at\x01tatwrecursively', 1);('inequality conclude proof', 1);('lemma c14c53', 1);('transformer covering lemma c8proof lemma c14', 1);('2w \x02a g0\x14 \x14tnlogn\x00fltwtwk\x01kr1\x01 logn\x00fltatak\x01kr1\x01ofirst', 1);('tat\x01 xtr\x1bt \x1btrxtevte t andtwt\x01rmhatevt', 1);('notethat lemma g6', 1);('r1\x14r0\x01e tt\x001y 0ev e', 1);('r1\x14r0\x01t\x001y 0ev e 61by', 1);('lemma c10', 1);('xtr\x1bt \x1btrxt\x01', 1);('xtr\x1bt \x1btrxtr0\x01qt 0ev e t\x13on hand', 1);('lemma c12', 1);('xtwt2wt', 1);('twk\x01kr1\x11\x14logn\x10\x08mhaxtwtwt2wt twk\x01kr1\x11\x142 h\x01d2\x01log\x121 2rtrmhattw\x13', 1);('h\x01d2\x01log\x121 2r0\x01qt 0ev e t\x13where', 1);('choice tw', 1);('theperlayer resolutions ftg0\x14t\x14t\x001that', 1);('c17', 1);('ist\x001xt0\x14t\x01\x12rmhatevt xtr\x1bt \x1btrxte t\x13\x01t\x001y t1e\x1a e \x15', 1);('c24for', 1);('0\x14t\x14t\x001 settrtranst\x01qt\x001 t1ev e', 1);('c24', 1);('lemma c14 c22 c23', 1);('andthe choices offtg0\x14t\x14t\x001 obtainlogn\x00fltransk\x01kr1\x01\x14t\x001xt0supfw', 1);('2w \x02a g0\x14 \x14tnlogn\x00fltwtwk\x01kr1\x01 logn\x00fltatak\x01kr1\x01o\x144 h\x01d2t\x01log\x121 2rtranstrt\x13therefore conclude proof', 1);('lemma c862d optimization error analysisproof proposition', 1);('letblf\x12', 1);('stationarypointb\x12that0\x14r\x12blfb\x12\x12\x00b\x12 behrfl\x00xyfb\x12\x01r\x12fb\x12x\x12\x00b\x12isince objective function', 1);('ky\x00fxk22is convex respect fx wehave0\x14behrfl\x00xyf\x12\x03\x01f\x00f\x12\x03xiwhere\x12\x03 argmin\x122\x02blf\x12', 1);('nition objective function', 1);('y\x00fb\x12x 2\x142kyk2 2kfb\x12x', 1);('d1where', 1);('aggregation layer agg\x12rdprdyoutputs', 1);('thatblfb\x12\x00blf\x12\x03\x14behrfl\x00xyfb\x12\x01fb\x12\x00f\x12\x03xi\x14behrfl\x00xyfb\x12\x01fb\x12\x00f\x12\x03xibehrfl\x00xyfb\x12\x01r\x12fb\x12x\x12\x00b\x12ibehrfl\x00xyfb\x12\x01\x00fb\x12x r\x12fb\x12x\x12\x00b\x12\x00f\x12\x03x\x01i\x14be\x14 rfl\x00xyfb\x12\x01 2\x01 fb\x12x r\x12fb\x12x\x12\x00b\x12\x00f\x12\x03x 2\x15\x144\x01 fb\x12x r\x12fb\x12x\x12\x00b\x12\x00f\x12\x03x', 1);('d2where', 1);('cauchyschwartz', 1);('line followsfrom', 1);('d1', 1);('d2', 1);('\x122\x02 haveblfb\x12\x00blf\x12\x03\x144\x01min\x122\x02beh fb\x12x r\x12fb\x12x\x12\x00b\x12\x00f\x12\x03x 2itherefore conclude proof', 1);('rkhse1 latenttovalue rkhsrecall', 1);('followshltv\x1ag zmsk', 1);('z0kltvz0zmskdz0kg \x01mskkhltv1\x1b', 1);('e163which', 1);('inner product h\x01\x01ihltv', 1);('nition kernel functionkltv\x01\x01msk g \x01msk2h', 1);('ltvthatg', 1);('z0kltvz0zmskdz0\x12z z0 z0mskdz0zw 2rd\x13 zmsk w zmsk', 1);('e2from e2', 1);('w corresponds vector wi2rdpin function class', 1);('gyiwhich', 1);('g \x01msk 2hltvg \x01mskg \x01msk', 1);('hltvz', 1);('z0kltvz0zmsk zdzdz0\x12z z0 z0mskdz0\x13\x12z z zmskdz\x13kw k22', 1);('e3where', 1);('nition kernel function', 1);('kltv\x01\x01msk', 1);('nition w', 1);('e2 combining e2 e3', 1);('thede nition ofhltvin', 1);('havehltv\x08w zmsk w 2rdkw k21', 1);('gyithus', 1);('gyicorresponding', 1);('ith entry functions function classgis', 1);('rkhshltv', 1);('gyis', 1);('contains thelatenttotarget functions', 1);('supervised learningproof theorem', 1);('letf\x122f', 1);('thede nition approximation error', 1);('haveeapprox minf2fattnehl\x00xyf\x01i\x00ehl\x00xyf\x03\x01i\x14ehl\x00xyf\x12\x01i\x00ehl\x00xyf\x03\x01ieh f\x12xmsk\x00f\x03x 22i\x142eh f\x12xmsk\x00fywxmsk 22i 2eh fywxmsk\x00f\x03x 22i\x142\x0f2attn 2eh fywxmsk\x00f\x03x 22i', 1);('e464where', 1);('f\x122f attn', 1);('nition regression function f\x03x', 1);('linefollows 511in', 1);('gap regression function f\x03x', 1);('ezjx\x02g\x03zmsk\x03ezjx\x02gywzmsk\x03ezjx\x02g\x03zmsk\x00gywzmsk\x03fywxmsk ezjx\x02g\x03zmsk\x00gywzmsk\x03where', 1);('attentionfywxmsk thateh f\x03x\x00fywxmsk 22ie\x14', 1);('e5by assumption', 1);('22dyxi1ezjx\x02g\x03izmsk\x00gywizmsk\x032\x14dyxi1 g\x03i\x01msk\x00gywi\x01msk', 1);('e6 e5', 1);('obtaineh f\x03x\x00fywxmsk 22i\x14e\x02\x0f2gmsk\x03\x0f2gmsk', 1);('e7finally', 1);('e7 e4', 1);('obtaineapprox\x142\x0f2attn 2\x0f2gmskwhich concludes proof', 1);('selfsupervised learningproof theorem', 1);('recall bwdswsslwssl\x001wsslis', 1);('wede ne key surrogate function followsefptxmsk', 1);('pt bbfptxmsk pt65for', 1);('dsf\x12ds\x01i\x00ehl\x00xy dsf\x03ds\x01ie8eh', 1);('22i\x143eh f\x12dsxmsk', 1);('ds\x00efwdsxmsk pt', 1);('22i 3eh efwdsxmsk', 1);('22i 3eh fywdsxmsk', 1);('22i\x143\x0f2aggb 3eh efwdsxmsk', 1);('ds\x00fywdsxmsk ds', 1);('22i z i3eh fywdsxmsk', 1);('22i z iiwhere', 1);('nition regression function f\x03dsx', 1);('eydsjxand', 1);('bbfptzmsk pt\x00wdsezjx\x02 dszmsk ds\x03', 1);('b\x10bfptxmsk pt\x00f\x03ptx\x11\x10bf\x03ptx\x00ezjx\x02wds dszmsk ds\x03\x11', 1);('b\x00bfptxmsk pt\x00f\x03ptx\x01', 1);('z ii', 1);('dszmsk ds\x03\x11', 1);('z iii', 1);('e9in', 1);('terms ii iii', 1);('haveii\x14kbk22\x01 bfptxmsk', 1);('22\x14\x16\x01 bfptxmsk', 1);('e10on', 1);('bin', 1);('bezjx\x02g\x03ptzmsk pt\x00wssl dszmsk ds\x03', 1);('ezjx\x02g\x03ptzmsk pt\x00gywsslzmsk ds\x03', 1);('pt\x00gywsslizmsk ds\x032\x14\x16\x01dxi1', 1);('pt\x00gywsslizmsk ds', 1);('ptmsk ds e1166where', 1);('assumption61 recall', 1);('e10 e11 e9', 1);('eh', 1);('22i\x14eh2\x16\x01 bfptxmsk', 1);('ptmsk dsi\x142\x16\x01eptapprox', 1);('ptmsk dsi', 1);('2\x16\x01\x00eptapprox \x0f2sslmsk', 1);('ptmsk ds\x01 e12where', 1);('nition regression function f\x03ptx', 1);('eyptjxfor', 1);('ii arguments', 1);('e5', 1);('e\x14 ezjx\x02g\x03dszmsk ds\x00gywdszmsk ds\x03', 1);('e13by assumption', 1);('ezjx\x02g\x03dszmsk ds\x00gywdszmsk ds\x03', 1);('ds\x00gywdsizmsk ds\x032\x14dyxi1', 1);('ds e14taking e14 e13', 1);('ds\x03\x0f2gmsk ds e15taking e12 e15 e8', 1);('auxiliary proofs generalizationf1', 1);('dudley entropy integral lemma c7proof letj', 1);('denote njthe', 1);('fdnthatachieves', 1);('nfdnjk\x01kr1', 1);('words exists bfj2nj67such max i2njfxi\x00bfjij\x14jfor anyf2f havee\x0f\x14supf2fnxi1\x0fi\x01fxi\x15e\x0f\x14supf2f\x1anxi1\x0fi\x01\x00fxi\x00bfji\x01j\x001xj1nxi1\x0fi\x01bfji\x00bfj1i\x00nxi1\x0fi\x01bf1i\x1b\x15\x14e\x0f\x14supf2fnxi1\x0fi\x01\x00fxi\x00bfji\x01\x15j\x001xj1e\x0f\x14supf2fnxi1\x0fi\x01bfji\x00bfj1i\x15e\x0f\x14supf2fnxi1\x0fi\x01bf1i\x15\x14e\x0f\x14supf2fnxi1\x0fi\x01\x00fxi\x00bfji\x01\x15z ij\x001xj1e\x0f\x14supf2fnxi1\x0fi\x01bfji\x00bfj1izii\x15where', 1);('v1f01\x02ng', 1);('boundi ii', 1);('havei\x14e\x0f\x14nxi1j\x0fij\x15\x01supf2fmaxi2n fxi\x00bfji \x14n\x01j', 1);('f1bounding', 1);('ii havesupf2fbfj2njbfj12nj1kbfj\x00bfj1k2\x14 supf2fbfj2njkbfj\x00fdnk2 supf2fbfj12nj1kfdn\x00bfj1k2\x14pn\x01supf2fbfj2njkbfj\x00fdnk1pn\x01 supf2fbfj12nj1kfdn\x00bfj1k1\x14pn\x01jpn\x01j1 3pn\x01j1by', 1);('massarts', 1);('nite class lemma havee\x0f\x14supf2fnxi1\x0fi\x01bfji\x00bfj1i\x15\x143pn\x01j1\x01q2', 1);('f1 f2', 1);('jsuch', 1);('that\x18\x14jtherefore conclude proof', 1);('lemma c7f11', 1);('matrix ball covering lemma c9proof lemma c9 letm', 1);('m1md12rd2\x02d1 wheremj2rd1\x021 vecm m1md12r1\x02d1d2', 1);('ne sectional norm vec', 1);('vecm rd2sd1kmkrswhich veri', 1);('proper norm', 1);('lemma g1', 1);('settingbb\x03\x08m2rd1d2kmkrd2sd1\x141 \x08m2rd2\x02d1kmkrs\x141 andk\x01kk\x01k\x03k\x01krd2sd1 obtainlogn\x10\x08m2rd2\x02d1kmkrs\x14rm k\x01krs\x11 logn\x10\x08m2rd1d2kmkrd2sd1\x141', 1);('rmk\x01krs\x11\x14vol2rm\x01b\x03bvolbd1d2\x01log\x121', 1);('2rm\x13therefore conclude proof', 1);('lemma c9f2 lipschitz continuity multihead attentionfirst', 1);('continuity softmaxlemma', 1);('f1 lipschitz continuous softmax suppose', 1);('qbq2r1\x02dk andkbk2rl\x02dp choice \x1b 2dp12s', 1);('softmax qk\x00softmax qbk 1\x14\x00kqkrkkkr1\x01\x01kk\x00bkkr1', 1);('softmax qk\x00softmax bqk 1\x14\x00kqkrkkkr1\x01\x01kq\x00bqkr', 1);('f469proof letp', 1);('p1pl softmax qk2r1\x02l havepexp\x08\x00kq\x00kk222\x1b2', 1);('denoteg\x00kq\x00kk222\x1b2andg', 1);('jacobian', 1);('pwith respect kbej2rl\x02dp andp diagp\x00pp havejpkpg\x01gkpgkwheregk eq\x00ek\x1b2', 1);('heree02rl\x02lis', 1);('unit matrix', 1);('0th entryis', 1);('continuity softmax respect', 1);('kandk\x01kr1we', 1);('lx1j\x01', 1);('1\x14lx1kj\x01k1\x14lx1kjkr1\x01k\x01kr\x14k\x01kr1\x01lx1kjkr1where \x01 \x011 \x01l', 1);('bypl1kjkr1for any2l havekjkr1\x14d1\x001rp\x1b2\x01', 1);('peq\x00ek', 1);('1d1sp\x1b2\x01p\x01 e\x00pq\x00k 1d1spp\x1b2\x01ke\x00pks\x01kq\x00kkrwhere rst equality', 1);('consequence obtainx2lkjkr1\x14d1sp\x1b2\x01x2lp\x01ke\x00pks\x01kq\x00kkr\x14d1sp\x1b2\x01\x00kqkrkkkr1\x01\x01x2lp\x01ke\x00pks', 1);('f5on', 1);('hand havex2lp\x01ke\x00pksx2l\x1ap\x01\x14x06lps0 1\x00ps\x151s\x1b\x14x2lp\x01\x0221\x00ps\x031s\x1421s', 1);('f6therefore f5 f6', 1);('\x1b 2dp12sx2lkjkr1\x142dp1s\x1b2\x01\x00kqkrkkkr1\x01thus softmax', 1);('kwith', 1);('respect tok\x01kr1 whichproves', 1);('kq', 1);('f4', 1);('lemma f170f21', 1);('parameter lipschitz continuity lemma c11proof', 1);('notational simplicity writeheadiattn', 1);('smxwqixwkixwviheadiattn smxcwqixcwkixcwviby', 1);('nition multihehead attention', 1);('mhaxw\x00mhaxcw r1\x14 hxi1headi\x00hxi1headi r1\x14hxi1 headi\x00headi r1', 1);('f7by', 1);('nition attention', 1);('headi\x00headi r1 attn', 1);('smxwqixwkixwvi\x00attn smxcwqixcwkixcwvi', 1);('xwvisoftmax xwqixwki\x00xcwvisoftmax xcwqixcwki', 1);('r1 max2l', 1);('xwqixwki\x00xcwvisoftmax xcwqixcwki rf8note thatkxwqikr', 1);('xwqi', 1);('r\x11\x01kxkr1\x14qiki\x01rthen 2l', 1);('xwqixwki\x00xcwvisoftmax xcwqixcwki r\x14 softmax xcwqixcwkixwvi\x00cwvi r \x00softmax xwqixwki\x00softmax xcwqixcwki\x01xwvi r\x14', 1);('rs\x01kxkr1 softmax xwqixwki\x00softmax xcwqixcwki 1\x01', 1);('r1\x11\x01vir2\x01qiki\x14r\x01vi qikivi\x01r3\x01qiki', 1);('f10where', 1);('f1', 1);('f9', 1);('f10 f8', 1);('headi\x00headi r1\x14r\x01vi qikivi\x01r3\x01qiki', 1);('f1171finally', 1);('f11 f7', 1);('mhaxw\x00mhaxcw r1\x14r\x01hxi1vir3\x01hxi1qiki\x01qikitherefore conclude proof', 1);('lemma c11f22', 1);('input lipschitz continuity lemma c13proof', 1);('slight abuse notations writeheadiattn', 1);('smxwqixwkixwviheadiattn smbxwqibxwkibxwvisimilar f7', 1);('mhaxw\x00mhabxw r1\x14hxi1 headi\x00headi r1for', 1);('headi\x00headi r1', 1);('xwqixwki\x00bxwvisoftmax bxwqibxwki r\x14 softmax bxwqibxwki 1\x01', 1);('r\x01kx\x00bxkr1 softmax xwqixwki\x00softmax bxwqibxwki 1\x01', 1);('r2\x01qiki2\x03\x01kx\x00bxkr1 f12where', 1);('lemma f1 f9', 1);('inequality followsfrom', 1);('lemma f1', 1);('f9 summing f12', 1);('mhaxw\x00mhabxw r1\x14\x1ahxi1vi\x01\x021', 1);('r2\x01qiki2\x03\x1b\x01kx\x00bxkr1\x14hxi1vir2\x01hxi1qiki2vi\x15\x01kx\x00bxkr1therefore', 1);('lemma c1372g auxiliary lemmaslemma g1', 1);('ratios metric entropy wainwright', 1);('consider', 1);('pair ofnormsk\x01k andk\x01k\x03onrd', 1);('bandb\x03be', 1);('corresponding unit balls', 1);('b\x03in', 1);('thek\x01knorm obeys bounds\x00d\x01volb\x03volb\x14n\x00b\x03k\x01k\x01\x14vol2\x01b\x03bvolblemma', 1);('g2 caponnetto de vito', 1);('\x17 probability space \x18bea random', 1);('thatthere exists constants', 1);('b\x1b', 1);('h\x14b2ase\x02k\x18k2h\x03\x14\x1b2then', 1);('l\x001lxi1\x18i\x00e\x18', 1);('g3', 1);('rs conjugate pair', 1);('m2rd1\x02d2b2rd2\x021b2rd2\x02d3', 1);('letm', 1);('m1\x01\x01\x01md2 andb b1\x01\x01\x01bd2 havekmbkr d2xj1bj\x01mj r\x14\x12d2xj1jbjj\x13\x01maxj2d2kmjkrkmkr1\x01kbk1also havekmbkr d2xj1bj\x01mj r\x14\x12d2xj1jbjj\x01kmjkr\x13\x14kmkrs\x01kbkras consequence b b1\x01\x01\x01bd3 havekmbkr1 maxj2d3kmbjkr\x14maxj2d3kmkrs\x01kbjkrkmkrs\x01kbkr1on hand', 1);('nition matrix operator norm', 1);('obtainkmbkr1 maxj2d3kmbjkr\x14maxj2d3kmkr\x01kbjkrkmkr\x01kbkr1therefore conclude proof', 1);('lemma g373lemma g4 covering coe\x0ecient bounds', 1);('\x14t\x14t\x0011 \x1awt\x14evt qkt2vt\x01rt2e\x1atrmhawt\x14rvtqktrqkt\x01rt2rmhatwheree\x1atandrmhatare', 1);('rmhaw c15', 1);('havermhawt hxi1rvti', 1);('rxt2\x01hxi1qtiktirqtirkti\x14rvt rt2\x01maxi2hfqtiktig\x01hxi1rqtirktirvtqktrqkt\x01rt2rmhatalso', 1);('nition \x1aw', 1);('c16', 1);('have1 \x1awt', 1);('rxt2\x01hxi1qtikti2vti\x14evt rt2\x01maxi2hfqtiktig2\x01hxi1vtievt', 1);('qkt2vt\x01rt2e\x1attherefore conclude proof', 1);('lemma g4lemma g5 simpli', 1);('covering coe\x0ecient', 1);('rtrtranst o\x10tplog2', 1);('ptqlog1 \x10r0 plog1 \x14\x10\x11where factors', 1);('right hand side', 1);('c8 rtandrtranstarede', 1);('c6 c10', 1);('nitions \x14tand\x10tin', 1);('c7', 1);('havermhate\x1atrvtqktrqkt\x01rt2evt qkt2vt\x01rt2\x14max\x1arvtevtrqktqktvt\x1b\x14\x14te\x1atevt', 1);('\x10t\x01rt274which givesrtranstt\x001xt0\x14\x12rmhate\x1at xtr\x1bt \x1btrxte t\x13\x01t\x001y t1e\x1a ev \x15\x14t\x001xt0\x1a\x14t\x14t\x01t\x001y t1\x021 \x10t\x01rt2\x03\x1b\x142\x14\x01t\x001xt0\x1at\x001y t1\x021 \x10\x01rt2\x03\x1bwhere', 1);('nition \x14and\x10in', 1);('rtin c6', 1);('havertr0\x01t\x001y 0ev e \x14r0\x011 2tas consequence obtainrtranstrt\x142\x14r0\x011 2t\x01t\x001xt0t\x001y t1\x021 \x10r0\x011', 1);('\x03\x142\x14r0\x011 2t\x01t\x001xt0\x021 \x10r0\x011 4t\x03t\x00t2 2\x14\x01\x021 \x10r0\x011 4t\x033\x01\x021 \x10r0\x011 4t\x03t\x001\x10\x011 2t\x142\x14\x10\x01\x021 \x10r0\x011 4t\x03t3thus usingpab\x14papband log1 ab\x14log1 log1 b obtainqlog1', 1);('rtranstrt o\x10qt2log2 tlog1', 1);('\x10r0 log1 \x14\x10\x11o\x10tplog2 ptqlog1 \x10r0 plog1 \x14\x10\x11therefore conclude proof', 1);('lemma g5lemma g6 interlayer magnitude suppose r0', 1);('r1\x14e trt', 1);('c6proof settingbx', 1);('f7', 1);('mhaxw r1\x14o\x01hxi1kheadikr175we i2hkheadikr1', 1);('xwvisoftmax xwqixwki', 1);('r1 maxl2l', 1);('xlwqixwki r\x14maxl2l softmax xlwqixwki 1\x01', 1);('mhaxwx r1\x14kxkr1\x12hxi1vi\x13\x01kxkr1', 1);('r1\x141 vt\x01', 1);('g1on', 1);('hand setting bxt 0l\x02din', 1);('c20', 1);('xt1', 1);('r1 ffnxtat r1\x14e t\x01', 1);('g2recursively', 1);('g1 g2', 1);('lemma g676', 1);