('fsoi', 38);('gaussian', 21);('bayesian', 19);('l2\x1a', 18);('lcurve', 17);('theorem', 13);('toeplitz', 12);('map', 11);('lg', 8);('pli1ci', 8);('rkhs', 8);('da', 7);('dartr', 7);('inverse problem', 7);('additionally', 7);('figure', 6);('hilbert', 6);('l2s\x1a', 6);('proposition', 6);('proper subspace', 6);('assumption', 6);('dataadaptive', 6);('eigenvalue problem', 5);('lg\x001', 5);('a3', 5);('q\x0010', 5);('lghas', 5);('small noise limit', 5);('stable posterior', 5);('adiscretization101102103104105101610131010107104101model', 4);('iqr da', 4);('iqr fixed', 4);('amodel', 4);('iqr', 4);('lgis', 4);('suppose assumption', 4);('fr\x13', 4);('function space identi ability', 4);('penalty term', 4);('tikhonov', 4);('springer', 3);('machine learning', 3);('ais', 3);('inverse problems', 3);('d2lgl2\x1a', 3);('rkhs tikhonov', 3);('white noise', 3);('hopkins', 3);('pdes', 3);('attains posterior', 3);('numerical', 3);('furthermore', 3);('adaptive data', 3);('divergent posterior', 3);('computer methods applied mechanics engineering', 2);('lu maggioni tang learning', 2);('computing', 2);('scienti', 2);('siam', 2);('q lang', 2);('particle systems', 2);('annals statistics', 2);('error101102103104105101610131010107104101partial observation101102103104105101610131010107104101wrong noise101102103104105101610131010107104101 discrete', 2);('hyperparameter \x15\x03in', 2);('statistical', 2);('fsoi l2\x1a', 2);('n0q', 2);('i ji1\x14ij\x14lis', 2);('bh', 2);('part', 2);('able part', 2);('lgin', 2);('map true', 2);('map da', 2);('75thand 25thpercentiles true2fsoi1', 2);('daprior', 2);('regression matrix', 2);('cases dataadaptive', 2);('independent simulations', 2);('errors posterior', 2);('wrong noise assumption', 2);('r10', 2);('relative errors posterior', 2);('inverse problem dataadaptive', 2);('example', 2);('bqb', 2);('basis matrix', 2);('relation', 2);('letaandbbe', 2);('hence', 2);('computational', 2);('figures', 2);('aoptimal', 2);('mse map', 2);('remark', 2);('expected mse map', 2);('priors', 2);('smallnoise limit', 2);('cameronmartin', 2);('di', 2);('di\x15i', 2);('assume', 2);('n0q0', 2);('lebesgue', 2);('nitedimensional ie', 2);('recall', 2);('aand', 2);('htrue', 2);('dis', 2);('fsoi h', 2);('l2\x1ain', 2);('echet derivative', 2);('n0\x1b2\x11lg', 2);('dlg', 2);('orthonormal basis', 2);('gis', 2);('delta function', 2);('kronecker', 2);('examples', 2);('function space learning', 2);('function', 2);('functional quadratic', 2);('suppose', 2);('e\x11y\x11y0', 2);('consider', 2);('incomplete data', 2);('model error', 2);('learning', 2);('interaction kernels', 2);('rkhsnorm', 2);('zellners', 2);('importantly', 2);('covariance matrix', 2);('appendix', 2);('matrices integraloperators', 2);('regularization method', 2);('square errorof', 2);('true kernel', 2);('issue dataadaptive', 2);('common use nondegenerate', 2);('approach overcomes illposedness', 2);('matrices integral operators', 2);('investigacion operativa', 1);('estadisticay', 1);('trabajos', 1);('regression hypotheses', 1);('odds ratios', 1);('zellner siow posterior', 1);('functional linear regressionthe', 1);('space approach', 1);('yuan cai', 1);('learning nonlocal physics fromhigh delity synthetic data', 1);('h yu n trask gulian delia datadriven', 1);('datadriven peridynamic continuum model upscalingmolecular dynamics', 1);('h yu silling delia', 1);('particle systemsarxiv preprint arxiv220507937', 1);('eld nonparametric estimation', 1);('r yao x chen yang mean', 1);('sovietmath', 1);('problems regularization method', 1);('n tihonov solution', 1);('methodological', 1);('series b', 1);('statisticalsociety', 1);('r tibshirani regression shrinkage selection via lasso', 1);('acta numer', 1);('stuart inverse', 1);('measures journal', 1);('characteristic kernels andrkhs', 1);('k sriperumbudur k fukumizu g r lanckriet universality', 1);('376a2451a2487201550 b', 1);('lowrank approximations bayesian linear inverse problems', 1);('tenorio marzouk optimal', 1);('spantini solonen cui j martin', 1);('computational appliedmathematics', 1);('adaptive quadrature matlab journal', 1);('shampine vectorized', 1);('l f', 1);('noise removal algorithmsphysica nonlinear phenomena', 1);('total variation', 1);('rudin osher e fatemi nonlinear', 1);('monte carlo statistical methods springer', 1);('robert g casella', 1);('physics', 1);('ows learning kernels data abyss journal ofcomputational', 1);('h owhadi g r yoo kernel', 1);('motsch e tadmor heterophilious dynamics enhances consensus siam rev', 1);('wsindyphysica nonlinear phenomena', 1);('eld equations particle data', 1);('messenger bortz learning', 1);('swarm interaction dynamics density evolutionarxiv preprint arxiv211202675', 1);('mavridis tirumalai j baras learning', 1);('nature machine intelligence', 1);('universal approximation theorem operators', 1);('nonlinear operators', 1);('lu p jin g pang z zhang g e karniadakis learning', 1);('universal approximation theorem operators arxiv preprintarxiv191003193', 1);('nonlinear operators identifyingdi erential equations', 1);('lu p jin g e karniadakis deeponet learning', 1);('proc natl acad sci usa', 1);('inference interaction laws systemsof agents trajectory data', 1);('lu zhong tang maggioni nonparametric', 1);('foundations computational mathematics', 1);('multiple trajectories', 1);('interaction kernels stochastic systems interactingparticles', 1);('multiple trajectories journal', 1);('interaction kernels heterogeneous systems agentsfrom', 1);('machine learning pmlr', 1);('proceedings mathematical scienti', 1);('regularization learning kernels inoperators', 1);('lu q lang q data', 1);('learning kernels nonlocal operators arxiv preprintarxiv220511006', 1);('lu q yu nonparametric', 1);('conferenceon learning representations', 1);('neural operator parametric partial di erential equations', 1);('liu k bhattacharya stuart anandkumar fourier', 1);('kovachki k azizzadenesheli', 1);('z li n', 1);('stochastic processes applications', 1);('identi ability interaction functions insystems', 1);('zhang', 1);('lu maggioni tang', 1);('z li', 1);('paivarinta e somersalo linear', 1);('lehtinen', 1);('york', 1);('inc', 1);('p lax functional analysis john wiley', 1);('eld equations rstorder systems', 1);('lu learning', 1);('particlesarxiv preprint arxiv210605565', 1);('eld equations', 1);('ability interaction kernels', 1);('lu identi', 1);('maps function spaces arxiv preprint arxiv210808481', 1);('liu k bhattacharya stuart anandkumar neural', 1);('kovachki z li k azizzadenesheli', 1);('j kaipio e somersalo statistical computational inverse problems springer', 1);('ann statist', 1);('methods machine learning', 1);('j smola kernel', 1);('sch\x7f', 1);('hofmann', 1);('identi cation nonlocal potential inaggregation arxiv preprint arxiv220703358', 1);('liao h liu liu numerical', 1);('h kang', 1);('wit', 1);('p johnston advances computational bioengineering', 1);('computational inverse problems electrocardiology', 1);('numerical treatment inverse problems', 1);('hansen lcurve', 1);('numer algor', 1);('package analysis solution', 1);('hansen regularization tools matlab', 1);('statistical models volume 40cambridge university press', 1);('r nickl mathematical', 1);('e gin\x13', 1);('numerical algorithms', 1);('tools matlab package iterative regularizationmethods largescale test problems', 1);('hansen j g nagy ir', 1);('gazzola p', 1);('gaussianprocesses arxiv preprint arxiv210602735', 1);('j feng ren tang datadriven', 1);('constraints siam rev', 1);('problems', 1);('lehoucq k zhou analysis approximation nonlocaldi', 1);('gunzburger r', 1);('arxiv201103762 math stat', 1);('mckeanvlasov', 1);('nonparametric', 1);('della maestra ho', 1);('acta numerica', 1);('methods nonlocaland fractional models', 1);('glusa gunzburger x tian z zhou numerical', 1);('delia q', 1);('uncertainty quanti', 1);('siamasa', 1);('rates learninglinear operators noisy data', 1);('kovachki n h nelsen stuart convergence', 1);('hoop n', 1);('neural networks arxiv preprint arxiv220313181', 1);('costaccuracy tradeo', 1);('hoop z huang e quin stuart', 1);('uncertaintyquanti cation pages', 1);('handbook', 1);('bayesian approach inverse problems', 1);('dashti stuart', 1);('simple crossvalidation perspective part ii nonparametric kernel ows', 1);('dynamical systems fromdata', 1);('hamzi j susiluoto braverman h owhadi learning', 1);('darcy', 1);('university press201413', 1);('cambridge', 1);('nite dimensions', 1);('media200612 g da prato j zabczyk stochastic', 1);('science business', 1);('nitedimensional analysis', 1);('g da prato', 1);('subspace methodsbernoulli', 1);('performance analysis', 1);('cui x tong', 1);('cambridgeuniversity', 1);('theory approximation theory viewpoint volume', 1);('cucker x zhou learning', 1);('science pages273304', 1);('experimental design review', 1);('k chaloner verdinelli bayesian', 1);('active particles', 1);('usion equations dynamics asymptotics andsingular limits', 1);('j carrillo k craig yao aggregationdi', 1);('cham', 1);('matematica italiana springer', 1);('lecture notes', 1);('applications', 1);('bucur e valdinoci nonlocal di', 1);('pmlr', 1);('kernel learning27ininternational conference', 1);('deep learning need', 1);('belkin mandal', 1);('jun', 1);('variable selection', 1);('bayesian model choice withapplication', 1);('criteria', 1);('j bayarri j berger forte g garc\x13', 1);('regularization algorithms learning theory journal ofcomplexity', 1);('rosasco', 1);('bauer pereverzev', 1);('error101102103104105101610131010107104101partial observation101102103104105101610131010107104101wrong noise3 f', 1);('error101102103104105101610131010107104101partial observation101102103104105101610131010107104101wrong noisefigure', 1);('50505101520curvature 103curvaturefigure', 1);('selection hyperparameter \x15\x030738074074207440746420246lcurvelcurveopt', 1);('bayesian analysis', 1);('experimental designs inin nite dimensions', 1);('bayesian aand doptimal', 1);('alexanderian p j gloor ghattas', 1);('statistician', 1);('society series', 1);('journalof', 1);('note zellners gprior', 1);('reference informative', 1);('parisetti ag', 1);('c c', 1);('agliari', 1);('analyze optimal hyperparameterreferences1', 1);('theerror numerical computation matrix inversion solution linear systems cana ect result \x15\x03is', 1);('optimal hyperparameter method', 1);('large variation of\x15\x03suggests di\x0eculty', 1);('true kernel general', 1);('types errors bthe strength noise smoothness', 1);('thatthe optimal hyperparameter', 1);('similar majority scale', 1);('present \x15\x03in simulations', 1);('lshaped', 1);('method selectsthe parameter attains maximal curvature corner', 1);('wherer\x15 k \x15khganderepresents square root loss', 1);('select hyperparameter\x15\x03in dataadaptive', 1);('1\x0011the hyperparameter', 1);('corresponding eigenvectors', 1);('\x15diag\x1a orthonormalinl2\x1a eigenvalues f840gand', 1);('eigenvectors f', 1);('following', 1);('positive eigenvalues', 1);('lgwith', 1);('2g whichare eigenvectors', 1);('linear span f', 1);('l2\x1a fsoi', 1);('proper subset', 1);('fu3g inverse problem illde', 1);('explorationmeasure data', 1);('weights entries coe\x0ecient', 1);('qd02assigns', 1);('l2\x1abecause', 1);('dataset fu1u2g inverse problem', 1);('inverse problemis', 1);('operatorlghas eigenvaluesf11g', 1);('i2and4i2', 1);('identity matrix', 1);('qd01are', 1);('a1and', 1);('r3 theregression', 1);('informationfrom data identify \x001 result', 1);('datasetfu1g exploration measure \x1ais degenerate \x1a\x001', 1);('analyze wellposedness inverse problem terms operator', 1);('a3we', 1);('qd032416', 1);('qd02248', 1);('covariances \x15\x03qd0b\x001ab\x001areqd01240', 1);('diag\x1a', 1);('a2additionally', 1);('datasets area1240', 1);('apkluklukof', 1);('0u1u0u21u20u1u00u1u0u2035the regression matrices', 1);('lulu24u21u1u0', 1);('rank2 regression matrixlu\x14u1u000u1u0\x15', 1);('eachu u0u1', 1);('pkjuk0j2pkjuk1jjuk0j25since', 1);('pkjuk1j2pkjuk1jjuk0j', 1);('matrix datasetfuk uk0uk1gkleads explorationmeasure onsf\x00101g\x1a\x001', 1);('numerical examplescomputation', 1);('details', 1);('measure zeroa3', 1);('q12hhas', 1);('distribution isgaussiann0bqb', 1);('xbc', 1);('satis es', 1);('distribution randomvectorx h 1ih li2rl', 1);('complete basis need', 1);('sincef', 1);('byh iq ji', 1);('qis', 1);('agaussian distribution', 1);('coe\x0ecient c2rlof', 1);('space withbasis matrix', 1);('spanf igli1withl\x141', 1);('leth', 1);('a3 coe\x0ecients', 1);('measure onthe linear space basis spanslemma', 1);('hand distribution coe\x0ecient determines', 1);('ecc eb\x001xxb\x001 b\x001ab\x001on', 1);('distribution cb\x001xisn0b\x001ab\x001 thecovariance', 1);('gaussiann0a', 1);('h 1ih liis', 1);('thateh k li2 h k lq k li haveeh kih li 12\x00eh k li2\x00eh ki2\x00eh ki2\x01h kq lihence random vector', 1);('similarly', 1);('variable h hihas distributionn0hhqhithus haveh ki\x18n 0h kq ki eachk', 1);('nition h2h random', 1);('h iq jiproof', 1);('aij', 1);('measuren0b\x001ab\x001 matrix', 1);('nite coe\x0ecient c2rlof', 1);('hypothesis spaceh spanf igli1\x1ahwithl\x141 basis matrix', 1);('hand', 1);('letn0qbe gaussian', 1);('a2 operator', 1);('full partial basislemma', 1);('variable coe\x0ecient', 1);('gaussianrandom', 1);('lemma speci es covariance coe\x0ecient', 1);('ie\x15k0 allk product measure \x19q1k1nak\x15kwhereakhaeki2rfor eachkthe', 1);('ker qf0g', 1);('iseihahi\x0012hqhhifor anyh2h measure isnondegenerate', 1);('rheihxhi\x19dx', 1);('transform b\x19h', 1);('fourier', 1);('measure \x19naqi', 1);('qis gaussian', 1);('aand covariance operator', 1);('hwith', 1);('qa', 1);('orderand eigenfucntions', 1);('f\x15kekg1k1the eigenvalues', 1);('ishqxyihxqyiandhqxxi\x150 anyxy2h andpkhqekeki1for completeorthonormal basis fekg1k1', 1);('symmetric nonnegative trace class operator', 1);('qbe', 1);('borel', 1);('inner product h\x01\x01i letbh', 1);('hbe hilbert', 1);('covariance operator', 1);('b\x001av\x03v\x001 thusb\x001ab\x001v\x03v\x001v\x03v', 1);('avbv\x03', 1);('sincevbvi', 1);('brkhs ba\x001b', 1);('a1cv\x00\x03\x001v\x001cwhere', 1);('lg\x001cv\x00', 1);('brkhs v\x03v\x001inh lg\x001', 1);('ic\x08 cv\x00', 1);('v\x08 x1\x14i\x14lci', 1);('thenwe', 1);('land \x08', 1);('followsnext compute h', 1);('equation', 1);('haveh i\x15k kil2\x1aplj1bijvjk\x15kfor eachi', 1);('bwe', 1);('56let kplj1vjk jwithvbvi kis eigenfunction oflgwith eigenvalue \x15kif ih i\x15k kil2\x1ah ilg kil2\x1ax1\x14j\x14lh ilg jil2\x1avjkx1\x14j\x14laijvjkwhere', 1);('ethe', 1);('unique minimizer loss', 1);('part henceb lg\x001 d', 1);('true ier trueuk fk', 1);('particular data noiseless model error andit', 1);('uniqueminimizer ofe inh', 1);('h hence', 1);('unique zero loss functionals', 1);('b thisestimator', 1);('lg\x001 dis', 1);('estimator b', 1);('fsoinext d2lgl2\x1a', 1);('function space weconclude', 1);('0such thatlg', 1);('note orthogonal complement null space', 1);('functional unique minimizer', 1);('c rst note quadratic loss', 1);('functional 214for', 1);('n0\x1b2\x11lgpart', 1);('thus\x0f\x11has gaussian', 1);('il2\x1afor 2l2\x1a', 1);('zero andvariance\x1b2\x11h', 1);('variable h \x0f\x11il2\x1a1np1\x14k\x14nhr uk\x11kiyis', 1);('whitenoise random', 1);('riesz', 1);('nitions operator', 1);('trueil2\x1ah \x0f\x18il2\x1ah \x0f\x11il2\x1awhere rst term', 1);('il2\x1a1nx1\x14k\x14nhr ukr trueukiyhr uk\x18kiyhr uk\x11kiyh', 1);('hand side', 1);('infkr trueuk \x18k\x11kinto', 1);('din', 1);('lg23proof theorem', 1);('inversion operator', 1);('trlg rsgrr\x1ardr1theorem', 1);('nite trace', 1);('ghas', 1);('p344the operatorlgwith integral kernel', 1);('hencersgrr\x1ardr\x14cjsj1', 1);('thusgrs grs\x1ar\x1as\x14c\x1ar\x001\x1as\x001for', 1);('1nx1\x14k\x14nzgukxrxgukxsx\x16dx\x14c\x1ar\x1asfor andrs2s whereczmax 1\x14k\x14ksupxy2jgukxyj', 1);('thengrs', 1);('have\x1ar 1znp1\x14k\x14nr gukxrx \x16dx', 1);('trlg rsgrr\x1ardrproof', 1);('atraceclass operator', 1);('a1 assumption', 1);('space satis espkhqekeki1for completeorthonormal basis fekg1k1lemma', 1);('qon hilbert', 1);('traceclass operatorrecall operator', 1);('lgde', 1);('lemma shows inversion operator', 1);('functional unique minimizerthe', 1);('main theme identi ability theory nd function space quadraticloss', 1);('ability theorythe', 1);('appendixa1 identi', 1);('yue yu mauro maggioni', 1);('flwould', 1);('university research fund', 1);('fa95502010288 fa95502110317 xw', 1);('catalyst', 1);('fl', 1);('methodologies eg46acknowledgmentsthe work', 1);('monte carlo', 1);('mcmc', 1);('open understandhow illposedness', 1);('nonlinear u', 1);('number linearlyindependent data fukgincreases', 1);('u linear u examples', 1);('statistical models eg22 operator', 1);('inverse problem whenthe datafukgare', 1);('big data', 1);('relevant era', 1);('various directions', 1);('covariancethrough fractional operator', 1);('interest overcomethese limitations future research', 1);('dependence theselection hyperparameter tendency', 1);('limitations dataadaptive', 1);('small noise limitswe', 1);('types errors', 1);('integral operators presence', 1);('toeplitzmatrices', 1);('advantage dataadaptive', 1);('analysis dataadaptive priorin computational practice', 1);('trace covariance operator', 1);('expectedmean square error posterior', 1);('dataadaptiveprior improves quality posterior', 1);('true kernelwhen perturbation vanishes dataadaptive priors covariance inversion operatorwith hyperparameter', 1);('small noise limit converges identi', 1);('small data induces perturbation eigenspace zeroeigenvalues inversion operatorwe', 1);('whenthe observation noise', 1);('approach overcomes illposedness nondegenerate priorhowever show', 1);('singularinversion operator', 1);('inverse problem learning kernels operators', 1);('conclusionthe', 1);('future work6', 1);('detect smoothness thetrue kernel', 1);('lgswiths\x150', 1);('open selectthe covariance operator', 1);('true kernel nonsmooth', 1);('restrictive data', 1);('true kernel inthe dataadaptive', 1);('unreliable covariancesecond premise dataadaptive', 1);('improper hyperparameter lead posterior inaccurate', 1);('smoothness asymptotic consistency', 1);('method stateoftheart method', 1);('relies selection hyperparameter\x15\x03', 1);('l2\x1athe', 1);('ie inverse problem', 1);('advantage vanishes operator', 1);('singular operator', 1);('overcomesthe illposedness', 1);('eigenspace withpositive eigenvalues operator', 1);('errorsoutside datadependent function space identi ability', 1);('practical method advantages disadvantages majoradvantage dataadaptive', 1);('dataadaptive prioras', 1);('limitations', 1);('kernel true54', 1);('small noise limit21figure', 1);('robust posterior', 1);('removes risk', 1);('con rm dataadaptive', 1);('kernel truein summary numerical results', 1);('priorbut when\x1b\x11', 1);('region percentiles', 1);('observation noise \x1b\x11', 1);('uncertainty cases', 1);('region thepercentiles', 1);('drawing samples posterior moreaccurate posterior', 1);('fsoirespectively', 1);('typical simulation trueis', 1);('posterior terms meanthe 75thand 25thpercentiles', 1);('medianin proof', 1);('error101102103104105108106104102100102104partial observation101102103104105108106104102100102104wrong', 1);('error101102103104105108106104102100102104partial observation101102103104105108106104102100102104wrong noise101102103104105108106104102100102104discretization101102103104105108106104102100102104l2 error discrete', 1);('fsoi discretization101102103104105108106104102100102104l2', 1);('iqr l2\x1a', 1);('model error partial observation error b shown20figure', 1);('due theerror', 1);('partial', 1);('model', 1);('andwrong noise', 1);('discretization', 1);('convergenceof posterior', 1);('small noiselimits whereas', 1);('fsoithe da', 1);('true kernels', 1);('decay \x1b\x110 error', 1);('wrong noise assumption casesthe error posterior', 1);('cases discretization', 1);('computedadmatchesbin sense b2rangead', 1);('diverge hand', 1);('priors posterior', 1);('ofad making', 1);('model error partial observation error bcauses perturbation', 1);('a3 similarlyeither', 1);('discrepancy betweenbandacleads perturbation', 1);('ac', 1);('posterior meanwhen', 1);('cases thedaprior', 1);('true kernels outsideof', 1);('simulations scenario', 1);('error101102103104105102100102104partial observation101102103104105102100102104wrong', 1);('error101102103104105102100102104partial observation101102103104105102100102104wrong noise101102103104105102100102104discretization101102103104105102100102104l2 error discrete', 1);('standard deviation \x1b\x11decreasesdiscretization101102103104105102100102104l2 error', 1);('observation noises', 1);('discrete data', 1);('bottom', 1);('continuous fukg', 1);('aiscomputed', 1);('row regression matrix', 1);('top', 1);('types errors discretizationmodel error partial observation', 1);('errors theposterior', 1);('50thand 25thpercentiles', 1);('interquartile', 1);('compute bfor simulationfigure', 1);('data fukgand basis functions', 1);('adacandbare', 1);('exploration measure matrices', 1);('adnote', 1);('lowfrequency eigenspace', 1);('ad', 1);('thejth eigenvector', 1);('wesample trueplj0c\x03j jwithc\x03fromn0i3 wheref jpli1vij', 1);('samples trueinside', 1);('sample coe\x0ecient c\x03of trueplj1c\x03j jfrom', 1);('sampledtwo scenarios', 1);('independent simulations inwhich trueare', 1);('report interquartile range', 1);('throughthe accuracy posterior', 1);('small noise limit posterior meanwe access performance', 1);('di erent levels observation noise \x1b\x11in 10\x001\x1810\x005so', 1);('error function', 1);('method report', 1);('cases compute posterior', 1);('variance level', 1);('weadd ap3', 1);('notice', 1);('interval\x00p3\x1b\x11p4yp3\x1b\x11p4y introduce error', 1);('wrong noise assumption assume', 1);('model error4', 1);('model error assume', 1);('model error3', 1);('forl 0l', 1);('fkmisses data rst quarter interval iefkl', 1);('partial observation', 1);('model error2', 1);('discretization error', 1);('happenin practice1', 1);('types errors addition observation noise bthat', 1);('multiple almostzero eigenvalueswe', 1);('inl2\x1a sincelghas', 1);('particular inverse problem', 1);('singular b', 1);('proper subsetof \x0011', 1);('sis', 1);('adb', 1);('badandlgwhich', 1);('shows exploration measure eigenvalues basis matrix', 1);('acfigure', 1);('thecontinuous uks quadrature integrations', 1);('e ects discretization error', 1);('pjj1', 1);('integration br uky', 1);('riemann', 1);('sum integrationadii0 1nnxk1jxj1br iukyjbr i0ukyj4ybi 1nx1\x14k\x14nlxl1br iukxlfkyl4ywhere approximate', 1);('aandbusing riemann', 1);('knots uniform partitionof \x0011 approximate', 1);('functions ie piecewise polynomials degree', 1);('bsplinebasis', 1);('spanf igli1 wheref igli1are', 1);('constant set', 1);('aoperator lgwithzbeing', 1);('bregression', 1);('15n104010201001020eigenvalues nbasis matrix', 1);('adb1', 1);('exploration measure eigenvalues basis matrix b regression matrixadand', 1);('dataset density\x1ar 1znnxk1z01rr1 uky dy r2\x001118figure', 1);('small model errorthe exploration measure', 1);('nomodel error \x1b\x18', 1);('variance\x1b2\x114yand\x18ky \x1b\x18uyjuyjare arti cial model errors \x1b\x18', 1);('wrong noise assumption case speci', 1);('ukyl \x11kl\x18kyl 58where\x11klare iidn0\x1b2\x11 random variables', 1);('data are\x08ukxjfkyl 3k1on uniform meshes fxjgjj1andfylgll1of 01withj', 1);('global adaptive quadraturemethod', 1);('n\x0016', 1);('normal distributions', 1);('inputoutput dataset\x08ukfk 3k1we setfukg3k1to probability densities', 1);('operator 26r uy', 1);('xyl201', 1);('wrong noiseassumptionrecall', 1);('data iv', 1);('types errors idiscretization error ii model error ii partial observation', 1);('convolution operator', 1);('similar demonstratethe computation', 1);('function space oflearningl2\x1a', 1);('continuous kernels integral operators', 1);('kernels integral operatorsfor', 1);('continuous', 1);('abecausevkfkis', 1);('bp1\x14k\x14n\x1bkvkvkfkis inthe range', 1);('range spanfvkgnk1where vks', 1);('ap1\x14k\x14n\x1b2kvkwkwkvkp1\x14k\x14n\x1b2kvkvk', 1);('unitary vectors', 1);('lk\x1bkwkvkwithwk2rm\x021andvk2rn\x021bothbeing', 1);('rank1 array', 1);('terms rank1 arraysnext k', 1);('ap1\x14k\x14np1\x14i\x14nklkilkiandbp1\x14k\x14np1\x14i\x14nklkifkin', 1);('lklkp1\x14ij\x14nk\x1b2kivkiwkiwkjvkjp1\x14i\x14nk\x1b2kivkivkip1\x14i\x14nklkilki', 1);('singular vectors orthonormal ie wkiwkj\x0eijandvkivkj\x0eijdenotelki\x1bkiwkivki rank1', 1);('wheref\x1bkiwkivkigare singularvalues', 1);('lkgiveslkp1\x14i\x14nk\x1bkiwkivki', 1);('singular valuedecomposition', 1);('svd', 1);('rank1 arrays', 1);('lks', 1);('show su\x0eces', 1);('aproof', 1);('wherelk2rn\x02mandfk2rn\x021for 1\x14k\x14n andmnn integers b2range', 1);('letap1\x14k\x14nlklkandbp1\x14k\x14nlkfk', 1);('derivatives throughintegration parts 30proposition', 1);('di erent regression arrays fromthose inadue discretization', 1);('continuous inverse problems', 1);('data fk', 1);('2rminlk fkfor 1\x14k\x14n regardless presence modelerror', 1);('discreteinverse problem', 1);('proposition shows', 1);('discrete problemmore', 1);('aor', 1);('inthe range operator', 1);('data bis', 1);('small noise limit m1exists regardless model erroreg\x18u 001ujuj2 computational error', 1);('range regression operator', 1);('show error', 1);('full rank operator17numerical tests', 1);('zero eigenvalue direction', 1);('becauseqd1has', 1);('theoriginal priorsq1', 1);('qd1is', 1);('71the trace dataadaptive priors posterior covariance', 1);('relative error', 1);('fsoibecause', 1);('part trueoutside', 1);('major bias', 1);('accurate truekernel', 1);('accurate originalpriors posterior', 1);('observationsthe dataadaptive', 1);('true 1in', 1);('standard deviations tracesand', 1);('compute trace covariance operator posterior', 1);('following remark', 1);('aspects trace covariance operator bias posterior', 1);('performance posterior', 1);('nondegenerateprior case', 1);('demonstrates signi cant advantage dataadaptive', 1);('standard deviations ofthe traces', 1);('bykm\x00 truekl2\x1ak truekl2\x1a', 1);('relative bias estimator mis', 1);('udata isfu3 11gthe', 1);('n0\x1b2\x11', 1);('random noises', 1);('independent datasets', 1);('bias m1 andbias ofmd1 traces covariance posteriors', 1);('standard deviations', 1);('ofm1bias ofmd1trq1trqd11112fsoi 034\x06001010\x06011 034\x0600000037\x060001012fsoi 094\x06001066\x06009 034\x0600000037\x06000 compute', 1);('bias', 1);('teoplitz', 1);('posteriors learning kernel', 1);('performance', 1);('lginl2\x1a', 1);('dataset fu3g eigenvectors', 1);('i3', 1);('2gl2\x1af840g\x03the basisf igare', 1);('3gl2\x1af222gfu3 11g', 1);('3gl2\x1af11gfu1u2 01g', 1);('fosi eigenvalues lgfu1', 1);('typical datasetsdatafukg\x1aonf\x00101g', 1);('learning kernel ina', 1);('lgfor', 1);('exploration measure', 1);('signi cantlyimproves accuracy posterior', 1);('thedatasetfu3 11gleads', 1);('datasetfu1u2 01gleads', 1);('r3', 1);('dataset fu1 10gleads', 1);('representative datasets inverse problem', 1);('sametoeplitz matrix n', 1);('coe\x0ecient c priors andposteriors', 1);('removethe redundant rows', 1);('aandbto', 1);('r2n\x001', 1);('independent basis forl2s\x1a', 1);('positive basis matrix singular basis functions linearlydependent', 1);('diag\x1a thusif\x1ais', 1);('basis matrix f ir \x0eri\x00rginl2s\x1a', 1);('thenthe', 1);('iwithci ri ish spanf ig2n\x001i1 16r2n\x001with basis ir \x0eri\x00r2l2sr where\x0eis', 1);('p2n\x001i1ci', 1);('unspokenhypothesis space vector', 1);('z\x001p1\x14k\x14np0\x14ij\x14n\x0ei\x00j\x00rljukjjwithrl2s', 1);('elements exploration measure basisfunctions exploration measure \x1ain', 1);('bin', 1);('unstable perturbations inverse problem illposedwe need identify basis matrix', 1);('howeverpseudoinverse', 1);('a\x001bwitha1np1\x14k\x14nluklukandb1np1\x14k\x14nlukfk a\x001is', 1);('lse', 1);('squares estimator', 1);('new information recovery', 1);('independent data fukgnk1brings', 1);('linear usincer u', 1);('luis', 1);('lu', 1);('eachu amatrixlu2rn\x022n\x001such thatr u', 1);('u linear', 1);('sr2n\x001withsfrlg2n\x001l1withrll\x00n sincer', 1);('kernel vector', 1);('data model', 1);('matrix measurement datafukfk2rn\x02rngnk1by', 1);('rn\x02ntoeplitz', 1);('kernel 2r2n\x001in', 1);('dataadaptive function space identi abilityand advantage dataadaptive priorrecall aim', 1);('typical example discrete kernels', 1);('nitedimensional functionspace learning', 1);('vector kernel', 1);('qd0\x15\x001\x03b\x001ab\x001\x19d1nmd1qd1md1\x1b\x002\x11qd1b qd1\x1b2\x11a\x1b2\x11\x15\x03ba\x001b\x00152 discrete', 1);('q0i\x191nm1q1m1 a\x1b2\x11i\x001b q', 1);('mean covariance\x190nm0q0m0', 1);('i2h\x1al2\x1agaussian measure', 1);('posteriors coe\x0ecients cof', 1);('summarize priors posteriors computation', 1);('v\x03v\x001ba\x001bwe', 1);('iinlg12l2\x1a haveh', 1);('additionally plici', 1);('kplj1vjk jg', 1);('lgaref', 1);('corresponding eigenfunctions', 1);('diag\x151\x15l', 1);('bin51 avbv\x03', 1);('generalize eigenvalueproblem', 1);('nedin53 operator', 1);('spanf igli1\x13lgl2\x1awithl\x141 wherelgl2\x1al2\x1abe integral operator', 1);('hypothesis space satis es', 1);('appendix a1proposition', 1);('eigenvalueproblem proof', 1);('lgare', 1);('proposition shows eigenvalues', 1);('av\x15bv', 1);('generalizedeigenvalue problem', 1);('trace operator', 1);('bin51', 1);('spanf igli1 h iq ji', 1);('n0qonh', 1);('lemma a2 a3', 1);('independent of15the basis relation distributions coe\x0ecient function characterizedby', 1);('posterior distributions function', 1);('posterior distributions coe\x0ecient cdepend basis f igli1 theyare', 1);('distributions coe\x0ecient function emphasizethat', 1);('lgsee proposition', 1);('general eigenvalue problem tosolve eigenvalues', 1);('brkhs', 1);('computation matrix', 1);('basis functions f igare', 1);('isbrkhsij h ilg\x001 jil2\x1ah i jihg', 1);('lemma28', 1);('rkhs hgde', 1);('covarianceqd0in55 pseudoinverse basis matrix f igin', 1);('b\x001ab\x001in', 1);('gprior basis hypothesis space orthonormal inl2\x1athat basis matrix b h i jil2\x1a1\x14ij\x14li haveqd0a', 1);('relation zellners', 1);('letdb\x001a12and writeqd1asqd1\x1b2\x11a\x1b2\x11\x15\x03ba\x001b\x001\x1b2\x11ddad\x15i\x001d 56remark', 1);('a\x001', 1);('increase thenumerical stability', 1);('large numerical error', 1);('qd1in55can', 1);('pseudoinverse singular matrix inverse matrix', 1);('avoiding', 1);('abremark', 1);('balancebetween minimization likelihood control regularization\x15\x03 argmax\x15min\x14\x15\x14\x15max\x14l\x15 \x14l\x15 x0y00\x00x0y00x02 y0232where\x15minand\x15maxare', 1);('method maximize curvature', 1);('loglogplot curve l\x15 y\x15x\x15 withy\x152c\x15ba\x001bc\x15andx\x152ec\x15 wherec\x15a\x15ba\x001b\x001b', 1);('select hyperparameter \x15\x03by', 1);('thelikelihood 52d\x19d1cdcexp\x10\x0012\x02\x1b\x002\x11cac\x002cbcfn cqd0\x001c\x03\x11thus completingthe squares exponent', 1);('n0qd0', 1);('lemma a2', 1);('nition dataadaptive', 1);('qd0\x15\x03b\x001ab\x001follows', 1);('md1\x1b\x002\x11qd1b 55wherebis basis matrix', 1);('qd1\x1b2\x11a\x1b2\x11\x15\x03ba\x001b\x001', 1);('terms coe\x0ecient cin', 1);('spanf igli1\x1al2\x1awithl\x141 letlgl2\x1al2\x1abe integral operator', 1);('hypothesis space', 1);('computationin terms c compute dataadaptive', 1);('a\x1b2\x11i\x001', 1);('a\x1b2\x11i\x001b q', 1);('posterior \x191nm1q1 withm1', 1);('coe\x0ecient isc\x18\x190n0q0 withq0il', 1);('theorem27 bayesian', 1);('is14model error computational error', 1);('bis range', 1);('ahowever lse', 1);('squares estimator bca\x001bis default choice solution bis range', 1);('dil2\x1a53the', 1);('byaij 1nx1\x14k\x14nhr iukr jukiyhlg i jil2\x1abi 1nx1\x14k\x14nhr iukfkiyh i', 1);('readsec cac\x002cbcfn 52where regression matrix', 1);('negative loglikelihood', 1);('simple requirementreduces redundancy basis functionsin terms c', 1);('basis matrixb h i jil2\x1a1\x14ij\x14l 51is nonsingular ie basis functions', 1);('dataadaptive basis', 1);('l2\x1abecause\x1ais', 1);('basis f igis', 1);('distributions thecoe\x0ecientc2rl', 1);('bsplinespolynomials', 1);('hypothesisspaceh spanf igli1\x1al2\x1a withl\x141 basis function f igcan', 1);('nitedimensional function spaces oflearningin practice goal estimate coe\x0ecient cof', 1);('matrices andintegral operators', 1);('computational practice', 1);('implementationof dataadaptive', 1);('previous sections', 1);('abstract theory', 1);('based', 1);('possible moment momentarrives', 1);('operators spirit weavoid selection basis function space lass', 1);('analysis distributions', 1);('possible moment thatwe', 1);('future research5', 1);('scope study', 1);('fullanalysis optimal \x15\x03is', 1);('appendix a3', 1);('particular itdepends', 1);('muchsmaller maximal ratio maxi\x14kf\x15ir\x001igand', 1);('account partpikri optimal \x15\x03in practice', 1);('componentwise comparison thesum', 1);('theorems', 1);('spectra condition maxi\x14kf\x15ir\x001ig\x14\x15\x03in', 1);('conditions', 1);('class priorsremark', 1);('aoptimality', 1);('trq1 pi\x14k\x15ir\x001iisminimized', 1);('certain class gr1rk', 1);('design seeksa', 1);('estimator equaltotrq1 optimal choice \x190', 1);('certain class 2and', 1);('minimizes trace posterior covariance operator', 1);('priors frigsatisfying\x15\x03maxi\x14kf\x15ir\x001ig', 1);('aoptimalityamong', 1);('44shows dataadaptive', 1);('aoptimality theorem', 1);('trace posterior covariance intheorem 44remark', 1);('truek2l2\x1aitrqd1 onlyif\x15\x03', 1);('e\x19d0e\x11hk\x16d1\x00', 1);('2however dataadaptive', 1);('estimator trace posterior covariance', 1);('e\x190e\x11hk\x161\x00', 1);('trace posterior covariance thereis model error', 1);('q1', 1);('\x15\x03maxif\x15ir\x001ig \x15i\x1b2\x11\x15\x03\x15\x001i\x001\x15i\x1b2\x11r\x001i\x001for eachi\x15k andhencetrqd1tr', 1);('x1\x14i\x14k\x1b2\x11\x15i\x1b2\x11\x15\x03\x15\x001i\x001trq1 x1\x14i\x14k\x1b2\x11\x15i\x1b2\x11r\x001i\x001xikri47thus', 1);('operators aretrqd1', 1);('nition trace', 1);('q1if\x15\x03mini\x14kf\x15ir\x001igproof', 1);('ri 0for allik havetrqd1tr', 1);('trqd1tr q1if\x15\x03maxi\x14kf\x15ir\x001igadditionally', 1);('holdsrecall thatqd1andq1are posterior covariance operators dataadaptive', 1);('a1a2', 1);('posterior covariance', 1);('trace', 1);('47for discussionstheorem', 1);('account partpikrisee', 1);('proof basedon componentwise comparison', 1);('traceof covariance note condition su\x0ecient', 1);('outperforms nondegenerate', 1);('theorem shows condition \x15\x03maxi\x14kf\x15ir\x001ig dataadaptive', 1);('priors di', 1);('inequality strict ri0 ik', 1);('inequality strict \x15i riforsome 1\x14i\x14k', 1);('particular rst inequality strict \x15\x031', 1);('note that\x15\x03\x141 \x15i\x1b2\x11\x152\x03\x15\x001i\x14\x15i\x1b2\x11\x15\x03\x15\x001imaxi\x14kf\x15ir\x001ig\x14\x15\x03\x15i\x1b2\x11\x15\x03\x15\x001i\x15\x15i\x1b2\x11r\x001ithene\x19d0e\x11k\x16d1\x00 truek2l2\x1a\x14x1\x14i\x14k\x00\x15i\x1b2\x11\x15\x03\x15\x001i\x01\x001\x1b2\x11\x00\x15i\x1b2\x11\x15\x03\x15\x001i\x01\x002j\x0f\x18ij2\x14x1\x14i\x14k\x00\x15i\x1b2\x11r\x001i\x01\x002\x1b2\x11\x15i\x1b4\x11r\x001ij\x0f\x18ij2\x14e\x190e\x11k\x161\x00 truek2l2\x1ain', 1);('expectations equalto', 1);('priors samethe', 1);('allik and\x15irifor alli\x14k ie', 1);('x1\x14i\x14k\x00\x15i\x1b2\x11r\x001i\x01\x002\x1b2\x11\x15i\x1b4\x11r\x001ij\x0f\x18ij2xikri\x1b\x004\x11r2ij\x0f\x18ij2clearly', 1);('x1\x14i\x14k\x00\x15i\x1b2\x11\x15\x03\x15\x001i\x01\x002\x1b2\x11\x15i\x1b4\x11\x152\x03\x15\x001ij\x0f\x18ij2 xikri46e\x190e\x11k\x161\x00', 1);('truek2l2\x1aiande\x11hk\x161\x00 truek2l2\x1aiaree\x19d0e\x11k\x16d1\x00 truek2l2\x1a', 1);('e\x11hk\x16d1\x00', 1);('true\x18\x190 expectations the12mses', 1);('truei\x161\x00 truexi\x151 i\x00\x15i\x1b2\x11r\x001i\x01\x001\x1b\x11\x1512i\x0f\x11i\x00\x1b2\x11r\x001i truei \x0f\x18irecall thatf\x0f\x11igandf trueigare', 1);('xik', 1);('have\x16d1\x00 truex1\x14i\x14k i\x00\x15i\x1b2\x11\x15\x03\x15\x001i\x01\x001\x1b\x11\x1512i\x0f\x11i\x00\x1b2\x11\x15\x03\x15\x001i truei \x0f\x18i', 1);('priors sameproof', 1);('nondegenerate priors iee\x19d0e\x11hk\x16d1\x00 truek2l2\x1ai\x14e\x190e\x11hk\x161\x00 truek2l2\x1ai 45where equality', 1);('estimator dataadaptive', 1);('addition maxi\x14kf\x15ir\x001ig\x14\x15\x03\x141', 1);('a1a2holds assume', 1);('estimator thenondegenerate priorstheorem', 1);('fsoiwe', 1);('small noise limit converges topki1 truei projection trueinthe', 1);('small noise limit lim \x1b2\x110\x16d1pki1\x10 truei \x15\x001i\x0f\x18i\x11', 1);('lg2\x1b2\x11\x15\x03lg\x001\x001 das\x16d1x1\x14i\x14k\x00\x15i\x1b2\x11\x15\x03\x15\x001i\x01\x001 di', 1);('dpi di', 1);('eq', 1);('new posterior', 1);('vanishesproof claims', 1);('true kernel thefsoihin41 model error', 1);('particular small noise limit converges projection', 1);('a1a2holds', 1);('noise limit', 1);('small', 1);('model error vanishestheorem', 1);('true function', 1);('small noise limit limit convergesto projection', 1);('reduces uncertainty posterior terms thetrace posterior covariancewe show rst posterior', 1);('square error', 1);('dqd1\x1b2\x11lg\x1b2\x11\x15\x03lg\x001\x001the', 1);('dq1\x1b2\x11lg\x1b2\x11q\x0010\x001\x19d0n\x16d0qd0\x16d0', 1);('mean covariance\x190n\x160q0\x160', 1);('l2\x1agaussian', 1);('improves accuracy', 1);('improvingthe stability', 1);('improves quality posterior inthree aspects', 1);('show dataadaptive', 1);('comparing', 1);('quality posterior', 1);('estimatorthe dataadaptive', 1);('quality', 1);('priors posteriors side sidebyside', 1);('l2\x1awe', 1);('hyperparameter adaptive data', 1);('words dataadaptive', 1);('gaussiandistribution', 1);('case posterior', 1);('likelihood ratio', 1);('lg\x1b2\x11\x15\x03lg\x001\x001 dqd1\x1b2\x11lg\x1b2\x11\x15\x03lg\x001\x001', 1);('posterior becomes\x16d1', 1);('d e\x0012h \x15\x03lg\x001 il2\x1a8', 1);('hisd\x19d0', 1);('nitedimensional probability density', 1);('whenhis', 1);('fsoi hin', 1);('distribution support', 1);('detailsthis dataadaptive', 1);('optimal tradeo likelihood', 1);('method in24 e ective', 1);('select hyperparameter \x15\x03\x150 adaptive data', 1);('adaptive datain practice', 1);('by\x19d0n\x16d0qd0 \x16d0 0qd0\x15\x001\x03lg 42where hyperparameter \x15\x03\x150is', 1);('l2\x1awith', 1);('letlgbe', 1);('dataadaptive priorde nition', 1);('risk priorsee', 1);('nite theposteriorn\x161q1', 1);('azero eigenvaluerecall section', 1);('spaces vectorspace di erent norms', 1);('a2', 1);('measures section', 1);('brief reviewof', 1);('space operatorlgsee eg', 1);('respect norm k k2hgpi\x15i0\x15\x001ih ii2l2\x1a', 1);('hgis', 1);('ig\x15i0 41where closure', 1);('hgspanf', 1);('arehspanf ig\x15i0l2\x1a', 1);('fsoi rkhs', 1);('28the datadependent', 1);('lemma', 1);('eigenpairs f\x15i igi\x151with', 1);('nitetraceclass operator', 1);('notations section', 1);('covariance likelihood counterpart', 1);('gaussianmeasure', 1);('specify posterior', 1);('posteriorwe rst introduce dataadaptive', 1);('nondegenerate priors quality ofthe posterior1041', 1);('large class', 1);('evenwith suboptimal \x15\x03 outperforms', 1);('true kernel model error vanishes', 1);('particular small noise limit converges identi ablepart', 1);('lter error', 1);('important design dataadaptive', 1);('error outsideof dataadaptive', 1);('highlights risk nondegenerate', 1);('range theregression matrix', 1);('regression vector bis', 1);('dto', 1);('extendit general case proof', 1);('withlgfor sake simplicity', 1);('q0commutes', 1);('q0asin a2', 1);('full rank covariance', 1);('full rank', 1);('nite rank data discrete', 1);('assumption a1holds', 1);('assumptions a1a2 theorem', 1);('divergent \x161 becauselim\x1b\x110 \x161\x00xik\x1b\x002\x11ri\x0f\x18i ix1\x14i\x14k\x10 truei \x15\x001i\x0f\x18i\x11 iandpik\x1b\x002\x11ri\x0f\x18i idivergeswe remark', 1);('ie part components \x0f\x18iwithik contaminates posterior', 1);('ixik\x1b\x002\x11ri\x0f\x18i 36thus model error', 1);('lg\x1b2\x11q\x0010\x001 din', 1);('truei \x1b\x11\x1512i\x0f\x11i\x0f\x18i 35there posterior', 1);('dxi di', 1);('fsoi combining', 1);('true iil2\x1afor alli', 1);('truei h', 1);('thetrue kernel truepi truei', 1);('orthonormal basis f ig write\x0f\x11\x1b\x11pi\x15i0\x1512i\x0f\x11i wheref\x0f\x11igare iidn01 random variables', 1);('conditional data observation', 1);('\x161in33 diverges \x1b\x110proof', 1);('speci', 1);('risk leadingto divergent posterior', 1);('risk', 1);('ie \x0f\x18pi\x0f\x18i ihas component \x0f\x18i06 0for somei0k', 1);('lga3', 1);('esq0 iri iwithri0for alli wheref igiare orthonormal eigenfunctions', 1);('n0q0satis', 1);('spanf igki1a2 covariance', 1);('rst zero eigenvaluewherekis', 1);('followsa1 operatorlgin212 zero eigenvalues', 1);('existence error', 1);('nite rank commutes', 1);('small observation noiselimit show', 1);('risk leadingto catastrophic error posterior', 1);('learning kernels operators nondegenerate', 1);('adaptive data nondegenerate priorworks', 1);('nondegenerate measure ie covariance operatorq0has zero eigenvalue', 1);('illposedinverse problem wellde', 1);('crucial role', 1);('distribution plays', 1);('illde ned32 risk nondegenerate priorthe', 1);('lg\x001 dmay', 1);('lg\x001is', 1);('d\x1b\x002\x11lg\x001', 1);('likelihood distributionasnlg\x001', 1);('nitedimensional case problematic', 1);('il2\x1acfn\x13 34which likelihood', 1);('isd\x191d\x190exp\x0012\x1b\x002\x11e exp\x12\x0012\x1b\x002\x11hlg il2\x1a\x002h', 1);('derivative respect', 1);('radonnikodym', 1);('l2s\x1aposteriorn\x161q1', 1);('positive traceclass operator', 1);('posterior followspriorn0q0 whereq0is', 1);('wewrite', 1);('means covariance operators', 1);('brief review', 1);('appendixa2', 1);('generic notion', 1);('nite elements', 1);('shasin', 1);('datain nitedimensional case space', 1);('il2\x1a di erence regularization approach', 1);('penalty term \x1b2\x11h', 1);('loss ie estimator regularization approach usinga', 1);('\x161in33 minimizer', 1);('short agrees posterior', 1);('particular maximal posteriori', 1);('il2\x1a negativelog likelihood loss function posterior corresponds', 1);('corresponds regularization term', 1);('notethat gaussian', 1);('regularization approach', 1);('lg\x1b2\x11q\x0010\x001 dandq1\x1b2\x11lg\x1b2\x11q\x0010\x001', 1);('n\x161q1', 1);('il2\x1a\x13 32it', 1);('likelihoodd\x191 d exp\x12\x0012\x1b\x002\x11e h', 1);('zero eigenvalueposterior distribution density', 1);('whenlg\x001exists itcan illde', 1);('gaussian nlg\x001 d\x1b2\x11lg\x001', 1);('thatthis distribution nondegenerate', 1);('il2\x1acfn\x01 31wheree loss function', 1);('nondegenerate measure8likelihood distribution data densityd\x19l d exp\x0012\x1b2\x11e exp\x00\x0012\x1b2\x11hlg il2\x1a\x002h', 1);('positive matrix', 1);('densityd\x190 d e\x0012h', 1);('measureprior distribution', 1);('likelihoodand posterior terms probability densities respect', 1);('gaussian n0\x1b2\x11i', 1);('nitedimensional measurementnoise', 1);('yis', 1);('norm satisfyingk k2pdi1 ri2\x1ari', 1);('rdwith', 1);('sfr1rdg example', 1);('rst space', 1);('nitedimensional casefinitedimensional case', 1);('posterior space', 1);('purposeof illustration rst specify', 1);('likelihood theposterior', 1);('approachin study focus', 1);('thesediscussions', 1);('posterior divergent', 1);('catastrophic errorin sense', 1);('ensure wellposedness posteriorhowever show', 1);('available aboutthe kernel', 1);('isstable perturbations observation noise', 1);('inversion risk nondegenerate priorthe', 1);('a\x15ba\x001b\x001b3 bayesian', 1);('x1\x14i\x14lbci', 1);('estimator isb', 1);('ec', 1);('regularization becomese\x15c', 1);('loss function', 1);('brkhsh', 1);('rkhsbasis', 1);('rkhsk', 1);('uses normof', 1);('regression problem solvingcinacb regression matrix', 1);('spanf igli1 inverse problem', 1);('iin prescribedhypothesis space', 1);('regularizedin computational practice estimate coe\x0ecients cof', 1);('ensuresthat estimator', 1);('rkhs dartr', 1);('220whereihis identity operator', 1);('hg lg2\x15\x03ih\x001lg d', 1);('il2\x1acfn 219with optimal hyperparameter', 1);('\x15k k2hghlg\x15lg\x001 il2\x1a\x002h', 1);('rkhse\x15 e', 1);('regularizes loss norm', 1);('i2l2\x1a havehh iixi\x15ic2ik k2l2\x1axic2ik k2hgxi\x15i0\x15\x001ic2i 218where', 1);('pici', 1);('lgbyf\x15i', 1);('denote', 1);('il2\x1a8 2hg 217b', 1);('lg\x0012', 1);('inner product satis esh ihghlg\x0012', 1);('hglg12l2\x1aandits', 1);('kernel satis es', 1);('rkhs hgwithgin211', 1);('statements holda', 1);('26holds thatlgin212is', 1);('rkhs suppose assumption', 1);('section44', 1);('standard operator characterization', 1);('rkhsthe', 1);('norm dataadaptive', 1);('inverseproblem wellde', 1);('ensures learning', 1);('regularization method lters error', 1);('approach mitigate illposedness23', 1);('aregularization method', 1);('trueas result', 1);('true2h\x08h otherwords data', 1);('trueform orthogonal decomposition', 1);('htrueand', 1);('information truewhere', 1);('encodes information', 1);('donly', 1);('eve expansion \x0f\x11pi\x1512i\x0f\x11i', 1);('gaussiann0lg karhunenlo\x12', 1);('\x0f\x182lgl2\x1awhen observation noise', 1);('scenarioswhen model error', 1);('according', 1);('inverse problemre', 1);('zero eigenvalue', 1);('thecompact operator', 1);('unique solution', 1);('analyze illposedness inverse problems operatorlgand', 1);('lg\x001 d', 1);('true2hand observation noise model error haveb', 1);('lg\x001 dfurthermore', 1);('unique minimizer', 1);('igi\x15i0with closure', 1);('fsoi eishspanf', 1);('dc', 1);('inl2\x1aisre 2lg \x00', 1);('satisfyh\x0f\x18 il2\x1a1nx1\x14k\x14nhr uk\x18kiyh\x0f\x11 il2\x1a1nx1\x14k\x14nhr uk\x11kiy8 2l2\x1ab', 1);('true\x0f\x18\x0f\x11 216where\x0f\x18comes model error random \x0f\x11comes observation noise andit', 1);('d2l2\x1ahas', 1);('statements hold6a datadependent function', 1);('d2l2\x1abe riesz', 1);('26holds thatlgis', 1);('amodel error', 1);('yvalued', 1);('space identi ability', 1);('appendix a1theorem', 1);('theorem characterizes', 1);('il2\x1a1nx1\x14k\x14nhr ukfkiy8 2l2\x1a 215the', 1);('linear functionalh', 1);('d2l2\x1a riesz', 1);('ase hh ii\x0021nx1\x14k\x14nhr ukfkiy1nx1\x14k\x14nkfkk2yhlg il2\x1a\x002h', 1);('ashh iihlg il2\x1a 213and', 1);('2l2\x1athe bilinear form', 1);('eigenfunctions areorthonormal', 1);('f\x15i igtheeigenpairs oflgwith eigenvalues', 1);('lemma a1 hereafter', 1);('positive semide nite traceclass operator', 1);('sgrs\x1asds 212is', 1);('zs', 1);('lgl2\x1al2\x1alg', 1);('integral operator', 1);('max 1\x14k\x14nsupxy2jgukxyj1under', 1);('integrability gassume', 1);('r assumption', 1);('true mild regularityconditions data fukgand operator', 1);('fundamental study identi ability assumption', 1);('compact operator whichis', 1);('nes selfadjoint', 1);('gde', 1);('assumethat data', 1);('positive semide nite sensethatpnij1cicjgrirj\x150 anyfcigni1\x1arandfrigni1\x1as', 1);('nition bivariate function', 1);('discrete probability density \x1awhen density existsby', 1);('probability rwhen\x1ade', 1);('1nx1\x14k\x14nzgukxrxgukxsx\x16dx 211in abuse notation', 1);('grs\x1ar\x1aswithgrs', 1);('ggiven', 1);('y\x00x y\x00zgukxygukzy\x16dx\x16dz\x15\x16dyzszs r sgrs\x1adr\x1ads210where integral kernel', 1);('echet derivative rst introduce bilinear form hh\x01\x01ii58 2l2s\x1ahh ii1nx1\x14k\x14nhr ukr ukiy1nx1\x14k\x14nz\x14z', 1);('unique zero compute', 1);('echet derivativehas', 1);('unique minimizersince loss', 1);('whic hehas', 1);('l2s\x1ain', 1);('linear subspace', 1);('ein27', 1);('bythe loss functionalde nition', 1);('ambient function space', 1);('l2s\x1awith', 1);('nes ambientfunction space learning', 1);('information data', 1);('support region', 1);('important role learning function', 1);('constantwe call\x1aanexploration measure plays', 1);('sfx\x00yxy2g', 1);('exploration data kernel\x1adr 1znx1\x14k\x14nzz\x0ey\x00x\x00r gukxy \x16dx\x16dy r2s 29where\x0eis', 1);('introduce empirical probabilitymeasure', 1);('supportof kernel', 1);('aregularization strategywe', 1);('rst specify space datadependent fashion', 1);('data hope identify kernel data providesinformation', 1);('learning kernels', 1);('space identi abilitydatadependent function space identi ability', 1);('tackles thisissue review', 1);('function space identify kernel datadependent', 1);('infact', 1);('learning kernels operators', 1);('rstkindfredholm integral equation regressionhowever function space', 1);('classical inverse problems', 1);('nes function space search solution function space andhence penalty term prespeci', 1);('crucial success regularization', 1);('clearly', 1);('select optimal hyperparameter forexample', 1);('inner product norm', 1);('regularization methods', 1);('references section', 1);('importance inverse problem surprise tremendousamount e orts', 1);('strength regularization', 1);('\x15r 28wherer penalty term \x15is hyperparameter', 1);('penalty term loss functionale\x15', 1);('approach section 3regularization methods aim alleviate illposedness', 1);('ameliorate illposedness review hereregularization methods', 1);('singular regressionmatrix4regularization', 1);('section illposedness isdue derivative loss', 1);('sensitive data iethis inverse problem', 1);('multiple minima', 1);('nitedimensional linear spacehowever loss', 1);('squares regression hypothesis space', 1);('nd minimizer', 1);('square error assumption noise\x11is', 1);('functional empirical', 1);('arg min 2he wheree 1n\x1b2\x11x1\x14k\x14nkr uk\x00fkk2y 27here loss', 1);('hb', 1);('functional ahypothesis space', 1);('identify kernel variational approach nds minimizer loss', 1);('eld equation interaction particles', 1);('u r\x01ur\x08\x03uin', 1);('aggression operator', 1);('withguxy u0yux u0xuy', 1);('nonlinear operator corresponds', 1);('y\x00xu0yux u0xuydx8y2rby', 1);('zr', 1);('nonlinear operatorr uy', 1);('rrin', 1);('interaction kernel', 1);('letxc10randyl2rand', 1);('interaction', 1);('support kernel', 1);('withguxy uy\x00ux', 1);('thisexample', 1);('\x0ey\x00y0for anyyy02rd', 1);('here\x11is', 1);('withxl2rdandyl2rd nonlocal operators arisein19', 1);('nonlocal operatorr uy', 1);('rdrin', 1);('estimate kernel', 1);('nonlocal', 1);('nitedimensional version', 1);('lebesguemeasure', 1);('01guxy ux', 1);('\x0ey0\x00yfor anyyy0201 theform operator', 1);('y\x00xuxdx8y201 26we', 1);('z10', 1);('integral operatorr uy', 1);('aim nd function \x0011r', 1);('letxyl201', 1);('integral', 1);('sr2n\x001withsfrlg2n\x001l1withrll\x00nexample', 1);('uniformdiscrete measure kernel vector', 1);('f12ngguxy uy', 1);('matrix integraloperator form', 1);('unknown model error', 1);('data modelr u\x11\x18u f \x11\x18n0\x1b2\x11inxyrn 25where\x18urepresents', 1);('2rn\x02n ier ij i\x00jfor 1\x14ij\x14n measurement datafukfk2rn\x02rngnk1by', 1);('thetoeplitz matrix', 1);('estimation kernel', 1);('kernels toeplitz', 1);('homogenization approximation integrals operators3example', 1);('matrix integral operators nonlocal operators examples themodel error', 1);('examplesinclude toeplitz', 1);('matrix operators image processing', 1);('future worksuch operators', 1);('measure generalization bivariate kernels xy x\x02yrwill', 1);('space thelebesgue measure discrete', 1);('euclidean', 1);('y\x00xguxy\x16dx8y2 24where \x16 measure space', 1);('kernels formr uy', 1);('focuson operators', 1);('1andr 2are wellde', 1);('2such operators', 1);('23for anyc1c22rand', 1);('2c1r 1c2r', 1);('rc1', 1);('linear nonlinear u', 1);('input data uthe operator', 1);('unknown errors modelerror computational error', 1);('here\x18', 1);('\x1b2\x11hffiyfor anyf2y', 1);('eh\x11fi2y', 1);('white noise sense', 1);('ts data pairs fukfkgnk1in formr u \x11\x18f 22where measurement noise \x11is', 1);('xyso', 1);('space goal nd kernel function', 1);('yis hilbert', 1);('xis banach', 1);('datadfukfkgnk1ukfk2x\x02y 21where', 1);('kernels operators data', 1);('kernels operatorswe', 1);('mathematical setup study function space learning inversion operator functionspace identi ability21', 1);('learning kernels operatorsthis section introduces inverse problem learning kernels operators', 1);('bayesianapproach2', 1);('study rst analyze selection', 1);('nonlocal kernels homogenization ofpdes eg', 1);('particle systemseg', 1);('kernels nonlocal kernels learning kernels operators hasbeen', 1);('input output identify thekernel', 1);('aim approximate operator', 1);('thesemethods', 1);('operator learning', 1);('kernel methods seeeg5', 1);('focus di ers focus', 1);('normkernel methods operator learning study focuses learning kernels notthe operators', 1);('theregularization dataadaptive', 1);('information study shows advantage dataadaptive', 1);('nondegenerate measure islittle', 1);('theprior', 1);('l1norm lasso', 1);('rudinosherfatemi', 1);('total variation norm', 1);('widelyusedeuclidean norm', 1);('various regularization terms', 1);('regularization norm', 1);('regularization methods likelihood function providesa loss function variational approach', 1);('tikhonovridge', 1);('thevariational approach', 1);('kernel nitedimensional basis functions areorthonormal function space learningvariational approach regularization', 1);('fast approximation posterior', 1);('lowrank property utilizedfor', 1);('inverse problems focus e\x0ecient', 1);('focus di erentfrom studies', 1);('linear inverseproblems likelihood', 1);('workbayesian inverse problems study selection', 1);('related', 1);('proofs computational details11', 1);('future research', 1);('conclude ndings', 1);('numerical tests', 1);('computational practice demonstratesthe advantage dataadaptive', 1);('discusses dataadaptive', 1);('analyze itsadvantage section', 1);('issue introduce dataadaptive', 1);('approach show issue', 1);('mathematicalsetup study shows illposedness inverse problem illposedness leadsonto section', 1);('section 2introduces inverse problem learning kernels operators reviews variationalapproach', 1);('work section', 1);('section 5the', 1);('smallnoise limits', 1);('leadsto divergent posterior', 1);('select hyperparameter', 1);('analysis computational practice dataadaptiveprior', 1);('section 42furthermore', 1);('uncertainty posterior terms trace ofthe posterior covariance', 1);('estimator ii', 1);('canimprove quality posterior', 1);('able parts', 1);('small noise limit converges theidenti', 1);('dataadaptive priors covariance inversionoperator hyperparameter', 1);('particular inversion operator perturbation datadependentwe', 1);('wrong noise assumptionin', 1);('types errors data computation idiscretization error ii model error iii partial observations iv', 1);('32such perturbation', 1);('observation noise decreases zero data inducesa perturbation eigenspace zero eigenvalues inversion operator', 1);('risk catastrophic error itleads divergent posterior', 1);('ensure thewellposedness posteriorhowever show', 1);('available kernel', 1);('stable perturbations observation noise eg', 1);('functional variationalapproachthe', 1);('order derivative loss', 1);('35this inversion operator covariance matrix likelihood distribution kernelis nitedimensional', 1);('inversion operator singular lowrank datadependent', 1);('due nonlocal dependence inverse problem', 1);('onthe kernel', 1);('regression operator', 1);('dec', 1);('qlang1jhuedu feilumathjhuedu xiongwangjhuedu 1arxiv221214163v1 statml', 1);('usa', 1);('baltimore md', 1);('mathematics', 1);('ukneilchada123gmailcom', 1);('edinburgh eh14', 1);('actuarial mathematics statistics heriot watt', 1);('general kernels', 1);('complexity kernels applications', 1);('t databut', 1);('44the inverse problem learning kernels operators data integral part theseapplications kernels userspeci', 1);('multiagentsystems eg', 1);('stochasticprocesses nonlocal fractional di usions eg', 1);('partial di erential equations', 1);('operator learning eg', 1);('numerous applications machine learning kernel methods eg', 1);('design operators functionspaces', 1);('nitedimensional variables', 1);('nonlocal longrange dependence interaction betweenhigh', 1);('introductionkernels', 1);('mathematics subject classi', 1);('inverse problemrkhs', 1);('kernels operators linear', 1);('small noise limitskeywords', 1);('wrong noise assumption contrast dataadaptive', 1);('types errors discretizationerror model error partial observation', 1);('leadto divergent posterior', 1);('analysis computational practice dataadaptive', 1);('small noise limit dataadaptive priors covariance inversion operator ahyperparameter', 1);('small thedata induces perturbation eigenspace zero eigenvalues inversion operatorwe introduce dataadaptive', 1);('observation noise', 1);('approachovercomes illposedness nondegenerate', 1);('datadependent singular inversion operator', 1);('nonlocal dependence inverse problem', 1);('learning kernels operators data inverseproblem general interest', 1);('designoperators function spaces', 1);('nonlocal dependence', 1);('2023abstractkernels e\x0ecient', 1);('bayesian learningof kernels operatorsneil k chadaquanjun langfei luxiong wangjanuary', 1);