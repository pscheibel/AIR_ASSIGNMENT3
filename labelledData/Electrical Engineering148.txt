('ftvsr', 88);('vsr', 63);('lr', 36);('frequency domain', 27);('frequency attention', 26);('basicvsr', 26);('hr', 24);('psnr', 24);('iconvsr', 22);('figure', 20);('lfa', 20);('cvpr', 19);('comisr', 18);('video super-resolution', 18);('crf25', 18);('reds', 18);('dfa', 17);('tsf', 16);('vol', 15);('no', 15);('august', 15);('ttvsr', 15);('dct', 14);('transformer', 14);('of latex class files', 13);('realbasicvsr', 13);('gfa', 13);('iccv', 13);('dual frequency attention', 12);('edvr', 11);('vid4', 11);('methods [', 10);('compared', 10);('f [', 10);('tf', 10);('compression artifacts', 9);('different compression algorithms', 9);('video', 9);('bd', 9);('frequency', 9);('sf', 9);('] dataset', 9);('crf35', 9);('j. fu', 8);('evaluation', 8);('visualization results', 8);('flops', 8);('spectral maps', 7);('real-world scenarios', 7);('different degradations', 7);('generalization ability', 7);('following', 7);('previous works [', 7);('t [', 7);('i [', 7);('ts', 7);('table', 7);('videolq', 7);('sota', 7);('basicvsr++', 7);('ablation study', 7);('learning', 7);('c. dong', 7);('deep', 7);('video frames', 6);('china', 6);('h. yang', 6);('crf', 6);('high-frequency textures', 6);('dt lr', 6);('t1', 6);('reds4', 6);('clip', 6);('visualization', 6);('rg-noise', 6);('cnn', 6);('global frequency relations', 5);('local frequency relations', 5);('beijing', 5);('sydney', 5);('video compression', 5);('bicubic', 5);('blur kernel', 5);('rgb', 5);('different frequency bands', 5);('f ] }', 5);('global frequency attention', 5);('equation', 5);('x. wang', 5);('eccv', 5);('r. timofte', 5);('ph.d.', 5);('additive noises', 4);('frequency-transformer', 4);('low-quality videos', 4);('frequency band', 4);('video processing', 4);('frequency transformer', 4);('temporal information', 4);('microsoft', 4);('real-world scenes', 4);('ground truth', 4);('comparison', 4);('bi', 4);('ba-', 4);('temporal dimensions', 4);('sr', 4);('pixel domain', 4);('] }', 4);('attention', 4);('dct-based', 4);('global information', 4);('token q', 4);('f ]', 4);('st', 4);('time-frequency attention', 4);('afreq', 4);('entry shows', 4);('mucan', 4);('vimeo-90k', 4);('gaussian', 4);('crf15', 4);('visual quality', 4);('cnn freq', 4);('k. c. chan', 4);('c. c. loy', 4);('k. zhang', 4);('l. van gool', 4);('blind super-resolution', 4);('extensive', 3);('noise', 3);('real-world vsr', 3);('degradation process', 3);('low-resolution videos', 3);('z. qiu', 3);('e-mail', 3);('realvsr', 3);('low-frequency information', 3);('transformers', 3);('recurrent structure', 3);('typically', 3);('frvsr', 3);('rsdn', 3);('transformer-based', 3);('approaches [', 3);('t.', 3);('dlr', 3);('freq', 3);('frequency tokens', 3);('fa', 3);('different types', 3);('sm', 3);('local information', 3);('additive noise', 3);('space-frequency attention', 3);('tfreq', 3);('ptof tsf', 3);('duf', 3);('state-of-the-art methods', 3);('compression per', 3);('fair comparison', 3);('ssim', 3);('cqp', 3);('cbr', 3);('superior visual quality', 3);('sicvsr++ [', 3);('different frequency attention mechanisms', 3);('l. zhang', 3);('super- resolution', 3);('k. yu', 3);('z. wang', 3);('s. zhou', 3);('x. xu', 3);('c. liu', 3);('tpami', 3);('f. yang', 3);('h. lu', 3);('s. gu', 3);('springer', 3);('neurips', 3);('image recognition', 3);('video compression artifact reduction', 3);('j. gu', 3);('j. liang', 3);('ijcai', 3);('existing vsr', 2);('degradation processes', 2);('different self-attention schemes', 2);('joint space-frequency attention', 2);('video enhancement quality', 2);('compression', 2);('blur', 2);('computer vision', 2);('d. fu', 2);('p.r', 2);('darlington', 2);('nsw', 2);('australia', 2);('d. liu', 2);('c. xu', 2);('noise parameters', 2);('different', 2);('local patches', 2);('h.264', 2);('compression rate', 2);('li', 2);('laplacian', 2);('fig', 2);('low-resolution frames', 2);('gt', 2);('] uses', 2);('sicvsr [', 2);('object structure', 2);('different patterns', 2);('similar patterns', 2);('superior performance', 2);('previous work [', 2);('section 4.3.2', 2);('rate factor', 2);('bitrate', 2);('blur-based vsr', 2);('noise-based vsr', 2);('state- of-the-art results', 2);('adjacent frames', 2);('computational costs', 2);('sota vsr', 2);('input frames', 2);('real-world degradations', 2);('fcanet', 2);('d3', 2);('jpeg', 2);('width w', 2);('scale factor', 2);('2d indexes', 2);('b1', 2);('frequency tokenization', 2);('frequency dimen- sions', 2);('spectral frame', 2);('t=', 2);('extracts frequency tokens', 2);('high- frequency visual details', 2);('kk', 2);('f.', 2);('value tokens', 2);('essential components', 2);('based', 2);('time-frequency', 2);('time-space-frequency', 2);('v f', 2);('dual', 2);('real-world video super-resolution', 2);('local frequency attention', 2);('spatial patches', 2);('dual frequency attention e.', 2);('introduce frequency attention', 2);('temporal dimension', 2);('attention computes', 2);('local frequency attention lis', 2);('frequency dimensions', 2);('different temporal frames', 2);('time-space-frequency attention', 2);('joint space- time-frequency domain', 2);('s.', 2);('it sr=rdct', 2);('sfis', 2);('ht', 2);('previous works', 2);('methodsaverage', 2);('compression crf25 crf15 crf25 crf35 clip', 2);('tecogan', 2);('final model', 2);('ablation studies', 2);('input images', 2);('datasets', 2);('compression rates', 2);('compression problems', 2);('compression problem', 2);('cqp25', 2);('cbr1500k', 2);('scale parameter', 2);('com-', 2);('videos', 2);('superior visualization results', 2);('trans', 2);('pixel', 2);('ablation', 2);('frequency atten- tion', 2);('frequency domain shows', 2);('frequency+ftvsr', 2);('real-world case', 2);('base', 2);('fre- quency domain', 2);('ieee', 2);('s. li', 2);('y. xu', 2);('c.', 2);('loy', 2);('cvprw', 2);('m. s. sajjadi', 2);('blind video super-resolution', 2);('y. li', 2);('m.-h. yang', 2);('image', 2);('b. guo', 2);('x. tao', 2);('j. wang', 2);('j. jia', 2);('recurrent', 2);('y. zeng', 2);('h. zheng', 2);('t. mei', 2);('g. lu', 2);('w. ouyang', 2);('d. xu', 2);('x. zhang', 2);('z. gao', 2);('blind', 2);('y. liu', 2);('y. qiao', 2);('m. ehrlich', 2);('x. li', 2);('z. zhang', 2);('learn-', 2);('aaai', 2);('asia', 2);('current research interests', 2);('acm multimedia', 2);('research interests', 2);('pc', 2);('journal of latex class files', 1);('learning spatiotemporal frequency-transformer', 1);('low-quality video super-resolution zhongwei qiu', 1);('huan y', 1);('jianlong fu', 1);('daochang liu', 1);('chang xu', 1);('dongmei fu abstract video super-resolution', 1);('restore high-resolution', 1);('pertinent textures', 1);('nearby frames', 1);('significant progress', 1);('transmit high-quality textures', 1);('low-quality sequences', 1);('space-time-frequency domain', 1);('real visual texture', 1);('novel dual frequency attention', 1);('temporal-frequency attention', 1);('outperforms state-of-the-art methods', 1);('different low-quality videos', 1);('clear visual margins', 1);('code', 1);('index terms video super-resolution', 1);('ntroduction video', 1);('fundamental task', 1);('broad range', 1);('high-definition television [', 1);('video surveillance [', 1);('methods focus', 1);('windows [', 1);('recurrent structures [', 1);('great success', 1);('user devices', 1);('low-quality formats', 1);('unknown degradations', 1);('various corruptions', 1);('blur kernels', 1);('degra- dations result', 1);('different information loss', 1);('low-quality frames', 1);('different artifacts', 1);('such variational characteristics', 1);('qiuzhongwei @ xs.ustb.edu.cn', 1);('fdm ustb @ ustb.edu.cn', 1);('huayan @ microsoft.com', 1);('jianf @ microsoft.com', 1);('daochang.liu @ sydney.edu.au', 1);('c.xu @ sydney.edu.au', 1);('corresponding', 1);('huan yang', 1);('dongmei fudegradation', 1);('unknown degradation', 1);('degra- dation kernels', 1);('spe- cial modules', 1);('degradation parameters', 1);('quantification process', 1);('im- age patches', 1);('discrete cosine transformation', 1);('global degradations', 1);('different information', 1);('commonest sources', 1);('video codec', 1);('constant rate factor', 1);('sota iconvsr', 1);('method [', 1);('pleasant visual results', 1);('restoration processes', 1);('unseen compression artifacts', 1);('common tex- tures', 1);('] retrain', 1);('high-frequency compression artifacts', 1);('] predicts detail-', 1);('aware flow', 1);('enhancement module', 1);('large gaps', 1);('compression degradation', 1);('special designs.arxiv:2212.14046v1 [ eess.iv ]', 1);('dec', 1);('bibdnoisecompressiongtbibdnoisecompressiongtcompression', 1);('downsampling', 1);('ground-truth', 1);('high- resolution', 1);('low-resolution frame', 1);('new real-world datasets', 1);('prob- lems', 1);('new dataset', 1);('pre-', 1);('pre-cleaning', 1);('video compression problem', 1);('image pairs', 1);('video super- resolution', 1);('insightful idea', 1);('dis-', 1);('cosine transform', 1);('low-quality video frames', 1);('enable interactions', 1);('various frequency bands', 1);('fre- quency representation treats', 1);('high-frequency visual information', 1);('attention guides', 1);('high- frequency textures', 1);('corruption artifacts', 1);('dual frequency at-', 1);('global fre- quency relations', 1);('local areas', 1);('local attention', 1);('global area', 1);('global attention', 1);('additionally', 1);('time attention', 1);('frequency interactions', 1);('main contributions', 1);('introduce learning frequency dependencies', 1);('different self-attention strategies', 1);('processing frequency-domain video', 1);('temporal- frequency attention', 1);('previous work', 1);('new contributions lie', 1);('multiple compression algorithms', 1);('quantization parameters', 1);('section 4.3.3', 1);('section 4.3.4', 1);('section 4.3.5', 1);('blur-based', 1);('noise-based', 1);('r elated work', 1);('uncompressed video super-resolution', 1);('image super- resolution method [', 1);('existing', 1);('video super-resolution ap- proaches [', 1);('] focus', 1);('compression crf25iconvsr comisr ftvsr', 1);('ours', 1);('freq.amp', 1);('iconvsr comisr ftvsr gt fig', 1);('visualizations', 1);('zoom-in patches', 1);('top-right corner', 1);('high-frequency information', 1);('amplitude-frequency', 1);('frequency bands', 1);('sliding-window structure', 1);('sliding-window structures', 1);('3d con- volution [', 1);('optical flow [', 1);('deformable convolu- tion [', 1);('3dsrnet [', 1);('] adopts 3d convolution', 1);('extract temporal', 1);('sttn', 1);('] esti- mates optical flow', 1);('warp target frames', 1);('] adopts', 1);('deformable convolution', 1);('align temporal', 1);('long-distance temporal fea- tures', 1);('transmit long-distance temporal informa- tion', 1);('] restores', 1);('] designs', 1);('two- stream structure-detail block', 1);('bidirectional recurrent structure', 1);('backward propagation', 1);('notable benefits', 1);('whole sequence', 1);('recently', 1);('different attention [', 1);('aggregate information', 1);('impressive advancements', 1);('degra- dation processes', 1);('blur degrada- tion kernels', 1);('compressed video super-resolution compressed', 1);('video compression re- sults', 1);('additional high-frequency artifacts', 1);('specific model', 1);('mainstream solutions', 1);('compression challenge', 1);('] applies', 1);('] models', 1);('experimental', 1);('huge differences', 1);('degra- dation kernel', 1);('joint training', 1);('obvious gains', 1);('specific model designs', 1);('detail-aware module', 1);('align high-resolution', 1);('real-world video super-resolution towards', 1);('different degradation kernels', 1);('natural solution', 1);('real-world data', 1);('] captures', 1);('two-camera system', 1);('camera system', 1);('datasets [', 1);('] assumes', 1);('unknown degrada- tion parameters', 1);('blind video super-resolution meth-journal', 1);('blind image super-resolution ap- proaches [', 1);('degradation kernels', 1);('different modules', 1);('particular designs', 1);('real-world problems', 1);('recent', 1);('works [', 1);('] utilize generative adversarial network [', 1);('data augmentation', 1);('diverse degradations [', 1);('promising results', 1);('real-world images', 1);('image-level data augments', 1);('videos [', 1);('realba-', 1);('adopts pre-process module', 1);('pre-process methods', 1);('generalizability limitations', 1);('attention mech- anism', 1);('frequency learning existing', 1);('low-level restoration tasks [', 1);('high-level semantic tasks [', 1);('high-level semantic tasks', 1);('transform images', 1);('computational cost', 1);('frequency channel attention', 1);('resnets', 1);('classifi- cation tasks', 1);('numerous', 1);('low-level studies', 1);('content details', 1);('frequency decomposition', 1);('] design multi-branch networks', 1);('or-net', 1);('] separates', 1);('different frequency components', 1);('cnns', 1);('designs frequency enhancement units', 1);('meth- ods [', 1);('] transform images', 1);('] tries', 1);('dual-domain restoration module', 1);('ehrlich', 1);('y-channel', 1);('correction network', 1);('color channel correction network', 1);('distinguish noises', 1);('quan- tification', 1);('degradation prob- lems', 1);('ethod', 1);('problem formulation', 1);('coun- terparts', 1);('account degradations', 1);('ilr=', 1);('lr|t', 1);('frame length', 1);('ihr=', 1);('hr|t', 1);('bicubic interpolation', 1);('forcomplicated', 1);('lrcan', 1);('lr=v', 1);('hrk', 1);('means convolution', 1);('scale s.nmeans ad- ditive noises', 1);('quan- tization', 1);('compression process', 1);('super-resolution frames', 1);('isr=', 1);('sr|t', 1);('frequency-based tokenization', 1);('patch rep- resentation', 1);('discrete cosine transform', 1);('discrete cosine transform discrete cosine transform', 1);('cosine components', 1);('different 2d frequencies', 1);('image patch', 1);('pof', 1);('height band width b', 1);('abbdct block', 1);('dis', 1);('b1x', 1);('x=0b1x y=0p', 1);('u 2b', 1);('v 2b', 1);('u [', 1);('] andv [', 1);('rep- resents', 1);('orthonormality andc', 1);('bifu=', 1);('ilrby', 1);('bbas equation', 1);('ilr', 1);('tfch bw brepresents', 1);('2d spectral map', 1);('h bandw brepresent', 1);('sequence length', 1);('image channels', 1);('frequency number', 1);('f=b2', 1);('frequency dimension', 1);('fvisual', 1);('frequency tokens settcan', 1);('{ f', 1);('feature size', 1);('ch bw', 1);('frequency tokenization mechanism', 1);('information ex-', 1);('forces thejournal', 1);('patch dct blockwise', 1);('... ...... ...... ... ......', 1);('tokenizeimage', 1);('tokenization flow upsampledctsfattention wtfattention', 1);('c rdctca time -space -frequency', 1);('flow extractor', 1);('attention mechanism', 1);('image/frequency transformation', 1);('fusion layer', 1);('append elementa', 1);('append element', 1);('flow warpw', 1);('flow warp', 1);('concatec', 1);('concate', 1);('bicubic fig', 1);('stin', 1);('joint time-space- frequency domain', 1);('computes time-space-frequency', 1);('space-frequency', 1);('sand time-frequency', 1);('neural network', 1);('low-frequency signals', 1);('high-frequency signals', 1);('combined', 1);('frequency at- tention mechanism', 1);('low-frequency informa- tion', 1);('frequency signals', 1);('different spatial blocks', 1);('block size', 1);('utilize temporal information', 1);('tokenization process', 1);('extract temporal frequency tokens', 1);('ckk.n', 1);('block number', 1);('dif-', 1);('traditional vision', 1);('crop image patches', 1);('spatial visual tokens', 1);('nblocks', 1);('total number', 1);('tnf', 1);('whole tokenization process', 1);('frequency-based attention', 1);('visual tokens', 1);('query tokens', 1);('qare', 1);('spectral map', 1);('keyskand', 1);('vare', 1);('spectral maps {', 1);('target frame', 1);('q=', 1);('{ q', 1);('k=', 1);('{ k', 1);('v=', 1);('{ v', 1);('different kinds', 1);('basic frequency atten- tion', 1);('temporal di- mensions', 1);('space- frequency', 1);('frequency attention aims', 1);('relationship be- tween', 1);('frequency band contains', 1);('whole image', 1);('basic frequency attention', 1);('uniform formulation', 1);('q f', 1);('k f', 1);('q fk f dk', 1);('softmax activation function', 1);('dk denotes', 1);('normalization factor', 1);('ffn', 1);('multi-head frequency attention', 1);('head h=', 1);('qh', 1);('kh', 1);('vh', 1);('h [', 1);('hmeans', 1);('head number', 1);('concat', 1);('opera- tion', 1);('low-quality video super-resolution', 1);('high degrada- tion', 1);('huge chal- lenges', 1);('blur degra- dation', 1);('whole images', 1);('different quantization errors', 1);('frequency do-', 1);('frequency relationship', 1);('different spatial patches', 1);('similar architecture', 1);('fnfrequency', 1);('patch number', 1);('frequency attention matrix', 1);('fnfn', 1);('restores tokens', 1);('matrix multiplication', 1);('attention matrix', 1);('dual frequency attention e', 1);('e =', 1);('means concat op- eration', 1);('multi-head dual frequency attention', 1);('splits tokens', 1);('compute frequency attention', 1);('original query tokens', 1);('global degradation', 1);('generate high- frequency texture', 1);('local fre- quency relations', 1);('local degradation', 1);('models ability', 1);('fdfffdfchw cwhfdffchw', 1);('gfafndfnfnfndfchw ffn', 1);('ckk', 1);('kkcwhfdn', 1);('dfak', 1);('vq cwhfgfalfa fchwc/2c/2fndfndfnfnfndfchw qqkkvvk', 1);('vlinearsm linearlinear linearsmlinear linearlinearsmfig', 1);('means matrix multiplication', 1);('means softmax function', 1);('essential frequency at- tentions', 1);('global frequency attention g', 1);('local frequency attention l', 1);('joint time-space-frequency domain', 1);('joint time-space- frequency dimension', 1);('space/time-frequency attention space-frequency', 1);('frequency at- tention weights', 1);('spatial blocks', 1);('com- putes', 1);('spatial dimension', 1);('sare', 1);('space-frequency tokens', 1);('nftokens', 1);('space dimension', 1);('spatial position', 1);('different video frames', 1);('fig-', 1);('computes frequency attention', 1);('tare', 1);('time-frequency tokens', 1);('tftokens', 1);('attention computes thejournal', 1);('space time space time space time space', 1);('timespace', 1);('space/time', 1);('space -time -frequency', 1);('space/time-frequency attention', 1);('space-time-frequency attention', 1);('red cube', 1);('green areas', 1);('candidate areas', 1);('spatio-temporal information', 1);('utilize spatio-temporal information', 1);('joint space-time-frequency domain', 1);('f ] computes', 1);('inputs oftsare', 1);('joint time- space-frequency domain', 1);('tnftokens', 1);('andsf attention', 1);('stcan', 1);('s.t.= s', 1);('strepresents', 1);('sfirstly', 1);('time-frequency atten- tiont', 1);('stis', 1);('tscan', 1);('computes time-frequency atten-', 1);('computes space-frequency attention', 1);('tsis', 1);('stperforms', 1);('tem- poral learning', 1);('real- world', 1);('basic frequency attention module', 1);('similar recurrent structure', 1);('h.', 1);('it lr', 1);('{ s', 1);('} .represents', 1);('fu- sion operation', 1);('linear', 1);('pt= t', 1);('rt', 1);('rt=', 1);('qs', 1);('ks', 1);('vs', 1);('ht=w', 1);('ht1', 1);('ot', 1);('htrepresents', 1);('past frames', 1);('ht1according', 1);('ot.wrepresents', 1);('flow warp operation', 1);('htis', 1);('dt lr.qsare', 1);('it lrby bicubic', 1);('kand vare', 1);('it lrby', 1);('upsample neu- ral network', 1);('upsample operations', 1);('location guidance', 1);('hard-to-recover parts', 1);('qtis', 1);('temporal- frequency query tokens', 1);('pt+rt', 1);('charbon-', 1);('nier penalty loss [', 1);('total loss l', 1);('l=1 ttx', 1);('t=1q ||it', 1);('hrit sr||2+2', 1);('constant value', 1);('= 1e3.journal', 1);('methods toflow', 1);('ftvsr reds4', 1);('] 27.98/0.799 28.63/0.825 31.09/0.880 29.68/0.868 31.42/0.890 31.67/0.895 32.12/0.901 32.42/0.907', 1);('] 25.85/0.766 27.38/0.832 27.85/0.850 27.31/0.840 27.96/0.855 28.04/0.857 28.40/0.864 28.70/0.869', 1);('] 25.61/0.775 24.19/0.692 22.17/0.588 23.46/0.622 24.02/0.686 25.76/0.773 23.54/0.689', 1);('] 28.72/0.805 25.98/0.706 23.36/0.600 24.38/0.629 26.01/0.702 28.30/0.783 25.21/0.708', 1);('] 26.93/0.768 25.46/0.690 22.95/0.589 24.01/0.624 25.39/0.682 27.95/0.768 24.48/0.686', 1);('] 27.61/0.784 25.72/0.696 23.22/0.579 24.25/0.631 25.65/0.687 28.17/0.770 24.79/0.694', 1);('] 27.66/0.768 25.48/0.679 23.03/0.579 24.04/0.602 25.40/0.673 27.93/0.766 24.54/0.676', 1);('] 29.05/0.814 25.93/0.704 23.22/0.596 24.37/0.628 26.01/0.702 28.13/0.777 25.21/0.709', 1);('] 29.10/0.816 25.93/0.704 23.22/0.596 24.35/0.627 26.00/0.702 28.16/0.777 25.22/0.709', 1);('] 28.67/0.804 25.96/0.705 23.55/0.600 24.39/0.628 26.02/0.702 28.25/0.781 25.17/0.707', 1);('] 28.40/0.809 26.47/0.728 23.56/0.599 24.76/0.660 26.54/0.722 29.14/0.805 25.44/0.724', 1);('30.55/0.854 28.13/0.778 24.87/0.660 26.12/0.703 28.81/0.779 30.21/0.839 27.38/0.782', 1);('e xperiments', 1);('details', 1);('adam', 1);('cosine annealing', 1);('beta1 =', 1);('.9andbeta2 =', 1);('.99for training', 1);('batch size', 1);('learning rate', 1);('video length', 1);('quick ablation study', 1);('final performance', 1);('input size', 1);('super-resolution scale', 1);('random rotations', 1);('vertical flips', 1);('horizontal flips', 1);('data augmentations', 1);('100k iterations', 1);('rapid ablation study', 1);('400k iterations', 1);('quick evaluation', 1);('backbone network', 1);('following basicvsr', 1);('motion estimation module', 1);('5k iterations', 1);('stable training', 1);('transform spectral maps', 1);('cuda', 1);('evaluation metrics', 1);('] datasets', 1);('training videos', 1);('video contains', 1);('image size', 1);('dataset contains 30to50frames', 1);('real web- sites', 1);('flickr', 1);('youtube', 1);('various contents', 1);('image sizes', 1);('scene changes', 1);('evaluation metrics following', 1);('peak signal- to-noise ratio', 1);('structural similarity index', 1);('effective- ness', 1);('different degradation settings', 1);('uncompressed vsr evaluation', 1);('compressed vsr evaluation', 1);('common setting', 1);('following comisr', 1);('compression algorithm', 1);('typical compression algorithms', 1);('con-', 1);('quantization parameter', 1);('compression crf25 crf15 crf25 crf35', 1);('calendar city foliage walk', 1);('] 24.40/0.773 23.06/0.660 21.27/0.515 21.16/0.634 23.78/0.632 22.97/0.603 24.33/0.771', 1);('] 26.34/0.771 24.45/0.667 22.31/0.534 21.69/0.648 25.51/0.626 24.01/0.606 26.72/0.786', 1);('] 25.25/0.741 23.94/0.639 21.99/0.479 21.34/0.624 25.26/0.561 23.50/0.592 25.73/0.756', 1);('] 26.01/0.766 24.33/0.655 22.05/0.482 21.55/0.631 25.40/0.575 24.11/0.625 26.21/0.764', 1);('] 26.58/0.781 24.06/0.650 21.29/0.483 21.72/0.650 25.28/0.615 23.69/0.591 25.57/0.747', 1);('] 26.56/0.780 24.28/0.656 21.97/0.509 21.64/0.641 25.45/0.620 23.79/0.586 26.26/0.774', 1);('] 26.65/0.782 24.31/0.657 21.97/0.509 21.67/0.644 25.46/0.621 23.83/0.588 26.26/0.774', 1);('] 25.85/0.753 24.34/0.661 22.26/0.531 21.60/0.643 25.38/0.620 23.93/0.599 26.43/0.782', 1);('] 26.43/0.791 24.97/0.701 22.35/0.509 22.81/0.695 25.94/0.640 24.66/0.656 26.95/0.799', 1);('27.40/0.811 25.38/0.706 22.61/0.540 22.97/0.720 26.29/0.670 24.94/0.664 27.30/0.816', 1);('compression crf15 gt ftvsr comisr iconvsr basicvsr mucan edvr compression crf15 gt ftvsr comisr iconvsr basicvsr mucan edvr compression crf25 gt ftvsr comisr iconvsr basicvsr mucan edvr compression crf25 gt ftvsr comisr iconvsr basicvsr mucan edvr compression crf35 gt ftvsr comisr iconvsr basicvsr mucan edvr compression crf35 gt ftvsr comisr iconvsr basicvsr mucan edvr', 1);('compression edvr mucan basicvsr comisr iconvsr ftvsr gt', 1);('compression edvr mucan basicvsr comisr iconvsr ftvsr gt fig', 1);('blur-based vsr evaluation', 1);('noise-based vsr evaluation', 1);('noise level', 1);('real-world vsr evaluation', 1);('uncompressed videos', 1);('afair comparison', 1);('visualization comparisons', 1);('shows betterjournal', 1);('visualization quality', 1);('compressed videos', 1);('ap- proaches', 1);('compression algorithms', 1);('com- pression algorithms', 1);('compression modes', 1);('different compression rates', 1);('evaluation results', 1);('compression results', 1);('fair compar- ison', 1);('compression training process', 1);('able results', 1);('obtains 25.93db', 1);('model capacity', 1);('] de- signs', 1);('special compression-aware module', 1);('addi-', 1);('enormous potential', 1);('video compression dilemma', 1);('especially', 1);('] performs', 1);('methods crf', 1);('] 26.57/0.760 25.42/0.710 26.90/0.774', 1);('] 25.98/0.706 26.46/0.718 29.55/0.836', 1);('] 25.93/0.704 26.62/0.722 30.41/0.858', 1);('] 25.93/0.704 26.64/0.772 30.52/0.860', 1);('] 25.91/0.702 26.67/0.723 31.01/0.860', 1);('] 25.98/0.706 26.65/0.723 30.80/0.864', 1);('28.13/0.778 28.77/0.793 31.08/0.865', 1);('basicvsriconvsrbasicvsr++ttvsrftvsrgt basicvsriconvsrbasicvsr++ttvsrftvsrgtcompressioncrf25 compressioncqp25 fig', 1);('gener- ation', 1);('low- frequency information', 1);('clean module', 1);('phenomenon shows', 1);('different compression algo-journal', 1);('means bicubic', 1);('methods bi bd rg-noise realbasicvsr', 1);('] 27.04/0.780 26.70/0.783 26.07/0.736', 1);('] 31.09/0.880 34.73/0.925 28.74/0.810', 1);('] 31.42/0.890 35.23/0.931 29.60/0.841', 1);('] 31.67/0.895 35.37/0.933 29.88/0.848', 1);('] 32.12/0.901 35.54/0.935 29.81/0.846', 1);('] 32.38/0.906 35.57/0.935 30.20/0.854', 1);('32.42/0.907 37.81/0.949 30.48/0.852', 1);('rg-noisebasicvsriconvsrbasicvsr++ttvsrftvsrgt basicvsriconvsrbasicvsr++ttvsrftvsrgtbd fig', 1);('superior ability', 1);('frequency attention mechanism', 1);('dif- ferent', 1);('] show', 1);('clean mechanism', 1);('re-', 1);('different kernels', 1);('real-worldlrvideosinputbasicvsriconvsrbasicvsr++ttvsrftvsr real-worldlrvideos basicvsr++ttvsrftvsriconvsrbasicvsrinputfig', 1);('dataset [', 1);('methods params', 1);('psnr/ssim duf', 1);('27.28/0.763 4.3.4', 1);('clean mod- ule', 1);('real- world videos', 1);('dataset pro-', 1);('contains low-quality videos', 1);('compression crf25compression crf25 pixel', 1);('ftvsr gtpixel', 1);('ftvsr gt fig', 1);('frequency learning mechanism', 1);('domain', 1);('backboneaverage', 1);('29.05/0.814 25.93/0.704 23.22/0.596 24.37/0.628 26.01/0.702 28.13/0.777 25.21/0.709', 1);('29.20/0.825 26.87/0.745 23.83/0.629 24.98/0.666 27.11/0.746 29.36/0.818 26.05/0.751', 1);('29.51/0.837 27.15/0.759 24.03/0.644 25.20/0.684 27.53/0.763 29.47/0.828 26.33/0.766', 1);('29.70/0.843 27.28/0.763 24.22/0.646 25.26/0.609 27.75/0.766 29.62/0.831 26.47/0.772 real-world', 1);('parameters', 1);('psnr/ssim', 1);('10.8m parameters', 1);('comparable parameters', 1);('operation re-', 1);('trans-', 1);('frequency learning', 1);('section 4.4.1', 1);('section 4.4.2', 1);('section 4.4.3', 1);('cnn-based', 1);('frequency domains', 1);('ta-', 1);('pixel+cnn', 1);('frequency attention lfa', 1);('gfa dfa crf25', 1);('27.23/0.761 27.14/0.759 27.53/0.765', 1);('35.82/0.930 35.87/0.936 36.33/0.939', 1);('26.05/0.677 26.09/0.680 26.35/0.685 videos', 1);('model obtains', 1);('poor capacity', 1);('cnn-', 1);('fre-', 1);('quency+cnn setting yields', 1);('frequency+transformer', 1);('replacing', 1);('basic attention mechanism', 1);('capac- ity', 1);('vanilla attention', 1);('real-worldcaseinputlfagfadfa fig', 1);('means vanilla attention', 1);('type crf15 crf25 crf35 base', 1);('29.51/0.837 27.15/0.759 24.03/0.644', 1);('s29.63/0.840', 1);('27.23/0.761 24.12/0.646', 1);('t29.60/0.840', 1);('27.11/0.760 24.05/0.641', 1);('ts29.61/0.839', 1);('27.22/0.760 24.11/0.644', 1);('ts29.65/0.841', 1);('27.24/0.762 24.12/0.645', 1);('st29.70/0.843', 1);('27.28/0.763 24.22/0.646 4.4.2', 1);('global frequency relation', 1);('various degra- dations', 1);('confer- ence', 1);('attention block', 1);('conference version', 1);('visual comparison', 1);('figure11', 1);('various frequency attention', 1);('attention mechanism computes spatial self- attention', 1);('local frequencyattention', 1);('space-frequency attention s', 1);('joint time-space-frequency attention', 1);('tsandst', 1);('stcomputes', 1);('space- frequency attention', 1);('stwill', 1);('benefit time-frequency attention', 1);('temporal learning', 1);('onclusions', 1);('unique spatiotemporal', 1);('extract frequency tokens', 1);('deep features', 1);('challenging degradation problem', 1);('real world', 1);('captures frequency interactions', 1);('multiple frequency bands', 1);('frequency-based', 1);('ca- pacity', 1);('explore frequency attention', 1);('joint space-time- frequency domain', 1);('references', 1);('t. goto', 1);('t. fukuoka', 1);('f. nagashima', 1);('s. hirano', 1);('m. sakurai', 1);('super-resolution', 1);('icpr', 1);('h. zhang', 1);('h. shen', 1);('super-resolution re- construction algorithm', 1);('surveillance images', 1);('processing', 1);('s. y. kim', 1);('j. lim', 1);('t. na', 1);('m. kim', 1);('3d convolutional neural networks', 1);('arxiv preprint arxiv:1812.09079', 1);('d. tao', 1);('fast', 1);('spatio- temporal residual network', 1);('y. tian', 1);('y. zhang', 1);('y. fu', 1);('tdan', 1);('temporally-', 1);('deformable alignment network', 1);('deformable convolutional net-', 1);('r. vemulapalli', 1);('m. brown', 1);('frame-recurrent', 1);('yi', 1);('k. jiang', 1);('j. jiang', 1);('t. lu', 1);('x. tian', 1);('j. ma', 1);('omniscient', 1);('im-', 1);('x. qian', 1);('trajectory-aware transformer', 1);('d. sun', 1);('bayesian adaptive video', 1);('super resolution', 1);('s. lee', 1);('m. choi', 1);('k. m. lee', 1);('dynavsr', 1);('dynamic', 1);('wacv', 1);('j. pan', 1);('h. bai', 1);('j. dong', 1);('j. zhang', 1);('j. tang', 1);('jin', 1);('milanfar', 1);('compression-informed', 1);('x. yang', 1);('w. xiang', 1);('h. zeng', 1);('real-world', 1);('benchmark dataset', 1);('investigating', 1);('spatiotemporal frequency-transformer', 1);('k.', 1);('x. tang', 1);('deep convolutional networks', 1);('texture transformer network', 1);('image super-resolution', 1);('t. h. kim', 1);('m. hirsch', 1);('b. scholkopf', 1);('spatio-', 1);('temporal transformer network', 1);('video restoration', 1);('h. gao', 1);('r. liao', 1);('detail-revealing', 1);('deep video super-resolution', 1);('m. haris', 1);('g. shakhnarovich', 1);('n. ukita', 1);('back- projection network', 1);('t. isobe', 1);('x. jia', 1);('s. wang', 1);('q. tian', 1);('recurrent structure-detail network', 1);('h. chao', 1);('improving', 1);('image synthesis', 1);('w. li', 1);('t. guo', 1);('l. qi', 1);('j. lu', 1);('multi-', 1);('correspondence aggregation network', 1);('j. cao', 1);('super-resolution transformer', 1);('arxiv preprint arxiv:2106.06847', 1);('attention convolutional neural network', 1);('j. luo', 1);('multi-attention convolutional neural network', 1);('m.-t. sun', 1);('l. chen', 1);('non-local kalman network', 1);('tip', 1);('l. gao', 1);('k. tian', 1);('h. sun', 1);('non-local', 1);('s. nah', 1);('s. baik', 1);('s. hong', 1);('g. moon', 1);('k. mu lee', 1);('ntire', 1);('dataset', 1);('t. xue', 1);('b. chen', 1);('j. wu', 1);('d. wei', 1);('w. t. freeman', 1);('ijcv', 1);('w. zuo', 1);('iterative kernel correction', 1);('z. hui', 1);('j. li', 1);('x. gao', 1);('non-differentiable optimization', 1);('g. sun', 1);('mutual affine network', 1);('variant kernel estimation', 1);('blind image super-resolution', 1);('flow-', 1);('y. ma', 1);('w. sun', 1);('towards', 1);('real scene super-resolution', 1);('raw images', 1);('a. liu', 1);('image super- resolution', 1);('l. xie', 1);('y. shan', 1);('real-esrgan', 1);('training', 1);('pure synthetic data', 1);('designing', 1);('prac- tical degradation model', 1);('deep blind image super-resolution', 1);('s. wu', 1);('esrgan', 1);('enhanced', 1);('super-resolution generative adversarial networks', 1);('eccvw', 1);('s. chang', 1);('q. ling', 1);('y. yang', 1);('t. s. huang', 1);('fast restoration', 1);('jpeg-compressed', 1);('l. davis', 1);('s.-n. lim', 1);('a. shrivastava', 1);('quantization', 1);('jpeg artifact correction', 1);('x. jin', 1);('t. yu', 1);('s. sun', 1);('y. pang', 1);('z. chen', 1);('omni-frequency region-adaptive representations', 1);('real image super-resolution', 1);('m. fritsche', 1);('real- world super-resolution', 1);('iccvw', 1);('l. s. davis', 1);('residual learning', 1);('jpeg transform domain', 1);('k. xu', 1);('m. qin', 1);('f. sun', 1);('y. wang', 1);('y.-k. chen', 1);('f. ren', 1);('z. qin', 1);('zhang', 1);('f. wu', 1);('channel attention networks', 1);('l. gueguen', 1);('a. sergeev', 1);('b. kadlec', 1);('r. liu', 1);('j. yosinski', 1);('faster', 1);('neural networks', 1);('a. dosovitskiy', 1);('l. beyer', 1);('a. kolesnikov', 1);('d. weissenborn', 1);('x. zhai', 1);('t. unterthiner', 1);('m. dehghani', 1);('m. minderer', 1);('g. heigold', 1);('s. gelly', 1);('arxiv preprint arxiv:2010.11929', 1);('z. liu', 1);('y. lin', 1);('y. cao', 1);('h. hu', 1);('y. wei', 1);('s. lin', 1);('swin', 1);('hierarchical', 1);('vision transformer', 1);('y. jo', 1);('s. w. oh', 1);('j. kang', 1);('s. j. kim', 1);('video super- resolution network', 1);('explicit motion compensation', 1);('w.-s. lai', 1);('j.-b', 1);('huang', 1);('n. ahuja', 1);('laplacian pyramid networks', 1);('accurate super-resolution', 1);('m. chu', 1);('y. xie', 1);('j. mayer', 1);('l. leal-taix', 1);('n. thuerey', 1);('temporal coherence', 1);('video generation', 1);('acm tog', 1);('a. c. bovik', 1);('h. r. sheikh', 1);('e. p', 1);('simoncelli', 1);('quality assessment', 1);('error visibility', 1);('structural similarity', 1);('ieee tip', 1);('degradation-', 1);('meta-restoration network', 1);('arxiv preprint arxiv:2207.00943', 1);('zhongwei qiu zhongwei qiu', 1);('b.s', 1);('sci-', 1);('automation', 1);('electrical en-', 1);('research student', 1);('research inter- ests', 1);('2d/3d human pose estimation', 1);('video super-resolution.journal of latex class files', 1);('huan yang huan y', 1);('bs', 1);('computer science', 1);('shanghai jiao tong uni-', 1);('current research interest', 1);('video synthesis', 1);('jianlong fu jianlong fu', 1);('lead re-', 1);('multimedia search', 1);('mining', 1);('pattern recognition', 1);('in- telligent system', 1);('automa-', 1);('chinese academy', 1);('computer vi- sion', 1);('computational photography', 1);('lan- guage', 1);('book chapter', 1);('lead', 1);('guest editor', 1);('ieee trans', 1);('pattern analysis', 1);('machine intel-', 1);('fine-grained categorization', 1);('area chair', 1);('icme', 1);('best paper', 1);('core technologies', 1);('windows', 1);('bing multimedia search', 1);('azure media', 1);('xiaoice', 1);('daochang liu daochang liu', 1);('post- doctoral researcher', 1);('peking uni-', 1);('b.e', 1);('tongji', 1);('generative learning', 1);('video understanding', 1);('artificial intelligence', 1);('chang xu chang xu', 1);('phd', 1);('peking', 1);('senior lecturer', 1);('arc decra', 1);('computer', 1);('prestigious journals', 1);('tier conferences', 1);('machine learning algorithms', 1);('appli- cations', 1);('paper awards', 1);('distinguished paper', 1);('icml', 1);('iclr', 1);('top ten distinguished senior pc member', 1);('dongmei fu dongmei fu', 1);('m.s', 1);('de- gree', 1);('polytechnical', 1);('automation science', 1);('tech-', 1);('ustb', 1);('professor', 1);('doctoral su-', 1);('na- tional projects', 1);('corrosion data', 1);('image processing', 1);('automation control theory', 1);('im- age processing', 1);