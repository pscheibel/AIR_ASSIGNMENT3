('uda', 55);('garda', 35);('dice', 33);('cs', 29);('ods', 28);('ace', 27);('comput', 26);('vis', 26);('target domains', 25);('d0', 24);('gan', 23);('conf', 22);('pattern recog', 19);('int', 18);('ieee conf', 18);('domain adaptation', 17);('source domain', 17);('muhdi', 16);('cvpr', 16);('target domain', 14);('advent', 14);('segmentation model', 13);('d1', 13);('tab', 13);('med', 12);('continual learning', 11);('fig', 11);('ed', 10);('es', 10);('cardiac segmentation', 9);('adaptsegnet', 9);('lb', 9);('learn', 9);('continual', 8);('figure', 8);('adv', 8);('neural inform', 8);('process', 8);('syst', 8);('neurips', 8);('semantic segmentation', 7);('similarly', 7);('continual sequence', 7);('canon', 7);('ieee trans', 7);('mach', 7);('different domains', 6);('optic disc segmentation', 6);('mr', 6);('content loss', 6);('iclr', 6);('imaging', 6);('source data', 5);('furthermore', 5);('mis', 5);('new target domain', 5);('previous domains', 5);('d2', 5);('philips', 5);('siemens', 5);('represent', 5);('learning', 5);('image comput', 5);('miccai', 5);('new domains', 4);('strict continual', 4);('source image', 4);('entire distribution', 4);('intermediate target domains', 4);('target domain images', 4);('memory buffer', 4);('generate images', 4);('x jz', 4);('sec', 4);('ema', 4);('image distillation', 4);('random initializations', 4);('second-best results', 4);('test dice', 4);('d0 lb', 4);('sd-ub', 4);('t. darrell', 4);('intell', 4);('x. liu', 4);('tmi', 4);('neural networks', 4);('worksh', 4);('icml', 4);('l. herranz', 4);('iccv', 4);('unsupervised', 4);('p.-a', 4);('heng', 4);('comp.-assisted interv', 4);('myo lv rv', 4);('generative appearance replay', 3);('optic', 3);('dnns', 3);('source images', 3);('adapting', 3);('target images', 3);('sample images', 3);('different tasks', 3);('cfp', 3);('dil', 3);('multiple target domains', 3);('gand', 3);('adapt', 3);('pl', 3);('real images', 3);('source training', 3);('dt', 3);('gto', 3);('distillation losses', 3);('optic disc', 3);('2d slices', 3);('] \x15cpf1', 3);('loss \x15segf1', 3);('ub', 3);('2adaptsegnet [', 3);('d1 sd-ub', 3);('d2 sd-ub', 3);('continual domain sequence', 3);('performance analysis', 3);('gardas', 3);('training methodtest dice', 3);('ours', 3);('pattern anal', 3);('tpami', 3);('zhang', 3);('cvprw', 3);('incremental learning', 3);('s. jui', 3);('j.', 3);('weijer', 3);('q. dou', 3);('c. chen', 3);('source-free', 3);('xu', 3);('zurich', 2);('switzerland', 2);('uppsala', 2);('large amounts', 2);('medical applications', 2);('cardiac', 2);('natural images', 2);('classication [', 2);('medical images', 2);('images [', 2);('imagenet', 2);('] aims', 2);('previous target domains', 2);('new target domains', 2);('... ...', 2);('incremental uda', 2);('overview', 2);('segmentation model m', 2);('target image', 2);('memory unit', 2);('target styles', 2);('synthetic images', 2);('generative replay', 2);('domain-incremental learning', 2);('uma', 2);('continual uda', 2);('cycada', 2);('synergistic image', 2);('model adaptation', 2);('wu', 2);('style information', 2);('model adapts', 2);('mand', 2);('gis', 2);('appearance characteristics', 2);('segmentation map', 2);('source', 2);('cross-entropy loss', 2);('lm=\x001 hwhx', 2);('domain label', 2);('z\x18pzh a\x10', 2);('g0', 2);('t\x001and instantiate', 2);('gp', 2);('fake images', 2);('xp 0jzand', 2);('inspired', 2);('adaptive instance normalization', 2);('adain', 2);('standard deviation', 2);('new domain', 2);('feature space', 2);('fp 0jz', 2);('g.', 2);('distillation loss', 2);('ez\x18pz', 2);('equation', 2);('segmentation', 2);('mp', 2);('previous model', 2);('previous ones', 2);('summary', 2);('implementation details', 2);('secs', 2);('ablation studies', 2);('refuge', 2);('source segmentation training', 2);('optic disc center', 2);('cardiac regions', 2);('left ventricle', 2);('lv', 2);('right ventricle', 2);('rv', 2);('myo', 2);('multi-centre', 2);('u-net', 2);('projection discriminator', 2);('content', 2);('50gsegmentation loss', 2);('f.', 2);('vgg19', 2);('random rotations', 2);('comparisons', 2);('kowa', 2);('nidek', 2);('d0d1d2', 2);('d0+d1+d2md-ub', 2);('pytorch', 2);('domain-wise scores', 2);('large gap', 2);('pp ond2', 2);('detailed', 2);('compared', 2);('step6065707580859095100 overall dice', 2);('[ % ]', 2);('cs fig', 2);('evolution', 2);('aces', 2);('overall scores', 2);('examples', 2);('real', 2);('dataset domains', 2);('steps t=', 2);('ods cs', 2);('step50556065707580859095100 dice', 2);('domain [ % ]', 2);('new data', 2);('variance values', 2);('eq', 2);('k.', 2);('x. zhang', 2);('image recognition', 2);('semantic', 2);('deep learning', 2);('x. huang', 2);('x. zhuang', 2);('m. gabrani', 2);('r. kemker', 2);('c. kanan', 2);('t.-h', 2);('vu', 2);('p. p', 2);('m. cord', 2);('z. wu', 2);('j. kim', 2);('s. wang', 2);('g. m.', 2);('ven', 2);('t. tuytelaars', 2);('a. s. tolias', 2);('overcoming', 2);('l. yu', 2);('c. wu', 2);('wang', 2);('e. tzeng', 2);('j. hoffman', 2);('k. saenko', 2);('adversarial', 2);('j. wang', 2);('adversarial domain adaptation', 2);('c. baumgartner', 2);('b. glocker', 2);('h. chen', 2);('j.-y', 2);('zhu', 2);('t.', 2);('p. isola', 2);('a. efros', 2);('medical image segmentation', 2);('chest x-ray classication', 2);('a. mukhopadhyay', 2);('j. n. kundu', 2);('r. v', 2);('babu', 2);('source-free domain adaptation', 2);('model', 2);('s. lu', 2);('h. fu', 2);('j. lee', 2);('t. karras', 2);('t. aila', 2);('s. laine', 2);('j. lehtinen', 2);('a1', 2);('label-wise', 2);('d0 d1 d2overall myo lv rv', 2);('\x00 \x00 \x00 \x00', 2);('\x00 \x00 \x00 \x00 \x00 \x00 \x00 \x00', 2);('d0+d1+d2 md-ub', 2);('generative', 1);('appearance replay', 1);('boqi chen1', 1);('kevin thandiackal1', 1);('pushpak pati1and orcun goksel2', 1);('1ibm research', 1);('europe', 1);('applications', 1);('medicine', 1);('eth zurich', 1);('information', 1);('sweden abstract deep', 1);('learning models', 1);('real-world scenarios', 1);('training', 1);('origi- nate', 1);('multiple different domains', 1);('certain settings', 1);('prohibit retention', 1);('privacy regulations', 1);('continual learning scenarios', 1);('continual adaptation', 1);('multiple domains', 1);('previous approaches', 1);('practical scenarios', 1);('different organs', 1);('keywords unsupervised', 1);('disc segmen- tation', 1);('introduction deep neural networks', 1);('remarkable performance', 1);('various computer vision tasks', 1);('semantic segmentation [', 1);('similar success', 1);('training images', 1);('medical experts', 1);('annotating', 1);('dense annotations', 1);('strong need', 1);('dnn', 1);('medical datasets usu- ally', 1);('small number', 1);('natural image datasets', 1);('such small datasets', 1);('unseen domains [', 1);('unsupervised domain adaptation', 1);('rst training', 1);('source domaind0and afterwards adapting', 1);('target domaind1', 1);('alleviate annotation costs', 1);('real-world', 1);('above scenario', 1);('applicable solutions', 1);('multiple datasets', 1);('dtbecome', 1);('different time points', 1);('useful knowledge', 1);('patient data', 1);('strict privacy regulations', 1);('indenite data storage', 1);('such medical scenarios', 1);('access data', 1);('learning problem', 1);('cl', 1);('respective domain', 1);('rst time', 1);('recent techniques', 1);('looser constraints', 1);('herein term', 1);('subsequent target domain', 1);('multi-head distillation', 1);('performs knowledge distillation', 1);('current target domain', 1);('changing environ-', 1);('stylearxiv:2301.01211v1 [ cs.cv ]', 1);('jan', 1);('continual uda fig', 1);('generates images', 1);('segmentation ground truth', 1);('replay images', 1);('future access', 1);('previous target styles', 1);('turn affects', 1);('knowledge preservation', 1);('intermediate targets', 1);('con- tinual', 1);('employ generative replay [', 1);('substitute images', 1);('currently-inaccessible domain', 1);('generative adversarial network', 1);('importantly', 1);('memory buffers', 1);('gan-based', 1);('source domain images', 1);('representative samples', 1);('effective knowledge preservation', 1);('main contributions', 1);('rst segmentation technique', 1);('oper- ates', 1);('introducea novel combination', 1);('stochastic generator', 1);('methods em-', 1);('separate memory buffers', 1);('new state-of-the-art performance', 1);('conduct experiments', 1);('color fundus photography', 1);('magnetic resonance', 1);('related', 1);('brief overview', 1);('relevant research', 1);('learning aims', 1);('simulate real-world data avail- ability constraints', 1);('sequential learning', 1);('knowledge [', 1);('major dimensions fo-', 1);('regularization [', 1);('parameter isola- tion [', 1);('prototypical representations [', 1);('generative replay [', 1);('methods', 1);('prototypical representations', 1);('store class-representative prototypes', 1);('new tasks', 1);('generative model learns', 1);('synthesize images [', 1);('classication/segmentation model', 1);('original data', 1);('state-of-the-art performance', 1);('task-incremental benchmarks', 1);('segmentation [', 1);('common paradigm', 1);('domain alignment', 1);('target domain representations', 1);('input images', 1);('certain intermediate', 1);('model outputs', 1);('classication/segmentation models', 1);('domain-adversarial neural network', 1);('dann', 1);('main models', 1);('extractor uses', 1);('negative gradient', 1);('domain classier', 1);('taxonomy', 1);('different domain adaptation settings', 1);('settingsource', 1);('trainingmultiple target', 1);('unsup', 1);('source-free uda', 1);('gan-inspired', 1);('adversarial training', 1);('alignment [', 1);('computer tomography', 1);('ct', 1);('employ adversarial losses', 1);('model output spaces', 1);('alternatively', 1);('cyclegan', 1);('align domains', 1);('image space', 1);('cycle-consistent ad-', 1);('feature alignment', 1);('sifa', 1);('image-level domain alignment', 1);('adapt models', 1);('learning settings', 1);('continual learning settings', 1);('medical data', 1);('sequential uda', 1);('different settings', 1);('herein group', 1);('individual settings', 1);('segmentation tasks [', 1);('actual source data', 1);('target adaptations', 1);('naming', 1);('continual learning literature [', 1);('multiple classes/tasks', 1);('sequence.in contrast', 1);('adapting models', 1);('domain adversarial training', 1);('multiple distillation losses', 1);('knowledge distilla- tion', 1);('source images and/or', 1);('current target images', 1);('deterministic encoder- decoder architecture', 1);('target domain style', 1);('replay memory buffer', 1);('complete distribution', 1);('previous target domains/images', 1);('adaptation sequence', 1);('study continual', 1);('challenging scenario', 1);('previous domain', 1);('method', 1);('images x02', 1);('0\x12rh\x02w\x02cwith segmentation label maps y02', 1);('0\x12 f1', 1);('lgh\x02wfrom', 1);('d0=f', 1);('gn0 i=1', 1);('image channels', 1);('image height', 1);('image width', 1);('following', 1);('d0is', 1);('adapting m', 1);('t\x151target', 1);('t=fx1', 1);('xtg', 1);('thet-th target domain', 1);('current domain', 1);('access samples', 1);('synthetic data', 1);('data tomto', 1);('mare', 1);('synthesize images', 1);('training phase', 1);('synthetic samples', 1);('separate appearances', 1);('trainable frozengenerator', 1);('discriminatorfeature', 1);('extractorsegmentation modelfeature', 1);('distill', 1);('real/fake real/faketraintrain ...', 1);('distilladapt', 1);('mpinto', 1);('current model m', 1);('mshall', 1);('target-like image', 1);('mpfor', 1);('corresponding source-like image', 1);('above process', 1);('whenever data', 1);('source domain data', 1);('input image x', 1);('mpredicts', 1);('specically', 1);('output logit', 1);('mfor', 1);('labellat pixel position', 1);('corresponding probability', 1);('softmax operation', 1);('segmentation label map', 1);('h=1wx w=1lx l=11fy', 1);('=lglog\x10 m', 1);('indicator function', 1);('generative replay model', 1);('projection discrimi- natord [', 1);('noise vector z', 1);('image content', 1);('corresponding appearance', 1);('x jzlearns', 1);('generate synthetic samples x jzof domaind .gis', 1);('logistic loss [', 1);('lg=e', 1);('z\x18pzh a\x10 \x00d\x00', 1);('softplus operation', 1);('gby', 1);('distinguish synthetic', 1);('ld=e', 1);('d\x00 g', 1);('0\x01\x11i +e x\x18d0h a\x10 \x00d\x00', 1);('x\x01\x11i +\x15r1r1', 1);('gradient penalty term', 1);('ex\x18d0krxd', 1);('main challenge', 1);('trivial solution', 1);('mon', 1);('trainable generator', 1);('gt', 1);('gtbeing', 1);('gwith', 1);('dthat', 1);('repre- sentations', 1);('extractor f', 1);('accordingly', 1);('source-like image xp 0jz=gp', 1);('real image xtfrom', 1);('current dataset', 1);('maps fp 0jz=f', 1);('xp 0jz', 1);('target-like image xtjz=g', 1);('rst need', 1);('ftjzshould look', 1);('instance-level statis- tics', 1);('feature map', 1);('corresponding image', 1);('instance-level statistics', 1);('fp 0jzto', 1);('map ~fp tjzthat encodes', 1);('~fp tjz=adain\x10 fp 0jz', 1);('ft\x11 =\x1b', 1);('@ fp 0jz\x00\x16\x10 fp 0jz\x11 \x1b\x10 fp 0jz\x111', 1);('a+\x16', 1);('identify ~fp tjzas', 1);('ftjzas fake', 1);('doptimizes', 1);('luda d=e', 1);('d\x10', 1);('ftjz\x11\x11i +ez\x18pz xt\x18dth a\x10 \x00d\x10 t', 1);('~fp tjz\x11\x11i +\x15r1r1', 1);('gtries', 1);('dwhile', 1);('luda g=e', 1);('z2pzh a\x10 \x00d\x10 t', 1);('ftjz\x11\x11i +\x15conlcon', 1);('rst term encourages', 1);('realistic target appearance', 1);('generatetwo images', 1);('different appearance characteristics', 1);('different domain labels', 1);('ftjzandfp 0jzshould', 1);('appearance information', 1);('re-normalization ~f0jz=adain', 1);('lcon=hx', 1);('h=1wx w=1cx h=c fp', 1);('feature maps', 1);('gshall', 1);('gshould', 1);('generate data', 1);('ldis dandldis g.', 1);('previous do- mains \x18uf', 1);('t\x001gand random noise vectors z\x18pz', 1);('previous generator', 1);('gpand', 1);('current generator', 1);('previous generator xp jz=gp', 1);('corresponding images', 1);('current generator x jz=g', 1);('ldis d= ez\x18pz', 1);('d\x10 f\x00 g', 1);('\x11\x13 +a\x12 \x00d\x10', 1);('f\x00 gp', 1);('\x11\x13 #', 1);('ldis g=ladv gz', 1);('} | {', 1);('a\x12 \x00d\x10', 1);('f\x00 g', 1);('\x11\x13 # +\x15img', 1);('k1 # | { z }', 1);('limg g', 1);('rst termladv gin', 1);('feature level', 1);('` 1image', 1);('image level', 1);('such image-', 1);('feature-level distillation', 1);('continual learning tasks', 1);('class- incremental learning [', 1);('batch intotwo halves', 1);('training strategy', 1);('nal objectives', 1);('dandgbecome ld=luda d+ldis d', 1);('g+ldis g', 1);('new target domaindt', 1);('mphereafter', 1);('trainable model', 1);('minitialized', 1);('mp.mis', 1);('corresponding pseudo- labels', 1);('knowledge distillation [', 1);('current model', 1);('mpon', 1);('knowledge distillation', 1);('rst pass', 1);('source image x0jz=g', 1);('pseudo segmentation map ^m0at', 1);('temperature parameter', 1);('knowledge distillation literature [', 1);('softer probability distribution', 1);('one-hot labels', 1);('noise input z', 1);('source image x0jz', 1);('image x jz=g', 1);('ground- truth segmentation map', 1);('utilize ^m0as', 1);('silver- standard/approximate', 1);('ground truth', 1);('h=1wx w=1lx l=1^m', 1);('log\x10 m', 1);('images x jzare', 1);('dtwhile', 1);('domaindevice', 1);('imagestest images', 1);('odsd0 canon', 1);('d1 kowa', 1);('d2 nidek', 1);('csd0 philips', 1);('d1 siemens', 1);('d2 canon', 1);('experiments', 1);('below', 1);('rst describe', 1);('present comparisons', 1);('disc segmentation', 1);('clinical detection', 1);('glaucoma [', 1);('image datasets', 1);('retinal fundus glaucoma challenge refuge', 1);('diabetic retinopathy image dataset idrid', 1);('retinal image', 1);('optic nerve evaluation', 1);('deep learning rim-one dl', 1);('multiple centers', 1);('different scanners', 1);('representative benchmark', 1);('select subsets', 1);('aforementioned datasets', 1);('different camera', 1);('d0the', 1);('canon cr-2', 1);('idrid', 1);('kowa vx-10', 1);('digital fundus camera', 1);('rim-one dl', 1);('nidek afc-210', 1);('non-mydriatic fundus camera', 1);('% training images', 1);('% test images', 1);('simple boundary detection algorithm [', 1);('left ventricle my- ocardium', 1);('evaluation setting', 1);('dynamic- range', 1);('grayscale images', 1);('multi-class segmentation', 1);('multi-vendor', 1);('multi-disease cardiac segmentation', 1);('ms', 1);('challenge [', 1);('contains volumes', 1);('multiple hospitals', 1);('spain', 1);('germany', 1);('1.5t scanners', 1);('different vendors', 1);('source dataset', 1);('d1and d2consist', 1);('exact data distri- bution', 1);('image denotes', 1);('multiple sequential 2d slices', 1);('test time', 1);('2d inference', 1);('3d volume', 1);('bias eld cor- rection [', 1);('min-max intensity normalization', 1);('maximum values', 1);('95th intensity percentiles', 1);('in-plane resolution', 1);('] segmentation model', 1);('decoder consist', 1);('ve convolutional blocks', 1);('skip', 1);('stochastic gradient descent', 1);('sgd', 1);('learning rate', 1);('throughout', 1);('experimental settings', 1);('batch size', 1);('weight decay', 1);('domain training', 1);('available real samples', 1);('entire dataset', 1);('target domain addition', 1);('generative module', 1);('discriminator incorporates', 1);('mini-batch discrimination layer [', 1);('bet- ter sample diversity', 1);('hyperparameter optimization', 1);('method parameter values description garda\x15conf1', 1);('loss \x15imgf1', 1);('image', 1);('distillation \x15r1f0:2', 1);('50gsegmentation loss \x15fdf0:01', 1);('1gfeature distillation \x15ddf1', 1);('50gdistribution distillation \x15prevf0:1', 1);('0:5gdistribution distillation', 1);('] \x15stylef0:1', 1);('5gstyle loss \x15contf0:1', 1);('loss \x15klf0:1', 1);('kl', 1);('divergence loss', 1);('source domain training', 1);('discriminator distinguishes', 1);('target adaptation domains', 1);('darchitecture', 1);('convolutional layers', 1);('target adaptation training', 1);('four-layer backbone', 1);('previous work [', 1);('] architecture', 1);('gcomprises', 1);('linear layers', 1);('style-convolution layers [', 1);('style modula- tion', 1);('noise injection', 1);('gs', 1);('parameters \x12', 1);('iterations n', 1);('= \x12', 1);('gfrom', 1);('generate samples', 1);('poor local minimum', 1);('adam', 1);('learning rate [', 1);('vertical ips', 1);('loss weights', 1);('r1regularization', 1);('fair comparison', 1);('real data', 1);('domain-wise', 1);('\x06standard deviation', 1);('training methodods', 1);('overalld0d1d2 overall', 1);('] 95:4\x060:072:4\x063:3 47:3\x063:1 71:7\x060:7 78:8\x060:7 62:0\x061:1 48:4\x061:8 63:1\x061:2', 1);('] 95:9\x060:068:6\x065:6 52:7\x063:4 72:3\x062:9 82:2\x060:167:7\x061:7 53:8\x061:3 67:9\x061:0', 1);('] 87:8\x064:1 82:9\x061:6 57:4\x064:0 76:0\x062:6 82:0\x060:5 73:6\x061:158:6\x061:0 71:4\x060:9', 1);('] 92:3\x063:9 84:1\x060:559:8\x065:978:7\x061:379:5\x061:2 71:0\x062:7 59:9\x065:970:1\x063:3', 1);('94:6\x060:387:9\x060:1 65:2\x061:5 82:6\x060:4 82:8\x060:1 76:0\x060:2 67:2\x060:1 75:3\x060:1', 1);('\x00 92:3\x00 \x00 \x00 82:4\x00 \x00', 1);('\x00 \x00 93:1\x00 \x00 \x00 85:5\x00', 1);('real source domain images', 1);('above methods', 1);('meth- ods', 1);('muhdi1', 1);('nvidia a100 gpu', 1);('only adapt', 1);('such methods', 1);('experimental comparisons', 1);('experimental', 1);('foreground labels', 1);('d0denotes', 1);('d2represent', 1);('different methods', 1);('performance measure', 1);('different random training initializations', 1);('d0and', 1);('report single-domain', 1);('corresponding domain', 1);('//github.com/valeoai/muhdithe multi-domain', 1);('md-ub', 1);('percentage points', 1);('seg- mentation model', 1);('adaptation performance', 1);('score ond0', 1);('ap- proach outperforms', 1);('muhdis', 1);('scores ond0', 1);('previous state-of-the-art', 1);('such improvement', 1);('initial gap', 1);('md- ub', 1);('different initializations', 1);('important quality', 1);('appendix', 1);('clear gap', 1);('pp ond1and', 1);('md-ub adaptsegnet advent ace muhdi ours', 1);('training step', 1);('labels occupy', 1);('small part', 1);('model aims', 1);('foreground label', 1);('adaptation perfor- mance', 1);('d1andd2', 1);('method improves domain-wise', 1);('successful continual domain adaptation', 1);('standard deviations', 1);('sequential', 1);('domain sequence', 1);('overall segmentation performance', 1);('models need', 1);('ad- dress', 1);('overall score', 1);('initial performance ond0', 1);('similar overall score', 1);('nal overall score', 1);('entire domain sequence', 1);('qualitative', 1);('present test images', 1);('corresponding segmentation maps', 1);('quantitative results', 1);('method performs', 1);('anatomical structures', 1);('relevant parts', 1);('adaptation step', 1);('generator captures', 1);('orange tint ofd1as', 1);('darker appearance', 1);('d2with', 1);('images stays', 1);('segmentation training', 1);('step t= 2that', 1);('such augmentations', 1);('analogously', 1);('reference rectangles', 1);('appear- ance differences', 1);('d1tend', 1);('d0appear', 1);('brightest overall', 1);('high-dynamic range', 1);('human eye', 1);('rgb', 1);('such differences', 1);('hinder gener-fig', 1);('real test images', 1);('segmentation maps', 1);('pink rectangles', 1);('visual aid', 1);('relevant anatomical structures', 1);('different domains.table', 1);('d1and', 1);('1st row', 1);('\x06 std-dev', 1);('superior results', 1);('d1 trainingtest dice', 1);('85:1\x060:2 75:8\x060:0', 1);('d287:9\x060:1', 1);('d2 trainingtest dice', 1);('63:9\x061:2 63:3\x060:2', 1);('d265:2\x061:5', 1);('67:2\x060:1 alization', 1);('effective continual adaptation schemes', 1);('different domain characteristics', 1);('anatomical content', 1);('additionally', 1);('discussion', 1);('forward', 1);('useful information', 1);('previous target domain', 1);('continual learning literature', 1);('intermediate adaptation tod1helps', 1);('d2for', 1);('additional domains', 1);('owing', 1);('nd continual', 1);('segment images', 1);('care facility acquires', 1);('right model', 1);('continual model', 1);('similar images', 1);('comparison', 1);('rst extracts', 1);('appearance statistics', 1);('appearance infor- mation', 1);('reproduce images', 1);('superior quality', 1);('images exhibit', 1);('severe checkerboard artifacts', 1);('real samples', 1);('target domain statistics', 1);('simple random noise vector input', 1);('vgg', 1);('performance gain', 1);('ablation', 1);('conduct ablation experiments', 1);('cardiac magnetic resonance', 1);('content zby', 1);('table', 1);('d2ours\x00lcon85:9', 1);('ours\x00limg g82:2', 1);('ours\x00ladv87:5', 1);('d1 sd-ub\x00', 1);('92:3\x00 \x00', 1);('d2 sd-ub\x00', 1);('\x00 93:1\x00', 1);(':8 vidual impact', 1);('nal segmentation performance', 1);('performance gains', 1);('omitting', 1);('content loss causes', 1);('pp ond0andd1', 1);('interestingly', 1);('content loss increases', 1);('ldis g=ladv g+\x15imglimg gfor', 1);('ldis d', 1);('non- adversarial components', 1);('non-adversarial componentis', 1);('image distillation loss', 1);('segmentation performance', 1);('namely', 1);('scores drop', 1);('adversarial components', 1);('ladv=ladv g+ldis d', 1);('ours\x00ladv', 1);('source domain performance', 1);('ablation study conrms', 1);('new state- of-the-art segmentation performance', 1);('continual domain adaptation', 1);('conclusions', 1);('novel segmen- tation method', 1);('rst segmentation method', 1);('potential limitation', 1);('domain appearance adaptation', 1);('daily basis', 1);('comprehensive experiments', 1);('color fundus photography im- ages', 1);('magnetic resonance images', 1);('qualitative results', 1);('synthesize meaningful images', 1);('ablation study highlights', 1);('adversarial distillation', 1);('overall', 1);('domain sequences', 1);('new datasets', 1);('continual sequences', 1);('acknowledgments', 1);('krishna chaitanya', 1);('neerav karani', 1);('insightful discussions', 1);('valuable advice', 1);('dataset selection', 1);('preprocessing.references [', 1);('s. ren', 1);('sun', 1);('deep residual learning', 1);('a. dosovitskiy', 1);('l. beyer', 1);('a. kolesnikov', 1);('d. weissenborn', 1);('x. zhai', 1);('t. unterthiner', 1);('m. dehghani', 1);('m. minderer', 1);('g. heigold', 1);('s. gelly', 1);('j. uszkoreit', 1);('n. houlsby', 1);('trans-', 1);('z. liu', 1);('h. mao', 1);('c.-y', 1);('c. feichtenhofer', 1);('s. xie', 1);('e. shelhamer', 1);('fully', 1);('convolutional networks', 1);('l.-c. chen', 1);('g. papandreou', 1);('i. kokkinos', 1);('k. murphy', 1);('a. l. yuille', 1);('deeplab', 1);('image segmentation', 1);('deep convolutional nets', 1);('atrous convolution', 1);('p. porwal', 1);('s. pachade', 1);('r. kamble', 1);('m. kokare', 1);('g. deshmukh', 1);('sa-', 1);('f. meriaudeau', 1);('indian diabetic retinopathy image dataset', 1);('diabetic retinopathy', 1);('data', 1);('f. j. f. batista', 1);('t. diaz-aleman', 1);('j. sigut', 1);('s. alayon', 1);('r. arnay', 1);('d. angel-pereira', 1);('rim-one', 1);('retinal image database', 1);('image analysis', 1);('stereology', 1);('online', 1);('//www.ias-iss.org/ojs/ias/article/view/2346 [', 1);('m. campello', 1);('p. gkontra', 1);('c. izquierdo', 1);('c. martin-isla', 1);('a. sojoudi', 1);('p. m.', 1);('k. maier-hein', 1);('j. ma', 1);('m. parre', 1);('a. albiol', 1);('f. kong', 1);('s. c. shadden', 1);('j. c. acero', 1);('sundaresan', 1);('m. saber', 1);('m. elattar', 1);('h. li', 1);('b. menze', 1);('k. firas', 1);('c. haarburger', 1);('c. m. scannell', 1);('m. veta', 1);('a. carscadden', 1);('k. punithakumar', 1);('s. a. tsaftaris', 1);('x. yang', 1);('l. li', 1);('d. vilad', 1);('m. l. descalzo', 1);('a. guala', 1);('l. la mura', 1);('m. g. friedrich', 1);('r. garg', 1);('j. lebel', 1);('f. henriques', 1);('m. karakas', 1);('e.', 1);('c avus', 1);('s. e. petersen', 1);('s. escalera', 1);('s. segu', 1);('j. f. rodr', 1);('k. lekadir', 1);('ms challenge', 1);('n. brancati', 1);('a. m. anniciello', 1);('p. pati', 1);('d. riccio', 1);('g. scognamiglio', 1);('g. jaume', 1);('g. de pietro', 1);('m. di bonito', 1);('a. foncubierta', 1);('g. botti', 1);('f. feroce', 1);('m. frucci', 1);('bracs', 1);('breast carcinoma', 1);('e histology images', 1);('database', 1);('o. russakovsky', 1);('j. deng', 1);('h. su', 1);('j. krause', 1);('s. satheesh', 1);('s. ma', 1);('z. huang', 1);('a. karpathy', 1);('a. khosla', 1);('m. bernstein', 1);('a. c. berg', 1);('l. fei- fei', 1);('large scale visual recognition challenge', 1);('j. comput', 1);('ijcv', 1);('van', 1);('laak', 1);('g. litjens', 1);('f. ciompi', 1);('deep', 1);('nature', 1);('w. m. kouw', 1);('m. loog', 1);('target labels', 1);('g. wilson', 1);('d. j. cook', 1);('acm trans', 1);('sys', 1);('tech', 1);('m. mccloskey', 1);('n. j. cohen', 1);('catastrophic interference', 1);('connec-', 1);('networks', 1);('sequential learning problem', 1);('psychology', 1);('motivation', 1);('g. i. parisi', 1);('j. l. part', 1);('s. wermter', 1);('lifelong learning', 1);('a. saporta', 1);('a. douillard', 1);('multi-head', 1);('x. wang', 1);('j. e. gonzalez', 1);('t. goldstein', 1);('l. s. davis', 1);('h. shin', 1);('j. k. lee', 1);('j. kim sk t-brain', 1);('deep generative replay', 1);('fearnet', 1);('brain-inspired model', 1);('incre-', 1);('cong', 1);('m. zhao', 1);('j. li', 1);('l. carin', 1);('gan memory', 1);('forgetting', 1);('k. thandiackal', 1);('t. portenier', 1);('a. giovannini', 1);('o. goksel', 1);('generative feature-driven image replay', 1);('arxiv preprint:2106.05350', 1);('i. j. goodfellow', 1);('j. pouget-abadie', 1);('m. mirza', 1);('b. xu', 1);('d. warde-farley', 1);('s. ozair', 1);('a. courville', 1);('bengio', 1);('generative adversarial nets', 1);('s. farquhar', 1);('gal', 1);('towards robust evaluations', 1);('arxiv preprint:1805.09733', 1);('nature machine intelligence', 1);('m. de lange', 1);('r. aljundi', 1);('m. masana', 1);('s. parisot', 1);('x. jia', 1);('a. leonardis', 1);('g. slabaugh', 1);('continual learning survey', 1);('defying', 1);('classication tasks', 1);('j. kirkpatrick', 1);('r. pascanu', 1);('n. rabinowitz', 1);('j. veness', 1);('g. desjardins', 1);('a. rusu', 1);('m. kieran', 1);('j. quan', 1);('t. ramalho', 1);('a. grabska-barwinska', 1);('d. hassabis', 1);('c. clopath', 1);('d. kumaran', 1);('r. hadsell', 1);('proceedings', 1);('national academy', 1);('f. zenke', 1);('b. poole', 1);('s. ganguli', 1);('synaptic intelligence', 1);('c. v', 1);('nguyen', 1);('li', 1);('t. d. bui', 1);('r. e. turner', 1);('variational continual learning', 1);('vancouver', 1);('bc', 1);('canada', 1);('a. mallya', 1);('d. davis', 1);('s. lazebnik', 1);('piggyback', 1);('single network', 1);('multiple tasks', 1);('mask weights', 1);('eur', 1);('eccv', 1);('j. serr', 1);('d. sur', 1);('m. miron', 1);('a. karatzoglou', 1);('catas- trophic', 1);('hard attention', 1);('m. wortsman', 1);('ramanujan', 1);('r. liu', 1);('a. kembhavi', 1);('m. rastegari', 1);('j. yosinski', 1);('a. farhadi', 1);('supermasks', 1);('superposition', 1);('b. twardowski', 1);('k. wang', 1);('cheng', 1);('v. d.', 1);('drift compensation', 1);('class-incremental learning', 1);('f. zhu', 1);('x.-y', 1);('c. wang', 1);('f. yin', 1);('c.-l. liu', 1);('prototype', 1);('m. toldo', 1);('m. ozay', 1);('bring', 1);('evanescent representations', 1);('lifelong class incremental learning', 1);('van de weijer', 1);('b. radu-', 1);('memory replay gans', 1);('new categories', 1);('o. ostapenko', 1);('m. puscas', 1);('t. klein', 1);('p. j', 1);('m. nabi', 1);('remember', 1);('synaptic plasticity driven framework', 1);('m. menta', 1);('b. raducanu', 1);('a. d. bagdanov', 1);('generative feature replay', 1);('class- incremental learning', 1);('h. t. siegelmann', 1);('brain-inspired', 1);('articial neural networks', 1);('nature communications', 1);('ganin', 1);('e. ustinova', 1);('h. ajakan', 1);('p. germain', 1);('h. larochelle', 1);('f. lavio-', 1);('m. marchand', 1);('lempitsky', 1);('domain-adversarial', 1);('machine learning', 1);('jmlr', 1);('discrim- inative domain adaptation', 1);('m.', 1);('z. cao', 1);('m. i. jordan', 1);('conditional', 1);('r. xu', 1);('g. li', 1);('j. yang', 1);('l. lin', 1);('larger', 1);('norm approach', 1);('k. kamnitsas', 1);('c. ledig', 1);('newcombe', 1);('j. simpson', 1);('a. kane', 1);('d. menon', 1);('a. nori', 1);('a. criminisi', 1);('d. rueckert', 1);('brain lesion segmentation', 1);('adversarial networks', 1);('info', 1);('proc', 1);('c. ouyang', 1);('pnp-adanet', 1);('plug-and-play', 1);('adversarial domain adaptation network', 1);('ieee access', 1);('tsai', 1);('w.-c. hung', 1);('s. schulter', 1);('k. sohn', 1);('m.-h. yang', 1);('m. chandraker', 1);('output space', 1);('h. jain', 1);('m. bucher', 1);('entropy minimization', 1);('unpaired', 1);('image-to-image translation', 1);('cycle-consistent adversarial networks', 1);('cycle-consistent', 1);('adversarial domain adapta- tion', 1);('j. qin', 1);('p. a. heng', 1);('bidirectional cross-modality adaptation', 1);('n. karani', 1);('k. chaitanya', 1);('e. konukoglu', 1);('lifelong learning approach', 1);('brain mr segmentation', 1);('m. lenga', 1);('h. schulz', 1);('a. saalbach', 1);('c. gonzalez', 1);('g. sakas', 1);('arxiv preprint:2010.11008', 1);('s. srivastava', 1);('m. yaqub', 1);('k. nandakumar', 1);('z. ge', 1);('d. mahapatra', 1);('domain incremental learning', 1);('low-resource clinical settings', 1);('comp.-', 1);('interv', 1);('dom', 1);('adap', 1);('rep', 1);('transfer', 1);('t. kalb', 1);('m. roschani', 1);('m. ruf', 1);('j. beyerer', 1);('domain-incremental semantic segmentation', 1);('ieee intell', 1);('vehicles symp', 1);('iv', 1);('k. li', 1);('domain-incremental', 1);('cardiac image segmentation', 1);('p. garg', 1);('r. saluja', 1);('n. balasubramanian', 1);('c. arora', 1);('a. subramanian', 1);('c. jawahar', 1);('multi-domain', 1);('semantic seg- mentation', 1);('ieee wint', 1);('app', 1);('wacv', 1);('a. ranem', 1);('c. gonz', 1);('hippocam- pus segmentation', 1);('n. venkat', 1);('r.', 1);('universal', 1);('r. li', 1);('q. jiao', 1);('w. cao', 1);('h.-s. wong', 1);('s. wu', 1);('s. yang', 1);('generalized', 1);('h. xia', 1);('h. zhao', 1);('z. ding', 1);('adaptive', 1);('adversarial network', 1);('free domain adaptation', 1);('liu', 1);('w. zhang', 1);('j. huang', 1);('d. guan', 1);('a. xiao', 1);('historical', 1);('contrastive learning', 1);('a. kulkarni', 1);('a. singh', 1);('jampani', 1);('gen-', 1);('domain adaptive semantic segmentation', 1);('s. stan', 1);('m. rostami', 1);('continual semantic segmentation', 1);('aaai', 1);('q. liu', 1);('jin', 1);('domain adaptive fundus image segmentation', 1);('t. miyato', 1);('m. koyama', 1);('arxiv preprint:1802.05637', 1);('l. mescheder', 1);('a. geiger', 1);('s. nowozin', 1);('training methods', 1);('gans', 1);('converge', 1);('s. belongie', 1);('arbitrary', 1);('g. hinton', 1);('o. vinyals', 1);('dean', 1);('distilling', 1);('knowledge', 1);('neural network', 1);('arxiv preprint:1503.02531', 1);('m. s. haleem', 1);('l. han', 1);('van hemert', 1);('b. li', 1);('automatic', 1);('colour retinal images', 1);('glaucoma diagnosis', 1);('j. i. orlando', 1);('b. breda', 1);('keer', 1);('d. r. bathula', 1);('a. diaz- pinto', 1);('r. fang', 1);('l. xiaoxiao', 1);('p. liu', 1);('b. murugesan', 1);('naranjo', 1);('s. s. r. phaye', 1);('s. m. shankaranarayana', 1);('a. sikka', 1);('a.', 1);('van den', 1);('hengel', 1);('j. wu', 1);('g. xu', 1);('p. yin', 1);('f. li', 1);('h. bogunovi', 1);('glaucoma assessment', 1);('fundus photographs', 1);('image anal', 1);('media', 1);('s. zhang', 1);('yan', 1);('q. wu', 1);('m. yang', 1);('m. tan', 1);('attention', 1);('retinal image segmentation', 1);('j. xu', 1);('o. chutatape', 1);('e. sung', 1);('c. zheng', 1);('p. c. t. kuan', 1);('deformable model technique', 1);('glaucoma analysis', 1);('pattern recognition', 1);('n. j. tustison', 1);('b. avants', 1);('p. a. cook', 1);('zheng', 1);('a. egan', 1);('p. a. yushkevich', 1);('j. c. gee', 1);('n4itk', 1);('n3 bias correction', 1);('o. ronneberger', 1);('p. fischer', 1);('t. brox', 1);('convolutional', 1);('biomedical image segmentation', 1);('progressive', 1);('k. simonyan', 1);('a. zisserman', 1);('deep convolutional networks', 1);('large-scale image recognition', 1);('m. aittala', 1);('j. hellsten', 1);('analyzing', 1);('improving', 1);('image quality', 1);('stylegan', 1);('yazc', 1);('c.-s. foo', 1);('s. winkler', 1);('k.-h. yap', 1);('g. piliouras', 1);('chan-', 1);('unusual effectiveness', 1);('averaging', 1);('gan training', 1);('m. wulfmeier', 1);('a. bewley', 1);('i. posner', 1);('incremental', 1);('ieee int', 1);('robot', 1);('autom', 1);('a. paszke', 1);('s. gross', 1);('f. massa', 1);('a. lerer', 1);('j. bradbury', 1);('g. chanan', 1);('t. killeen', 1);('z. lin', 1);('n. gimelshein', 1);('l. antiga', 1);('a. desmaison', 1);('a. k', 1);('e. yang', 1);('z. devito', 1);('m. raison', 1);('a. tejani', 1);('s. chilamkurthy', 1);('b. steiner', 1);('l. fang', 1);('j. bai', 1);('s. chintala', 1);('imperative style', 1);('high- performance deep learning', 1);('d. lopez-paz', 1);('m. ranzato', 1);('gradient', 1);('episodic memory', 1);('cardiac segmentation results', 1);('a2', 1);('] 76:2\x061:0 77:7\x061:0 70:2\x060:7 74:7\x060:8 72:2\x060:6 58:5\x061:2 52:8\x061:5 61:2\x061:0 55:7\x063:1 52:1\x062:2 35:1\x061:6 47:7\x062:2 61:2\x061:1', 1);('] 80:0\x060:7 81:0\x060:574:3\x061:5 78:4\x060:5 78:0\x060:765:3\x061:3 55:3\x062:5 66:2\x061:1 66:8\x061:5 58:8\x062:1 35:9\x062:6 53:8\x060:9 66:1\x060:8', 1);('] 79:5\x060:279:1\x061:5 76:8\x060:278:5\x060:679:9\x060:368:8\x060:765:9\x061:671:6\x060:871:0\x060:464:8\x061:241:6\x061:8 59:1\x061:069:7\x060:4', 1);('] 74:5\x062:0 76:8\x061:3 73:1\x065:2 74:8\x062:0 77:8\x061:9 64:7\x063:2 60:6\x064:0 67:7\x062:8 66:1\x063:0 56:1\x067:1 44:7\x065:955:6\x065:1 62:4\x062:7', 1);('78:0\x060:1 79:5\x060:281:3\x060:0 79:6\x060:177:2\x060:372:0\x060:2 73:4\x060:1 74:2\x060:269:6\x060:272:5\x060:1 60:4\x060:2 67:5\x060:1 73:8\x060:1', 1);('79:7\x00 \x00 \x00 \x00 \x00', 1);('table a2', 1);('] 91:0\x060:7 78:0\x060:9 80:1\x060:6 83:0\x060:6 79:4\x061:2 53:9\x061:3 55:3\x062:1 62:9\x061:2 64:3\x062:3 44:6\x060:8 38:6\x062:2 49:2\x061:3 65:0\x060:9', 1);('] 93:3\x060:7 81:4\x060:983:2\x061:0 86:0\x060:385:1\x060:4 63:5\x061:7 58:7\x065:1 69:1\x062:1 72:9\x063:2 52:2\x067:1 36:2\x067:8 53:7\x061:7 69:6\x061:2', 1);('] 93:1\x060:479:7\x061:0 83:8\x060:185:5\x060:487:4\x060:569:0\x061:370:4\x062:2 75:6\x061:378:6\x060:5 54:0\x061:341:5\x061:9 58:1\x061:0 73:1\x060:6', 1);('] 90:6\x061:5 80:0\x060:581:6\x060:0 84:1\x060:5 86:9\x061:365:4\x062:8 70:7\x064:574:3\x062:6 80:6\x064:051:0\x068:060:9\x069:064:2\x066:874:2\x063:1', 1);('92:6\x060:1 79:3\x060:286:3\x060:1 86:1\x060:186:3\x060:469:5\x060:3 77:3\x060:1 77:7\x060:3 80:8\x060:2 59:4\x060:160:5\x060:166:9\x060:1 76:9\x060:1', 1);('85:1\x00 \x00 \x00 \x00 \x00', 1);