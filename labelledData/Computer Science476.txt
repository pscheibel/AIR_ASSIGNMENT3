('cad', 51);('bev', 27);('ugv', 25);('lidar', 24);('cadnet', 19);('sam', 16);('dynamic objects', 15);('fig', 13);('semantic map', 9);('ieeecvf', 6);('thin objects', 6);('bevbased', 6);('point clouds', 6);('mae', 5);('cad bev', 5);('bevsemantic', 5);('stvl', 4);('ihd', 4);('visual', 4);('traversable area', 4);('systems', 3);('ieee', 3);('fh', 3);('l1', 3);('iii', 3);('kitti', 3);('li', 3);('fkpk', 3);('current frame', 3);('number', 3);('historical points', 3);('robotics', 2);('andautomation letters vol', 2);('ieee robotics', 2);('international conference', 2);('ieeersj', 2);('computer visionand pattern recognition', 2);('computervision pattern recognition', 2);('negative obstacles', 2);('sidewalk', 2);('2d costmap', 2);('corridor', 2);('dynamic obstacles', 2);('realworld', 2);('inthe', 2);('worstk', 2);('lidarpoints', 2);('sam9', 2);('single', 2);('ii bev', 2);('ii', 2);('sim', 2);('blue area', 2);('row ground truth', 2);('experimental results', 2);('eqs', 2);('initial probability distribution', 2);('dismse', 2);('cadloss', 2);('attention weights', 2);('semantic information', 2);('mlpmaxpoolstructure', 2);('points polar feature extraction', 2);('cartesian', 2);('form label', 2);('multiframe fusion', 2);('pointnet', 2);('pointpillars', 2);('main components', 2);('3d object detection', 2);('lidarpoint', 2);('wedemonstrate', 2);('stabilityattention module sam sam', 2);('rnn', 2);('dynamic features', 2);('shaban', 2);('peng', 2);('extensive', 2);('robotics vde2012', 1);('german conference', 1);('robotik', 1);('dynamic constraints autonomousrobots', 1);('hoffmann bertramtrajectory', 1);('w osch f', 1);('feiten', 1);('osmann w', 1);('cyberphysical systems', 1);('systems inacmieee', 1);('autonomous vehicles', 1);('enabling', 1);('kato tokunaga maruyama maeda hirabayashiy kitsukawa monrroy ando fujii azumi autowareon', 1);('available httpsdevelopernvidiacomisaacsim35', 1);('online', 1);('nvidia isaac', 1);('stachnissand j gall semantickitti dataset semantic scene understanding lidar sequences proc ieeecvf internationalconf computer vision', 1);('j behley garbade milioto j quenzel behnke', 1);('neural information processing systems vol', 1);('advances', 1);('learning entropyminimization', 1);('grandvalet bengio semisupervised', 1);('springer2015', 1);('international conference onmedical image', 1);('networksfor biomedical image segmentation', 1);('ronneberger p fischer brox unet convolutional', 1);('eurographics', 1);('fast voxel traversal algorithm', 1);('j amanatides woo', 1);('robots systems', 1);('international conference onintelligent', 1);('costmaps forcontextsensitive navigation', 1);('smart layered', 1);('v lu hershberger', 1);('model mapperceive', 1);('casas sadat r urtasun mp3', 1);('ieeecvfconference computer vision pattern recognition', 1);('visibility 3d object detection', 1);('exploiting', 1);('ramanan', 1);('p hu j ziglar', 1);('computervision springer', 1);('european conference', 1);('lstm approach temporal 3d objectdetection lidar point clouds', 1);('pantofaru rosst funkhouser fathi', 1);('zhang kundu', 1);('r huang', 1);('computer vision patternrecognition', 1);('3d object detection point cloud sequences', 1);('anguelov offboard', 1);('deng', 1);('r qi zhou najibi p sun k v', 1);('grid representation online lidar point cloudssemantic segmentation', 1);('gong h forooshpolarnet', 1);('zhang z zhou p david x yue z xi', 1);('recognition', 1);('computer vision', 1);('asymmetrical 3d convolution networks forlidar segmentation', 1);('lin cylindrical', 1);('li h li', 1);('hong', 1);('x zhu h zhou wang', 1);('ieeeconference computer vision pattern recognition', 1);('3d classication segmentation', 1);('j guibas pointnet deeplearning', 1);('r q charles h su kaichun', 1);('automation', 1);('international conference onrobotics', 1);('efcientconvolutional neural networks', 1);('object detection 3d point clouds', 1);('fast', 1);('h tong posnerv', 1);('engelcke rao z wang', 1);('rome italy2015', 1);('online point cloud objectdetection', 1);('z wang posner v', 1);('conference onintelligent transportation', 1);('negative obstacledetection analysis', 1);('j larson trivedi lidar', 1);('journalof', 1);('basednegative obstacle detection eld autonomous land vehicles', 1);('e shang x wu hu q yuan h lidar', 1);('onlineavailable httpsgithubcomrosperceptionpointcloud tolaserscan18', 1);('pointcloud tolaserscan', 1);('p bovbel hidalgo foote', 1);('negative obstacle navigation', 1);('aware planningand behaviours', 1);('surfaces attitude', 1);('talbot sa j lewis e hernandezn kottege n hudson virtual', 1);('hines k stepanas', 1);('intelligent robots systems', 1);('ieeersjinternational', 1);('indoor environments', 1);('mobile robot navigation uneven', 1);('silva autonomous', 1);('c w', 1);('wanm qh meng', 1);('tung', 1);('meng mitchell li', 1);('wang', 1);('journalof advanced robotic systems', 1);('dynamic world', 1);('robot perception', 1);('aview', 1);('voxel layer', 1);('macenski tsai feinberg spatiotemporal', 1);('zhou crossviewsemantic', 1);('pan j sun h leung andonian', 1);('geometry andsemantic point cloud arxiv preprint arxiv200611436', 1);('eye view semantic segmentation', 1);('h ng k radia j chen wang gog j e gonzalezbevseg', 1);('ieeetransactions intelligent', 1);('dense topview understanding', 1);('semanticsegmentation lidar data', 1);('stiller r stiefelhagen mass multiattentional', 1);('bieder p heidenreich', 1);('k peng j fei k yang roitberg j zhang', 1);('robot learning', 1);('annual', 1);('terrainclassication offroad autonomous', 1);('boots fox semantic', 1);('shaban x meng j lee', 1);('intelligentrobots systems', 1);('scene completion lidarpoint clouds', 1);('zhang semantic', 1);('wen', 1);('x yang h zou x kong huang liu', 1);('corl', 1);('paths unknownspace', 1);('han j ban e campbell', 1);('computer vision pattern recognition', 1);('encoders object detection point clouds inieeecvf conference', 1);('zhou j yang beijbompointpillars fast', 1);('h caesar', 1);('h lang v', 1);('3d object detectionfrom point clouds', 1);('luo r urtasun pixor realtime', 1);('yang', 1);('sensors', 1);('sparsely', 1);('yan mao', 1);('learning point', 1);('endtoend', 1);('zhou tuzel v', 1);('vision pattern recognition', 1);('conference oncomputer', 1);('3d objectdetection network autonomous', 1);('li xia multiview', 1);('x chen h j wan', 1);('access', 1);('common practices', 1);('survey ofautonomous', 1);('e yurtsever j lambert carballo k takeda', 1);('asurvey expert systems applications', 1);('de souza selfdriving', 1);('paulaveronese oliveirasantos', 1);('mutz', 1);('ao f', 1);('jesus r berriel paix', 1);('cardosoa forechi', 1);('badue r guidolini r v carneiro p azevedo v', 1);('range scenariosreferences1 c', 1);('future plan todesign multilevel', 1);('onthe premise traversability binary limits thedeployment range', 1);('current design', 1);('forugv navigation', 1);('autoware stvl', 1);('semantic maps', 1);('robust traversability prediction thanthe', 1);('perception realworld experimentsthat', 1);('facilitates deployment practice', 1);('ground truthwhich', 1);('learning scheme', 1);('extractthe spatial', 1);('multiframe fusion module', 1);('navigation design', 1);('accessible depth cad', 1);('robust traversability representation namelycircular', 1);('onclusionwe', 1);('success ratev c', 1);('test scenarios method collide object13and', 1);('different environments', 1);('providesa robust traversability prediction', 1);('vehiclespedestrians curbs', 1);('various obstacles', 1);('caduniformly', 1);('denition maps canbe', 1);('scenario resultingin number collisionsby comparison method', 1);('scenario andtables chairs shelves', 1);('objects trashcans lamp posts tree trunks', 1);('collisionalso 3d detection', 1);('highdenition maps theevent', 1);('detect obstacles', 1);('3d detectionbasedautoware', 1);('highdenition maps locationsof curbs stairs', 1);('comprehensive autonomous', 1);('scenario downward stairs thestairhall scenarioautoware', 1);('negative obstacles downward curbsin', 1);('stvlcannot', 1);('curbs addition', 1);('drivewayscenario', 1);('collisionother', 1);('low obstacles collidewith', 1);('threshold toohigh', 1);('unable drive', 1);('obstacles makingthe', 1);('pointson ground', 1);('high stability thepreset height threshold poses problems practicalapplications threshold', 1);('cloudgeometric relationships', 1);('obstacle positions', 1);('thisway', 1);('preset height range 2d map', 1);('supplemental video thepractical navigation performancestvl', 1);('quantitative results listedin', 1);('analysis', 1);('perception module basedon', 1);('autoware', 1);('complete navigation experiments', 1);('teb', 1);('voxel grid forthe planning module', 1);('baselines comparison', 1);('autoware35', 1);('opensourceautonomous navigation approaches', 1);('negative obstacles othersbaselines', 1);('collisionswhich pedestrians', 1);('collision situation threecategories', 1);('successfulnavigation tests', 1);('average speed', 1);('averagespeed', 1);('navigation goal', 1);('ratio number times theugv', 1);('rate', 1);('rate collision averagespeed', 1);('metrics success', 1);('ugvs', 1);('times staticand', 1);('negative obstacles downward curbs stairseach', 1);('sidewalk stairhallcontain', 1);('approach baselines', 1);('indoor onesstairhall', 1);('driveway sidewalk', 1);('outdoor ones', 1);('real scenarios', 1);('cadscenarios', 1);('local planner', 1);('local planneras', 1);('weimplement timedelasticband teb', 1);('frame satises realtime requirement', 1);('cpu gtx1650 gpu', 1);('height 08m groundthe program runs onboard computer i59400h', 1);('vlp16 lidar lidar', 1);('wtgahrs1 imu top103 gps', 1);('agilex scoutugv', 1);('deploy method', 1);('setups', 1);('navigation approaches1', 1);('feasibility method realworldapplications deploy', 1);('experimentsto', 1);('small number', 1);('improves generalization ability', 1);('samples pointwhich', 1);('training setcontains', 1);('performance model improves signicantlyon comparison group', 1);('cuontop', 1);('output probability distributionof', 1);('vquantitative comparison different navigation methods realworld experiments senarios methodssuccess rate collisionped collisionneg collisionother avg speedstatic dynamic static dynamic static dynamic static dynamic static dynamicoutdoordrivewayauto', 1);('loss function12table', 1);('model decreases thecondence improves groups improvement condence demonstrates', 1);('pufor', 1);('samples primary group', 1);('primarygroup gap scenarios', 1);('low prediction condence performanceon comparison group', 1);('data themodel', 1);('primary comparison', 1);('7080the validation', 1);('conf mae confpriacmpbpl', 1);('comparison', 1);('ivcomparison semisupervised learning schemes plpuandcurepresent labeled training set primary group unlabeled training set primary group theunlabeled training set comparison group respectively training setprimary', 1);('iv', 1);('validation setthe', 1);('samples comparison group', 1);('intothree parts', 1);('primary group samples', 1);('forthe', 1);('comprehensive experimental results', 1);('comparison group', 1);('group primarygroup', 1);('groupbcontains', 1);('wide roads total', 1);('highway scenarioswith', 1);('acontainssequences', 1);('scenarios group', 1);('training interms generalization ability samples betweenscenarios', 1);('samples training improvethe generalization ability model', 1);('introduction largenumber', 1);('evaluation semisupervised learning semisupervised', 1);('occurs adistance', 1);('mostprudent choice', 1);('avoiding', 1);('imagesfrom single frame', 1);('red boxes', 1);('image illustration', 1);('point cloud visualization correspondingtopdown view', 1);('image realworld photo bottom', 1);('subgure top', 1);('historical frame c individualframes', 1);('current frame b', 1);('typical cases', 1);('historical framesa b cfig', 1);('columns images rightboth', 1);('top view point clouds', 1);('multiframe point clouds', 1);('top view theoriginal', 1);('right realworld photos visualization', 1);('tests multiframe fusion', 1);('howeverthis', 1);('lightness thecolor edges', 1);('8c case', 1);('times asshown', 1);('locations', 1);('individual frames', 1);('framesthus weight w3is', 1);('f3pexhibits', 1);('historical framewhile frames', 1);('fig8b', 1);('main problem', 1);('thisis', 1);('history frame', 1);('multiframe fusion\x0fdynamic object', 1);('historical features', 1);('thecurrent frame empty', 1);('low obstacles curbs barriers', 1);('historical ones', 1);('current frame presentin', 1);('theshade', 1);('thevertical', 1);('horizontal direction indicatesdifferent frames', 1);('purple column', 1);('attentionweightswkk 1f', 1);('yellow row', 1);('f0p', 1);('orange parts thepolar', 1);('images green', 1);('spatial location indicatedin', 1);('right isthe illustration', 1);('realworld photosand point cloud visualization', 1);('fig8', 1);('illustration case', 1);('historical points ofsuch', 1);('predictedcad errors position', 1);('rightmost column', 1);('overlap themas', 1);('bythe attention weights', 1);('frame point cloud image', 1);('shadows images', 1);('dynamic objects vehicles andpedestrians lead', 1);('column wecan observe', 1);('overlap themultiframe point clouds', 1);('scenes containingsome', 1);('inrealworld scenarioswe show performance', 1);('different multiframefusion methods', 1);('previous subsectionwe', 1);('sam qualitative analysis', 1);('number density pointsin frame needs', 1);('number framesto', 1);('long 5frame version', 1);('respect efciencyof deployment 9frame version', 1);('wrong predictions', 1);('fig6 sam5', 1);('middle row', 1);('frames increasethe stability', 1);('slight increase number', 1);('9frame fusion introduces historicalpoints', 1);('results penultimaterow', 1);('test 9frame version', 1);('dynamic objects addition', 1);('reduces theinterference', 1);('multiframe fusion structure', 1);('black circles', 1);('dynamic objects cf', 1);('method suffersfrom', 1);('merge concatmethods', 1);('low obstacles', 1);('accurate prediction especiallyfor', 1);('cloud sufcient', 1);('axes center image', 1);('tohistorical frames', 1);('gray ones', 1);('points points', 1);('different multiframe fusion methods', 1);('large blind spot', 1);('top leftimage', 1);('firstly', 1);('20for multiframe fusion prediction results allmethods', 1);('outperforms theregression method', 1);('improves prediction precision 4028and', 1);('iiicadloss', 1);('bottom row', 1);('cadaround', 1);('concentrates probability distribution', 1);('cadlosswhich', 1);('thequantitative metrics reason', 1);('crossentropyoutputs outliers suffers', 1);('distant onestherefore', 1);('spatial correlation', 1);('relationship categories', 1);('crossentropy loss', 1);('worstkthis', 1);('loss regressionin terms', 1);('crossentropyloss classication outperforms', 1);('classication task', 1);('cadas', 1);('crossentropy loss signicantlylower regression method', 1);('iii mae', 1);('inthe top', 1);('loss functions', 1);('dynamic objectsresults', 1);('different multiframe fusion modules thehistorical points', 1);('percentage errors theprediction direction', 1);('dynamic objects ratioof', 1);('point location', 1);('number ratio thenumber ihd', 1);('historical dynamic objectsas', 1);('20\x0fihd interference', 1);('predictions andwe', 1);('thenecessity multiframe fusion\x0fworstk average', 1);('curb prediction', 1);('particular weshow', 1);('absolute error outputcad ground truth annotation', 1);('different methods\x0fmae', 1);('mae worstk', 1);('table methodwe employ', 1);('show impact ofadditional frames cf', 1);('pool scenariosand', 1);('corresponding negative obstacles', 1);('cnn', 1);('time dimension intochannel dimension fuse temporal', 1);('multiframefusion methods', 1);('mannerbaselines metrics baselines', 1);('different loss functions models thisexperiment', 1);('dataset evaluatethe effect', 1);('wherethe data', 1);('prediciton resultsof ablation experiments', 1);('cadloss sam cad', 1);('different multiframe fusion modules', 1);('different loss functions', 1);('performance ofcadnet', 1);('ablation experiments', 1);('robust traversabilityprediction', 1);('edge locations ofnegative obstacles', 1);('morereliable ground truth introduction spatial constraintsallow', 1);('negative obstacle comparison', 1);('theedge locations', 1);('low accuracy', 1);('ground truth lackssufcient semantic annotations results clutteredprediction', 1);('due effectivelidar echoes', 1);('098negative obstacles', 1);('merge', 1);('celoss', 1);('num ratiol1loss', 1);('iiiresults ablation experimentsmethodsmae worstk ihdtotal curb', 1);('type oftable', 1);('semantic map predicts semantic categorieson sides curb', 1);('informationfrom empty locations rst type negativeobstacles', 1);('low groundthe cliff edge pool bridgewithout guardrails', 1);('detect sidewalk', 1);('sidewalk andthe', 1);('typesone downward curb', 1);('methodsnegative obstacles', 1);('sametype vehicles motion comparison', 1);('poor performance', 1);('obvious bottom', 1);('categoriesof objects', 1);('semantic map lowestprediction accuracy', 1);('wecan', 1);('serious large objects vehicles', 1);('dynamic objects ground truth ofbev semantic map consistent static ones ofthe categories', 1);('3the annotation', 1);('cadand bev', 1);('visualization prediction results', 1);('maethe', 1);('thin objects terms accuracy', 1);('bevfor', 1);('thin objects 90accuracy', 1);('semantic weights contrast spatialconstraints', 1);('due lackof', 1);('content predictedbecomes simpler binary classication traversabilitythe nal prediction performance', 1);('thin objects forbevb', 1);('poor prediction', 1);('methods adjustingthe weights semantic categories fundamentallysolve problem', 1);('certain category objects deteriorate prediction othercategories', 1);('improvingthe prediction accuracy', 1);('accuracy theothers category', 1);('semantic mapsobjects', 1);('category labels', 1);('yellow ground truth image static andthe', 1);('semantic map highlight', 1);('ground truth shows theground truth', 1);('semantic map prediction middle', 1);('image thevisualization', 1);('prediction accuracy thin8fig', 1);('sim howeverwhen', 1);('prediction thinobjects', 1);('low theweight', 1);('datasets itsaccuracy regard', 1);('regard theothers category', 1);('bevm1', 1);('prediction accuracy', 1);('kitti simthe', 1);('method signicantlyoutperforms', 1);('methods allthe', 1);('fair comparison', 1);('iias bevm1 bevm75 bevm20', 1);('20as weights', 1);('different semanticweights', 1);('test prediction performance', 1);('categories objects to1', 1);('weights pedestrian bicycleand rider', 1);('mass', 1);('different category weights example', 1);('map improves sensitivity network tothin objects setting', 1);('clear semantic information categories', 1);('thin objectsdue lack spatial constraints', 1);('semantic map inaccurate', 1);('bevb\x0fbev', 1);('method binaryclassication', 1);('bevm bev', 1);('methods multiclassicationare', 1);('number semantic categoriesin', 1);('impact traversabilityprediction', 1);('design binaryclassication', 1);('predicts onlythe accessible depth', 1);('semantic map predicts multiclass semanticinformation environment', 1);('bev\x0fbev', 1);('multiple experimental congurationsfor', 1);('15m raxis polar', 1);('15m forbothxandyaxis', 1);('meters ie', 1);('theorigin prediction range', 1);('semantic map 01m', 1);('baseline comparison', 1);('types objects suchas static vehicles sidewalk vegetation\x0ftotal', 1);('negative objects\x0fothers', 1);('poolwithout guardrails', 1);('thedownward curb edges', 1);('kittiin sim ugv', 1);('negative', 1);('vehicles bicycles pedestrians\x0fnegative', 1);('large numberof poles barriers included\x0fdynamic', 1);('addition pedestrians', 1);('pedestrians riders bicycles inkitti', 1);('objects', 1);('border traversablearea metrics', 1);('precisionof representations', 1);('prediction directions', 1);('accessible depths inthose', 1);('wealso', 1);('predictedtraversable distance differs ground truth nomore 05m', 1);('representations byprediction accuracy prediction direction', 1);('traversable areathus', 1);('semantic map semantic image borderdistance', 1);('ground truthof', 1);('accessible depths labels', 1);('absolute error', 1);('intuitiveevaluation metric', 1);('thorny issue', 1);('cad bevsemantic', 1);('thevalidation setsmetrics', 1);('theexperimental results', 1);('dataset training', 1);('semantic mapamong methods', 1);('ground truth prediction', 1);('bevm1 bevm75 bevm20 bevb torepresent cad', 1);('semantic map prediction', 1);('bottom', 1);('pointclouds simulator environment', 1);('top', 1);('corresponding thin objects', 1);('contains wealth dynamicobjects', 1);('kittis', 1);('demonstrates robustness ourmethodsince', 1);('thin dynamic negativeobstacles', 1);('isaac simsimulator', 1);('webuild environment', 1);('lack negativeobstacles', 1);('urban autonomous', 1);('point cloud datasets', 1);('iidataset semantic kitti', 1);('semantic map rst', 1);('comparison bev', 1);('multiple scenarios1', 1);('learning scheme usingdata', 1);('sam\x0fevaluation', 1);('multiframe fusionmethod', 1);('different multiframe fusionmethods\x0fqualitative analysis', 1);('use ofdifferent loss functions', 1);('methods terms therobustness traversability prediction\x0fablation experiments', 1);('9the perception experiments', 1);('hyperparameter \x1bgof distance weight gjdineq', 1);('twobalance factors', 1);('historical point clouds formultiframe fusion ie f', 1);('satisesthe requirements obstacle avoidance', 1);('distance resolution angularresolution 0117m', 1);('nr', 1);('extraction module 3pairs encoderdecoder structures scale spatialfeature', 1);('maximum prediction radius to15 meters', 1);('perception experimentsfor cadnet', 1);('realworld scenariosa', 1);('andevaluate feasibility', 1);('supplemental video', 1);('extensive comparisons ablation experiments', 1);('robustness traversability prediction', 1);('e xperimentsin', 1);('aswvart 11e\x00\x1b2t\x00\x162 where\x1b2and\x162are hyperparametersiv', 1);('variance loss', 1);('balance factor wvartis', 1);('u 10where', 1);('lvar', 1);('u wvart', 1);('lreg', 1);('loss islu ut', 1);('adjacent bpositions calculatethe regularization loss 0jmis sum adjacent bprobability valuesthus total', 1);('probability distributionin radial direction entropy regularization loss islreg u 1nnxj1nrbxm1\x00 0jmlog 0jm 0jmbmxdbm\x0011 ujd9since', 1);('stage training introducethe variance loss', 1);('rst useentropy regularization', 1);('constant factor good choice', 1);('variance bya', 1);('stage training variance willbecome', 1);('variance theprobability distribution variance loss function islvar u 1nnxj1nrxd1d\x00nrxd1d ujd2 ujd 8however probability distribution', 1);('part wemake', 1);('unsupervised training', 1);('1n gand\x1bgis hyperparameter2', 1);('lfljjj', 1);('aroundthe label gjd 1\x00e\x00d\x00lj22\x1b2gd 1n r whereljisthejth depth ground truth index form label', 1);('mse', 1);('00471n rggis distance weight', 1);('thin dynamic negative otherskittibevm1', 1);('others total', 1);('thin dynamic negative', 1);('methods', 1);('iicomparison bev based methods kitti simaccuracy mae', 1);('jd201andyjd2f01garethe prediction probability label subject f jdjj1n 1n rgandyfyjdjj 1n d6table', 1);('crossentropy loss functions areldm ly 1nnxj1nrxd1gjdyjd\x00 ljd2 6lce ly 1nnxj1nrxd1\x00yjdlog ljd 7wherejanddrepresent indexes angular division andradial division', 1);('increasethe probability value label classthe', 1);('labeland crossentropy loss', 1);('loss concentrateon probability distribution output', 1);('aswcet 11e\x00\x1b1t\x00\x161 where\x1b1and\x161are hyperparameterscadnet rst', 1);('timeat crossentropy loss', 1);('thebalance coefcient wcetis weight', 1);('lce', 1);('thedismse lossldm crossentropy loss', 1);('distance weight probabilities', 1);('msewith', 1);('square error', 1);('ly wcetlce ly5the', 1);('ldm', 1);('lcad', 1);('asll lyt', 1);('cadlossas', 1);('crossentropy loss considersthe label class design multistage loss', 1);('part wecannot', 1);('loss themisclassication', 1);('raxis thecloser prediction label', 1);('representation thereare correlations', 1);('supervised training cad', 1);('parts \x15is balance factor thetwo losses1', 1);('training samples tdenotes epoch oftrainingllandluare loss functions supervisedand', 1);('su', 1);('yiisthe', 1);('t 1nlnlxi1ll liyit\x151nunuxi1lu uit4where liand uirepresent prediction probability theith', 1);('sysu', 1);('loss function', 1);('thesemisupervised', 1);('radial direction spacedimension constrain overall probability distributionto', 1);('theprobability distribution space accessibledepth belongssince network predicts probability distribution themaximum accessible depth', 1);('nrparts', 1);('nrclassicationtask', 1);('variable large continuous space', 1);('regress distance', 1);('difcult thenetwork', 1);('regressiontask experiments', 1);('semisupervised trainingalthough cad', 1);('subsequent module spatial', 1);('output tothe', 1);('3fais nal multiframe', 1);('f0pfh', 1);('f0pwithfhfa', 1);('weightedsummation use convolutional layer fuse', 1);('ensure completeness currentfeaturef0p', 1);('fhfhfxk1fkp\x01wk', 1);('generate fusedhistorical', 1);('1f weightedbywkk 1f', 1);('historical polar', 1);('fkp thenthe', 1);('wk', 1);('w0khave', 1);('downsample multiframe polar featuresfkpat', 1);('shape 1\x02nr2\x02n2', 1);('w0k', 1);('location total weights off0kpcan', 1);('historical featureswkis weight', 1);('theframet\x002as examplegreater value weight', 1);('different frames computation correlation vector', 1);('process position', 1);('historical features fuses multiframe point clouds rightpart illustration', 1);('unstable dynamic features', 1);('learnable linear layer subject correlationvectorvk weight wkrepresents stability thefeatures kth frame', 1);('nal attention weight', 1);('length correlationvectorvkisf length multiframe featuresequence f', 1);('kk', 1);('qkisnot', 1);('meaningless calculate correlation', 1);('asvkf knjn 0fn6kg knqk\x01kn 1since', 1);('correlation vector vk', 1);('kof', 1);('qkis', 1);('keyk0but queryq0 eachhistorical frame', 1);('f00pisonly', 1);('f00prelated', 1);('accurate polar', 1);('point cloud', 1);('qkandkk mlp', 1);('frame obtaintwo', 1);('f0kpof', 1);('featuresfor polar', 1);('f0pwith', 1);('fpto', 1);('locations emptyfeatures conducive correlation calculationtherefore rst downsample', 1);('tothe sparsity point cloud', 1);('local features', 1);('fpare', 1);('01f themultiframe polar', 1);('illustratedin detail', 1);('sam structure', 1);('module calculates thecorrelation features2', 1);('cadwe', 1);('fuse multiframe point clouds', 1);('hence', 1);('low correlation', 1);('thewhole sequence', 1);('stability correlationbetween', 1);('stable way eliminatethe', 1);('transientwhile ground', 1);('overall point cloudsequence location pedestrian', 1);('certain momentthen location spatial', 1);('ifa', 1);('low point cloud', 1);('stabilityas example ground', 1);('semantic information points thinkabout problem perspective', 1);('historical frames', 1);('eliminatethe points', 1);('todynamic objects', 1);('ground truth points', 1);('dynamic objects inmultiframe fusion', 1);('methods utilize pointwise', 1);('stabilityattention module1 dynamic feature analysis', 1);('moduleas referenceb', 1);('output max probability value predictionreliability direction', 1);('argmax generate', 1);('encode adjacentspatial featuressince output method probability distributionwe', 1);('feature extraction', 1);('31like encoderdecoder structure', 1);('unet', 1);('analogous', 1);('wholespace need', 1);('localfeatures respect location sector pillaris', 1);('structure multiframe', 1);('mlpmaxpool', 1);('fa3 spatial feature extracting whether', 1);('stabilityattention module', 1);('shape isf 1cpnrn wherecpis number channelsthenfpis input', 1);('fpffkpjk', 1);('frames overall polar', 1);('creates f', 1);('sector pillar', 1);('frame andare', 1);('different frames max', 1);('construct local spatialfeatures cylindrical shape noteworthy', 1);('current posepi0 points input', 1);('historical pose pikand', 1);('system subject transformationtikbetween', 1);('1f rst', 1);('sikk', 1);('thehistorical', 1);('determines shape spatial', 1);('division thespace', 1);('wherenrandndenote number divisions alongtheraxis axis', 1);('fig1', 1);('pillars asshown', 1);('nr\x02nsector', 1);('rand', 1);('space aroundthe robot cylinder', 1);('model minimize meanabsolute error prediction label2', 1);('lijis thedepth index form jth direction goal theperception module', 1);('ndirections', 1);('asliflijjj 1n g wherenindicates labelcontains accessible depth', 1);('si0of', 1);('label correspondingto point cloud', 1);('sensor thepoint cloudsikis capturedliis', 1);('intensity pikis pose', 1);('lidarecho', 1);('elements includingthe threedimensional coordinates', 1);('current frame fhistorical frames totallypfk0nikpoints row ofsikrepresents', 1);('point cloudconsists', 1);('nikpoints', 1);('samples fsikpikji1n uk 0fg wheresik2rnik\x024is thekth framein theith point cloud contains', 1);('samplesfsikpikliji 1n lk0fg', 1);('nnlnuincludesnllabeled', 1);('training dataset', 1);('problem statement', 1);('points polar feature extraction stabilityattentionmodule sam spatial feature extraction samwill', 1);('extraction structure network bothconsistent polar', 1);('spatial representation thespatial', 1);('moresuitable task', 1);('radial axis polar coordinates', 1);('spatial description comparison predictingthe probability distribution traversability continuousspace', 1);('system destroys continuity', 1);('the4common orthogonal', 1);('lrega cadnetcadnet', 1);('adjacent partition', 1);('numberindex', 1);('distance', 1);('factors inllluandlg', 1);('balance', 1);('raxisyjd ljd ujdthedth probability value jth direction iny l u \x15', 1);('index', 1);('lit training', 1);('onehot', 1);('fpandfasemisupervised training', 1);('polar', 1);('depth annotation jth directioninlifpfhfa', 1);('ith samplelijindex', 1);('sikpik pose lidarli label', 1);('historical framesijkindices data samples directions', 1);('raxis andaxisf', 1);('nnlnunrn number', 1);('dataset', 1);('itable inomenclaturesymbols descriptioncadnetnlnu numbers', 1);('key symbols section', 1);('training process lossfunctions', 1);('finallywe', 1);('stabilityattention module cadnet', 1);('processing owof point clouds analyze detail', 1);('introducethe network structure', 1);('ethodsthis', 1);('stable featuresiii', 1);('multiframe point clouds fusion module', 1);('fromthe perspective', 1);('effective laser echoes andthus ray', 1);('outdoor environmentslidar', 1);('serious problem', 1);('intensive amore', 1);('disadvantage ofsuch methods', 1);('applicable otherapproaches', 1);('rnnbased', 1);('notcontain semantic information', 1);('foreground background', 1);('applicable task oftraversability prediction', 1);('foreground points fusedhowever methods', 1);('multiframe point clouds fusion methods', 1);('multiframe point clouds fusion importantpart traversability prediction', 1);('point clouds difcult toobtain sufcient spacial information singleframe pointcloud', 1);('formdue sparsity', 1);('perception module polar', 1);('geometric unity spatial', 1);('polarcoordinate system equalize distribution points eachpartition', 1);('describe spatial', 1);('zhang', 1);('zhu', 1);('point clouds acartesian', 1);('global features bycnn methods', 1);('rst dividethe space partitions encode local', 1);('second', 1);('points polar feature extraction stabilityattention module sam spatial featureextractionpointnet', 1);('after3fig', 1);('usedvoxel grid', 1);('extract spacial', 1);('lidarbased ugvnavigation', 1);('key role perception module', 1);('lidar points processing ugv navigationa', 1);('range applicationsb', 1);('points fora', 1);('spatial distribution', 1);('present thecadnet', 1);('negative obstacles strict requirementsfor', 1);('larson', 1);('shang', 1);('obstacles acertain height', 1);('heightrange laser scan', 1);('forexample bovbel', 1);('calculatethe obstacle distance geometry point clouds', 1);('traditional approaches', 1);('therealso', 1);('semanticclassication location lack constraints thespatial dimension edges', 1);('semantic segmentation approaches', 1);('points camera images', 1);('semantic map directlyfrom', 1);('points semantic map', 1);('complete sparsesemantic', 1);('scene completion task', 1);('rich traversability information', 1);('attention 813due', 1);('recently bevsemantic', 1);('vast outdoor scenarios', 1);('suchmethods lead high memory consumption computationalcosts', 1);('clouds calculate traversability', 1);('model surroundingenvironment 3d occupancy map', 1);('exible efcient traversability representationsubject', 1);('diverse obstacles', 1);('highdenition maps', 1);('traversability representation ugv navigationusually ugv', 1);('multiframe point clouds fusion methods necessaryfor traversability predictiona', 1);('point processing methods', 1);('navigation briey reviews relevant', 1);('different types traversability representation', 1);('section rst reviews', 1);('r elated workthis', 1);('dynamic objects multiframe point clouds fusionii', 1);('tackle interference', 1);('stabilityattention moduleto', 1);('cad\x0fin cadnet', 1);('regard spatialdistribution point clouds', 1);('semisupervisedmanner extract', 1);('robusttraversability representation', 1);('circular accessible depth', 1);('thatcad outperforms baselines terms robustness thetraversability predictionoverall contributions paper threefold\x0fwe', 1);('path planning methods', 1);('practicalugv navigation experiments', 1);('real world', 1);('annotation tool tofacilitate application method', 1);('dynamic objectsin', 1);('signicantlyreduces interference', 1);('attention weightsand', 1);('correlation overall', 1);('unstable andhave', 1);('whole sequence attentionweights', 1);('calculatesthe correlation coefcients', 1);('multiframe point clouds fusion', 1);('stability proposean', 1);('notinclude semantic information', 1);('module contrast', 1);('inthe memory', 1);('semantic map contains semantic information', 1);('interferes thetraversability prediction', 1);('vehicles pedestrians', 1);('historical informationto', 1);('important fuse', 1);('low negativeobstacles', 1);('point cloud lacks sufcient information prediction traversability', 1);('singleframe', 1);('blind spots sparsity point clouds', 1);('problems largelidar', 1);('efciency realworld applicationsthe traversability prediction', 1);('learning ensures', 1);('semantic map applicabilityto', 1);('datasince ground truth annotations', 1);('large amount', 1);('learning widersample distribution', 1);('navigationalso semisupervision', 1);('representobstacles border', 1);('kinds points', 1);('small number labels toinform', 1);('need annotate', 1);('assuch', 1);('spatial dimension', 1);('boththe entropy variance probability distributionto', 1);('areable introduce', 1);('inherent propertyof probability distribution', 1);('training ofcadnet', 1);('radialdirection spatial dimension', 1);('maximum accessible depth', 1);('predicts probability distribution', 1);('independent probabilities ofsemantic categories', 1);('frombev methods', 1);('different', 1);('regard thespatial distribution', 1);('representation analyze road traversability forugv navigation learning', 1);('present neural network', 1);('dynamic objectswe', 1);('providesmore robust predictions', 1);('reliable annotations', 1);('dynamic static objects exists', 1);('suffer inconsistentannotations', 1);('theground truth', 1);('locationsof obstacles', 1);('thin objects thesecond issue', 1);('20222the robustness prediction', 1);('dec', 1);('distances improvesarxiv221213676v1 csro', 1);('thin objects occupymore directions', 1);('polar representation', 1);('system spatial constraintcad predicts border', 1);('traversable area facilitates theintroduction spatial constraint', 1);('expresses distanceto border', 1);('polarcoordinate system', 1);('rst issue', 1);('predicts maximumaccessible depth circular directions', 1);('semantic category pixelwise location', 1);('traversability surroundingenvironment', 1);('different kindsof obstacles', 1);('circular accessible depth cad bevsemantic', 1);('traversability representation', 1);('unreliable prediction', 1);('ground truth tactic results objectsof category', 1);('tokeep singleframe point clouds', 1);('shadows ground truth address thisproblem', 1);('multiframe point clouds result', 1);('generate desne ground truth', 1);('mostmethods', 1);('essential part ground truth productionhowever', 1);('semantic map thusdensication', 1);('dense ground truth isimportant prediction', 1);('due tothe generation process ground truth', 1);('cars bicycles', 1);('semantic map robust predictingdynamic objects', 1);('thin obstaclessecond', 1);('anunreliable prediction', 1);('networkextract informative', 1);('constraint pixelwise classication', 1);('thin objects aspedestrians lamp posts road barriers occupy asmall number pixels', 1);('imprecise prediction ofthe border location', 1);('thetraversable area', 1);('crossentropy lossdoes impose spatial constraint border', 1);('traversable areait noteworthy', 1);('different locations onthe spatial distribution border', 1);('pixelwise classication focuses onlyon semantic', 1);('traversable area itis', 1);('semantic map spatialconstraint border', 1);('thinobjects pedestrians poles barriers rootcause issue', 1);('semantic map robust', 1);('wei zhang email', 1);('hangzhou chinacorresponding', 1);('fuxi ai lab netease', 1);('jinan chinax huang', 1);('engineeringshandong', 1);('affectthe robustness traversability predictionall authors school control science', 1);('major issues', 1);('facilitates thesubsequent planning control', 1);('richerand diverse information road traversability thanmost 3d detection techniques improves securityof autonomous navigation hand describesthe traversability', 1);('traversability representationin autonomous navigation kind representation treatstraversability prediction semantic segmentation', 1);('different typical highway forautonomous drivingbirdseye view', 1);('inspection delivery tasks inenvironments', 1);('downward stairswhen', 1);('irregular obstaclessuch trunks lamp posts barriers', 1);('regular 3d boxes particularthis problem', 1);('present training dataset irregular shapesthat', 1);('due lack ofa robust traversability prediction case objectsdo', 1);('serious accidents', 1);('perception approaches', 1);('3d detection techniques', 1);('objects vehicles pedestrians', 1);('autonomous navigationfocuses', 1);('terms traversability representation semisupervisedlearning ugv navigationi ntroductionmost', 1);('realworld scenariosindex', 1);('show itperforms', 1);('thatcad outperforms baselines terms robustness precisionwe', 1);('large amount data', 1);('encodes spatial information ofthe', 1);('system focuses', 1);('lidar cad', 1);('frompoint clouds', 1);('encode spatial', 1);('stabilityattention module sam', 1);('multiframe point cloud fusion module', 1);('neural network', 1);('irregular obstacles predictcad', 1);('various scenarios', 1);('ground vehicle', 1);('robust traversability representation foran', 1);('circular accessible depth cad', 1);('yuenan zhao xueqin huang yibin li wei zhangabstract', 1);('accessible depth robust traversabilityrepresentation ugv navigationshikuan xie ran', 1);