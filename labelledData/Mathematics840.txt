('rl', 23);('rashidinejad', 18);('lemma', 14);('zhan', 13);('chen', 12);('lp', 11);('o1n', 10);('theorem', 9);('assumption', 8);('international conference', 6);('xie', 5);('mdp', 5);('hoe', 5);('pmlr', 5);('markov', 4);('spc', 4);('problem', 4);('sample complexity', 4);('wandb', 4);('hence', 4);('decision processes', 3);('levine', 3);('ueharaand sun', 3);('lpbased', 3);('mdps', 3);('optimal policy', 3);('iis', 3);('machine learning', 3);('reinforcement learning', 2);('framework ine', 2);('vinyals', 2);('key', 2);('function classes', 2);('bellman', 2);('ine data', 2);('o1n16', 2);('lpinduced', 2);('uehara', 2);('jin', 2);('li', 2);('cheng', 2);('nachum', 2);('independent work', 2);('lagrangian', 2);('mis', 2);('pr', 2);('j0', 2);('throughout', 2);('puterman', 2);('dene', 2);('furthermore', 2);('wandbare', 2);('completenesstype assumption', 2);('jiang', 2);('zhanet', 2);('initial distribution', 2);('dd', 2);('dis', 2);('compared', 2);('specically', 2);('s0', 2);('suppose', 2);('max optimal policy', 2);('theoptimal policy', 2);('chenand jiang', 2);('cis', 2);('suppose assumptions3', 2);('proceedings', 2);('information processing systems', 2);('machinelearning', 2);('robotics', 2);('advances neural information processing systems', 2);('arxiv221213861v1 cslg', 1);('dec', 1);('function approximationasuman ozdaglarsarath pattathiljiawei zhangkaiqing zhangabstractoine', 1);('optimal policy sequential', 1);('fur ther interactionwiththeenvironment', 1);('recenttheoreticalprogresshasfocusedonde', 1);('velopingsampleecient oine', 1);('assumptions data coverageand function approximators', 1);('case excess', 1);('largestateaction spaces', 1);('linear programminglp reformulation', 1);('promi se enablessamplee', 1);('partialdatacoverage realizability assumptionson function classeswith favorablecomputational tractability work revisit', 1);('statistical rates terms sample size key enabl er introduceproperconstraints reformulationinstead', 1);('regularizationas th eliteraturesometimesalsowithcarefulchoicesofthefunctioncla ssesandinitialstatedistributions', 1);('wehopeour', 1);('insightsfurtheradvocate thestudyofthelp f rameworkaswell asthe', 1);('primaldual minimaxoptimizationino inerl1', 1);('introductionrecent', 1);('tremendous empirical successe reinforcement learning', 1);('sequentialdecision making problems', 1);('mnih', 1);('silver', 1);('rich function approximators eg', 1);('neural networks', 1);('large interaction data environment', 1);('successful examples aboveare', 1);('datahungry cases interaction ata', 1);('obtainedin online fashion', 1);('powerful simula tors game enginessilver', 1);('andphysics simul ators', 1);('todorov', 1);('information decision systems lids', 1);('ssachusetts institute', 1);('technologydepartment electrical computer engineering ece', 1);('systems', 1);('isruniversity maryland', 1);('college park asuman sarathp jw zhang kaiqingmitedu', 1);('sp', 1);('mathworks engineering', 1);('ao kz', 1);('mitdsta', 1);('kzalso', 1);('acknowledges support', 1);('simons berkeley researchfellowship1on', 1);('online int eraction impractical', 1);('data collection', 1);('expensive andor mpractical environmentis', 1);('di cult simulate', 1);('real world applications fall int', 1);('robotics autonomous', 1);('maddern', 1);('tseng', 1);('recommender systems', 1);('swam', 1);('cases online interaction avai', 1);('wantto utilize', 1);('data e ective generalization', 1);('promising framework', 1);('rlin', 1);('realworld applicationshowever practice ine', 1);('su er training instability issueduetotheuseoffunctionapproximationegneuralnetwo rksandthe distributionshiftissue', 1);('distinction ine data distribution', 1);('asaresultintheoryguaranteeing', 1);('samplee ciency ine', 1);('function approximation usuallyrequires', 1);('strong assumptions function classes thedataset particularmanyearlierresultsmunos andszepesvri2008scherrer 2014chen andjiang2019zhanget', 1);('bellmancomplete', 1);('ie valuefunction class closedunder', 1);('operator dataset', 1);('full coverage iethedatacovers thestatedistributions inducedby allpolicies assumptionsare', 1);('nonmonotone function class ie assumption', 1);('whenaricher function class', 1);('andismuch str ongerthanthecommon assumption realizability ie theoptimal solution liesinthefunctionclass inst', 1);('possiblestateaction pairs', 1);('realworld ap plicationssignicant progress', 1);('relax assu mptions exampleliu', 1);('al202 1xieet al2021uehara andsun2021haveshownthatusingthe pessimistic mechanismthatchoosestheworstcastvaluefunction model uncertainty', 1);('th e', 1);('full coverage assumption', 1);('singlepolicy ie optimal policy coverage assumptionnonetheless results', 1);('assumptions algor ithms', 1);('th e hand worksrequireonlyrealizability butwithadditionallyeithers trongerthanallpolicycoverageassumptions data coverage', 1);('un iqueness optimalpolicy', 1);('full data coverageand completeness assumptions seminal use f linearprogramminglp reformulation', 1);('mdps th', 1);('framework onlysignicantlyweakenstheassumptionsbutalsobetterenab lescomputationallytractablealgorithms', 1);('algorithms andanalyses', 1);('versionofthelpformulation whichcallsforstrongerassu mptionsthansinglepolicy coverage', 1);('suboptimal rates ie', 1);('wherenis size dataset paper revisit furt', 1);('power ofthelpframework ine', 1);('rlwith', 1);('performance guarantees andadvance theexistin g2results', 1);('contributions f ollowscontributions', 1);('algorithms optimal terms ofsample size', 1);('sample complexity partial data coverage genera l function approximation', 1);('behavioral regulariza tion', 1);('inparticular', 1);('optimal rate', 1);('standard singlepolicyconcentrability', 1);('completenesstype assumption function class', 1);('ads nearoptimal rateofos1nwhenreducingtothetabularcaseimprovingeventhestat eoftheart tabularcase result', 1);('g eneral function approximationget', 1);('r ealizability assumptionwe', 1);('o1gapn', 1);('rate partial coverage assumption', 1);('slight v ariantofstandardspcwhere', 1);('gapdenotestheminimaldi', 1);('erencebetweenthevaluesofthebest action secondbest', 1);('finall', 1);('note algorithmsinherit', 1);('favorable computational tractability', 1);('2022the key algorithms introduce', 1);('appropriate constraints', 1);('main text', 1);('optimization problems whi ch improves sampleeciency', 1);('function class complexity b e', 1);('role regularization plays literature', 1);('results section', 1);('open question inchen andjiang2022 howtointegratetheideasintheconc urrentworkschen andjiang2022', 1);('address weaknesses hope analysesandinsights advocate study', 1);('framework n oine', 1);('rl11 related workwe', 1);('literature review subsect ion categorize results', 1);('assumptions data andfunction classdata coverage assumptions', 1);('early', 1);('theallpolicy concentrability assumption ie ine data', 1);('exploratory enoughto', 1);('state distributions', 1);('munos szepesvri', 1);('tothis assum ption asthe fulldatacoverageassumption', 1);('slightly', 1);('variant assumes weig', 1);('version allpolicy concentrability coe cient', 1);('signicant progr ess', 1);('relaxfull coverage assumption partial coverage ones', 1);('pessimistic value iterat ion', 1);('algorithms tabular linear', 1);('singlepolicy concentrabili ty assumption data coverage general function approximation', 1);('va riants', 1);('account partial data coverage', 1);('uehara sun', 1);('algorit hms', 1);('recent works', 1);('pa rtial data coverage arezhan', 1);('onecommonassumptiononfunctionclassisthebellmancompletenessonvaluefunctionsmunos', 1);('andszepesvri200 8scherrer2014chen', 1);('jiang2019 xie', 1);('th e value function class tobe', 1);('operator denition ssumption', 1);('tabular linear', 1);('mdpmodel uehara', 1);('realizability iethefunctionclassonlyneedsto', 1);('target function interest eg optimal value functionxie andjiang2021', 1);('xie jiang2021relieso', 1);('inf', 1);('al2020zanette202 1foster', 1);('good data coverage', 1);('assu mption value functionis su cient samplee cient oine', 1);('function approximation density ratio addition tovalue functio n', 1);('al2022chen andjiang2022jiang', 1);('huang20', 1);('inparticular zhan', 1);('recent works thatassume onlyrealizability onbothvaluefunction anddensi tyratio andpartialdatacoverage', 1);('additionallyrequires data coverage', 1);('thegreedy optimal action uniquefor statesindependent work', 1);('rashidinejadetal', 1);('paper cameacross concurrent', 1);('o1nrateundergeneralfunctionapproximationviathelpframe', 1);('behavioral regularization', 1);('2022requires completenesstype assumptions', 1);('whic h', 1);('mirroringthe rst', 1);('results ie section', 1);('h ave', 1);('di erent data coverage assumption ie section 4rashidinejad', 1);('paper di erent followingaspects', 1);('methodalmwhileweproposetosolvetheoptimization withconst', 1);('thefunction classes', 1);('corresponding complet eness realizability assumptionsaredi erentseesection3formoredetails', 1);('thirdwithadi', 1);('erentandrathersimple analysis results', 1);('improves thestateoftheart result', 1);('tabular c ase', 1);('theimportance occupancyvalidityconstraintsandourconstrainedformulati insection3mirrorstheroleof', 1);('alm rashidinejad', 1);('validit constraints4notation vector vrd usebardblvbardblpto', 1);('pnorm p0 andif subscript bardblvbardbldenotes 2norm', 1);('bardblvbardbl0denotes numberof nonzero elements v matrix', 1);('mrmn', 1);('frobenius', 1);('mto', 1);('transpose asets usestodenote cardinality', 1);('theprobability distributionovers function class f usefto', 1);('cardinality discrete andits', 1);('continuous use', 1);('eto', 1);('expectation matrixmrmnm0 denotes element', 1);('rdtodenote', 1);('real vector space elements non', 1);('weuse diag m1mn', 1);('block diagonal matrix', 1);('proper dimension sediagonal blocks', 1);('m1mnhave', 1);('thesame dimension', 1);('wefollow', 1);('ratio occurs2', 1);('background21 modelandsetupmarkov', 1);('decision process', 1);('consider', 1);('tupleabracketletsapr 0abracketriht wheress1ssandaa1aadenote state actionspacesoftheagent', 1);('rsa01istherewardfunction1psasdenotesthetransition', 1);('denotes discount factor 0s denotes initialstate distribution', 1);('sandaare', 1);('large orderto', 1);('depen cardinalities', 1);('sanda letsadenoteamarkovstationary', 1);('policy oftheagentdeterminin g thedistribution actions state', 1);('occupancy measureover stateaction spaces', 1);('by0sa1summationdisplayt0tprstsata0 1where', 1);('stsata0 isthe probability theevent', 1);('thepair sa timetunder policy', 1);('slight abuse notation use 0s summationtextaa0sato', 1);('occupancy measure states notational convenience weconcatenate stateaction occupancy measure 0sa vector', 1);('as0bracketleftig0s1a10s1aa0ssa10ssaabracketrightigrsa2given policy', 1);('corresponding stateaction stat evalue functions', 1);('qandv', 1);('case deterministic reward eas e presentation results', 1);('caseof randomrewards5where trajectory', 1);('policy andvs', 1);('easqsathe', 1);('overall goal tond apolicy solves', 1);('problemmaxj01es0bracketleftigvsbracketrightig 3wherej0 denotes returnunderand0 ie 1times', 1);('valuefunction policy', 1);('initial distribution 0note', 1);('j0r0', 1);('whererrs1a1rssaa01sa 4it', 1);('optimal solution', 1);('mdp markov sta', 1);('tionary policy ageneral distribution use andj', 1);('occupancymeasure average value function policy', 1);('andj simplicity initialdistribution', 1);('clear contextnote optimal policy', 1);('unique dene vvandqqforconvenience', 1);('rl consider', 1);('dcontainingnsamples', 1);('suppose dsiaisirini1', 1);('iid samp les siai', 1);('summationtextasa implies siare', 1);('iid fromthe distribution', 1);('conditional distribution', 1);('behavior policy ifcorresponds theoccupancy measure policyin paper', 1);('behavior policy', 1);('stateaction pa ir siai rirsiaiandsipsiai', 1);('ndsa subset sample indices 1nthatincludestheindicesofthesamplesin', 1);('dthatvisitstateactionpairinthesenseof', 1);('similarly', 1);('ndsas andnds', 1);('indices data samplesindsuch siaisisasandsis', 1);('denetheempirical versionof ied asdsa ndsan goal ine', 1);('datasetdtolearn apolicy optimalitygap', 1);('j0j0is', 1);('smallpartial data coverage', 1);('scenario ofine data partialcoverage', 1);('di erence werst introduce', 1);('denition policyconcentrability', 1);('denition1 policy concentrability forany', 1);('policy andinitialstate distribution andthe', 1);('ine data distribution dene', 1);('c0to', 1);('upperbound suchthatsasacfor allsasanotethat', 1);('ccharacterizeshowwellthetrajectorygeneratedbythepoli', 1);('full coverage exists', 1);('cthat', 1);('upper boundsc0forallpolicymunos', 1);('szepesvri', 1);('scherrer', 1);('contrast whenwe', 1);('optimal policy concentrability assu mption thatis', 1);('focus partial coverage setting andspecify assumption later22', 1);('lpbasedreformulationsit', 1);('optimal policy optimizes', 1);('initial distribution 0in model insection', 1);('maximi zesvs states ssmoreover optimality condition', 1);('linear program', 1);('puterma', 1);('n 1994minv1vstpsavrsavsss aa5wherepsa', 1);('psas1psasss', 1);('vector state transition probabilitiesfor stateaction pair sa', 1);('letp ps1a1ps1aapssa1pssaarsmand1a111ranote', 1);('initialstate distribution', 1);('insteadof0 generality ect solution tabular case', 1);('howeveras', 1);('sections choice', 1);('di erence function approximation setting', 1);('address chall', 1);('settings inerl', 1);('interestingly', 1);('linearfunction approximation case', 1);('de farias van roy', 1);('context approximate', 1);('dynamic programmingthe', 1);('corresponding dual formulation', 1);('lp equation', 1);('followsmaxrsummationtextssaarsasastm1 06where matrix', 1);('asmdiag1a1apwe focus', 1);('dual formulation', 1);('th', 1);('togenerate policy whereis', 1);('asassasummationtextasa 7thisthen corresponds optimal policy', 1);('mdp puterman', 1);('study relationship occupancy meas ure data distribution', 1);('lp thi', 1);('themarginal importance', 1);('formulation themdp inthel iterature', 1);('firstwedene', 1);('wrmsuch wsasasa iewsa denotes ratio occupancy measure targ', 1);('policyandthe inedata distributionforeach', 1);('kssassa1kssassa', 1);('entries zeros', 1);('distributions anddoversasas', 1);('psassa', 1);('finallywe', 1);('dene matriceskesaskssaandkdesasdkssa 8furthermore dene urmsuch usa rsasathen', 1);('lemma relates quantities theones n', 1);('6lemma1 followingrelationshipuwr', 1);('kw', 1);('9proofnote therst inequality', 1);('den itions uandwthe', 1);('kssa', 1);('andmssa denotethe ssath element matrices', 1);('kandm', 1);('kssa mssasa', 1);('nowkwssummationdisplaysakssawsasummationdisplaysamssasawsamsthereby', 1);('sfollowsmaxwuwstkw1 w010letwbe solution', 1);('slight abuse notation wis', 1);('aswaswsaassummationtextaawsaasifsummationtextaawsaas01aifsummationtextaawsaas011where recall conditional distribution agivensunder canalso', 1);('asthe behavior policythe', 1);('equivalent minimax reformulation', 1);('10is giv', 1);('byminwrmmaxvrsuwvkw1 12throughout paper denewvuwvkw1', 1);('empiricalformulationsince', 1);('exact distributions', 1);('l setting', 1);('beanempirical estimateof wecanuse ifisknownto', 1);('empirical counterpart 13dwvudwvkdw1 14wherewerecall thedenition', 1);('kdin', 1);('anddene udrmasudsarsadsawithdsa ndsan focus', 1);('empirical minimax optimization problemminwrmmaxvrsdwv', 1);('functionapproximationto', 1);('large state action spaces function approximation', 1);('decision variables', 1);('eg value functions wellasthedensityratios', 1);('inthefollowingtwosectionsweprop', 1);('osetwoo inerlalgorithmswith function approximation di erent variables section', 1);('relax equalityconstraint', 1);('inequality constraints', 1);('fu nction approximation wand', 1);('additional variable completeness ssumption', 1);('thatour algorithm', 1);('optimal sample complexity terms f sample size evenimproves stateoftheart results', 1);('abular case section', 1);('usefunction approximation minimax problem', 1);('iginal form achievethe 1nrate', 1);('gap function', 1);('qsee', 1);('denition section 4with realizability assumption thefunction clas ses3', 1);('case optimal rate completenesstype assumptionwe', 1);('formulationundersinglepolicyconcentrabilityandsomeco mpletenesstypeassumptionswe state assumptions followsassumption', 1);('rmrssuch', 1);('wargmax xbardblxbardbl1xkw10iewkw10bardblkw10bardbl1letwandbbethefunctionclassesforwandxww', 1);('iewwandxwbfor anyww', 1);('iebardblwbardblbwforallwwand2bardblxbardbl1for allxbseveral', 1);('contains n ot realizability ofwforw', 1);('bforxwbfor', 1);('thecompletenesstypeassumptionsarestandardintheo', 1);('inerlliteraturemunos andszepesvri2note wwimplies', 1);('bw1sincewisa', 1);('supremum ratio', 1);('andcan bechall', 1);('certain cases', 1);('due hardness results', 1);('fost', 1);('bestof knowledge', 1);('assu realizability optimal solutions', 1);('andjiang 2022which', 1);('suboptimal computation ally', 1);('intractable defer oursolution tothe', 1);('case section 4second', 1);('completeness assumption', 1);('nee completeness ofonefunctionclass', 1);('bforxwwhilerashidinejad', 1);('al2022requiresthecompletenes sofuforuwwith thenotation therein therealizability v togetherwith', 1);('therealizability model', 1);('pwhich', 1);('bellmancompletenes', 1);('ueharaandsun', 1);('uandzthereinnext', 1);('rashidinej', 1);('thepolicy concentrability assumption', 1);('wh ich', 1);('theconcentrability assumption', 1);('singlepolicy concentrability thereexistssomeconstant c0suchthatforallsasa0sasac0cfor', 1);('additional propert ies relationshipbetween occupancy measure andthe', 1);('policy asshown next31', 1);('propertiesoftheinducedpolicy recall', 1);('denition occupancy measure', 1);('pol icyas0in', 1);('notethat', 1);('omit subscript 0in0throughout section asthe', 1);('clear contextnoticethatavector', 1);('rmisnotnecessarily', 1);('therst', 1);('lemma shows occupancy measure satises constraints inproblem 6with 0lemma', 1);('werecall thedenition in7', 1);('j0rproofthis', 1);('lemma aspecial case thenext lemmathe', 1);('close toifis setm', 1);('mma bounds absolutedierence randrlemma3 any0 haverbardblm10bardbl1110prooflet policy', 1);('ne', 1);('xt denessummationdisplayaasaand ssummationdisplayaasa 16note', 1);('sasas andsasasletprssbeacolumnstochasticmatrixthesumofallentriesofevery columnis', 1);('thestate transition probabilities un der policy iepjisummationdisplayaapsiasjasialso dene matrix', 1);('gdiags1s2ssrsas', 1);('andnotice fact', 1);('mgip', 1);('satises constraints', 1);('problem6 m10', 1);('impliesbardblm10bardbl1bardblmbardbl1bardblmgbardbl1bardblipbardbl11bardblbardbl1 17herethelastinequalityisbecause bardblpbardbl1bardblbardbl1whichfollowsfromthefact', 1);('pis', 1);('column stochastic matrixon hand', 1);('rsa01 sa haverrgbardblbardbl1', 1);('areformulated lpnow', 1);('state approach', 1);('c ontrolbardblm10bardbl1bardblkw10bardbl1', 1);('inner product rbe', 1);('close actualreturn policy ier motivates', 1);('constraint controlbardblkw10bardbl1recall udrmis', 1);('udsarsadsa approach', 1);('optimization problem', 1);('datasetdmaxwrmudwstxkdw10enxbww 1911whereenbw2logbwn', 1);('problem19canbeviewedasarelaxationoftheempiricalversion problem', 1);('kdw100to', 1);('inequalitysuppose solution', 1);('sadsawdsaas 20the performance policy', 1);('suppose assumptions1', 1);('2hold havej0j0d22bwradicalbiglogbw1nwithprobability', 1);('optimal sample complexity', 1);('terms ofsample size n general function approximation', 1);('rece nt workzhan', 1);('exchange realizability assumption vtherein completenesstype assumption', 1);('inerlalgorithms generalfunction approximation hav e theoptimal', 1);('xieet', 1);('intractableouralgorithm istractableifthef unctionclasses areconvexinheritingthecomputational advantageofthelpframeworkforo inerlzhan', 1);('wforwand', 1);('completenesstype assumptions needone need', 1);('comparable fun ction classes', 1);('need realizability vand', 1);('1dependence 11vs', 1);('simpler algorithm analysis', 1);('wenote', 1);('enforcethe constraint wd use technique', 1);('whil e weintroduce', 1);('program directlyremark', 1);('wbare', 1);('number number ex treme points', 1);('convex algorithm', 1);('tractable sinc e', 1);('proofoftheorem1first', 1);('thefeasibility optimizat ion problem 19lemma4', 1);('anywwsee assumption1', 1);('feasible 19with probability', 1);('112proofusehoedings inequality xbpxkkdwtexpparenleftiggnt28b2wparenrightigg 21this', 1);('fact xkkdwis random', 1);('t22bwlogwbn havepxkkdwtwb 22nowtakingtheunionboundoverall xbandalsoall wwwegetthenalresultnext show objective value udwdisclose uwlemma5 haveudwduw2bwnradicalbigglog1withprobability', 1);('wehaveudwdudwwith probability', 1);('wecan use', 1);('dings inequality tobound uudwas followspudwuwtexpparenleftiggnt22b2wparenrightigg', 1);('upperbound beequal havet2bwnradicalbigglog1', 1);('eventscompletes proofnext', 1);('boundfor bardblkwd10bardbl1lemma6 havebardblkwd10bardbl12enwithprobability', 1);('12proofwe rst havexkkdwenxb 25for anyxb wwwith probability', 1);('similar proof', 1);('im plies lemma sincewdw13thereforebardblkwd10bardbl1bardblkdwd10bardbl1bardblkkdwdbardbl1enen 26where rst term righthand side', 1);('wdsatises constraint in19', 1);('havej0uwudwd2bwnradicalbigglog1 27thistells usthat udwdisclose uwj0', 1);('dings inequality andunion', 1);('thatudwuw2bwnradicalbigglogw28for anyww', 1);('wdw haveudwduwd2bwnradicalbigglogw29withprobabilityatleast1', 1);('dene dsadsaswherewerecallthedenitionofdin', 1);('denition u uwdrd', 1);('boundthe di erencerdrdbardblmd10bardbl11 30where recall', 1);('dby', 1);('thetabular casein', 1);('subsection show results bedire', 1);('sample complexityhere need', 1);('realizable function classes', 1);('tractable use', 1);('continuous convex functio n classes', 1);('instead14of discrete nite ones', 1);('wwrmsummationtextawsabwssandb', 1);('11s convex', 1);('boundedness ssumptionsin', 1);('maxxbxkdw10bardblkdw10bardbl1bwslog2a2log1 n32ww 33we', 1);('suppose assumption', 1);('nondegenerate th e sense thatminas1 havej0j0d2bwsparenleftiglog2a2log1 parenrightig1nwithprobability16forany 13note', 1);('ample complexity ofthis algorithm', 1);('applicable stil l base analysis thederivations', 1);('proof theorem', 1);('thenumber extreme pointsof convex setsproofthe number extreme points', 1);('wandbare a1sand', 1);('2s slightabuse notation', 1);('bardblwbardbleandbardblbbardbledenote number extreme points', 1);('need modify', 1);('union concentrationbounds25and28', 1);('thesetwoinequalitiescanberep', 1);('twoinequalities terms thenumber extreme points1xkkdw2bwradicalbiglogbardblwbardblebardblvbardblen2bwradicalbigslog2a2nfor anyww xbwith probability12uudw2bwradicalbigsloga1nfor anywwwith probability1weonlyprovetherstclaimandthesecondonefollowssimila', 1);('letw0w1wbardblwbardbleb0x1xbardblbbardblebe', 1);('extreme points', 1);('wb', 1);('ww wehavewbardblwbardblesummationdisplayi1iwiandfor xbxbardblbbardblesummationdisplayj1jxj15for 1bardblwbardbleand 1bardblbbardblethat lie', 1);('corresponding simplexes wi xj', 1);('inequality union', 1);('w0b0we', 1);('havexjkkdwi2bwradicalbigslog2a2nwith probability1', 1);('jensens', 1);('probability 1we havexkkdw2bwradicalbiglogbardblwbardblebardblvbardblennext', 1);('logbardblwbardblebardblbbardble1 nondegenerate case min', 1);('as1', 1);('rst claim', 1);('strategy proof', 1);('theorem1', 1);('rashidin', 1);('ourresult yields', 1);('tabular case', 1);('o114n', 1);('o11n', 1);('fact reduction', 1);('th terms', 1);('stateoftheart result', 1);('2021which is4os132n', 1);('os1n', 1);('note thelowerboundforthetabularcaseis', 1);('sradicalbig1ninrashidinejad', 1);('bernsteins', 1);('dings concentration inequalitytogether variance reduction technique', 1);('sidford', 1);('improveourdependenceon1 1andattainthelowerboundweleavethesedirectionsofimprovementasfutureworksinceourfocusisonthegener alfunctionapproximationcase andon optimality sample complexity terms nthough', 1);('framework results', 1);('raises thequestioncanwe', 1);('tractable ine', 1);('o1nratebut', 1);('realizability partial data coverage assumption swhich', 1);('open question', 1);('question thenext section', 1);('framework3note specify dependence', 1);('sexplicitly', 1);('ierentfromoursandnotcomparablewhichwebelieve canbeofordersasours', 1);('wethusonly', 1);('focusonthedependence of1', 1);('alsotheadditional', 1);('bvtherein', 1);('14note denition', 1);('j0in rashidinejad', 1);('factoro fromour denition164', 1);('caseiirealizabilityonlywithgapdependencein', 1);('minimax optimizati', 1);('original formby', 1);('function approximation variables vandw', 1);('notice', 1);('relatedto setting', 1);('function appro ximation', 1);('thestateaction function', 1);('qandwwe', 1);('select wvfrom nite sets5wv', 1);('writeasfor notational convenience', 1);('formulation 10and12as ssforallssthroughout thissection', 1);('intheend', 1);('section relate return', 1);('note haveaccess theempirical version', 1);('dof', 1);('proposition species abasic', 1);('erty ofproposition1 optimal policy sa1safor allsasaproofthis', 1);('direct corollary fact policy denition havesa1sa sasathe design algorithms section', 1);('follo wing intuitive idea', 1);('according equation', 1);('wsuch thatsummationtextawsaas', 1);('policy whas tobe', 1);('uniform distribution example', 1);('decidedfrom ine data', 1);('direct approach', 1);('boundconstraint vanilla minimax problem', 1);('specicall', 1);('followingpopulation minimax problemminwrmmaxvrsuwvkw1stsummationdisplayawsaas1ss 34note', 1);('vanilla minimax problem', 1);('dierence weenforce', 1);('constraints onsummationtextawsaas order', 1);('casewherethepolicy wcannotbedeterminedproperlyfromtheo inedataset', 1);('byproposition', 1);('optimal solution wis', 1);('function approximation e', 1);('minimax problemminwwmaxvvuwvkw1', 1);('thatsummationtextawsaas1 sandany ww', 1);('noticethat', 1);('conict constraint wrmin', 1);('intersect thesets', 1);('wto', 1);('approximate optimal policy ine data', 1);('followingempirical version minimax problem 35minwwmaxvvudwvkdw1d 365as', 1);('case inniteclasses wecan replacethe results section sta ndard', 1);('assumptionsbefore', 1);('main theoretical result section rst state assumptions', 1);('additional notation rst', 1);('realiza bility assumptions thefunction classes', 1);('wandvassumption3 realizabilityandboundednessof wthereexistssomesolution', 1);('suppose bardblwbardblbwforallwwassumption', 1);('realizability boundedness vsuppose', 1);('vv1111snoticethatsimilarassumptionsareusedinzhanet al2022', 1);('chen jiang2022next', 1);('data coverage suggests inedata', 1);('pre sentation use', 1);('ine data distribution ies0sss0 recall summationtextaasafor anyss', 1);('anypolicyand anyss denessaaas0andtsaaqsavsremark2', 1);('s0for', 1);('algorithm statedlater', 1);('s0foranalysisnext', 1);('inactive stateaction pairs sa belowdenition', 1);('active stateaction pairs', 1);('stateaction pair sasaisactiveifqsa vs', 1);('otherwise', 1);('inactive pair', 1);('letisabe', 1);('inactive stateaction pairs', 1);('saithus', 1);('activestateactionpairswethenhavethefollowinglemmaontherelationship theinactivesetiandtheoptimal policylemma7', 1);('if0is', 1);('optimal policy 0sa0for anysai', 1);('if0as0foranysai', 1);('then0is anoptimal policyproofwe', 1);('rst part', 1);('0is optimal 0as', 1);('inactive sa', 1);('tand sai', 1);('therefore0sa0', 1);('vbe optimal value function', 1);('weonly', 1);('v0v apolicy denepjisummationdisplayaapsiasjasiandrrs1s1rssss18then', 1);('unique solution linear equationvp0vr0 37we', 1);('solution equation fact', 1);('pi', 1);('havep0ivr0i 38summationdisplayas0si0asipsiavrsia 39summationdisplayas0si0asiqsia 40vsi 41where', 1);('pvrqand', 1);('equality becauseqsa vs foras0s', 1);('thenvis', 1);('vv0 yields', 1);('resultnow state partial data coverage assumption rst troduce followingdenitions conveniencedenition4', 1);('data coverage', 1);('apolicyifas0impliessa0aoptimal policy optimal policy', 1);('exists leastoneoptimal policy policy', 1);('maxoptimal policy aoptimalpolicythat satises', 1);('sssstsforanyss0remark3 apolicy', 1);('means policy', 1);('behavior poli cy sensefor state ss0', 1);('optimal pair sacan', 1);('thebehaviorpolicy withpositive probability ais optimal action maximizes', 1);('qsathereforeitisreasonabletoassumethata', 1);('ifa', 1);('optimalpolicyexiststhenthemaxoptimal policy', 1);('ready state singlepolicy concentrabilit assumptionassumption', 1);('singlepolicy concentrability', 1);('c0such', 1);('forall sasasasaccremark', 1);('usual sin glepolicy concentrability assumption', 1);('rashidinejadet', 1);('whi ch assumes coverage anyoptimal policy', 1);('means optimal policy co', 1);('behavior policy ie optimal policy occupancy measure', 1);('theoine data distribution', 1);('sen se practice ine datadistribution', 1);('stationary dist ribution', 1);('chain undersomebehaviorpolicywhichcanbeobtainedbyrollingoutsome innitelyorsu cientlylong19trajectories', 1);('liu', 1);('satises xedpoint equationssummationdisplaysasapsas 42thentheusual singlepolicyconcentrability withinitial distribution impliesassumption5to', 1);('rst note', 1);('initial implies', 1);('policy aoptimal policyby denition', 1);('max optimal policysecond show optimal policy ifs0for ss thens0', 1);('0buts0 withpositive probability exists trajectory', 1);('st 0implies', 1);('tsuch st0', 1);('thenwe', 1);('initial distribution generates ies0is sampledfrom andthus s00', 1);('wethushave', 1);('st010bythedenitionof t0', 1);('moreovertheremustexistsomeaasuchthat', 1);('ast010andpst01ast00sincewehaveobservedthetransitionfromst01tost0 denition policy st01a0becauseast010for thisa', 1);('st00by42 contradicts assumption', 1);('implies optimal policy', 1);('maxoptimal policy s0for anysnelements0', 1);('sa0impliesss0andas0 implies sa0sinceis apolicy', 1);('combining', 1);('thesethree pointswe obtainour', 1);('assumption5finally', 1);('note optimal policy', 1);('thespecic singlepolicy concentrability assumption', 1);('c henand', 1);('assumes optimal po licy', 1);('original problem isunique42', 1);('mainresultsproposition', 1);('letbe', 1);('ccmax0such', 1);('that1sacsaforanysasa2s1sfor anyss3 optimal policy scmaxsfor anyssproofthe rst part', 1);('part optimal policy denecmaxsssswe rst', 1);('nite aoptimal policy', 1);('haves0 ss0', 1);('forsnelements0 assumption', 1);('main theorem dene gapof optimal', 1);('qfunctionbelow', 1);('minimal di erence optimal', 1);('qvalue', 1);('optimal andthesecond optimal actions', 1);('states ssdenition5', 1);('gapfor', 1);('sasa dene gapqsavsqsa', 1);('wethendene', 1);('minimal gap asq minsaiqsawhere recall', 1);('inactivestateactionpairs givenindenition3note', 1);('qsa0', 1);('toq0 denition', 1);('empty problem', 1);('active state ie policy optimal policy hereafter focus onthenondegenerate case', 1);('q0this', 1);('gap notion', 1);('co ntext ine', 1);('rlhowever', 1);('contrast work denition need', 1);('themaximizer max aqsa isuniquefor', 1);('standard online', 1);('rlsetting simchowitz', 1);('lattimore', 1);('andszep esvri', 1);('papiniet', 1);('yang', 1);('ready present follo wing theoremtheorem3', 1);('assumptions', 1);('o1nsamplecomplexityundersomesinglepolicyconcentrability', 1);('assumption f return', 1);('initial distributionfor', 1);('onsummationtextawsaasthe proof theorem', 1);('primal gap analysis', 1);('ozdaglar', 1);('generalization behaviors instochastic minimax optimizationnote', 1);('value function', 1);('jis', 1);('wehavethefollowing', 1);('corollary thatconnectsbacktotheretur n withinitialdistribution 0corollary1', 1);('underassumptions345andsupposethat', 1);('0iscoveredby iemaxss0sscforsome', 1);('c0', 1);('notethat corollary', 1);('coverage 0by', 1);('recall s0is', 1);('ies0sss0this means data states ss0', 1);('s0from', 1);('additional assumptions thecorrelation', 1);('initial statesoutsides0andhenceitisreasonabletoonlyconsidertheinitialdistr ibution0thatis', 1);('thecommonlyassumedsinglepolicyconcentrabilityinz', 1);('al2022chen andjiang2022', 1);('assumptio', 1);('asstatedinliu', 1);('asavalid occupancy measure behavior policyof', 1);('cexists', 1);('c11compared chen jiang', 1);('argmax aqsa', 1);('unique foranys algorithm', 1);('note algorithmdoes', 1);('knowledge gap', 1);('q compared zhan', 1);('singlepolicy concentrability assumption th eoriginalproblem', 1);('oftheregularizedproblem togetherwithonlytherealizabil ityassumptiononthefunctionclasses', 1);('o12', 1);('gap dependence thatin', 1);('o16note zhanet', 1);('vanilla vers ion minimax formulation', 1);('analysis requiresallpolicyconcentrability assumption', 1);('assumption thatonlyrequirestocoversomesingleoptimalpolicy', 1);('sect', 1);('achievedo12 sample complexity result gapdependent es', 1);('anycompletenesstype assumption43', 1);('theprimalgaprecall', 1);('denitions anddin', 1);('fact setwehave wvuwvkw1anddwvudwvkdw1dthe', 1);('empirical primal gaps', 1);('primal gap letvwmax', 1);('vvwvandvdwmax vvdwv', 1);('theempirical', 1);('primal gap', 1);('wvdw vdwminwwvdwand', 1);('populationprimal gap', 1);('wvw vwminwwvw', 1);('notational simplicity weomit superscripts', 1);('wvhereafter22431 generalizationoftheprimalgapwe', 1);('generalization boundfor theprim', 1);('havewdw42bwradicalbiglogvw1nforanywwproofsee section', 1);('a1432 boundingthepopulation', 1);('primalgapsuppose wdis solution minimax optimization problem', 1);('dwd0 proposition', 1);('thenwithprobability', 1);('boundingtheerrorusingprimalgapnext', 1);('need relate primal gap accuracy polic ydin terms', 1);('jjdlemma9', 1);('havejjd2cmax12qwdproofsee section', 1);('a2combining lemma', 1);('concludingremarksinthispaperwerevisitedthelinearprogrammingframewor', 1);('kforoinerlwithgeneralfunction approximation', 1);('obtainprovablye cientalgorithmswithonlypartialdatacoverageandfuncti onclassrealizabilityassumptions', 1);('weproposedtwoo', 1);('inerlalgorithmswithfunctionapproximation di erent decision variables', 1);('sample complexitywith partial data coverage', 1);('certain compl etenesstype assumption ora', 1);('data coverage assumption', 1);('standard singlepolicy concentrability', 1);('proper constraints l', 1);('minimaxoptimization problems', 1);('mdps23our', 1);('avenues future research ine', 1);('example isit', 1);('optimal sample complexity st andard singlepolicy concentrability assumption realizability', 1);('framework thegapdependent', 1);('general function approximation thebehavior policy', 1);('tha n', 1);('direct behavior cloningwould', 1);('partial data coverage', 1);('hope ur results', 1);('thelp framework usedreferencesphilip', 1);('amortila nan jiang tengyang xie', 1);('variant th e', 1);('wangfosterkakadelower', 1);('setting arxiv preprint arxiv201101075 2020jinglin', 1);('chen nan jiang informationtheoretic', 1);('conside rations batch reinforcement learning', 1);('pages 10421051pmlr 2019jinglin', 1);('chen nan jiang', 1);('ine reinforcement learning value densityratio realizability thepower gaps arxiv preprintarxiv220313935 2022chingan', 1);('cheng tengyang xie nan jiang alekh agarwal adversarially', 1);('trainedactor critic ine reinforcement learning arxiv preprintarxiv220202446 2022daniela', 1);('pucci de farias benjamin van roy', 1);('linear prog', 1);('approach toapproximate', 1);('operations', 1);('j foster akshay krishnamurthy david simchilevi', 1);('yunzong xu', 1);('inereinforcement learning', 1);('fundamental barriers value func tion approximation arxivpreprint arxiv211110919 2021scottfujimoto', 1);('davidmegeranddoinaprecup', 1);('policydeepreinforcementlearningwithout exploration', 1);('machin', 1);('icml', 1);('minimaxvalueintervalforo', 1);('advances', 1);('jin zhuoran yang zhaoran wang', 1);('pessimism prova', 1);('ecient inerl', 1);('inarxiv', 1);('preprintarxiv201215085 2020sham', 1);('kakade john langford approximately', 1);('optimal appro ximate', 1);('pages267274 2002aviralkumar', 1);('aurick zhou georgetucker', 1);('conservative', 1);('qlearningfor oine reinforcement learning conference', 1);('neural information processing systems neurips', 1);('lattimore csaba szepesvri bandit algorithms cambridge', 1);('press2020jongminleewonseokjeonbyungjunleejoellepineauan', 1);('optidiceoine', 1);('policy optimization', 1);('stationary distribution corre ction estimation arxivpreprint arxiv210610783 2021sergey', 1);('levine chelsea finn trevor darrell pieter abb', 1);('endtoend', 1);('training ofdeep visuomotor policies journal', 1);('research 171133413732016sergeylevinepeterpastoralexkrizhevskyjulianibarz anddeirdrequillen', 1);('learninghandeye', 1);('coordination robotic', 1);('largescale datacollection', 1);('international journal', 1);('levine aviral kumar george tucker justin fu', 1);('tutorial', 1);('review perspectives', 1);('probl emsarxiv preprintarxiv200501643 2020gen', 1);('li laixishi yuxinchenyuejie chiandyuting wei set', 1);('thesample complexity', 1);('ine reinforcement learning arxiv preprint arxiv220405275 2022qiangliu', 1);('lihong li ziyang tang', 1);('zhou breaki', 1);('ng curse horizoninnitehorizon policy estimation arxiv preprintarxiv181012429 2018yaoliuadithswaminathanalekhagarwalandemmabrunski', 1);('provablygoodbatchopolicy', 1);('great exploration', 1);('maddern geo', 1);('pascoe chris linegar paul newman', 1);('kmthe oxford robotcar dataset', 1);('theinternational', 1);('research 3613152017volodymyr', 1);('mnihkoraykavukcuoglu davidsilver andreiar', 1);('joelvenessmarcgbellemare alex graves martin riedmiller andreas k fidje', 1);('georg ostrovskiet', 1);('humanlevel', 1);('reinforcement lear ningnature', 1);('munos csaba szepesvri finitetime', 1);('bounds tt', 1);('value iteration', 1);('injournal machine learning', 1);('research volume', 1);('nachum bo dai ilya kostrikov yinlam chow lihong li', 1);('dale schuurmansalgaedice policygradientfromarbitraryexperience', 1);('arxivpreprintarxiv191202074 2019asuman', 1);('eozdaglarsarath pattathil jiaweizhangandkai', 1);('whatisagoodmetric', 1);('advancesinneuralinformationprocessing systems', 1);('url', 1);('httpsopenreviewnetforumidwygixxzszx 25matteopapiniandreatirinzonialdopacchiano', 1);('marcello restelli alessandro lazaricandmatteo pirotta reinforcement', 1);('learning linear', 1);('mdps constantregret', 1);('andrepresentation selection', 1);('2021martin l', 1);('puterman markov', 1);('discrete', 1);('sto chastic', 1);('rashidinejad banghua zhu cong jiantao jiao stuart russell bridgingoine', 1);('reinforcement learning imitation learning tale f pessimism', 1);('advancesin neural information processing systems', 1);('rashidinejad hanlin zhu kunhe yang stuart russell jiantao jiao optimalconservativeo', 1);('inerlwithgeneralfunctionapproximationviaaugmentedla grangianarxiv preprint arxiv221100716 2022bruno', 1);('scherrer approximate', 1);('policy iteration schemes co mparison', 1);('internationalconference machine learning', 1);('sidford mengdi wang xian wu lin yang', 1);('ye n', 1);('earoptimal time andsample complexities', 1);('decision processes generative modelinadvances inneural', 1);('informationprocessing systems', 1);('pages51865196 2018david', 1);('silver aja huang chris j maddison arthur guez laur', 1);('sifre george vanden driessche julian schrittwieser ioannisantonoglou veda panneershelvam marclanctot', 1);('mastering', 1);('deep neural netw orks tree searchnature', 1);('simchowitz kevin g jamieson nonasymptotic', 1);('gapde pendent regret boundsfor tabular', 1);('mdps advances neural informationprocessing systems', 1);('swaminathan akshay krishnamurthy alekh agarwal', 1);('dudik john langford damienjoseandimedzitouni', 1);('policyevaluation forslaterecommendationadvances inneural', 1);('tang yihao feng lihong li dengyong zhou qiang liu doubly', 1);('robustbias reduction innite horizon policy estimation', 1);('representations', 1);('mujoco aphysic', 1);('ieeersj', 1);('intelligent robo ts systems pages50265033', 1);('ieee', 1);('tseng yi luo sunan cui jentzung chien randal', 1);('k ten haken issamelnaqa deepreinforcementlearningforautomatedradi', 1);('physics', 1);('uehara wen sun pessimistic', 1);('rl pac', 1);('bounds andposterior', 1);('partial coverage arxiv eprints pagesarxiv2107 202126masatoshiueharajiaweihuangandnanjiang', 1);('minimaxweig', 1);('policy evaluation', 1);('vinyals timo ewalds sergey bartunov petko georgie', 1);('alexander sasha vezhnevets michelle yeo alireza makhzani heinrich kttler j', 1);('agapiou julian schrittwieser', 1);('starcraft ii', 1);('new challenge reinforcem ent learning arxiv preprintarxiv170804782 2017ruosong', 1);('wang dean foster sham kakade', 1);('sta tistical limits ofoinerlwithlinearfunctionapproximation', 1);('internationalconferenceonlearningrepresentations', 1);('xie nan jiang batch', 1);('valuefunction approxima tion realizability', 1);('ininternationalconference', 1);('learning', 1);('xie chingan cheng nan jiang paul mineiro', 1);('agarwalbellmanconsistent', 1);('pessimism ine reinforcement learning arxiv preprintarxiv210606926 2021kunhe', 1);('yang lin yang simon', 1);('qlearning', 1);('logarith mic regret', 1);('international conference onarticialintelligenceandstatistic spages15761584', 1);('zanette exponential', 1);('bounds batch reinfor cement learning', 1);('batch rlcan', 1);('zhan baihe huang audrey huang nan jiang jason lee', 1);('ine reinforcement learning realizability singlepolicy c oncentrability arxiv preprintarxiv220204634', 1);('zhang zhuoran yang han liu tong zhang tamer', 1);('b aar', 1);('finitesampleanalysis', 1);('batch multiagent reinforcemen learning networkedagentsieeetransactions', 1);('automatic', 1);('appendixa1 proofofproposition3by', 1);('denition havewdwwdwminwwdwminwwwvextendsinglevextendsinglevextendsinglevextendsinglemaxvvwvmaxvvdwvvextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsinglevextendsingleminwwmaxvvdwvminwwmaxvvwvvextendsinglevextendsinglevextendsinglevextendsinglemaxvvvextendsinglevextendsinglevextendsinglevextendsinglewvdwvvextendsinglevextendsinglevextendsinglevextendsinglemaxwwmaxvvvextendsinglevextendsinglevextendsinglevextendsingledwvwvvextendsinglevextendsinglevextendsinglevextendsingle 43first', 1);('dings inequality wv havewvdwvuduwvkkdw1vd44now probability', 1);('vw', 1);('bw1', 1);('proofoflemma9we', 1);('aseries lemmas', 1);('lem', 1);('letdsawdsasa', 1);('havesummationdisplaysaidsawdq28proofwe havewdwdwwdvwvsummationdisplaysarsasawdsasummationdisplaysawdsasavssummationdisplaysspsasvs1v0summationdisplaysarsasawsasummationdisplaysawsasavssummationdisplaysspsasvs1v0summationdisplaysawdsasawsasavsrsasummationdisplayspsasvssummationdisplaysawdsasawsasavsqsaqsummationdisplaysaiwdsasa 46where rst inequality', 1);('due denitions andq', 1);('inequality uses fact thatwsasa sa', 1);('q thiscompletes', 1);('dene apolicy asfollows1 ss0', 1);('asuch ats andsa0 letsadsasummationtextasaidsafor anequalawith sasai letsadsa', 1);('anyotherawith sai weletsa0thenfor', 1);('sieassasummationtextasa2 snelements0', 1);('asuch sasai ieathat maximizesqsa welet as1 andset as0 anyother aanote optimal policy construction', 1);('thenext lemma shows aoptimal policylemma11 aoptimal policy', 1);('s0for anysnelements0proofby construction', 1);('ss0 sa0 ifas0', 1);('aoptimal policy', 1);('assum', 1);('rstassumption5impliesthatforany snelements0sincesa0forall aawehave as0for allaa denition max optimal policy states', 1);('max optimal policy becausethe max policycan', 1);('whenever as0we as0 andthus sa0', 1);('proof29finallyweprovelemma9usinglemmas1011proposition2 andtheperformancedierence lemma', 1);('kakade', 1);('andlangford 2002proof', 1);('performance di erence lemma', 1);('dtoobtainjjd11summationdisplaysssbardbldssbardbl1because', 1);('sa0for snelements0by', 1);('havejjd11summationdisplayss0sbardbldssbardbl1by theconstruction havejjd11summationdisplayss0sbardbldssbardbl1 47121summationdisplayss0ssummationtextadsasummationdisplayasaidsa 4821summationdisplayss0sssummationtextadsassummationdisplayasaidsa 4922cmax12summationdisplaysaidsa 5032cmax12qwd 51where', 1);('construction fromd', 1);('proposition', 1);