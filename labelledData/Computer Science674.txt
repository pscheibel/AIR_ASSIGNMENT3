('url', 34);('lemda', 25);('corr', 7);('consistency regularizer', 6);('l2', 6);('v ae', 5);('mlpv ae', 5);('airbnb', 5);('reviews', 5);('starter funding', 5);('proceedings', 5);('computational linguistics', 5);('cubuk', 4);('mixgen', 4);('augmentation network', 4);('kl', 4);('mixup', 4);('attentionv ae', 4);('international conference', 4);('hutter', 3);('data', 3);('zhang', 3);('encoder decoder', 3);('mlpv ae attentionv ae', 3);('specically', 3);('hateful memes', 3);('advances neural information processing systems', 3);('icml', 3);('learning architectures', 2);('accordingly', 2);('researchers', 2);('kim', 2);('erezr ua', 2);('li', 2);('chen', 2);('huang', 2);('sun', 2);('data augmentation', 2);('ho', 2);('yun', 2);('wei zou', 2);('entailment', 2);('fadaee', 2);('sennrich', 2);('wang yang', 2);('andreas', 2);('similarly', 2);('xie', 2);('trivialaugment', 2);('augmentation', 2);('stateoftheart input augmentation', 2);('tang', 2);('large number latent', 2);('different backbones', 2);('shi', 2);('wang', 2);('sch', 2);('baltru', 2);('goodfellow', 2);('suzuki', 2);('task network fusion', 2);('consistency', 2);('latent', 2);('small number', 2);('tanget', 2);('algorithm', 2);('task network', 2);('original data', 2);('modality ainput modality bmodality', 2);('lemdas', 2);('ae', 2);('cls', 2);('darker', 2);('figure', 2);('d1 d2', 2);('multimodal network', 2);('stateoftheart data augmentation', 2);('multimodalnet', 2);('token embeddings', 2);('mixupmanifoldmixup mixgen lemdahateful memes', 2);('proceedings ieeecvf', 2);('curran associates inc', 2);('short papers', 2);('neural information processing systems', 2);('ildoo kim vilt visionandlanguage', 2);('learning multimodal data augmentationinfeature spacezichang liu\x03rice universityzl71riceeduzhiqiang tangamazon web serviceszqtangamazoncomxingjian shiamazon web servicesxjshiamazoncomaston zhangamazon web servicesastonzamazoncommu liamazon web servicesmliamazoncomanshumali shrivastavarice universityanshumaliriceeduandrew gordon wilsonnew york', 1);('amazon web servicesandrewgwcimsnyueduabstractthe', 1);('multiple modalities text audio visualdata', 1);('intelligent systems', 1);('promising advances', 1);('neural networks harness multimodal data', 1);('enormous success data augmentation', 1);('image classication', 1);('overall semantic structure data example caption', 1);('good description image standardaugmentations', 1);('challengingto specify', 1);('reasonable transformations', 1);('particular modalityin paper introduce', 1);('lemda learning multimodal data augmentation', 1);('aneasytouse method', 1);('multimodal datain', 1);('space constraints identities modalities relationship modalities', 1);('improvethe performance multimodal', 1);('combinations modalities', 1);('achievestateoftheart results', 1);('wide range applications', 1);('image textand tabular data1', 1);('ntroductionimagine', 1);('sound subtitles ability', 1);('multiple data modalities visual stimuli language audio information sources', 1);('onemodality isolation signicant constraint', 1);('traditional machine learning approaches', 1);('substantial research efforts', 1);('recent years', 1);('multimodaldeep learning', 1);('different modalities', 1);('baltrusaitis', 1);('various perspectives suchas model architectures', 1);('nagrani', 1);('choi lee2019', 1);('training techniques', 1);('2019a theoretical analysis', 1);('data augmentation multimodal learning', 1);('enormous practical impact single modality', 1);('value data efciency regularization', 1);('performance computer vision', 1);('hutter2021 zhang', 1);('natural language processing', 1);('amazon web services1arxiv221214453v1', 1);('dec', 1);('2022autoaugmentcifar10original imagelabel', 1);('descriptiona entailment', 1);('plane tricks', 1);('plane airc', 1);('aware plane loopd', 1);('neutral', 1);('top row shows', 1);('training samples', 1);('snlive xie', 1);('2019a avisual entailment dataset text description', 1);('image top', 1);('task isto', 1);('relationship image text description', 1);('entailmentneutral contradiction', 1);('bottom row shows', 1);('augmentation methods pair text description', 1);('images weobserve', 1);('data example smoke loop', 1);('new image', 1);('description pilot', 1);('aware planeis loop data c', 1);('entailmentkarimi', 1);('augmentation methods', 1);('particular modality inisolation example object classication vision', 1);('certain transformations suchas translations rotations', 1);('class label', 1);('language certainsentence manipulations', 1);('synonym replacement', 1);('meaning unchangedthe', 1);('immediate way', 1);('data augmentation multimodal', 1);('unimodal augmentation strategies', 1);('corresponding modalityhowever approach problematic', 1);('modality isolation maylead disharmony others', 1);('consider figure', 1);('training examples fromsnlive', 1);('2019a visionlanguage benchmark dataset description', 1);('withthe image top', 1);('label refers relationship image descriptionthe bottom row', 1);('stateoftheart image augmentationmethods', 1);('autoaugmentcifar10 autoaugmentsvhn', 1);('fordata b c image', 1);('autoaugmentimagenet', 1);('insmoke color plane', 1);('data aand image', 1);('recent image augmentation method', 1);('transformation random magnitude loop', 1);('data c', 1);('mislabeling', 1);('neural networks', 1);('data leadingto', 1);('poor performance', 1);('pleiss', 1);('general approach multimodal data augmentationfirst multimodal', 1);('input diverse', 1);('obvious modalities vision language others suchas sensory data', 1);('numeric categorical', 1);('learning includesa diverse', 1);('different crossmodal relationships datasets redundant', 1);('modalities others', 1);('complementary modalities reasonableassumption', 1);('modalities isolationin work', 1);('lemda learning', 1);('ultimodal ata ugmentation general multimodal data augmentation method', 1);('augments latent representation', 1);('modalities design augmentation transformation', 1);('learnable module thatit adaptive', 1);('various multimodal tasks crossmodal relationships augmentation moduleis', 1);('multimodal networks', 1);('informative data adversarial training', 1);('semantic structure consistency regularization constraints2over modalities tasks', 1);('different multimodalarchitectures summarize contributions', 1);('novel approach multimodal data augmentationsection', 1);('multimodal networks section', 1);('train augmentation module', 1);('informative label preservingdata method', 1);('simple easytouse', 1);('rst augmentationmethod', 1);('joint text image tabular data', 1);('territory section', 1);('boosts accuracy multimodal', 1);('variety baselines', 1);('augmentation methods section', 1);('ablation study', 1);('design choices', 1);('lemdain', 1);('particular study architecture augmentation module', 1);('ackground related workmultimodal', 1);('network architectures', 1);('multimodal', 1);('deep learning architectures', 1);('early late fusion', 1);('information modality', 1);('fusion network', 1);('raw input', 1);('fusion architectures', 1);('interaction lowlevel', 1);('choice multimodal tasks', 1);('strong crossmodal correlations', 1);('barnum', 1);('gao', 1);('lowlevel correspondence image', 1);('different words caption', 1);('different objects image note thatfeaturespace augmentation procedures', 1);('intractable earlyfusion architectures', 1);('early fusion', 1);('long sequence', 1);('token embeddings hand', 1);('late fusion focus workinput modality', 1);('mahajan', 1);('designis straightforward', 1);('new modality multimodal task', 1);('late', 1);('networks backbones modality making', 1);('inboth', 1);('early late fusion variety methods fuse information', 1);('standard approachesinclude', 1);('feed modalities', 1);('crossattentionbetween modalities', 1);('concatenate representations modalities', 1);('predictions modality ensemble', 1);('designthe multimodal network', 1);('task objective', 1);('available thecomputation budget', 1);('tsai', 1);('mahajan roth', 1);('readingsdata augmentation single modality tasks', 1);('natural language tasks vision', 1);('pertask basis', 1);('label invariant eg translations rotations', 1);('croppingand color adjustments transformation', 1);('cifar10', 1);('semantic information', 1);('mnist', 1);('automatic augmentationsin vision', 1);('neural architecture search', 1);('ratner', 1);('adversarial training informative examplesfawzi', 1);('natural language processing variety', 1);('standard interventions replacement deletion', 1);('karimi', 1);('automatic approaches backtranslation', 1);('context augmentation', 1);('kobayashi', 1);('linear interpolation trainingdata', 1);('tabular data techniques vision3algorithm', 1);('lemda traininginput', 1);('fbefore', 1);('fafter augmentation', 1);('training', 1);('setx task loss function l', 1);('lconsist', 1);('dosample minibatch', 1);('xcomputez', 1);('f beforexgenerate', 1);('gzy', 1);('f afterzyg f aftergzupdate augmentation network', 1);('gby', 1);('stochastic gradient \x00rlyg rlconsist yygupdate task network', 1);('fby', 1);('stochastic gradient rly rlygend whilesuch mixup', 1);('adversarial training', 1);('tabular setting', 1);('promising results', 1);('kadra', 1);('space augmentation', 1);('input augmentation', 1);('obvious transformations', 1);('latent vectors', 1);('data inputs neural network featurespace augmentation researchers', 1);('interpolation extrapolation noise addition andgenerative models', 1);('verma', 1);('liu', 1);('kumar', 1);('2019multimodal data augmentation', 1);('multimodaldata augmentation', 1);('visiontext tasks visual question', 1);('generate semantic', 1);('similar data', 1);('backtranslation textand adversarial noise image', 1);('generates text', 1);('avariational autoencoder crossmodal retrieval', 1);('gur', 1);('similar data externalknowledge sources crossmodal retrieval tasks stateoftheart augmentation procedure forvisuallanguage representation learning generates', 1);('new imagetext pairs', 1);('texts method', 1);('mixgen hao', 1);('work multimodal data augmentation relies', 1);('modalityspecic transformations contrast', 1);('rst time', 1);('tabular image andlanguage modalities', 1);('imagetext specic problems', 1);('approach3 l', 1);('emda', 1);('earning multimodal data augmentationwe', 1);('simple automatic approach multimodal data augmentationlemda learns augmentation network', 1);('multimodal task networkfto generateinformative data preserves semantic structure', 1);('sections', 1);('describe welearn parameters augmentation task networks', 1);('summarize trainingalgorithm', 1);('lemda figure', 1);('intuition theconsistency loss', 1);('describe design augmentation network31', 1);('raining task networkthe', 1);('parts fusion layer', 1);('fx fafterfbeforexwherefbefore', 1);('denotes layers fusion', 1);('fafterdenotes', 1);('layers fusion', 1);('training sample x passxuntil fusion layer', 1);('modalityfzigni1fbeforexwherenis number modalities', 1);('taken', 1);('fzigni1as inputs augmentation networkggenerates', 1);('additional latent vectors', 1);('gfzigni1 bothfzigni1andgfzigni1are', 1);('fedthrough rest target network', 1);('fafteras', 1);('distinct training data task network trainedin', 1);('standard way', 1);('task loss function', 1);('data ndminex\x18xly', 1);('lygwhere', 1);('raining augmentation networkinspired', 1);('adversarial data augmentation optimize parameters augmentation networkto maximize task loss task networks representation', 1);('updated4ymodality encodermodality b encoderinput', 1);('encoderinput modality caugmentation model multimodality fusionaugmentationnetwork', 1);('fusionmodality aencodermodality bencodermodality cencoderymodality', 1);('encodermodality b encoderinput', 1);('encoderinput modality caugmentation model multimodality fusionyaugmentationnetwork', 1);('network fusionmodality aencoder modality bencoder modality cencoder figure', 1);('top', 1);('training process tasknetwork', 1);('representations modality ziare', 1);('augmentation networkwhich generates', 1);('new latent vector modality', 1);('original features', 1);('rest task network', 1);('bottom', 1);('training process augmentationnetwork augmentation network', 1);('maximize task loss', 1);('consistencyloss describe', 1);('standard choices fusion section', 1);('design augmentationnetwork section 33by', 1);('data time introduce consistency regularizer encourages asimilar output distribution', 1);('formally', 1);('nd maxex\x18xlyg min', 1);('ex\x18xlconsist', 1);('yygwherelconsist yygdenotes divergence metric logit outputs', 1);('original data yand', 1);('data ygsuch', 1);('kullbackleibler', 1);('classication problems', 1);('consistency term samples', 1);('threshold task network cant', 1);('acondent prediction', 1);('unlikely prediction', 1);('good reference ground truth labeldesign decisions simplicity generality approach', 1);('strong empiricalperformance section', 1);('appealing features design decisions', 1);('klbased', 1);('minimize thel2distance', 1);('vector proxy preservingthe label augmentation', 1);('ablations factors section', 1);('hedesign augmentation networkthe', 1);('various forms', 1);('multimodal learning tasks andthe fusion strategies experiments', 1);('variational autoencoder', 1);('v aes', 1);('effective augmentation purposes', 1);('architectural choicesmlpv', 1);('v ae mlps', 1);('selfattention feedforward networksfzigni1are', 1);('ntokens', 1);('loss terms', 1);('reconstruction loss', 1);('divergence regularizer', 1);('regularizer encoder distribution', 1);('step foraugmentation networks \x00rlyg rlconsist yyg rlvae wherelvaerefers', 1);('kldivergence', 1);('regularizer latent', 1);('distributionthe major', 1);('multimodal task networkarchitectures', 1);('fusion architectures primary focus paper zirefers tothe representation single modality backbone eg', 1);('bert', 1);('modelandnis number modalities number backbone models concatenate fzigni1as', 1);('vector input', 1);('fzigni1as sequence', 1);('ntokens attentionv ae attentionv ae', 1);('nis', 1);('late fusionarchitectures', 1);('performance comparison twoarchitectures section', 1);('fusion architectures zicould sequenceof', 1);('text sequence patch', 1);('concatenation', 1);('high dimension input', 1);('ntuition whyconsistency regularizer discourages mislabeled datad1d2figure', 1);('motivation', 1);('green lines arethe ground truth model decision boundaries', 1);('background corresponds', 1);('loss task networkwe', 1);('d1', 1);('point informative', 1);('label consistency losswill', 1);('d1 d2 d2', 1);('crossesthe models decision boundary', 1);('thoughboth points incur training lossin', 1);('intuition consistencyregularizer', 1);('simple illustrative binary classication', 1);('background corresponds highertask training loss', 1);('solid green line', 1);('actual decision boundary', 1);('green lineis models decision boundary', 1);('similar increase task loss', 1);('adversarial loss term', 1);('d2', 1);('crosses models decision boundary andthus', 1);('likely different class label otherhand', 1);('empiricallyin', 1);('consistency loss confersaccuracy improvements', 1);('regularizersimilar intuition', 1);('uses thelogits distribution teacher model exponential', 1);('average models weights asthe', 1);('soft target', 1);('stillrecognizable teacher', 1);('2019bwhich designs', 1);('training objective toencourage', 1);('similar logits', 1);('e xperimentswe', 1);('realworld multimodal datasets curate list publicdatasets', 1);('image text numerical categorical inputs', 1);('summary ofthe source statistic modality identity introduce baselines section', 1);('describeexperimental settings section', 1);('main evaluation result section', 1);('finallywe', 1);('consistency regularizer choices augmentation modelarchitecture section', 1);('aselinesto', 1);('generalpurpose multimodal augmentation methods', 1);('wecompare', 1);('stateoftheart data augmentation methods vision languageand visiontext tasks', 1);('lemdaaugments', 1);('stateoftheart multimodal augmentationmethods visiontext tasks', 1);('methods generalpurpose', 1);('datasets tabular inputsinput', 1);('thedata modality images', 1);('effective method image classication tasks text', 1);('eda wei zou', 1);('aeda karimi', 1);('transformation fromall transformations', 1);('eda aeda', 1);('images inthe training data image classication', 1);('images andnumerical', 1);('text categorical', 1);('pairof data construct', 1);('generate random number juniformlybetween', 1);('j use rst data', 1);('mixup manifold mixup verma', 1);('performs interpolation betweenhidden representations', 1);('manifoldmixup', 1);('lemdamixgen mixgen hao', 1);('visiontext tasks', 1);('new data', 1);('images text42', 1);('e xperiment setupwe', 1);('multimodalnet shi', 1);('2021a datasets', 1);('snlive multimodalnetpasses', 1);('input modality', 1);('separate backbones concatenates representationegthe', 1);('backbones passes fusion', 1);('mlp', 1);('fusion layer useconvnet image backbone', 1);('electra', 1);('text backboneto', 1);('early fusion architectures', 1);('albef li', 1);('snlive albef', 1);('performs crossattention image patchembeddings text', 1);('original congurations', 1);('batch sizedataset', 1);('train test metric image text tabularhateful memes', 1);('accuracy x xfood101', 1);('accuracy x xsnlive', 1);('accuracy x xpetnder', 1);('quadratic kappa x x xmelbourne airbnb', 1);('accuracy x xnews', 1);('accuracy x xwine reviews', 1);('accuracy x xkick starter funding', 1);('rocauc x', 1);('summary source statistic modality identity7multimodalnetworkinputaugmentation', 1);('04047news channel', 1);('increases accuracy', 1);('original architectures alsooutperforms baselinesdue limitations computation memory', 1);('batch size', 1);('default load the4m', 1);('checkpoints setting', 1);('crossattention layer', 1);('theaugmentation', 1);('network augments', 1);('image patch', 1);('token embeddingfor', 1);('condence threshold consistency regularizer', 1);('study thischoice section', 1);('mixupand manifold mixup', 1);('ainresultswe', 1);('summarize performance comparison', 1);('plugging lemda multimodalnetand albef', 1);('consistent accuracy improvements', 1);('increase accuracy', 1);('hateful memes petnder', 1);('table 2illustrates', 1);('modality inputaugmentation methods hurt accuracy example news channel accordance theintuition introductory example', 1);('hurt accuracy exampleon', 1);('wine reviews similarly', 1);('latent space', 1);('manifold mixup', 1);('accuracy acrossdatasets', 1);('melbourne airbnb wine reviews manifold mixup', 1);('results accuracy drops', 1);('onthe', 1);('original architectures', 1);('wide range baselines44', 1);('blation studywe', 1);('ablation studies support design choice', 1);('lemdadataset regularizer consistency l2 consistency l2hateful memes', 1);('04051news channel', 1);('regularizer choice', 1);('regularization', 1);('augmentation network generallylead', 1);('network regularizer', 1);('consistency regularizer helpspreserve semantic structure augmentations', 1);('improves performance', 1);('whilel2', 1);('regularization attempts', 1);('original proxyfor semantic similarity consistency regularization access softmax outputs targetand augmentation networks', 1);('direct information labels8dataset', 1);('augmentation mlpv ae attentionv aehateful memes', 1);('04031news channel', 1);('augmentation networks', 1);('signicant gains overno augmentation', 1);('late fusion setting inputof augmentation networks', 1);('latent representationsdataset', 1);('memes', 1);('03964news channel', 1);('consistency loss', 1);('lowcondence data', 1);('betterendtoend accuracyarchitecture', 1);('difference', 1);('augmentation architectures', 1);('architectures increase performanceover augmentation', 1);('passes concatenation', 1);('nlatent', 1);('vector fusion layerswherenis number modalities', 1);('meansthat input', 1);('albefsince', 1);('thousands tokenscondence', 1);('masking', 1);('effect condence', 1);('training data', 1);('calculate consistencyloss', 1);('accuracy performanceis', 1);('sensitive precise value', 1);('herelationship modalitieswe', 1);('categorize relationship', 1);('available modalities', 1);('pyjxwherey\x18yandyis', 1);('target domain', 1);('ngconsist', 1);('correlation pyjx pyjxn essentially', 1);('multiple modalities reasonssuch', 1);('food101', 1);('task topredict food text recipe photo foodcomplementary', 1);('pyjx pyjfx1x2x ng', 1);('category suggests information', 1);('prediction modality complementaryto', 1);('information loss', 1);('meaning text image', 1);('harmful contentthe design', 1);('assumption crossmodal relationship', 1);('weobserve', 1);('improves performance regardless relationship95 c', 1);('onclusionjointly', 1);('multiple different modalities', 1);('crucial quest', 1);('autonomousintelligent agents introduce rst method', 1);('learning data augmentationacross arbitrary modalities', 1);('promising results awide range experiments', 1);('signicant conceptual ndingsabout multimodal data augmentation general', 1);('modality performsmuch', 1);('joint augmentation', 1);('popular input augmentation singlemodality tasks', 1);('promising modalityagnostic settings', 1);('multimodal augmentation policy outperform', 1);('accuracy whenaugmentation transformations', 1);('obvious categorical dataour investigation', 1);('latefusion architectures', 1);('strong results overa', 1);('wide range settings', 1);('augmentation strategies earlyfusion architectures', 1);('early', 1);('intractable computational costs', 1);('experiment earlyfusion architecture shows', 1);('efcient augmentation networks', 1);('importantlatent vectors', 1);('promising direction', 1);('future workreferencesjacob', 1);('andreas goodenough', 1);('compositional data augmentation', 1);('annualmeeting', 1);('online july', 1);('doi 1018653v12020aclmain676', 1);('tadas baltru', 1);('chaitanya ahuja louisphilippe morency multimodal', 1);('machine learninga survey taxonomy', 1);('george barnum sabera talukder yisong yue', 1);('early fusion multimodalrepresentation learning', 1);('yenchun chen linjie li licheng yu ahmed el kholy faisal ahmed zhe gan yu cheng', 1);('liu uniter', 1);('universal imagetext representations', 1);('yenchun chen linjie li licheng yu ahmed el kholy faisal ahmed zhe gan yu chengand jingjing liu uniter universal', 1);('imagetext representation learning 2019b', 1);('junho choi jongseok lee embracenet', 1);('learning architecture multimodalclassication', 1);('information fusion', 1);('cubuk barret zoph dandelion mane vijay vasudevan quoc v', 1);('autoaugmentlearning', 1);('augmentation strategies data', 1);('conference oncomputer', 1);('vision pattern recognition', 1);('dogus cubuk barret zoph jon shlens quoc', 1);('randaugment practical', 1);('automateddata augmentation', 1);('search space', 1);('h larochelle ranzato r hadsell mfbalcan h lin', 1);('marzieh fadaee arianna bisazza christof monz data', 1);('augmentation lowresource neural machine translation', 1);('annual meeting', 1);('association forcomputational', 1);('linguistics', 1);('vancouver canada july2017', 1);('doi 1018653v1p172090', 1);('httpsaclanthologyorgp172090 10alhussein', 1);('fawzi horst samulowitz deepak turaga pascal frossard adaptive', 1);('data augmentation image classication', 1);('ieee', 1);('image processing icip', 1);('gao peng li zhikui chen jianing zhang survey deep learning multimodaldata fusion neural computation', 1);('issn', 1);('doi 101162neco a01273', 1);('ian j goodfellow jonathon shlens', 1);('szegedy explaining', 1);('abs14126572 2015shir', 1);('gur natalia neverova chris stauffer sernam lim douwe kiela austin reiter crossmodal', 1);('retrieval augmentation multimodal classication', 1);('xiaoshuai hao yi zhu srikar appalaraju aston zhang wanqian zhang bo li mu li mixgen', 1);('new multimodal data augmentation', 1);('daniel ho eric liang ion stoica p abbeel xi chen population', 1);('efcientlearning', 1);('augmentation policy schedules', 1);('huang chenzhuang', 1);('zihui xue xuanyao chen hang zhao longbo huang whatmakes', 1);('multimodal learning', 1);('arlind kadra marius lindauer frank hutter josif grabocka welltuned', 1);('simple nets excelon tabular datasets', 1);('beygelzimer dauphin p liang j wortman vaughan', 1);('akbar karimi leonardo rossi andrea prati aeda', 1);('data augmentation technique fortext classication', 1);('wonjae kim bokyung', 1);('convolution region supervision', 1);('kim bokyung', 1);('convolution region supervision 2021b', 1);('sosuke kobayashi contextual', 1);('augmentation words paradigmatic relations', 1);('north american chapter', 1);('associationfor computational linguistics', 1);('language technologies', 1);('orleans louisiana june', 1);('varun kumar hadrien glaude cyprien', 1);('lichy william campbell', 1);('featurespace data augmentation fewshot intent classication', 1);('urlhttparxivorgabs191004176 junnan li ramprasaath r selvaraju akhilesh deepak gotmare shaq r joty caiming xiongand steven', 1);('h hoi align', 1);('vision', 1);('language representation learning withmomentum distillation', 1);('junnan li dongxu li caiming xiong steven hoi blip bootstrapping', 1);('visionlanguage understanding generation', 1);('xiaofeng liu yang zou lingsheng kong zhihui diao junliang yan jun wang site li pingjia jane data', 1);('latent space interpolation image classication', 1);('in2018', 1);('pattern recognition icpr', 1);('mahajan stefan roth diverse', 1);('h larochelle ranzato r hadsell mf balcan h lin', 1);('shweta mahajan iryna gurevych stefan roth latent', 1);('ows manytomanycrossdomain mappings', 1);('samuel g', 1);('frank hutter trivialaugment tuningfree', 1);('arsha nagrani yang anurag arnab jansen cordelia schmid chen sun attentionbottlenecks', 1);('multimodal fusion', 1);('geoff pleiss tianyi zhang ethan elenberg kilian q weinberger identifying', 1);('valentin vielzeuf st', 1);('pateux moez baccouche fr', 1);('jurie mfas multimodal', 1);('fusion architecture search', 1);('alexander j ratner henry ehrenberg zeshan hussain jared dunnmon christopher r', 1);('learning', 1);('compose domainspecic transformations data augmentation', 1);('advances', 1);('sayna ebrahimi samarth sinha trevor darrell zeynep akata crosslinked', 1);('variational autoencoders', 1);('zeroshot learning', 1);('rico sennrich barry haddow alexandra birch improving', 1);('neural machine translation modelswith monolingual data', 1);('xingjian shi jonas mueller nick erickson mu li alex smola multimodal', 1);('tables text elds', 1);('automated machine learning automl', 1);('shi jonas mueller nick erickson mu li alexander j smola benchmarking', 1);('multimodal automl tabular data text elds', 1);('proceedings neural information processing systems', 1);('datasets benchmarks', 1);('sun congying xia wenpeng yin tingting liang philip yu lifang mixuptransformer dynamic', 1);('data augmentation nlp tasks 2020a', 1);('xinwei sun yilun xu peng cao yuqing kong lingjing hu shanghang zhang yizhou wangtcgm', 1);('informationtheoretic framework', 1);('multimodality learning', 1);('abs200706793 2020b', 1);('teppei suzuki teachaugment data', 1);('augmentation optimization', 1);('teacher knowledge 2022url httpsarxivorgabs220212513', 1);('ruixue tang chao', 1);('zhang qi wu xiaokang yang semantic', 1);('equivalent adversarialdata augmentation visual question', 1);('arxiv', 1);('abs200709592 2020azhiqiang', 1);('tang yunhe gao leonid karlinsky prasanna sattigeri rogerio feris dimitrismetaxas onlineaugment online', 1);('domain knowledge 2020b', 1);('urlhttpsarxivorgabs200709271 yaohung hubert tsai liangkang huang ruslan salakhutdinov learning', 1);('robust visualsemantic embeddings', 1);('httpsarxivorgabs170305908 12yaohung', 1);('hubert tsai paul pu liang amir zadeh louisphilippe morency ruslan salakhutdinov learning', 1);('multimodal representations', 1);('learningrepresentations', 1);('vikas verma alex lamb christopher beckham amir naja ioannis mitliagkas david lopezpaz yoshua bengio manifold', 1);('kamalika chaudhuri ruslan salakhutdinov', 1);('internationalconference machine learning', 1);('proceedings machine learning', 1);('research pp64386447', 1);('pmlr', 1);('jun', 1);('liwei wang yin li jing huang svetlana lazebnik learning', 1);('twobranch neural networks forimagetext', 1);('william yang wang diyi yang thats', 1);('lexical framesemantic', 1);('data augmentation approach', 1);('automatic categorization', 1);('petpeeve tweets', 1);('empirical methods naturallanguage processing', 1);('lisbon portugal september', 1);('doi 1018653v1d151306', 1);('zixu wang yishu miao lucia specia crossmodal', 1);('generative augmentation visual', 1);('jason wei kai zou eda easy', 1);('data augmentation techniques', 1);('performance textclassication tasks', 1);('ning xie farley lai derek doran asim kadav visual', 1);('entailment novel task', 1);('image understanding arxiv preprint arxiv190106706 2019aqizhe', 1);('xie zihang dai eduard hovy minhthang luong quoc v', 1);('unsupervised', 1);('data augmentation consistency training 2019b', 1);('sangdoo yun dongyoon han seong joon oh sanghyuk chun junsuk choe youngjoon yoocutmix regularization', 1);('strategy train', 1);('strong classiers', 1);('localizable features', 1);('computer vision iccv october', 1);('zhang moustapha cisse yann n dauphin david lopezpaz', 1);('empiricalrisk minimization arxiv preprint arxiv171009412 2017xinyu', 1);('zhang qiang wang jian zhang zhao zhong adversarial', 1);('autoaugment arxiv preprintarxiv191211188 201913a', 1);('ore details designa1 etailed architectures augmentation networkwe', 1);('architecture task networkthe latent dimension', 1);('divergence regularizer encoderdistribution', 1);('reconstruction loss input output', 1);('inmlpv ae', 1);('relu', 1);('activation function', 1);('dropout', 1);('mapthe decoder symmetric encoder', 1);('features', 1);('crossattentionwe use', 1);('main focus paper', 1);('learnable augmentation network multimodal learning generative models asdiffusion models', 1);('gans', 1);('valid architectures', 1);('main concern', 1);('lie efciencyand', 1);('future worka2', 1);('mplementation details training procedurein', 1);('practice iterative train task augmentation networks', 1);('batch trainingdata', 1);('fafterfor', 1);('easy implementation withpytorch', 1);('autograd', 1);('e xperiment detailsb1 dditional studies training costone', 1);('extra training cost', 1);('optimizes augmentation network', 1);('task network incur', 1);('extra training costs', 1);('training throughput', 1);('complete understanding method', 1);('wesummarize', 1);('training throughputitsecond', 1);('413news channel', 1);('table summarizes training throughput', 1);('experiments', 1);('v100 gpu', 1);('approach incur', 1);('trainingcosthowever efciency', 1);('straightforward direction', 1);('currently', 1);('parameters task network', 1);('future direction14b2', 1);('dditional studies hyper parametersthe', 1);('optimization augmentation network minmax game', 1);('hyperparametersto balance', 1);('\x00w1rlyg w2rlconsist yyg w3rlvaewherelvaerefers', 1);('divergence regularizer latent', 1);('main experiment use w1', 1);('01on datasets', 1);('melbourneairbnb snlive melbourne airbnb snlive', 1);('relative consistent', 1);('different combinations w1w2 andw3 summarizethe result', 1);('petnder', 1);('observe consistent improvements', 1);('original multimodalnetwork', 1);('various combinationsw1w2w3', 1);('accuracy00001', 1);('network', 1);('petnder specically', 1);('\x00w1rlyg w2rlconsist yyg w3rlvaec', 1);('otivational examples augmenting one modalitywe', 1);('additional set experiments', 1);('stateoftheart augmentation techniques', 1);('bothtext image', 1);('content hateful', 1);('complementary information run baseline augmentation', 1);('modality independentlyon', 1);('modalities observe consistent improvements', 1);('essentially', 1);('crossmodality relationships wont lead toeffective augmentationmultimodal', 1);('network method image text image text06939trivial augment', 1);