('lm', 31);('asr', 22);('cer', 14);('transformer lm', 11);('librispeech', 11);('lookup dictionary', 10);('transformer', 9);('n-gram', 9);('tail tokens', 9);('ieee', 8);('online', 8);('english', 7);('eq', 7);('dictionary size', 6);('search', 6);('t. n. sainath', 6);('icassp', 6);('speech', 5);('computational linguistics', 5);('e2e asr', 4);('training data', 4);('bert', 4);('wer', 4);('id', 4);('input', 4);('di', 4);('token', 4);('espnet', 4);('memory size', 4);('international conference', 4);('processing', 4);('c. peyser', 4);('lms', 3);('overall', 3);('perfor- mance', 3);('speech recognition', 3);('language', 3);('tail words', 3);('rare words', 3);('current context', 3);('ids', 3);('attention module', 3);('dictionary memory', 3);('figure', 3);('uis', 3);('dictionary update', 3);('context selection', 3);('attention', 3);('trans-', 3);('ser', 3);('pg-19', 3);('conformer', 3);('ig', 3);('wu', 3);('acoustics', 3);('improving', 3);('r. pang', 3);('s. kumar', 3);('language model', 2);('automatic speech recognition', 2);('long-tail tokens', 2);('systems [', 2);('long-tail problem', 2);('contextual information', 2);('transformer lms', 2);('cur- rent', 2);('character error rate', 2);('error rate', 2);('mandarin', 2);('candidate tokens', 2);('english asr', 2);('input tokens', 2);('bernoulli', 2);('update ratio', 2);('output representation', 2);('corresponding dictionary memory', 2);('ours', 2);('evaluation', 2);('ilme', 2);('10k hours', 2);('voice input domain', 2);('voice search domain', 2);('overall performance', 2);('chinese test', 2);('% +', 2);('information gain', 2);('inference speed', 2);('rtf', 2);('a. kannan', 2);('c.-c. chiu', 2);('w. r. huang', 2);('t. strohman', 2);('arxiv', 2);('interspeech', 2);('jul', 2);('feng', 2);('memory augmented lookup dictionary based language modeling for automatic speech recognition yukun feng1', 1);('ming tu2', 1);('rui xia2', 1);('chuanzeng huang2', 1);('yuxuan wang2', 1);('hopkins university1 speech', 1);('intelligence', 1);('sami', 1);('bytedance2', 1);('yfeng55 @ jhu.edu', 1);('wangyuxuan.11 g @ bytedance.com', 1);('abstract recent', 1);('long-tail prediction problems', 1);('new memory', 1);('architec- ture', 1);('lookup dictionary incorporates', 1);('rich contextual information', 1);('intensive experiments', 1);('word/character error rate', 1);('tail tokens error rate', 1);('effective- ness', 1);('index terms automatic', 1);('rare words recognition', 1);('long-tail recognition', 1);('introduction', 1);('end-to- end', 1);('e2e', 1);('zero times', 1);('big chal- lenges', 1);('] resort', 1);('large corpora', 1);('textual data', 1);('] variants', 1);('computational cost', 1);('extra loss terms', 1);('rare words [', 1);('rnn lm', 1);('frequency information', 1);('n-grams', 1);('bytedance', 1);('rnn lms', 1);('can- didate tokens', 1);('inspired', 1);('effective training', 1);('dictio- nary', 1);('multi-vector array', 1);('enable memoriza- tion', 1);('rich context information', 1);('dictionarys values', 1);('specif-', 1);('contextual memory', 1);('current tokens sub- sequent', 1);('subsequent token occurs', 1);('corresponding multi-vector value', 1);('transformer blocks', 1);('relevant vectors', 1);('corresponding multi-vector memory', 1);('mandarin asr', 1);('notably', 1);('method show', 1);('% rela- tive', 1);('2-gram tail tokens', 1);('predic- tion', 1);('intensive analysis', 1);('different aspects', 1);('multi-vector memory', 1);('context information', 1);('to- ken frequency', 1);('inference efciency', 1);('proposed approach', 1);('subsections.arxiv:2301.00066v1 [ cs.cl ]', 1);('dec', 1);('tm tm tmtmc0c1 c2 e1e2 w0w1w2attention', 1);('di dn', 1);('w0', 1);('w1', 1);('] mod', 1);('= ioutput m', 1);('dictionaryselection updateufig', 1);('overview', 1);('wkrepresents', 1);('ekis', 1);('tm', 1);('auto-regressive manner', 1);('ckis', 1);('dictionary', 1);('indexing', 1);('ddd2ru\x02m\x02demb', 1);('extra hyper-parameter', 1);('mto', 1);('key-value pair', 1);('input sequence', 1);('corresponding dictionary index iis', 1);('modular hash', 1);('vocabulary id', 1);('multiple vectors', 1);('vector counterpart', 1);('equation', 1);('dictio- nary indexiis', 1);('kx n=k\x00n+1id', 1);('modulo operation', 1);('information redundancy', 1);('memory capacity', 1);('col- lision', 1);('nandmcan', 1);('results part', 1);('dithrough equation', 1);('memory vector dm iis', 1);('current tokens', 1);('token ek+1', 1);('fdm i=', 1);('dm i\x03 +ek+1\x03', 1);('dm i ifxk+1=', 1);('in- formation', 1);('experi- ments', 1);('xk+1\x18bern', 1);('di.pk+1', 1);('thek+ 1thtoken', 1);('pk+1=1', 1);('count', 1);('low frequency tokens', 1);('con- tribute', 1);('corresponding memory', 1);('high fre- quency tokens', 1);('training text', 1);('corresponding text tokenizer', 1);('input query', 1);('key- value', 1);('k-v', 1);('qkt', 1);('dictionary memory stores', 1);('select useful information', 1);('new output representation fckis', 1);('token distribution.model', 1);('input search overall tail-1 tail-2 overall tail-1 tail-2 cer=ser cer cer cer=ser cer cer conformer', 1);('] 5.42=40.37', 1);('] 5.35=40.19', 1);('+8.3 % +14.9 % +13.2 % +8.6 % +11.0 % +12.0 % +lml 4.83=37.29', 1);('+ours l 4.73=36.90', 1);('+2.1 % +3.7 % +1.3 % +5.4 % +6.3 % +7.0 %', 1);('voice input', 1);('voice search domain test', 1);('lrefers', 1);('training', 1);('inference', 1);('context selection operation', 1);('update information', 1);('current input sentence', 1);('current context selection', 1);('stabilize training', 1);('dictionary up- date', 1);('training steps', 1);('good distribution', 1);('information leakage', 1);('auto- regressive prediction', 1);('shallow fusion', 1);('weight \x15sf', 1);('internal language model estimation', 1);('domain mismatch be- tween textual distribution', 1);('n-best', 1);('beam search', 1);('experiment', 1);('datasets', 1);('] dataset', 1);('hours data', 1);('11gb in-domain text corpus', 1);('project gutenberg', 1);('sentence length', 1);('sentence-level corpus', 1);('unigram tokenizer [', 1);('vo- cabulary size', 1);('internal chinese video datasets', 1);('audio dataset', 1);('different domains', 1);('60gb text corpus', 1);('2gb corpus', 1);('pro- cess', 1);('chinese text', 1);('character level', 1);('vocabulary size', 1);('chinese characters', 1);('subword tokens', 1);('above men-', 1);('tail', 1);('frequency ratio', 1);('tail-1', 1);('tail-2', 1);('teset ses', 1);('1-gram word-level tail tokens', 1);('experimental', 1);('las', 1);('] ar- chitecture', 1);('] encoder', 1);('chinese dataset', 1);('sentence-level language', 1);('dropout rate', 1);('effective token number', 1);('adam', 1);('weight decay', 1);('10k warmup steps', 1);('look-up dic- tionary', 1);('mis', 1);('chinese datasets', 1);('large conguration respectively1', 1);('look-up dictio- nary', 1);('searchgrespectively', 1);('beam size', 1);('sentence error rate', 1);('token error rate', 1);('single-vector memory', 1);('method shows signicant improvement', 1);('baseline methods', 1);('clean', 1);('overall tail-1 overall tail-1 conformer', 1);('fig', 1);('different dictionary size', 1);('2gram tail tokens', 1);('in- crease', 1);('performance gain', 1);('outper- forms', 1);('shows consistent improvement', 1);('tail word error rate', 1);('analysis', 1);('different hyper-parameters', 1);('nin n-gram', 1);('memory up- date ratio', 1);('entry m', 1);('y axis', 1);('collision elevates', 1);('uandn', 1);('nmeans', 1);('4-gram performs', 1);('gram case', 1);('extra space', 1);('large dictionary size', 1);('10k dictionary size', 1);('different memory update settings', 1);('xk+1in eq', 1);('up- date', 1);('pk+1for', 1);('different tokens', 1);('large update ratio tends', 1);('memory update strategy', 1);('large memory size', 1);('mwould', 1);('se- lection', 1);('attention entropy', 1);('overall tail-1 tail-2', 1);('% freq', 1);('different memory update options', 1);('memory size0.00.20.40.60.81.0information gain', 1);('gradients8.258.308.358.408.45 cer ig gradients cer fig', 1);('overall cer', 1);('gradients', 1);('memory size m maps', 1);('token fck [', 1);('m.', 1);('gradient attribution', 1);('test [', 1);('ad- dress', 1);('dictionary memorys contribution', 1);('model variables', 1);('output prediction', 1);('model prediction', 1);('small relative gain', 1);('high computational cost', 1);('memory aug-', 1);('model size', 1);('additional computation', 1);('lookup dictio- nary', 1);('time cost', 1);('constant time cost', 1);('real', 1);('factor', 1);('nvidia a100 gpu', 1);('beam size batch size equals', 1);('such additional opera- tions', 1);('model size increases', 1);('conclusions', 1);('long tail tokens', 1);('tail words er- ror rate', 1);('different hyper-parameter settings', 1);('domain mismatch condition', 1);('general language', 1);('references', 1);('a. graves', 1);('sequence', 1);('recurrent neural net-', 1);('arxiv preprint arxiv:1211.3711', 1);('w. chan', 1);('n. jaitly', 1);('q. v', 1);('o. vinyals', 1);('listen', 1);('arxiv preprint arxiv:1508.01211', 1);('s. toshniwal', 1);('k. livescu', 1);('language model integration', 1);('encoder-decoder speech recognition', 1);('language technology workshop', 1);('slt', 1);('p. nguyen', 1);('z. chen', 1);('r. prabhavalkar', 1);('external language model', 1);('sequence-to-sequence model', 1);('sig-', 1);('g. pundak', 1);('proper noun recognition', 1);('end-to-end asr', 1);('mwer loss criterion', 1);('ieee interna-', 1);('tional conference', 1);('s. mavandadi', 1);('j. apfel', 1);('tail performance', 1);('delibera- tion e2e asr model', 1);('large text corpus', 1);('arxiv preprint arxiv:2008.10491', 1);('g. i. winata', 1);('g. wang', 1);('c. xiong', 1);('s. hoi', 1);('adapt-and-', 1);('overcoming', 1);('multilingual speech recognition', 1);('id=34kaz9hbjco [', 1);('k. deng', 1);('g. cheng', 1);('r. yang', 1);('yan', 1);('alleviating', 1);('asr long-', 1);('ieee/acm transactions', 1);('audio', 1);('language processing', 1);('sentence-select', 1);('large-scale', 1);('language model data selection', 1);('rare-word speech recognition', 1);('d. rybach', 1);('lookup-table recurrent language models', 1);('long tail speech recognition', 1);('c.-h. h. yang', 1);('l. liu', 1);('a. gandhe', 1);('gu', 1);('a. raju', 1);('d. fil-', 1);('i. bulyko', 1);('multi-task', 1);('ieee automatic speech recognition', 1);('understanding', 1);('asru', 1);('j. devlin', 1);('m.-w. chang', 1);('k. lee', 1);('k. toutanova', 1);('pre-training', 1);('deep bidirectional transformers', 1);('language understanding', 1);('proceedings', 1);('american chapter', 1);('language technologies', 1);('short papers', 1);('minneapolis', 1);('minnesota', 1);('jun', 1);('//aclanthology.org/n19-1423 [', 1);('k. irie', 1);('a. zeyer', 1);('r. schl', 1);('h. ney', 1);('deep transformers', 1);('q. wu', 1);('c. xing', 1);('li', 1);('g. ke', 1);('d.', 1);('t.- y', 1);('liu', 1);('language pre- training', 1);('iclr', 1);('id=lu5rs wcwen [', 1);('z. meng', 1);('n. kanda', 1);('gaur', 1);('s. parthasarathy', 1);('e. sun', 1);('l. lu', 1);('x. chen', 1);('j. li', 1);('gong', 1);('internal', 1);('language model training', 1);('domain-adaptive end-to-end speech recognition', 1);('acous-', 1);('panayotov', 1);('g. chen', 1);('d. povey', 1);('s. khudanpur', 1);('lib-', 1);('asr corpus', 1);('public domain audio books', 1);('j. w. rae', 1);('a. potapenko', 1);('s. m. jayakumar', 1);('c. hillier', 1);('t. p. lillicrap', 1);('compressive', 1);('long- range sequence', 1);('arxiv preprint', 1);('//arxiv.org/abs/1911.05507 [', 1);('t. kudo', 1);('subword', 1);('neural net- work translation models', 1);('multiple subword candidates', 1);('annual meeting', 1);('as-', 1);('papers', 1);('melbourne', 1);('australia', 1);('computa-', 1);('linguistics', 1);('//aclanthology.org/p18-1007 [', 1);('s. watanabe', 1);('t. hori', 1);('s. karita', 1);('t. hayashi', 1);('j. nishitoba', 1);('unno', 1);('n. enrique yalta soplin', 1);('j. heymann', 1);('m. wiesner', 1);('n. chen', 1);('a. renduchintala', 1);('t. ochiai', 1);('end-to-', 1);('speech processing toolkit', 1);('proc', 1);('a. gulati', 1);('j. qin', 1);('n. parmar', 1);('zhang', 1);('j. yu', 1);('w. han', 1);('s. wang', 1);('z. zhang', 1);('convolution-augmented', 1);('f. li', 1);('b. zheng', 1);('p. koehn', 1);('learn', 1);('recurrent memory', 1);('document-level machine translation', 1);('findings', 1);('naacl', 1);('seattle', 1);('//aclanthology.org/2022.ndings-naacl.105 [', 1);('m. ancona', 1);('e. ceolini', 1);('c. oztireli', 1);('m. gross', 1);('towards', 1);('attribution methods', 1);('deep neural networks', 1);('learning representations', 1);('id=sy21r9jaw [', 1);('g. qin', 1);('van durme', 1);('nlp task effectiveness', 1);('long-range transformers', 1);