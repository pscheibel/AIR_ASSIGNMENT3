('pcd', 101);('ieee', 21);('offset-attention', 19);('gpd', 18);('point cloud', 16);('completion network', 15);('international conference', 14);('computer vision', 11);('robotics', 11);('proceedings', 10);('pointr', 8);('furthermore', 7);('transformer', 7);('pcds', 6);('robotic arm', 6);('ycb', 6);('pcn', 6);('foldingnet', 6);('automation', 6);('icra', 6);('kinova', 5);('fi', 5);('pattern recognition', 5);('point clouds', 5);('fig', 4);('grasp pose detection', 4);('moveit', 4);('state-of-the-art methods', 4);('complete shape', 4);('shape completion', 4);('cnn', 4);('lr', 4);('gt', 4);('pgt', 4);('fc', 4);('success rate', 3);('3d shape completion', 3);('italy', 3);('network [', 3);('dataset [', 3);('reconstruction error', 3);('ii', 3);('grnet', 3);('point cloud completion', 3);('grasp candidate', 3);('point cloud completion network', 3);('fps', 3);('fe', 3);('depth camera', 3);('gk', 3);('iii-a', 3);('gt pcd', 3);('self-attention', 3);('encoder-decoder layer', 3);('fclayer', 3);('ps', 3);('springer', 3);('deep', 3);('z. liu', 3);('ieee/cvf', 3);('cloud data', 2);('experiments', 2);('completion tasks', 2);('real-world scenarios', 2);('systems', 2);('email', 2);('genoa', 2);('grasp pose', 2);('voxel grid', 2);('differently', 2);('layer [', 2);('grasp poses', 2);('figure', 2);('background information', 2);('pointnet++', 2);('clouds', 2);('trans-', 2);('completion performance', 2);('partial version', 2);('design choices', 2);('3d data', 2);('deep neural networks', 2);('grasp success rate', 2);('atlasnet', 2);('partial point cloud', 2);('vision', 2);('robotic grasping', 2);('rgb', 2);('rgb-d', 2);('knn', 2);('dgcnn', 2);('crto', 2);('feto', 2);('iii', 2);('robotiq', 2);('depth image', 2);('pm', 2);('cs', 2);('classication score', 2);('completion task', 2);('iv-a', 2);('ground-truth point cloud', 2);('cr', 2);('encoder network', 2);('initial pose', 2);('ad', 2);('chamfer-distance', 2);('msn', 2);('loss [', 2);('rois', 2);('real-world experiments', 2);('grasp proposal', 2);('iv', 2);('offset- attention', 2);('evaluation', 2);('fair comparison', 2);('baseline model', 2);('grasp', 2);('r. platt', 2);('robotic', 2);('ieee/rsj', 2);('intelligent robots', 2);('iros', 2);('s.-m. hu', 2);('dense point cloud completion', 2);('c. r. qi', 2);('h. su', 2);('l. j. guibas', 2);('international journal', 2);('eurographics', 2);('efcient', 2);('t. groueix', 2);('m. fisher', 2);('m. aubry', 2);('papier-m ache approach', 2);('learning 3d surface generation', 2);('x. yu', 2);('rao', 2);('j. lu', 2);('j. zhou', 2);('learning', 2);('a. mousavian', 2);('d. fox', 2);('wang', 2);('shape-completion', 1);('robotic grasp seyed s. mohammadi2', 1);('f. duarte1dimitris dimou1yiming wang3', 1);('taiana3pietro morerio3 atabak dehban1plinio moreno1alexandre bernardino1alessio del bue3jose santos-victor1 abstract real-world', 1);('complete 3d point', 1);('sparse viewpoints', 1);('inaccurate grasp poses', 1);('reliable grasp poses', 1);('transformer-based', 1);('encoder- decoder network', 1);('object pose', 1);('points permutation', 1);('wide range', 1);('3dsgrasp outperforms', 1);('state-of-the- art method', 1);('introduction robotic', 1);('essential role', 1);('real-world applications', 1);('collaborative robotics', 1);('seminal work', 1);('] uses 3d point', 1);('generate grasp poses', 1);('available 3d object structure', 1);('real practical scenarios', 1);('incomplete geometric information', 1);('drastic reduction', 1);('researchers', 1);('complete 3d object scans [', 1);('feasible camera path', 1);('additional sensors', 1);('interest [', 1);('careful calibration', 1);('paper aims', 1);('geometrical structure', 1);('ambiguous *', 1);('unions horizon', 1);('innovation programme', 1);('grant agreement', 1);('fct', 1);('isr/larsys', 1);('laboratory uid/eea/50009/2020', 1);('la/p/0083/2020 n. f. duarte', 1);('fct-ist', 1);('fellowship grant', 1);('pd/bd/135116/2017', 1);('roboticslisboa', 1);('instituto', 1);('universidade', 1);('lisboa', 1);('portu-', 1);('jasvg @ isr.tecnico.ulisboa.pt 2department', 1);('electrical', 1);('electronic', 1);('telecommunications engineering', 1);('analysis', 1);('pa vis', 1);('istituto italiano', 1);('tecnologia', 1);('iit', 1);('alessio.delbue g @ iit.it 4deep', 1);('visual learning', 1);('dvl', 1);('fondazione bruno kessler', 1);('trento', 1);('overall', 1);('3d robotic', 1);('depth sensor', 1);('feasible trajectory', 1);('encouraging results', 1);('different classes', 1);('initial', 1);('shape completion solutions [', 1);('3d point cloud', 1);('additional data', 1);('increases processing time', 1);('memory requirements', 1);('efcient networks [', 1);('point-', 1);('net [', 1);('] architecture', 1);('noise-free datasets', 1);('new model', 1);('3d point completion', 1);('realistic scenario', 1);('arbitrary object classes', 1);('method adopts', 1);('depth camera frame', 1);('additional information', 1);('real-world scene reference', 1);('partial input', 1);('top ofarxiv:2301.00866v1 [ cs.ro ]', 1);('jan', 1);('arm trajectory', 1);('completion method', 1);('completion benchmark dataset [', 1);('state- of-the-art methods', 1);('real scenario', 1);('accurate completions', 1);('successful grasp poses', 1);('promising grasp hypothesis', 1);('overall success rate score', 1);('main contributions', 1);('novel partial', 1);('ki-', 1);('nova arm', 1);('signicant improvement', 1);('present extensive ablation studies', 1);('related work', 1);('shape comple- tion', 1);('object shape completion', 1);('additional grasp poses', 1);('selection range', 1);('incomplete partial 3d data', 1);('3d shape completion methods', 1);('data-driven approaches [', 1);('geometry-based', 1);('methods [', 1);('shape priors', 1);('ge- ometric primitives', 1);('structural repetition [', 1);('ac- curate reconstructions', 1);('large-scale datasets', 1);('real-world 3d data', 1);('data-driven', 1);('shape completion priors', 1);('global point cloud level [', 1);('irregular 3d data', 1);('raw point cloud', 1);('regular data representation', 1);('cnns', 1);('pure 3d shape completion task [', 1);('grasp estimation [', 1);('memory usage', 1);('computational time', 1);('such methods', 1);('large [', 1);('shape comple- tion tasks', 1);('encoder-decoder architecture.the encoder', 1);('pointnet-based', 1);('backbone network', 1);('global features', 1);('coarse point cloud', 1);('mlp', 1);('following pcn', 1);('pure 3d shape completion tasks', 1);('others [', 1);('processing 3d', 1);('completion system', 1);('architecture [', 1);('signi- cant improvement', 1);('object completion', 1);('con- sists', 1);('encoder-decoder architecture', 1);('multi-head self-attention', 1);('reconstruction result', 1);('] network', 1);('3d grids', 1);('6d pose estimation module', 1);('additionally', 1);('reconstruction results', 1);('promising grasp poses', 1);('optimal pose', 1);('robots end-effector', 1);('successful grasp', 1);('contact points', 1);('large reality gap [', 1);('data-driven approaches aim', 1);('perceptual input', 1);('images [', 1);('grasp success', 1);('recent', 1);('data-driven approaches', 1);('data samples', 1);('domain randomization [', 1);('current', 1);('map 6dof pose candi- dates', 1);('clouds [', 1);('perceptual point', 1);('grasp pose score computation', 1);('renement pose procedure', 1);('amongst', 1);('computational efciency', 1);('score computation [', 1);('main steps', 1);('binary classication', 1);('iii-c.fig', 1);('architecture', 1);('center point', 1);('crof', 1);('local region', 1);('crand', 1);('positional embedding pe', 1);('peand', 1);('pcd pmand', 1);('generate high resolution', 1);('pcd pc', 1);('approach', 1);('realsense', 1);('oto', 1);('camera parameters', 1);('visible part', 1);('i.e partial 3d scan', 1);('partial 3d scan', 1);('background infor- mation', 1);('colourless partial', 1);('rst segment', 1);('pcd pp', 1);('pp=\x08 ppijppi2r3', 1);('n n=2048', 1);('segmentation network', 1);('pp', 1);('pcd pm', 1);('pmijpmi2r3', 1);('m=6144', 1);('real scene', 1);('gkon', 1);('grasp posesfgkg', 1);('gk=fgk', 1);('gk vgv=5with', 1);('corresponding classication scores', 1);('lastly', 1);('gkbcsthat', 1);('real robot', 1);('alignment problem', 1);('iii-b', 1);('loss functions', 1);('iii-c', 1);('grasp pose generation', 1);('evaluation network.a', 1);('data', 1);('primary stage', 1);('deep models', 1);('learning process [', 1);('completion approaches', 1);('data normalisation', 1);('cad', 1);('model [', 1);('completion protocols', 1);('partial shape', 1);('shape centroid', 1);('otherwise', 1);('ablation studies', 1);('effective technique', 1);('informa- tion', 1);('rst calculate', 1);('translational offset vector ftp2r3g', 1);('tp=1 nn', 1);('ppc= pp\x00tp', 1);('scale fsp2rgas', 1);('sp=max', 1);('wherek\x01k 2is norm-2', 1);('nal normalise', 1);('pcdfppngwill', 1);('ppn=ppc=sp', 1);('tpandspare', 1);('normalisation parameters', 1);('misalignment phenomenon', 1);('tp', 1);('sp', 1);('pponpgtsuch', 1);('pgtc=pgt\x00tp', 1);('real-world scenario', 1);('ground-truth pcd', 1);('section illustrates', 1);('completion network predicts', 1);('encoder-decoder block', 1);('intrinsic invariance', 1);('rigid trans- formation', 1);('skip-connections', 1);('gener- alisation', 1);('main blocks', 1);('e.g.like words', 1);('point sequence order', 1);('pcd ppinto', 1);('regions lr', 1);('lr=flr1', 1);('lr2', 1);('lrrgr=128by', 1);('farthestpointsampling', 1);('crijcri2r3', 1);('b=128', 1);('pcd-backbone', 1);('fe=ffe1', 1);('fe2', 1);('febgb=128', 1);('pe', 1);('pewith', 1);('fi=ffi1', 1);('fi2', 1);('fijgj=128of', 1);('offset-attention transformer', 1);('multi- head', 1);('usual self-attention layer', 1);('point cloud segmentation', 1);('clas- sication', 1);('relative pose', 1);('end- effector', 1);('real-world point cloud completion task', 1);('different positions', 1);('rigid transformations', 1);('robust object completion', 1);('sa', 1);('sa=fsa1', 1);('sa2', 1);('sajgby', 1);('fij\x00saj', 1);('ae=e', 1);('eis', 1);('ae=fae1', 1);('ae2', 1);('aewgw=1024is', 1);('layer measure', 1);('attention', 1);('encoder layer rst updates', 1);('max\x00 pooling', 1);('mp', 1);('global complete shape information', 1);('pcd ps', 1);('ps=\x08 psijpsi2r3', 1);('s=192', 1);('psis', 1);('psby', 1);('ae', 1);('qlayer', 1);('s\x023', 1);('decoder layer', 1);('dshares', 1);('exact architecture', 1);('cross-attention mechanisms [', 1);('for- mulate', 1);('decoder architecture', 1);('ad=d', 1);('q=fq1', 1);('q2', 1);('qxgx=192is', 1);('ad=', 1);('ad2', 1);('adygy=512are', 1);('feature vector', 1);('cloud generation', 1);('main objective', 1);('unseen part', 1);('max-', 1);('sparse point cloud', 1);('psreconstructed', 1);('fn', 1);('high resolution', 1);('fold', 1);('point cloud generation process', 1);('symbol +', 1);('pmis', 1);('pmwill', 1);('partial input point cloud', 1);('ppto', 1);('complete point cloud', 1);('pcwhere pc=\x08 pci2r3', 1);('z z=8192', 1);('encoder layer', 1);('element-wise summation', 1);('corresponding decoder layer', 1);('skip- connections', 1);('design choice', 1);('network', 1);('training', 1);('table', 1);('comparison of l2cdloss in different point cloud completion models on ycb dataset', 1);('we report the result of', 1);('seen categories and', 1);('unseen categories', 1);('method avg drill', 1);('mini soccer', 1);('tomato soup cleanser comet bleach', 1);('sugar mustard lemon morton', 1);('pringles', 1);('sponge', 1);('block cracker', 1);('banana stack blocks topnet', 1);('table ii ablation study on the network designs', 1);('model skip-connection offset-attention l2cd', 1);('d x x', 1);('table iii ablation study on the normalisation technique effect in l2cd loss method baseline', 1);('ours', 1);('l=lcd', 1);('pc', 1);('pcis', 1);('psandpc', 1);('c. grasp', 1);('pose generation', 1);('6dof grasp pose candidate', 1);('samples points', 1);('region', 1);('interest', 1);('roi', 1);('object detection algorithm', 1);('applications constraints', 1);('local search heuristic', 1);('suitable orientations', 1);('gkcorresponds', 1);('multiple view representation', 1);('orthogonal axes', 1);('soft-max', 1);('grasp candidate corresponds', 1);('goal pose', 1);('free trajectory', 1);('target pose', 1);('qualitative', 1);('real sensor', 1);('candidate grasp pose', 1);('extensive ablation studies', 1);('completion network architecture', 1);('real robotic experiments', 1);('iv-b', 1);('dataset', 1);('popular choice', 1);('training views', 1);('holdout view', 1);('holdout views', 1);('holdout models', 1);('holdout', 1);('holdout model', 1);('iv real robot experiment result', 1);('method avg pringles drill', 1);('mustard mug cleanser clamps', 1);('drill jell-o', 1);('baseball pitcher', 1);('% train/test', 1);('comparison', 1);('l2chamfer-distance', 1);('ground truth', 1);('completion networks', 1);('open- source code', 1);('reconstruction loss', 1);('competi- tors', 1);('state-of-the-art method', 1);('ablation', 1);('extensive experiments', 1);('network design choices', 1);('alignment processing technique', 1);('completion accuracy', 1);('variant models', 1);('ais', 1);('badds skip-connection', 1);('creplaces self-attention', 1);('model c', 1);('dwhen', 1);('skip- connection', 1);('does', 1);('baseline', 1);('different parameters', 1);('low- est reconstruction error', 1);('processing techniques', 1);('alarge reduction', 1);('kinova gen3', 1);('2f-85 gripper', 1);('intel realsense d430', 1);('segmentation network [', 1);('comple- tion network', 1);('] network generates', 1);('ranks grasp candidates', 1);('nal grasp', 1);('feasible solution', 1);('motion planner', 1);('different poses w.r.t', 1);('3dsgrasp con-', 1);('drill box dimensions', 1);('low success rate', 1);('hard case', 1);('maximum aperture', 1);('lid reduces', 1);('available grasp poses', 1);('3dsgrasp doubles', 1);('successful grasps', 1);('v. conclusions', 1);('new system', 1);('robotic grasp success rate', 1);('real-world experiment', 1);('central core', 1);('completion head', 1);('3d objects', 1);('new way', 1);('normalize partial', 1);('misalignment problem', 1);('improves robotic grasp success rate', 1);('completion error', 1);('state-of-the-art result', 1);('average grasp success rate', 1);('future work', 1);('multi-object shape completion', 1);('framework of3dsgrasp', 1);('3d completion accuracy', 1);('grasp success rate.references [', 1);('ten', 1);('detect grasp poses', 1);('3d point clouds', 1);('s. lu', 1);('r. wang', 1);('miao', 1);('c. mitash', 1);('k. bekris', 1);('online', 1);('object model reconstruction', 1);('lifelong improvement', 1);('robot manipulation', 1);('h.-y', 1);('lin', 1);('s.-c. liang', 1);('chen', 1);('multi-view image acquisition', 1);('pose estimation', 1);('ieee sensors', 1);('j. varley', 1);('c. dechant', 1);('a. richardson', 1);('j. ruales', 1);('p. allen', 1);('shape', 1);('j. lundell', 1);('f. verdoja', 1);('kyrki', 1);('robust', 1);('grasp planning', 1);('uncertain shape completions', 1);('con-', 1);('w. yuan', 1);('t. khot', 1);('d.', 1);('c. mertz', 1);('m. hebert', 1);('point completion network', 1);('m. liu', 1);('l. sheng', 1);('s. yang', 1);('j. shao', 1);('morphing', 1);('aaai', 1);('articial intelligence', 1);('k. mo', 1);('pointnet', 1);('3d classication', 1);('a. dosovitskiy', 1);('l. beyer', 1);('a. kolesnikov', 1);('d. weissenborn', 1);('x. zhai', 1);('t. unterthiner', 1);('m. dehghani', 1);('m. minderer', 1);('g. heigold', 1);('s. gelly', 1);('transformers', 1);('image recognition', 1);('arxiv preprint arxiv:2010.11929', 1);('j. wang', 1);('x. lin', 1);('h. yu', 1);('poat-net', 1);('parallel', 1);('3d object detection', 1);('ieee access', 1);('m.-h. guo', 1);('j.-x', 1);('cai', 1);('z.-n. liu', 1);('t.-j', 1);('mu', 1);('r. r. martin', 1);('pct', 1);('point cloud transformer', 1);('computational visual media', 1);('l. yi', 1);('metric space', 1);('advances', 1);('neural information processing systems', 1);('a.', 1);('m. gualtieri', 1);('k. saenko', 1);('pose detection', 1);('d. coleman', 1);('i. sucan', 1);('s. chitta', 1);('n. correll', 1);('reducing', 1);('complex robotic software', 1);('case study', 1);('software engineering', 1);('b. calli', 1);('a. singh', 1);('a. walsman', 1);('s. srinivasa', 1);('p. abbeel', 1);('a. m.', 1);('ycb object', 1);('towards', 1);('common benchmarks', 1);('manipulation research', 1);('icar', 1);('x. han', 1);('z. li', 1);('h. huang', 1);('e. kalogerakis', 1);('yu', 1);('high-resolution', 1);('global structure', 1);('local geometry inference', 1);('m. kazhdan', 1);('m. bolitho', 1);('h. hoppe', 1);('poisson', 1);('surface recon- struction', 1);('geometry', 1);('r. p.', 1);('figueiredo', 1);('p. moreno', 1);('a. bernardino', 1);('pose es- timation', 1);('symmetric objects', 1);('neurocomputing', 1);('m. berger', 1);('a. tagliasacchi', 1);('l. seversky', 1);('p. alliez', 1);('j. levine', 1);('a. sharf', 1);('c. silva', 1);('surface reconstruction', 1);('art', 1);('s. gurumurthy', 1);('s. agrawal', 1);('high delity semantic shape comple- tion', 1);('latent optimization', 1);('ieee winter', 1);('applications', 1);('wacv', 1);('yang', 1);('c. feng', 1);('shen', 1);('d. tian', 1);('point cloud auto-encoder', 1);('deep grid deformation', 1);('ieee conf', 1);('g. kim', 1);('b. c. russell', 1);('l. pan', 1);('t. wu', 1);('z. cai', 1);('m. xu', 1);('x. luo', 1);('multi-view', 1);('point cloud challenge', 1);('methods', 1);('arxiv preprint arxiv:2112.12053', 1);('z. wang', 1);('diverse', 1);('geometry-aware transformers', 1);('d. yang', 1);('t. tosun', 1);('b. eisner', 1);('isler', 1);('d. lee', 1);('3d reconstruction', 1);('m. van', 1);('merwe', 1);('q. lu', 1);('b. sundaralingam', 1);('m. matak', 1);('t. her-', 1);('continuous 3d reconstructions', 1);('w. chen', 1);('h. liang', 1);('z. chen', 1);('f. sun', 1);('j. zhang', 1);('improving', 1);('object grasp performance', 1);('sparse shape completion', 1);('intelligent', 1);('robotic systems', 1);('kim', 1);('b. russell', 1);('arxiv preprint arxiv:1802.05384', 1);('h. xie', 1);('h. yao', 1);('s. zhou', 1);('j. mao', 1);('s. zhang', 1);('w. sun', 1);('gridding', 1);('residual network', 1);('european conference', 1);('g.', 1);('k. wang', 1);('s. lian', 1);('k. zhao', 1);('vision-based', 1);('object localization', 1);('object pose estimation', 1);('grasp estimation', 1);('parallel grippers', 1);('articial intelligence review', 1);('i. lenz', 1);('h. lee', 1);('a. saxena', 1);('robotic grasps', 1);('j. redmon', 1);('a. angelova', 1);('real-time', 1);('grasp detection', 1);('convo- lutional neural networks', 1);('h.-s. fang', 1);('c. wang', 1);('m. gou', 1);('c. lu', 1);('graspnet-1billion', 1);('large- scale benchmark', 1);('general object', 1);('j. mahler', 1);('m. matl', 1);('satish', 1);('m. danielczuk', 1);('b. derose', 1);('s. mckinley', 1);('k. goldberg', 1);('ambidextrous robot', 1);('p. eaau4984', 1);('m. sundermeyer', 1);('r. triebel', 1);('contact-', 1);('6-dof grasp generation', 1);('c. eppner', 1);('6-dof graspnet', 1);('variational', 1);('grasp generation', 1);('object manipulation', 1);('b. zhao', 1);('h. zhang', 1);('x. lan', 1);('h. wang', 1);('z. tian', 1);('n. zheng', 1);('regnet', 1);('region-based', 1);('grasp network', 1);('end-to-end grasp detection', 1);('bengio', 1);('practical', 1);('deep architectures', 1);('neural', 1);('tricks', 1);('s. s. mohammadi', 1);('a. del bue', 1);('pointview-gcn', 1);('3d shape classication', 1);('multi-view point clouds', 1);('image processing', 1);('icip', 1);('sun', 1);('s. e. sarma', 1);('m. m. bronstein', 1);('j. m. solomon', 1);('dynamic', 1);('graph cnn', 1);('acm transactions', 1);('graphics', 1);('tog', 1);('h. lin', 1);('x. cheng', 1);('x. wu', 1);('d. shen', 1);('cat', 1);('cross attention', 1);('vision transformer', 1);('multimedia', 1);('expo', 1);('icme', 1);('l. p. tchapmi', 1);('kosaraju', 1);('h. rezatoghi', 1);('i. reid', 1);('s. savarese', 1);('topnet', 1);('structural', 1);('point cloud decoder', 1);('theieee/cvf conference', 1);