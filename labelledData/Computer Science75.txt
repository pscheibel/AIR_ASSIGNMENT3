('ceco', 46);('semantic segmentation', 35);('etf', 27);('scannet200', 26);('ade20k', 26);('cvpr', 26);('k\x001', 24);('fig', 22);('neural collapse', 21);('feature centers', 16);('minor classes', 14);('resnet-101', 13);('eq', 12);('class accuracy', 11);('ce', 10);('center regularization', 10);('iterations', 10);('coco-stuff164k', 10);('lov', 9);('image recognition', 8);('sec', 8);('dlv3p', 8);('% miou', 7);('comparison', 7);('iclr', 7);('neurips', 7);('scannet', 7);('papyan', 6);('figure', 6);('semantic', 6);('point cloud', 6);('3d semantic segmentation', 6);('point/pixel recognition', 6);('ablation', 6);('resnet-50', 6);('tight frame', 5);('terminal phase', 5);('contextual correlation', 5);('neural', 5);('classifier', 5);('standard deviations', 5);('k\x13', 5);('following', 5);('max k6=k0cos', 5);('lcr', 5);('center classier', 5);('cifar100 baseline', 5);('baseline', 5);('dice', 5);('disalign', 5);('csc', 5);('lg', 5);('% miou improvement', 5);('swin', 5);('beit', 5);('eccv', 5);('jiaya jia', 5);('contrastive learning', 5);('effective number', 5);('deep', 5);('pearson corr', 5);('coeff', 5);('mse', 4);('semantic seg- mentation', 4);('standard deviation', 4);('training progresses', 4);('neural networks', 4);('w=', 4);('[ w1', 4);('classier weights', 4);('w > kwk=', 4);('pearson', 4);('swin-t', 4);('sota', 4);('minkowskinet-34', 4);('swin-b', 4);('ocrnet', 4);('ieee tpami', 4);('iccv', 4);('liang-chieh chen', 4);('george papandreou', 4);('benjamin graham', 4);('visual recognition', 4);('............ \x001', 4);('frequent class', 4);('pif', 4);('sort', 4);('within-class means', 3);('symmetric structure', 3);('test leaderboard', 3);('solution structures', 3);('maximal equiangular separation', 3);('close position', 3);('semantic segmentation task', 3);('experimental results', 3);('seman- tic segmentation', 3);('image semantic segmentation', 3);('simplex equiangular', 3);('mathematically', 3);('stdk6=k0', 3);('cosines approach zero', 3);('k-th class', 3);('wk ] 2rd\x02k', 3);('ground truth', 3);('lemma', 3);('equiangular property', 3);('center collapse', 3);('point/pixel classier', 3);('feature', 3);('\x16 zk0', 3);('maximal separation', 3);('minkowskinet', 3);('] backbone', 3);('+ 1=', 3);('tail', 3);('imbalanced', 3);('scan- net200', 3);('loss function', 3);('minkowski', 3);('segmentation losses', 3);('focal', 3);('hrnet-w18', 3);('dlv3p resnet-50', 3);('hrnet-w48', 3);('springer', 3);('shu liu', 3);('tsung-yi lin', 3);('piotr doll', 3);('jian sun', 3);('hengshuang zhao', 3);('k\x001\x01\x01\x01', 3);('k\x0011\x01\x01\x01', 3);('k\x001\x001 k\x001\x01\x01\x01', 3);('ck', 3);('v0', 3);('point/pixel imbalance', 3);('cif', 3);('normalized', 3);('number020406080100accuracy', 3);('batch size', 3);('ceco figure', 3);('visualization', 3);('cityscapes', 3);('sim- plex equiangular', 2);('based', 2);('experimental', 2);('method ranks 1stand', 2);('new record', 2);('learning behaviors', 2);('deep neural network', 2);('neu- ral collapse phenomenon', 2);('classication model', 2);('elegant phenomenon', 2);('illustration', 2);('non- equiangular separation', 2);('3d space', 2);('clas- siers', 2);('neural collapse phenomenon', 2);('low correlation', 2);('classier needs', 2);('learnable classier', 2);('training samples', 2);('data imbalance', 2);('maximal discriminative ability', 2);('semantic class', 2);('center collapse regularizer', 2);('signicant improvements', 2);('] rst', 2);('cos', 2);('cifar100 feature', 2);('scannetv2 feature', 2);('scannet200 feature', 2);('ade20k feature', 2);('purple lines', 2);('blue lines', 2);('distinct pairs', 2);('semantic segmenta- tion', 2);('segmentation datasets', 2);('coco', 2);('col- lapse', 2);('u=ik', 2);('kg', 2);('k\x001is', 2);('neural collapse convergence', 2);('appendix', 2);('blue square part', 2);('purple square part', 2);('able classier', 2);('equiangular', 2);('maximal separated', 2);('maximal separation value', 2);('wsatises eq', 2);('off-the-shelf segmentation architecture', 2);('ce-based', 2);('concretely', 2);('w\x03', 2);('pk', 2);('resnet', 2);('main conclusions', 2);('thek-th class', 2);('imbalance severity', 2);('class image number', 2);('sample numbers', 2);('point/pixel frequency', 2);('gradient', 2);('recalling', 2);('rst analyze', 2);('\x16 z', 2);('cos|', 2);('details', 2);('conduct experiments', 2);('3d semantic segmenta- tion', 2);('2d semantic segmentation', 2);('average values', 2);('performance results', 2);('asz [', 2);('asz loss', 2);('method head comm', 2);('r50', 2);('r101', 2);('miou results', 2);('iou', 2);('deeplabv3+', 2);('supcon', 2);('clip', 2);('ceco\x03', 2);('contrastive scene contexts', 2);('backbone', 2);('ocrnet hrnet-w18', 2);('ocrnet hrnet-w48', 2);('upernet resnet-101', 2);('dlv3p resnet-101', 2);('upernet swin-t', 2);('upernet swin-b', 2);('test dataset', 2);('scannetv2', 2);('upernet', 2);('specically', 2);('cnn-', 2);('coco-stuff', 2);('tail classes', 2);('new regularization', 2);('yang wang', 2);('silvio savarese', 2);('image segmentation', 2);('stuff classes', 2);('learning', 2);('iasonas kokkinos', 2);('kevin murphy', 2);('alan', 2);('yuille', 2);('deep convolutional nets', 2);('crfs', 2);('florian schroff', 2);('hartwig adam', 2);('rethinking', 2);('convolutional neural networks', 2);('jiequan cui', 2);('zhisheng zhong', 2);('serge belongie', 2);('angela dai', 2);('matthias niener', 2);('deep neural networks', 2);('proceedings', 2);('national academy', 2);('pmlr', 2);('martin engelcke', 2);('laurens', 2);('van der', 2);('maaten', 2);('submanifold sparse convolutional networks', 2);('ross girshick', 2);('xy han', 2);('vardan papyan', 2);('david', 2);('donoho', 2);('kaiming', 2);('saining xie', 2);('boqing gong', 2);('li jiang', 2);('xiaojuan qi', 2);('fully', 2);('ieee', 2);('litany', 2);('bastian leibe', 2);('charles r qi', 2);('hao su', 2);('leonidas j guibas', 2);('icml', 2);('balanced', 2);('jingdong wang', 2);('bolei zhou', 2);('liang xie', 2);('yibo yang', 2);('vladlen koltun', 2);('jinxin zhou', 2);('xiao li', 2);('tianyu ding', 2);('chong', 2);('qing qu', 2);('zhihui zhu', 2);('avgk', 2);('w1k', 2);('uis', 2);('w >', 2);('havep k6=k0cos', 2);('m=q k\x001 kw', 2);('center imbalance', 2);('imbalance factor', 2);('if', 2);('scannet-v2', 2);('image frequency', 2);('center frequency', 2);('class categories', 2);('sgd', 2);('initial learning rate', 2);('input image', 2);('simple imbalance cases', 2);('performance', 2);('training', 2);('understanding imbalanced semantic segmentation', 1);('neural collapse zhisheng zhong1', 1);('cui1', 1);('yang2', 1);('wu3xiaojuan qi3xiangyu zhang4jiaya jia1 cuhk1jd explore academy2hku3megvii technology4', 1);('\x03equal contribution code', 1);('abstract', 1);('recent study', 1);('classier weight vectors converge', 1);('empir- ical', 1);('theoretical analysis', 1);('in- troduce', 1);('appealing struc- ture', 1);('signicant improve- ments', 1);('3d semantic segmentation bench- marks', 1);('introduction', 1);('last-layer representation', 1);('geometric perspective', 1);('] reveals', 1);('equal cosine similarity', 1);('nal classiers', 1);('feature cen- ters', 1);('global optimality', 1);('equiangular separation', 1);('collapse reveals', 1);('within- class centers', 1);('minor class', 1);('classier vectors lie', 1);('network degrades', 1);('loss functions', 1);('model [ 19,20,25,30,42,45,48,60,62,75 ]', 1);('current studies', 1);('neural collapse focus', 1);('performs classication', 1);('important pixel-wise classication problem', 1);('neural collapse perspective', 1);('fea- ture centers', 1);('sur-', 1);('symmetric equiangular sep- aration', 1);('classication benchmark datasets', 1);('different classes', 1);('class cor- relation', 1);('label space', 1);('simple experiment', 1);('1arxiv:2301.01100v1 [ cs.cv ]', 1);('jan', 1);('scannet200 ade20k learned', 1);('fixed', 1);('semantic segmentation model', 1);('image recognition [', 1);('im- age recognition', 1);('class distribu- tion', 1);('ex- plains', 1);('data [', 1);('semantic segmentation nat-', 1);('semantic classes', 1);('large area', 1);('point/pixel-wise classica- tion loss', 1);('backbone parameters', 1);('equiangular separation structure', 1);('minor classes lie', 1);('neural collapse renders', 1);('centers equian- gular separation', 1);('recognition [', 1);('inspired', 1);('enable adaptive class correla- tion', 1);('classier layer', 1);('classier forces', 1);('appealing structure', 1);('equiangu- lar separation', 1);('feature learning', 1);('semantic segmentation quality', 1);('theoretical results', 1);('rigorous explanation', 1);('segmentation architecture', 1);('simple method', 1);('multiple image', 1);('point cloud semantic segmentation benchmarks', 1);('overall contributions', 1);('explore neural collapse', 1);('symmet- ric structure', 1);('encour- age', 1);('related', 1);('class centers', 1);('elegant sym- metry', 1);('phe- nomenon', 1);('global opti- mality', 1);('regularization [ 60,73,75 ]', 1);('constraint [ 19,20,42,62 ]', 1);('explicit constraint [', 1);('un- der', 1);('loss func- tions [', 1);('classes [ 59,64,65 ]', 1);('equiangular separation state', 1);('substantial', 1);('for2d semantic segmentation', 1);('fcn', 1);('per-point/pixel classication', 1);('subsequently', 1);('approaches [', 1);('global infor- mation', 1);('sharp object boundaries', 1);('large re- ceptive eld', 1);('important role', 1);('global information', 1);('stud- ies [', 1);('spatial pyramid', 1);('contextual information', 1);('real- world 3d datasets [', 1);('signicant focus', 1);('recent years', 1);('approaches', 1);('point cloud segmentation', 1);('cate- gories', 1);('solutions [', 1);('regular voxels', 1);('sparse convolutions', 1);('point-based', 1);('methods [ 33,35,50,51,69 ]', 1);('position information', 1);('network architecture', 1);('module design', 1);('iterations0.00.10.20.30.40.5 coco-stuff164k feature', 1);('classiers', 1);('train class-means approach equiangularity', 1);('vertical axis shows', 1);('classes kandk0', 1);('data distribution', 1);('dis- tribution', 1);('able large-scale', 1);('learning view draws', 1);('neural collapse observations', 1);('recognition', 1);('ntraining', 1);('to- tal', 1);('annotations y2rn', 1);('kclasses', 1);('yi2 f1', 1);('kgas', 1);('last-layer d-dimensional', 1);('i-th sample', 1);('avgyi=kfzigis', 1);('last- layer', 1);('linear classier', 1);('neural collapse phe- nomenon', 1);('training error rate', 1);('denition', 1);('simplex equiangular tight frame', 1);('col- lection', 1);('vectors mk2rd', 1);('m=r k k\x001u\x12 ik\x001 k1k1', 1);('m=', 1);('[ m1', 1);('mk ] 2rd\x02k', 1);('u2rd\x02kallows', 1);('ikis', 1);('identity matrix', 1);('all-ones vector', 1);('equal ` 2norm', 1);('pair-wise angle', 1);('m > imj=k', 1);('k\x001\x0ei', 1);('pair- wise angle\x001', 1);('kvectors', 1);('rd', 1);('d\x15k\x001 [', 1);('important geometric properties', 1);('within-class centers converge', 1);('avgifzigis', 1);('last-layer fea- tures', 1);('classier vectors converge', 1);('^wk=wk=jjwkjj=^zkand satises', 1);('performs image-wise classication', 1);('corresponding structures', 1);('point cloud semantic segmentation', 1);('per- forms pixel-', 1);('point-wise classication', 1);('calculate statistics', 1);('semantic segmen- tation', 1);('cosine similarities', 1);('different classes k6=k0', 1);('cifar100', 1);('equiangular structure', 1);('similarly', 1);('classiers approach', 1);('maximal-angle structure', 1);('clas- sication', 1);('maximal separation structure', 1);('ypoint /', 1);('pixel representation', 1);('z point /', 1);('pixel classifier', 1);('classifierinput', 1);('x w1 w2w3w4center', 1);('regularization branchpoint', 1);('pixel recognition branch', 1);('zk_ gatheryk_ table floor wall sky ground tree', 1);('losspr losscr', 1);('... ... * * * *', 1);('framework', 1);('3d scene input illustration', 1);('2d image input illustration', 1);('conventional segmentation model', 1);('feature center collapse', 1);('non-equiangular structure', 1);('class contextual correlation', 1);('class im- balance', 1);('rigorous analysis', 1);('approach', 1);('motivation', 1);('classication problem', 1);('stud- ies', 1);('minor classes [', 1);('wk ]', 1);('rd\x02k', 1);('\x15 \x001', 1);('equality', 1);('please', 1);('reg- ularize', 1);('segmentation model', 1);('imbalance dilemma', 1);('semantic segmentation.4.2', 1);('collapse regularizer', 1);('maximum sep- aration properties', 1);('centercollapse regularizer', 1);('semantic segmentation problems', 1);('whole framework', 1);('point/pixel recogni- tion', 1);('upper part', 1);('bottom part', 1);('image segmentation model', 1);('point/pixel level man- ner', 1);('3d scene', 1);('n=hw', 1);('color dimension', 1);('image case', 1);('position dimension', 1);('feature representation', 1);('z=', 1);('[ z1', 1);('zn ] > 2rn\x02dafter', 1);('lprfor', 1);('feature centers \x16zk', 1);('generate center labels \x16ykof', 1);('ground truth y', 1);('\x16zk=1 nknkx yi=kzi', 1);('zbelonging', 1);('k- th class', 1);('centers \x16z= [ \x16z1', 1);('\x16zk ]', 1);('4rd\x02kand center labels \x16y= [', 1);('] 2rkfor', 1);('intro- duce', 1);('center collapse regularization loss', 1);('lcrupon', 1);('fea- ture centers \x16zand', 1);('center labels \x16yis', 1);('initial- ize', 1);('w\x03as', 1);('random simplex', 1);('maximal equiangular separation property', 1);('w\x03 k > w\x03 k0= 2\x12k\x0ek', 1);('k\x001\x001 k\x001\x13', 1);('k0 equals', 1);('type oflcrloss', 1);('=\x00kx k=1log exp\x00\x16z > kw\x03 k\x01', 1);('k0=1exp\x00\x16z > k0w\x03 k0\x01', 1);('total loss', 1);('ltotal=lpr', 1);('loss weight hyper-parameter', 1);('additionally', 1);('evalua- tion', 1);('conven- tional backbone', 1);('additional computations', 1);('empirical support', 1);('empirical evidence', 1);('appendix c.', 1);('trans- forms', 1);('point/pixel pair', 1);('center pair', 1);('factor [', 1);('nmax nmin', 1);('minimal numbers', 1);('scannetv2 scannet200 ade20k coco-stuff', 1);('imagesemantic segmentation', 1);('weak corre- lations', 1);('class point/pixel numbers', 1);('correlation measure- ment', 1);('correlation coefcients [', 1);('cifar100-lt-100 scannet200 ade20k', 1);('recognition methods', 1);('loss adjustment [', 1);('low correlations', 1);('pixel cases', 1);('regularizes imbalance', 1);('feature center space', 1);('global rep- resentation', 1);('theoretical support', 1);('center collapse losslcrfrom', 1);('center computation', 1);('@ wk=', 1);('\x16 zk+k\x001x k06=kpk', 1);('=nkx yi=k', 1);('\x16 zk', 1);('zi nk | { z } within-class+k\x001x k06=knkx yj=k0pk', 1);('zj nk0 | { z } between-class', 1);('\x16 zbelongs', 1);('softmax transformation', 1);('=exp\x00 \x16 z > wk\x01', 1);('k0=1exp\x00 \x16 z > wk0\x01', 1);('gradient w.r.twkis', 1);('within-class part containsnkterms', 1);('pulls wktowards', 1);('between- class part containsp k06=knk0terms', 1);('pushes wkaway', 1);('decision boundaries', 1);('center classier weights', 1);('imbalance gradi- ent', 1);('minor classes discrimination', 1);('equiangularityfeature', 1);('center equiangularity', 1);('adopting ceco', 1);('w.r.t point/pixel', 1);('center col- lapse losslcris', 1);('point/pixel fea- turezi', 1);('center collapse loss inuences', 1);('gradient view', 1);('suppose', 1);('class label yi=k', 1);('lcrwith', 1);('@ zi= @', 1);('@ \x16zk\x0f @ \x16 zk @ zi=kx k0=1pk0', 1);('\x0f1 nk', 1);('medium term', 1);('wk0\x00 wk', 1);('authors describe', 1);('minority collapse phe- nomenon', 1);('classier weight vectors', 1);('minor classes converge', 1);('similar direction', 1);('extreme imbalance case', 1);('lim nmax nk', 1);('nmax nk0', 1);('clas- sier', 1);('ob- tains', 1);('experiments', 1);('datasets', 1);('popular benchmarks', 1);('point cloud seman- tic segmentation', 1);('severe imbalance cases', 1);('implementation de- tails', 1);('dataset descriptions', 1);('appendix d.', 1);('conduct ablation experiments', 1);('ablation resultspc', 1);('cc scannet200 ade20k learned', 1);('fixed fixed', 1);('fixed learned', 1);('learned fixed', 1);('learned learned', 1);('pc', 1);('cc', 1);('loss weight scannet200 ade20k', 1);('loss weight hyper-parameter \x15', 1);('validation dataset', 1);('single-scale inference miou', 1);('equiangularity', 1);('maximal separation analysis', 1);('equiangularity property', 1);('classes kand k0', 1);('avgk6=k0jcos', 1);('4b show', 1);('different iterations', 1);('cosines approach zero indicat-', 1);('maximal angle', 1);('center collapse regularization', 1);('stan- dard deviation', 1);('classication neural collapse results', 1);('center clas- sier', 1);('point/pixel classi- er', 1);('center classier induces', 1);('strong regularization', 1);('cen- ter distribution', 1);('type scannet200 ade20k ce', 1);('asz +', 1);('ablations', 1);('performance comparison', 1);('segmentation framework', 1);('miou performance', 1);('consistent', 1);('sim- ilar', 1);('conventional semantic segmentation models', 1);('learnable point/pixel classier', 1);('ner point/pixel-level classication', 1);('loss weight hyper-parameter \x15.in', 1);('hyper-parameter \x15for', 1);('point/pixel recognition branchlprand', 1);('center regulariza- tion branchlcr', 1);('dif- ferent\x15values', 1);('value of\x15in', 1);('wide range', 1);('according', 1);('\x15= 0:5can', 1);('head', 1);('common andtailcategories', 1);('com- pare', 1);('segmen- tation framework', 1);('head comm', 1);('ins', 1);('samp', 1);('c-focal', 1);('table 5. miou comparison', 1);('11thnovember 2022.', 1);('previous methods', 1);('perfor- mance', 1);('orthogonality', 1);('seg- mentation losses', 1);('softiou', 1);('softtversky', 1);('segmentation results', 1);('novel regularization', 1);('famous seg- mentation losses', 1);('fur- ther', 1);('1.0-3.0 %', 1);('above ex- periments', 1);('powerful re- balance performance', 1);('supervised contrastive learning', 1);('sota lg', 1);('fair comparison', 1);('validation dataset 7method', 1);('upernet beit-l', 1);('beit-l', 1);('surpasses pre- vious methods', 1);('measure- ments', 1);('% ,5.4 %', 1);('valida- tion dataset', 1);('% ,5.2 % ,4.6 %', 1);('following mix3d', 1);('3d model', 1);('ensem- ble results', 1);('ranks 1ston', 1);('en- ables', 1);('great improvements', 1);('tail categories', 1);('various semantic segmen- tation head methods', 1);('different backbones', 1);('hr-', 1);('net [', 1);('% gains', 1);('164k dataset', 1);('ex- ibility', 1);('upernet resnet-50', 1);('cocostuff-164k', 1);('equipped', 1);('resnets', 1);('hrnets', 1);('base- lines', 1);('hrnet-18', 1);('model outperforms', 1);('cnn-based resnet-101', 1);('clear improvements', 1);('center collapse regulariza- tion', 1);('demon- strate', 1);('vari- ous backbones', 1);('segmentation head methods', 1);('visual', 1);('visual comparisons', 1);('appendix e.', 1);('precise semantic segmenta- tion masks', 1);('conclusion', 1);('neural collapse structures', 1);('contextual correla- tion', 1);('center collapse loss', 1);('adopting', 1);('future studies', 1);('limitation', 1);('appendix f.', 1);('8references [', 1);('md amirul islam', 1);('mrigank rochan', 1);('neil db bruce', 1);('gated', 1);('feedback renement network', 1);('dense image', 1);('iro armeni', 1);('ozan sener', 1);('amir r. zamir', 1);('helen jiang', 1);('ioan-', 1);('brilakis', 1);('martin fischer', 1);('3d seman- tic', 1);('indoor spaces', 1);('vijay badrinarayanan', 1);('alex kendall', 1);('roberto cipolla', 1);('segnet', 1);('deep convolutional encoder-decoder architecture', 1);('hangbo bao', 1);('li dong', 1);('furu wei', 1);('bert', 1);('pre- training', 1);('image transformers', 1);('j. behley', 1);('m. garbade', 1);('a. milioto', 1);('j. quenzel', 1);('s. behnke', 1);('c. stachniss', 1);('j. gall', 1);('semantickitti', 1);('se- mantic scene understanding', 1);('lidar', 1);('jacob benesty', 1);('jingdong chen', 1);('yiteng huang', 1);('israel co-', 1);('correlation coefcient', 1);('noise', 1);('speech processing', 1);('maxim berman', 1);('amal rannen triki', 1);('matthew', 1);('blaschko', 1);('asz-softmax loss', 1);('tractable surrogate', 1);('intersection-over-union measure', 1);('holger caesar', 1);('jasper uijlings', 1);('vittorio ferrari', 1);('coco- stuff', 1);('thing', 1);('kaidi cao', 1);('colin wei', 1);('adrien gaidon', 1);('nikos arechiga', 1);('tengyu ma', 1);('label- distribution-aware', 1);('image seg- mentation', 1);('deeplab', 1);('im- age segmentation', 1);('atrous con- volution', 1);('atrous convolution', 1);('seman- tic image segmentation', 1);('arxiv preprint arxiv:1706.05587', 1);('yukun zhu', 1);('encoder-decoder', 1);('separable convolution', 1);('semantic image segmentation', 1);('christopher choy', 1);('junyoung gwak', 1);('4d spatio-temporal', 1);('convnets', 1);('mmsegmentation contributors', 1);('mmsegmentation', 1);('openmmlab', 1);('semantic segmentation toolbox', 1);('/ / github', 1);('com /', 1);('bei yu', 1);('parametric', 1);('yin cui', 1);('menglin jia', 1);('yang', 1);('class-balanced', 1);('x. chang', 1);('manolis savva', 1);('maciej hal-', 1);('thomas funkhouser', 1);('richly-annotated', 1);('3d reconstructions', 1);('indoor scenes', 1);('cong fang', 1);('hangfeng', 1);('qi', 1);('weijie j su', 1);('explor-', 1);('minority', 1);('florian graf', 1);('christoph hofer', 1);('marc niethammer', 1);('roland kwitt', 1);('dissecting', 1);('inicml', 1);('laurens van der maaten', 1);('subman-', 1);('ifold sparse convolutional networks', 1);('agrim gupta', 1);('lvis', 1);('large vocabulary instance segmentation', 1);('proximity', 1);('central path', 1);('xiangyu zhang', 1);('shaoqing ren', 1);('residual learning', 1);('ji hou', 1);('exploring', 1);('data-efcient 3d scene understanding', 1);('chen huang', 1);('yining li', 1);('loy chen', 1);('xiaoou tang', 1);('attribute prediction', 1);('muhammad abdullah jamal', 1);('matthew brown', 1);('ming-hsuan yang', 1);('liqiang wang', 1);('domain adaptation perspective', 1);('wenlong ji', 1);('yiping lu', 1);('yiliang zhang', 1);('zhun deng', 1);('wei-', 1);('j su', 1);('bingyi kang', 1);('marcus rohrbach', 1);('zhicheng yan', 1);('albert gordo', 1);('jiashi feng', 1);('yannis kalantidis', 1);('decou-', 1);('recogni- tion', 1);('prannay khosla', 1);('piotr teterwak', 1);('chen wang', 1);('aaron sarna', 1);('yonglong tian', 1);('phillip isola', 1);('aaron maschinot', 1);('ce liu', 1);('dilip krishnan', 1);('supervised', 1);('nips', 1);('xin lai', 1);('jianhui liu', 1);('liwei wang', 1);('stratied', 1);('trans- 9former', 1);('3d point cloud segmentation', 1);('tianhong li', 1);('peng cao', 1);('yuan yuan', 1);('lijie fan', 1);('yuzhe yang', 1);('rogerio', 1);('feris', 1);('piotr indyk', 1);('dina katabi', 1);('targeted', 1);('yangyan li', 1);('rui bu', 1);('mingchao sun', 1);('wei wu', 1);('xinhan di', 1);('baoquan chen', 1);('pointcnn', 1);('convolution', 1);('guosheng lin', 1);('anton milan', 1);('chunhua shen', 1);('ian reid', 1);('renenet', 1);('multi-path', 1);('renement networks', 1);('high- resolution semantic segmentation', 1);('priya goyal', 1);('dense object detection', 1);('michael maire', 1);('james hays', 1);('pietro perona', 1);('deva ramanan', 1);('lawrence zitnick', 1);('microsoft coco', 1);('common objects', 1);('ze liu', 1);('yutong lin', 1);('yue cao', 1);('han hu', 1);('yixuan wei', 1);('zheng zhang', 1);('stephen lin', 1);('baining guo', 1);('hierarchical', 1);('vision transformer', 1);('ziwei liu', 1);('zhongqi miao', 1);('xiaohang zhan', 1);('jiayun wang', 1);('stella x yu', 1);('large-scale', 1);('open world', 1);('jonathan', 1);('evan shelhamer', 1);('trevor darrell', 1);('convolutional networks', 1);('jianfeng lu', 1);('stefan steinerberger', 1);('cross-entropy loss', 1);('arxiv preprint arxiv:2012.08465', 1);('aditya krishna menon', 1);('sadeep jayasumana', 1);('ankit singh rawat', 1);('himanshu jain', 1);('andreas veit', 1);('sanjiv kumar', 1);('long-tail', 1);('logit adjustment', 1);('fausto milletari', 1);('nassir navab', 1);('seyed-ahmad ahmadi', 1);('v-net', 1);('medical image segmentation', 1);('dustin g mixon', 1);('hans parshall', 1);('jianzong pi', 1);('neu-', 1);('ral collapse', 1);('arxiv preprint arxiv:2011.11619', 1);('alexey nekrasov', 1);('jonas schult', 1);('francis engelmann', 1);('mix3d', 1);('out-of-context', 1);('data aug- mentation', 1);('3d scenes', 1);('prevalence', 1);('deep learning training', 1);('tomaso poggio', 1);('qianli liao', 1);('explicit', 1);('implicit bias', 1);('deep network classiers', 1);('square loss', 1);('arxiv preprint arxiv:2101.00072', 1);('tobias pohlen', 1);('alexander hermans', 1);('markus mathias', 1);('full-resolution', 1);('residual networks', 1);('street scenes', 1);('kaichun mo', 1);('pointnet', 1);('3d classication', 1);('li yi', 1);('point- net++', 1);('metric space', 1);('alec radford', 1);('jong wook kim', 1);('chris hallacy', 1);('aditya ramesh', 1);('gabriel goh', 1);('sandhini agarwal', 1);('girish sastry', 1);('amanda askell', 1);('pamela mishkin', 1);('jack clark', 1);('learn-', 1);('transferable visual models', 1);('natural language super- vision', 1);('md atiqur rahman', 1);('optimizing', 1);('symposium', 1);('visual com-', 1);('jiawei ren', 1);('cunjun yu', 1);('shunan sheng', 1);('xiao ma', 1);('haiyu zhao', 1);('shuai yi', 1);('li', 1);('olaf ronneberger', 1);('philipp fischer', 1);('thomas brox', 1);('u-', 1);('convolutional', 1);('biomedical image segmen- tation', 1);('miccai', 1);('david rozenberszki', 1);('language-', 1);('indoor 3d semantic segmentation', 1);('seyed sadegh mohseni salehi', 1);('deniz erdogmus', 1);('ali gholipour', 1);('tversky', 1);('image segmentation us-', 1);('international workshop', 1);('machine learning', 1);('imaging', 1);('jun shu', 1);('qi xie', 1);('lixuan yi', 1);('qian zhao', 1);('sanping zhou', 1);('zongben xu', 1);('deyu meng', 1);('meta-weight-net', 1);('christos thrampoulidis', 1);('ganesh r kini', 1);('vala vakilian', 1);('tina behnia', 1);('imbalance', 1);('revisiting', 1);('neural-collapse geometry', 1);('arxiv preprint arxiv:2208.05512', 1);('tom tirer', 1);('joan bruna', 1);('extended', 1);('deep neural collapse', 1);('ke sun', 1);('tianheng cheng', 1);('borui jiang', 1);('chaorui deng', 1);('yang zhao', 1);('dong liu', 1);('yadong mu', 1);('mingkui tan', 1);('xinggang wang', 1);('high-resolution represen- tation learning', 1);('e weinan', 1);('stephan wojtowytsch', 1);('tetrahedral symmetry', 1);('penultimate layers', 1);('neural network classiers', 1);('arxiv preprint arxiv:2012.05420', 1);('tete xiao', 1);('yingcheng liu', 1);('yuning jiang', 1);('unied', 1);('scene understand-', 1);('deng cai', 1);('xiaofei', 1);('arxiv preprint arxiv:2204.08735', 1);('shixiang chen', 1);('xiangtai li', 1);('zhouchen lin', 1);('dacheng tao', 1);('fisher yu', 1);('multi-scale', 1);('context aggrega- tion', 1);('yuhui yuan', 1);('xilin chen', 1);('object-', 1);('contextual representations', 1);('songyang zhang', 1);('zeming li', 1);('shipeng yan', 1);('xuming', 1);('distribution', 1);('long-tail visual recognition', 1);('philip torr', 1);('point transformer', 1);('jianping shi', 1);('xiaogang wang', 1);('pyramid', 1);('im-', 1);('hang zhao', 1);('xavier puig', 1);('sanja fidler', 1);('adela barriuso', 1);('antonio torralba', 1);('scene', 1);('optimization landscape', 1);('neural col- lapse', 1);('global', 1);('arxiv preprint arxiv:2203.01238', 1);('jianggang zhu', 1);('zheng wang', 1);('jingjing chen', 1);('yi-ping phoebe chen', 1);('yu-gang jiang', 1);('jeremias sulam', 1);('geometric analysis', 1);('neu- ral collapse', 1);('imbalanced semantic segmentation', 1);('neural collapse supplementary material', 1);('centers approach maximal-angle equiangularity', 1);('maximal-angle degree', 1);('distinct classes', 1);('whole training process', 1);('zero implies', 1);('cosines converge', 1);('maximum separation', 1);('equiangular vectors', 1);('similar experiment', 1);('various semantic segmentation datasets', 1);('iterations0.00.10.20.30.4 coco-stuff164k feature', 1);('vertical axis', 1);('classication dataset', 1);('different semantic segmentation datasets', 1);('taken', 1);('feature centers suffer', 1);('difcult issue', 1);('great benet', 1);('feature center collapse regularizer', 1);('experiment', 1);('setting details', 1);('cifar-100', 1);('classication task', 1);('] model', 1);('point cloud semantic segmentation tasks', 1);('minkoswskinet-34', 1);('] models', 1);('image semantic segmentation tasks', 1);('training hyperparameters', 1);('conventional training setting', 1);('total number', 1);('above ve tasks', 1);('neural collapse statistics computations', 1);('sufciency', 1);('wis', 1);('=w > kwk0', 1);('=1 >', 1);('kw', 1);('w1k=kx', 1);('k=1kx k0=1w > kwk0 | { z }', 1);('k2terms=kx', 1);('k=1w > kwk | { z }', 1);('kterms+x', 1);('k6=k0w > kwk0 | { z }', 1);('havep k6=k0w > kwk0\x15\x00k', 1);('= max k6=k0w > kwk0\x15\x00k', 1);('w=r k k\x001u\x12 ik\x001 k1k1', 1);('rotation matrix', 1);('w=k k\x001\x12 ik\x001 k1k1', 1);('> \x12', 1);('ik\x001 k1k1', 1);('according eq', 1);('andw > kwk0=\x001', 1);('obviously', 1);('i.e.,8k6= k0', 1);('necessity', 1);('\x14 \x001', 1);('thenp k6=k0cos', 1);('\x14 \x00k', 1);('\x15 \x00k', 1);('w=2', 1);('m >', 1);('m=k\x001 kw', 1);('w=k\x001 k2', 1);('k\x001 k\x01\x01\x01', 1);('kk\x001 k\x01\x01\x01', 1);('k\x001 k\x01\x01\x01k\x001 k3', 1);('k1k1k', 1);('ik\x001 k1k1kis', 1);('k\x001and', 1);('c2 k=c', 1);('kck=ck', 1);('ck=v\x06v', 1);('v=h v0', 1);('k1ki', 1);('-dimension subspace perpendicular to1p', 1);('k1k', 1);('> =ck', 1);('orthogonal projector', 1);('mshares', 1);('column space', 1);('m=um\x06\x14 v0qk\x001', 1);('k1k\x15', 1);('> =um\x06q >', 1);('q=\x14qk\x001', 1);('qk\x0012rk\x001\x02k\x001andum2rd\x02kare', 1);('arbitrary orthogonal matrices', 1);('qq', 1);('> =iand \x06q > =q > \x06', 1);('m=um\x06q', 1);('> =umq > \x06v > =umq >', 1);('v\x06q', 1);('> =umq >', 1);('u=umq', 1);('mum=vqu', 1);('uq', 1);('> =ik', 1);('hence', 1);('m=uck', 1);('orthogonal matrix', 1);('w=r k k\x001m=r k k\x001u\x12 ik\x001 k1k1', 1);('maximal equiangular', 1);('\x03 14c', 1);('detailed empirical evidence', 1);('rebalance', 1);('reduction', 1);('important parameters', 1);('centers \x16z', 1);('centers labels \x16y', 1);('severe class imbalance issue', 1);('popular semantic segmentation benchmarks', 1);('convention [', 1);('=nmax nmin', 1);('wherenmax andnminare', 1);('point/pixel imbalance factor', 1);('center imbalance factor', 1);('ve times', 1);('rif', 1);('class imbalance issue', 1);('turn promotes', 1);('index0.000.070.140.210.280.35frequencyscannet-v2', 1);('if=116', 1);('if=11', 1);('index0.000.060.120.180.240.30scannet200', 1);('if=37256', 1);('if=597', 1);('index0.000.040.080.120.160.20ade20k pixel', 1);('if=827', 1);('if=282', 1);('index0.000.020.040.060.080.10coco-stuff164k pixel', 1);('if=2612', 1);('if=528 figure', 1);('class center imbalance', 1);('histogram', 1);('point/center frequency', 1);('class indexes', 1);('pixel/center frequency', 1);('asnmax nmin', 1);('reducing', 1);('correlation inuence', 1);('original input', 1);('higher-level semantic', 1);('general information', 1);('point/pixel- level', 1);('point/pixel-level pair', 1);('introduction part', 1);('common information', 1);('similar color', 1);('neighboring', 1);('class center pair', 1);('global level semantic representation', 1);('increases diversity', 1);('different samples', 1);('correlation coefcient [', 1);('class accuracy a2rkand', 1);('class frequency f= [ f1', 1);('fk ] 2rk', 1);('fk=nk nmax', 1);('=e [', 1);('] \x1b', 1);('cov', 1);('normalized image number020406080100accuracy', 1);('normalized pixel number020406080100accuracy', 1);('pixel', 1);('maximum image number', 1);('class point/pixel number', 1);('maximum point/pixel number', 1);('class center number', 1);('maximum center number', 1);('cifar-', 1);('pixel frequency', 1);('point frequency', 1);('previous studies', 1);('strategies [', 1);('class frequency', 1);('good results', 1);('different', 1);('image classication task', 1);('cifar100-lt', 1);('category accuracy', 1);('training samples [', 1);('image classication', 1);('unique instance', 1);('similar context', 1);('training semantic segmentation models', 1);('actual number', 1);('effective pixels', 1);('different images', 1);('different training signals', 1);('d. datasets description', 1);('details d.1', 1);('datasets scannet200', 1);('benchmark', 1);('active online benchmark evaluation', 1);('real-world environments', 1);('rozenberszki', 1);('benchmark benchmark', 1);('natural class imbalance', 1);('frequency number', 1);('surface points', 1);('challenging dataset', 1);('contains 22k', 1);('semantic concepts', 1);('2k images', 1);('large-scale scene understanding benchmark', 1);('object detection', 1);('164k images', 1);('5k images', 1);('thing classes', 1);('d.2', 1);('] codebase', 1);('20k steps', 1);('polynomial decay', 1);('data parallel', 1);('gpus', 1);('] use', 1);('mmsegmentation codebase [', 1);('training settings', 1);('cnn-based resnet-50c', 1);('resnet-101c', 1);('rst 7\x027convolution layer', 1);('consecutive 3\x023convolutions', 1);('semantic segmentation community [', 1);('hrnet-w', 1);('transformer [', 1);('be it', 1);('recent state-of-the-art performance', 1);('imagenet-22k', 1);('cnn-based', 1);('learning rate schedule [', 1);('weight decay', 1);('crop size', 1);('160k iterations', 1);('320k iterations', 1);('default optimizer', 1);('learning rate setup', 1);('standard random scale', 1);('random horizontal', 1);('random color', 1);('data augmentations [', 1);('horizontal ips', 1);('visual comparison', 1);('quantitative visualizations', 1);('cocostuff164k', 1);('figures', 1);('geometry information', 1);('precise semantic segmentation masks', 1);('input', 1);('cloud', 1);('groud truth', 1);('limitation analysis f.1', 1);('class number', 1);('above analysis', 1);('method backbone', 1);('dlv3p resnet-18', 1);('ceco resnet-18', 1);('ceco resnet-50', 1);('cityscapes.method', 1);('pointtransformer', 1);('sparseconvnet', 1);('method training inference dlv3p', 1);('0.725s 0.294s +', 1);('+18.3 %', 1);('5.844s 4.856s +', 1);('+10.2 %', 1);('inference time', 1);('imbal', 1);('factor cityscapes', 1);('factor comparison', 1);('f.2', 1);('inference', 1);('analysis', 1);('inference time results', 1);('nvidia geforce', 1);('gpu', 1);('imbalance performance', 1);('additional center regularization', 1);('time cost', 1);