('cvpr', 23);('cgg', 21);('mask2former', 14);('tab', 10);('coco', 9);('fig', 9);('instance segmentation', 8);('transformer', 8);('ovis', 7);('iccv', 7);('eccv', 7);('caption generation', 6);('osps', 6);('previous works', 6);('object detection', 5);('vlms', 5);('openseg', 5);('novel classes', 5);('caption generator', 5);('ovrcnn', 4);('previous methods', 4);('ground truth', 4);('ablation', 4);('pq', 3);('nouns', 3);('bert', 3);('compared', 3);('following', 3);('mmdetection', 3);('mscoco', 3);('unknown classes', 3);('unknown things', 3);('novel', 3);('ijcv', 3);('set panoptic segmentation osps', 2);('ourmethod', 2);('recently', 2);('imagenet21k', 2);('promptdet', 2);('extra datasets', 2);('training', 2);('red double decker', 2);('ovis osps', 2);('different', 2);('atthe', 2);('gflops', 2);('xpm', 2);('clip', 2);('detic', 2);('object queries', 2);('crossentropy ce', 2);('openvocabulary segmentation', 2);('image caption', 2);('crossentropy loss', 2);('objects image', 2);('set panoptic segmentation', 2);('setting model', 2);('pytorch', 2);('panoptic segmentation', 2);('resnet50', 2);('captions', 2);('ovod', 2);('caption grounding', 2);('3565m 22748ours', 2);('visualization fig', 2);('blue cider', 2);('visualization', 2);('ade20k', 2);('ineccv', 2);('nips', 2);('iniccv', 2);('ieee', 2);('transformer query generation', 2);('agrim gupta piotr', 2);('ross girshick lvis adataset', 2);('large vocabulary instance segmentation', 2);('icml', 2);('pmlr', 2);('incvpr', 2);('learning', 2);('neurips', 2);('piyush sharma nan ding sebastian goodman radusoricut conceptual', 2);('image alttext dataset', 2);('automatic image', 2);('aclpages', 2);('betrayed captions joint caption grounding generation', 1);('vocabulary instance segmentationjianzong wu1xiangtai li2\x03yhenghui ding2xia li3guangliang cheng4yunhai tong1chen', 1);('loy21key laboratory machine perception moe', 1);('articial intelligence peking university2slab nanyang technological university3eth zurich4sensetime researchjzwustupkueducn', 1);('ccloy gntuedusgabstractin work focus instancelevel', 1);('open vocabulary segmentation', 1);('segmenter forinstancewise novel categories', 1);('mask annotationswe', 1);('effective framework thehelp image captions', 1);('thousandsof object nouns captions', 1);('instances novelclasses', 1);('caption models', 1);('massive caption datasets', 1);('complex pipelines wepropose endtoend solution', 1);('particular devisea joint', 1);('caption grounding generation cgg', 1);('mask transformer', 1);('baseline framework novel', 1);('loss performs', 1);('explicit andimplicit multimodal', 1);('alignments designa lightweight caption generation head', 1);('additional caption supervision nd', 1);('generation complement', 1);('thesegmentation performance novel categories conduct', 1);('extensive experiments', 1);('dataset twosettings open', 1);('vocabulary instance segmentation ovisand', 1);('resultsdemonstrate superiority', 1);('framework overprevious', 1);('large improvement of68 map novel classes', 1);('extra caption data', 1);('improvements novelclasses', 1);('various settings1', 1);('introductioninstancelevel segmentation', 1);('core visiontask', 1);('segthe rst', 1);('authors contribute', 1);('parts', 1);('xiangtai', 1);('sensetime researchyprojectleader code', 1);('available httpsgithubcomjzwu48033552betrayedbycaptions', 1);('signicant research effort', 1);('current solutions', 1);('focus closedset problem assumes', 1);('setof object categories', 1);('applications need detect segment', 1);('new categories savethe need', 1);('new object categories zeroshot object detectionsegmentation', 1);('base classes', 1);('abilityto segment', 1);('new classes', 1);('zeroshot setting suffersfrom', 1);('low novelclass performance highlevel word embeddings', 1);('visual informationto address issue', 1);('recent work', 1);('open vocabulary setting', 1);('visual backbone', 1);('images learning', 1);('rich visual', 1);('vision language', 1);('approaches eg', 1);('vild', 1);('effectivemethods distill knowledge', 1);('detectors orsegmentation methods', 1);('works decouple learning', 1);('open vocabulary classication detectionsegmentation twostage pipeline', 1);('stateoftheart solutions', 1);('openvocabulary detectionsegmentation', 1);('dataset enlargethe', 1);('augments detection dataset imagecaptionpairs', 1);('internet recent xpm', 1);('alsopretrains model caption datasets', 1);('complex architecture design toleverage', 1);('performanceimprovement methods costeffective termsof data utilization paper explore use caption data', 1);('vision tasks', 1);('671arxiv230100805v1 cscv', 1);('jan', 1);('encodera', 1);('alarm clockand key flask bedvision', 1);('encodertext encodervision encodera', 1);('alarm clockand key flask bedword', 1);('encodervision encodersentence encodergrounding', 1);('lossgeneration lossc', 1);('object nouns caption generationword', 1);('featuresword featuressentence featuresobject nouns featuresa teddy', 1);('alarm clock beda', 1);('ovr cnn words', 1);('openseg nouns adjectivesnouns adjectivesextract', 1);('object nounsa teddy', 1);('alarm clockand key flask bedstage', 1);('pretraining', 1);('caption', 1);('encoderagnostic', 1);('segdet lossdetseg lossdetseg lossfigure', 1);('uses words caption', 1);('netunes twostage pipeline b', 1);('uses extraagnostic head segmentation', 1);('c method encodes object nouns captions caption groundingand words caption generation', 1);('frameworka woman', 1);('umbrellacar umbrella bus carthere', 1);('example instance segmentation panoptic segmentation', 1);('cgg categories', 1);('novel categoriessentences', 1);('knowledge rst', 1);('generation', 1);('frameworkrequires model align text', 1);('corresponding regionfeatures eg', 1);('1a b', 1);('learns model thatoutput caption', 1);('imagery input relationshipbetween', 1);('vocabulary instance segmentation', 1);('caption dataencode', 1);('rich structural semantic information mayhelp process novel class detection', 1);('1a adopts caption modelin', 1);('process caption data detection results', 1);('generation andinstance segmentationour framework', 1);('novel caption', 1);('extra caption decoder generation loss asshown', 1);('1c caption data', 1);('exploitedin input output stages', 1);('particular useobject queries inputs', 1);('input stage', 1);('object nouns groundeach object query', 1);('output stage lightweight', 1);('inthe generation loss losses', 1);('mutual effect novel class segmentation', 1);('training inference methoddrops caption generation module', 1);('ovis ospswith', 1);('extra computation costwe', 1);('different settings', 1);('instance segmentation ovisand', 1);('experimental', 1);('methodachieves signicant improvements novel classes', 1);('strong baseline', 1);('theproposed', 1);('new stateoftheart results oncoco', 1);('ovis coco osps', 1);('complex pipelines', 1);('figure', 1);('shows ourmethod predicts instance segmentation panoptic segmentation', 1);('corresponding caption', 1);('particular ourmethod', 1);('large improvement', 1);('map overprevious', 1);('previous method', 1);('related workzeroshot detection segmentation scaling', 1);('datacollection annotation laborious', 1);('expensive forlarge vocabulary detection segmentation', 1);('zeroshotdetection', 1);('segmentation', 1);('tries detectsegmentnovel categories annotations accessible training process', 1);('studies address problem', 1);('text embeddings', 1);('capacity ofword embeddings advent', 1);('visionlanguagemodels vlms', 1);('recent studies', 1);('open vocabulary settingopen', 1);('vocabulary object detection ovod recentstudies', 1);('open vocabulary', 1);('pretrainedlanguagetext pairs', 1);('captions text promptsfor instance', 1);('imagecaption data', 1);('novel objects netunes themodel zeroshot detection', 1);('works onimage classication', 1);('largescale imagetext pairs datasetsvild', 1);('rich representation', 1);('detpro', 1);('works extract pseudo region annotations', 1);('additional trainingdata detectors', 1);('improves performanceon novel classes image classication datasets', 1);('maxsize proposal image labelsmethods', 1);('enlargethe capacity training data nd', 1);('rare classes thusthey need computationannotation costs complexpipelines contrary focus', 1);('novel classes caption data', 1);('vlmsopen vocabulary segmentation ovs', 1);('ovodovs', 1);('model segment novelclasses', 1);('current', 1);('ovs', 1);('decouple maskgeneration mask classication', 1);('different stepsthe', 1);('generates mask regions', 1);('performs classication', 1);('denseclip', 1);('similar pipeline', 1);('ovd', 1);('pseudo masklabels method', 1);('endtoend pipeline', 1);('caption learning groundinggeneration segmentation learning', 1);('extract object nouns captions', 1);('thannouns adjectives', 1);('text encoderswe use', 1);('vlmalign', 1);('focus instancelevel openvocabulary segmentation task', 1);('semantic segmentationimage', 1);('captioning', 1);('model generate captions describe content images 59stateoftheart methods', 1);('multimodal attention designs', 1);('task multimodal translation problem', 1);('focus work design anew', 1);('model explore image', 1);('open vocabulary learning enhance novelclass discovery ability', 1);('knowledge study isthe rst attempt explores caption generation', 1);('ovs3 methodologyin', 1);('section rst review background openvocabulary instance segmentation', 1);('present ourcaption', 1);('grounding generation', 1);('framework aimsto', 1);('caption data joint caption groundingand generation31', 1);('backgroundproblem setting', 1);('rst describe openvocabularyproblem setting', 1);('dbfimymgnbm1be', 1);('images instance annotations', 1);('ofbase classesvb', 1);('duringthe training', 1);('thingclasses stuff classes', 1);('base classeseach image', 1);('imis', 1);('gtannotationsym', 1);('comprises instance masks', 1);('object classes order detect segmentnovel classes', 1);('leverageadditional imagelevel annotations ie image captions', 1);('letdcficycgncc1be', 1);('training images withimage caption annotations image', 1);('icis', 1);('witha captionyc', 1);('pixellevel annotations captionsare', 1);('vcis', 1);('largerthan base classes ie jvcj jvbj', 1);('additional information image caption datasetwould benecialopenvocabulary instance segmentation aims train amodel segment base classes', 1);('vband', 1);('novel classesvn', 1);('modeluses highlevel semantic embeddings', 1);('weights linear classier focus', 1);('knowledge captions tothe target classes', 1);('representation similaritiesbaseline', 1);('method', 1);('10model baseline', 1);('multimodal trainingwith captions', 1);('encoderdecoder architecture', 1);('object queries theobject queries interact encoder', 1);('image inferencemask2former', 1);('qfqigi', 1);('1nq object query qirepresentsone entity', 1);('multiple layer perceptronsmlps', 1);('project queries', 1);('embeddings maskclassication mask prediction', 1);('object query', 1);('ground truthmask', 1);('loss function islmask \x15clslcls\x15celce\x15diceldice wherelclsis', 1);('loss mask classicationandlceandldiceare', 1);('diceloss', 1);('thelearnable classier training inference', 1);('infig 3the', 1);('detect segment3people', 1);('table talkinga group people', 1);('losscaption generation lossclassification lossmask lossbackbonepixeldecoderimage', 1);('decoderqueriesmlpbase categoriesnovel categoriespersontraincarpizzapretrainedembeddingsmulti modalembeddings captiongeneratorsentenceencoderwordencodersentence', 1);('word featuresclassificationpredictionslosslegendtrainablefixedoutputcategoriesobject queriesoutputinput', 1);('imageremaining', 1);('trainingpeople tablefigure', 1);('framework input image', 1);('iis', 1);('mlp', 1);('nqmask', 1);('output pixel decoder query transferredintonqmultimodal embeddings femig similarity class embeddings', 1);('classication predictionsfemigalso outputs', 1);('loss generation loss text', 1);('word encoder sentence encoderclosedset objects', 1);('new framework32', 1);('cgg framework ovsoverview figure', 1);('overall pipeline ourcgg framework', 1);('based mask2former', 1);('text embeddings theweights nal linear classier', 1);('lossesthe caption', 1);('loss caption generation lossa caption generator', 1);('end outputqueries', 1);('sentence encoder wordencoder encode captions object nouns extractedfrom captions sentence', 1);('theformer', 1);('caption generation loss', 1);('loss inference wediscard', 1);('thesame inference procedure', 1);('mask2formerclassagnostic pretraining following', 1);('previous works212869 rst pretrain framework', 1);('basedata annotations classagnostic manner processis', 1);('similar training', 1);('region proposal network rpn', 1);('atthe rst stage goal', 1);('information object queries load', 1);('model joint training caption dataendtoend', 1);('caption grounding previous', 1);('works likeovrcnn', 1);('pretrain models caption datathe core idea', 1);('vision language v2l', 1);('projection layer language data novel classes', 1);('multiple multimodallosses', 1);('auxiliary selfsupervision lossthere', 1);('potential issues', 1);('training caption segmentation', 1);('explore caption data detectionsegmentationannotations training segmenter', 1);('secondlythere', 1);('regionword alignment', 1);('similarities betweenmultimodal embeddings allwords caption databecause', 1);('encounter visionlanguage', 1);('object nouns incaption data', 1);('class categories arealways nouns captionstherefore', 1);('entire sentence inputs extract object nouns sentence', 1);('word encoder extraction nds moreprecise semantic embeddings', 1);('multimodal embeddings', 1);('v2l', 1);('object queries group region', 1);('imagecaption pair', 1);('ic', 1);('rst calculate similarities betweennqmultimodal embeddings femigandnwword', 1);('captionscic 1nwnwxj1nqxi1acijhemiewjisiic 1nqnqxi1nwxj1aiijhemiewji1whereh\x01\x01iis dot product', 1);('vectorsscicandsiicare similarities image', 1);('iand', 1);('cnormalized', 1);('text image', 1);('thenormalization', 1);('asacijexphemiemjipnqi01exphemi0ewjiaiijexphemiemjipnwj01exphemiewj0i2the core idea', 1);('similarity betweenthe', 1);('imagecaption pairs', 1);('unmatched pairs', 1);('low traininggiven batch imagecaption pairs', 1);('bibc', 1);('loss composedof', 1);('textdimensionscas example image perspectivethe', 1);('loss followslicgroi \x00logexpscicpc02bcexpscic0 3and caption perspective', 1);('aslccgroc \x00logexpscicpi02biexpsci0c 4the nal', 1);('sum fourlosseslgro1jbijbixi1liigroii', 1);('licgroii', 1);('lccgrocj5optimizing', 1);('loss aligns multimodal embeddings language embeddings', 1);('large noun vocabularyendtoend', 1);('loss align regions words', 1);('caption data', 1);('generativesupervision signal', 1);('multimodal understanding key insight force modela couple', 1);('wo generation', 1);('input imagefigure', 1);('effectiveness caption generation generatedcaption depicts', 1);('rich information', 1);('object nounsto', 1);('instances relationshipsin image identify novel classes', 1);('groundingloss aims', 1);('nouns query embeddings closeas', 1);('possible generative loss decodes visual', 1);('intothe semantic embeddings', 1);('caption generationmodule', 1);('specic status relationships objects', 1);('multimodal embeddings encodethe regionwise information', 1);('embeddingsfemigas input lightweight caption generatorwhich', 1);('decoder layers', 1);('tosupervise', 1);('distribution text vocabularies', 1);('objective function theresearch eld caption generationlgen\x00nsxt1logp\x12wtjw1wt\x001 6wherep\x12 wtjw1 wt\x001is probability predictinga', 1);('particular word caption \x12denotes parameters generation network', 1);('hence', 1);('loss functionenforces', 1);('sentence consistent input captionc making multimodal embeddings', 1);('various objects potentialrelations imageoverall', 1);('loss', 1);('design overall training loss containsfour items ie classication loss', 1);('lcls', 1);('segmentation losslmask caption', 1);('lgro', 1);('andthe caption generation loss', 1);('lgen following', 1);('classication loss', 1);('dot product multimodal embeddingsemiand base class embeddings logit inputsthe nal loss function', 1);('lis', 1);('summation thefour losses', 1);('l\x15clslcls\x15masklmask', 1);('default setting', 1);('framework weights', 1);('baseline model', 1);('extra losses caption generation head duringthe training inference', 1);('embeddings classes', 1);('dot product', 1);('baseclasses novel classes', 1);('inference procedure', 1);('experiments41 experimental setupdataset settings', 1);('conduct experiments', 1);('baseclasses mask annotations', 1);('target classes', 1);('mask annotations', 1);('training imageswith', 1);('mask annotations base classes', 1);('mask instances base target classes', 1);('training setwith', 1);('images image', 1);('extracaption datasets', 1);('conceptual captions', 1);('3mimagecaption pairs', 1);('extracaption datasets detection datasets', 1);('caption dataset', 1);('cocopanoptic', 1);('different splits', 1);('kratios', 1);('previous works weuse', 1);('extra caption data trainingmetric', 1);('setting report', 1);('precision', 1);('map intersectionoverunion', 1);('iouof', 1);('analyze performances base targetclasses', 1);('testimage inputs', 1);('base classes targetclasses', 1);('onboth base target class images', 1);('model segment target classesand', 1);('class bias base classes', 1);('veryhigh scores', 1);('open vocabulary detectionwith', 1);('setting employ thepanoptic segmentation metrics', 1);('panoptic quality pq segmentation quality sq', 1);('reportknown classes', 1);('reference details data preparation foundin appendiximplementation', 1);('details', 1);('training framework 8gpus minibatch', 1);('gpu', 1);('adamw', 1);('weight decay', 1);('instance segmentationmethodconstrained generalizedbase novel base novel allovr', 1);('set panoptic segmentation ospsnote', 1);('eopsn', 1);('dual', 1);('allunknown things', 1);('complete open', 1);('unknown thing specic category report', 1);('pq sq', 1);('unknown categories', 1);('unknown classmethod', 1);('kknown unknownpqthsqthpqstsqstpqthsqtheopsn', 1);('full image size random crop', 1);('training process', 1);('10for classication head word encoder sentence encoder', 1);('input embeddings output transformer layers', 1);('lvis', 1);('class name parser extract objectnouns captions ensure', 1);('thetop100 queries model outputs', 1);('followingprevious work', 1);('thing mask predictions rst remainingbackground stuff mask predictions', 1);('backbone fair comparison42', 1);('resultsresults ovis', 1);('cggand', 1);('baselines open', 1);('setting novel categories input and68 map', 1);('setting base andnovel categories', 1);('challenging model', 1);('needsto distinguish novel categories', 1);('base categorieswhich data distribution bias training data', 1);('weobserved cgg', 1);('object detectionovod in21k', 1);('cc', 1);('epochs extra data ap50boxnovel ap50boxalldlwl', 1);('yfcc100m', 1);('in21k cc', 1);('laionnovel', 1);('settings shows effectiveness', 1);('language embeddings novel classes', 1);('themfrom base classesresults', 1);('show scalability', 1);('alsoperform experiments open', 1);('base classes base thingclasses', 1);('stuff classes', 1);('unchanged results shownin', 1);('traditional open', 1);('set panoptic segmentation cgg', 1);('performs difcultopen', 1);('eopsn dual', 1);('large marginof', 1);('effective training pipeline', 1);('open vocabulary knowledge caption data ourmodel', 1);('open vocabulary panoptic segmentationresults', 1);('segmentation task alsoevaluate open', 1);('ap50', 1);('score innovel classes', 1);('79in shorter training schedule', 1);('extra data', 1);('previous', 1);('largescale imagetext datasetsthus', 1);('training schedule', 1);('computational cost observe', 1);('inferior results inap50boxall', 1);('shorter training schedule andexposure base classes', 1);('analysiswe', 1);('ablation studies model validate effectiveness component ablations onthe', 1);('metric mapeffectiveness', 1);('intab 4a baseline class', 1);('emb', 1);('transfers class labels', 1);('corresponding text embeddings achievesa', 1);('score 02for novel class comparison', 1);('novel apto222', 1);('caption groundingwhich', 1);('align multimodal embeddings', 1);('module nal scorereaches', 1);('strict regularization', 1);('supervises beyondnouns example caption woman', 1);('performance decreases', 1);('pipeline previous', 1);('ovrcnn69', 1);('train embeddings', 1);('embsegm paper', 1);('pretrain classagnostic segmentor train themultimodal embeddings emion imagetext data nameit segmemb pipelines', 1);('intab 4b', 1);('asa candidate', 1);('inferior others base classes', 1);('signicantlyhigher scores novel classes phenomenon arisesbecause training segmentor', 1);('stage overts thebase classes', 1);('recall novel', 1);('nouns extraction cgg', 1);('extract onlyobject nouns sentences', 1);('validate effectiveness', 1);('different word selection strategies', 1);('extract words allnouns', 1);('object nouns results shownin', 1);('words novel', 1);('objects novel', 1);('decreasesby133 conclusion', 1);('impact models performancelayers', 1);('inuenceof layers transformer decoder caption generator results', 1);('4d test', 1);('layerstransformer decoders observe middle number of4', 1);('harm performance', 1);('map base classes', 1);('butalso increase computational costablation', 1);('classagnostic pretraining', 1);('classagnostic segmentor', 1);('segment base potentialnovel objects training multimodal embeddingsand caption generator ablations effectivenessof classagnostic', 1);('alternatives shownin', 1);('mapon novel classes decreases', 1);('trains multimodal embeddingsand caption generator map novel classes decreasesby', 1);('parameter analysis cgg', 1);('decoder caption generator', 1);('studies comparison analysis', 1);('coco ovisa effectiveness componentsbaseline gro gen base novelclass emb', 1);('gro x', 1);('gen x', 1);('cgg x x', 1);('training pipeline comparisonsettings base novel allembsegm', 1);('nouns extraction caption groundingmethod base novel allall words', 1);('caption generator designlayers base novel all2', 1);('effect classagnostic pretrainingsettings base novel allno', 1);('400freeze classagnostic', 1);('gflops parametersschedule parameters gflopsbaseline', 1);('inference', 1);('8119m 22933a person', 1);('large group cows couple people', 1);('table herd zebras', 1);('grass group cows', 1);('grassthere lot food table', 1);('black white photo', 1);('large brown dog couple elephants', 1);('dirt man', 1);('side hillfigure', 1);('visualization cgg', 1);('instance segmentation top panoptic segmentation bottom categories', 1);('arenovel categories', 1);('imageprediction pair', 1);('caption hascgg class agnostic pretrainfigure', 1);('space multimodal embeddingsfemig dimension embeddings', 1);('class label the17 novel', 1);('classes dot', 1);('corresponding mask', 1);('parameters', 1);('increases by1277 training total', 1);('text data', 1);('smallerthan images batch size', 1);('computational cost caption generator', 1);('thegflops parameters', 1);('inference asthe', 1);('shows thequalitative results', 1);('row shows panoptic resultsand', 1);('row shows instance results', 1);('highlightedin caption result shows framework canidentify segment base novel classes', 1);('comprehensive captions imagesembeddings space', 1);('shows tsnevisualization result', 1);('multimodal embeddingsright embeddings classagnostic', 1);('specically', 1);('model onthe', 1);('embeddings foreach image', 1);('strategy ofmask2former', 1);('mask loss', 1);('result ground truth labels multimodal embeddings', 1);('modelcannot distinguish', 1);('different novel classes embeddingspace classagnostic', 1);('generation embeddingscan formulate groups consistent categories5', 1);('conclusionin', 1);('present joint', 1);('framework instancelevel', 1);('open vocabulary segmentation core insights', 1);('caption contains', 1);('nouns leadsto', 1);('secondly', 1);('caption supervision signal forcesthe model', 1);('novel objects knowledge weare rst', 1);('segmentation caption generationfor', 1);('open vocabulary learning', 1);('signicant performance improvement', 1);('comparable results', 1);('extra largescale datasetspretraininglimitation', 1);('computation resources pretrain framework onextra caption datasets', 1);('vlmssuch clip', 1);('distillation supervision notexperiment', 1);('scale datasets', 1);('lvis openimage', 1);('future workacknowledgement work', 1);('key', 1);('research development', 1);('program chinano2020yfb2103402', 1);('acknowledgethe support', 1);('sensetime', 1);('resources work6 implementation', 1);('detailsbaseline details', 1);('table results', 1);('main paper use thesame', 1);('backbone fair comparison', 1);('thenumber', 1);('object queries 100by default method', 1);('v100 gpus following', 1);('metric use', 1);('apon iou', 1);('inference details', 1);('learning rate multiplier', 1);('backbone data augmentation use default largescale', 1);('lsj', 1);('augmentation random scale', 1);('to20 crop size', 1);('\x021024 use defaultmask', 1);('rcnn', 1);('inference setting', 1);('resize animage shorter side', 1);('forthe inference osps', 1);('default joint mergefor things stuff', 1);('thing mask rst', 1);('area stuff mask prediction thingpredictions', 1);('low score theymay', 1);('high score stuff mask', 1);('splits ovis osps ovis', 1);('48classes base classes', 1);('ospswe', 1);('theunknown', 1);('base classesare person bicycle car motorcycle truckboat bench bird horse sheep zebra giraffe backpack handbag skis kite surfboardbottle spoon bowl banana apple', 1);('instance segmentation object detection panoptic segmentation', 1);('apnovel', 1);('apbbox', 1);('object detectionmethodinstance', 1);('panopticap apnovel apbbox pq pqth pqstclasslabel', 1);('351w gro', 1);('350w gen', 1);('349broccoli carrot pizza donut chair bedtv laptop', 1);('remote microwave oven refrigerator book clock vase toothbrush trainbear suitcase frisbee fork sandwich toiletmouse toasterthe novel classes bus dog cow elephant umbrella tie skateboard cup knife cakecouch keyboard', 1);('scissors airplane catsnowboardfor', 1);('car cowpizza toilet', 1);('boat tie zebra', 1);('table banana bicycle cake sinkcat keyboard bear7', 1);('experiments resultswill joint grounding caption', 1);('fully supervised baseline', 1);('question performablation', 1);('main components', 1);('classembmeans', 1);('text embeddings maskclassication', 1);('classlabel', 1);('layer converts classes contiguous labels', 1);('class embeddings allthree tasks', 1);('forwithin class', 1);('generation modules', 1);('performance gain', 1);('osps weconclude', 1);('vocabularyinstance segmentation', 1);('explore inuenceof caption generation module', 1);('open vocabulary instance segmentation', 1);('shows results thecaption generator', 1);('overall segmentationquality', 1);('increases contrary quality ofthe caption', 1);('generation dropsthis means', 1);('betteropen vocabulary instance segmenter role cap9airplanebuscatdogcowelephantumbrellatiesnowboardskateboardcupknifecakecouchkeyboardsinkscissorsairplanebuscatdogcowelephantumbrellatiesnowboardskateboardcupknifecakecouchkeyboardsinkscissorsground', 1);('truthpredictfigure', 1);('correlation map', 1);('modelpredictions novel classes noun embeddings objectqueries novel classes', 1);('correlatedtion generator force model', 1);('existenceof novel objects', 1);('caption generationmodel goal', 1);('ovis osps8 visual analysis comparisonvisualization analysis nouns object querieswe', 1);('calculate correlation map predictedmultimodal embeddings emiand', 1);('model correctlydistinguish novel classes', 1);('segmentation masksmore', 1);('visual examples caption generation weobserve', 1);('cases caption', 1);('cggcan', 1);('objects notin category list', 1);('categories', 1);('similarity multimodal embeddings andclass embeddings', 1);('class embeddings accessible inference', 1);('top isa couple luggage oor luggage classin validation dataset', 1);('caption generator themodel classies luggage suitcase', 1);('withthe caption generation module', 1);('depicts word luggage bottom imagestennis', 1);('shows morevisualization results captionsmore', 1);('ovis osps infig', 1);('present visual results', 1);('ovis ospstasks cgg', 1);('segment classify novelcategories wellzero', 1);('shot visualization ade20k', 1);('11we show visualization results', 1);('dataset 77cgg detect segment novel classes zero shota couple pieces luggage top floorcgg', 1);('wo generatora couple people', 1);('examples', 1);('objects inthe category listmanner', 1);('generatescomprehensive captions', 1);('depict content theimagesreferences1', 1);('ankan bansal karan sikka gaurav sharma rama chellappa ajay divakaran zeroshot', 1);('daniel bolya chong zhou fanyi xiao yong jae leeyolact realtime', 1);('maxime bucher tuanhung vu matthieu cord patrickperez zeroshot', 1);('semantic segmentation', 1);('jiale cao rao muhammad anwer hisham cholakkal fahad shahbaz khan yanwei pang ling shao sipmaskspatial', 1);('information preservation', 1);('fast image video instance segmentation', 1);('nicolas carion francisco massa gabriel synnaeve nicolasusunier alexander kirillov sergey zagoruyko endtoend', 1);('object detection transformers', 1);('hao chen kunyang sun zhi tian chunhua shen yongming huang youliang yan blendmask', 1);('topdown meetsbottomup instance segmentation', 1);('kai chen jiaqi wang jiangmiao pang yuhang cao yuxiong xiaoxiao li shuyang sun wansen feng ziwei liujiarui xu', 1);('open mmlab detection toolbox benchmark arxiv preprint arxiv190607155', 1);('xinlei chen ross girshick kaiming piotr doll', 1);('artensormask foundation', 1);('dense object segmentation', 1);('bowen cheng maxwell collins yukun zhu ting liuthomas huang hartwig adam liangchieh chenpanopticdeeplab', 1);('simple strong fast baseline forbottomup panoptic segmentation', 1);('quality open', 1);('androuge metrics', 1);('captions layerssegmentation', 1);('caption generationbase novel blue1 blue2 blue3 blue4 cider rouge2', 1);('0289a group people', 1);('skateboards street bathroom sinkwith', 1);('large mirror itfigure', 1);('cgg input image left cgg', 1);('wocaption generation', 1);('right', 1);('mirror category list', 1);('street airplane', 1);('ground lot stuff tablea', 1);('plates food zebra', 1);('lot cars roadaperson', 1);('ontheground anumbrella couple elephants', 1);('bunch bananas', 1);('metal polea plate pizza table abunch ofbikes', 1);('toeach twodifferent', 1);('visualization results', 1);('ovis top', 1);('osps bottom', 1);('bowen cheng ishan misra alexander g schwing alexander kirillov rohit girdhar maskedattention', 1);('universal image segmentation', 1);('1211agroup ofpeople', 1);('display bedroom scene focus', 1);('small tablea couple cars', 1);('fire hydrant room', 1);('visualization ade20k', 1);('instance classes', 1);('classes cocoare', 1);('jia deng wei dong richard socher lijia li kai liand li feifei imagenet', 1);('largescale hierarchical imagedatabase', 1);('jacob devlin mingwei chang kenton lee kristinatoutanova bert pretraining', 1);('deep bidirectionaltransformers language understanding arxiv preprintarxiv181004805', 1);('henghui ding chang liu suchen wang xudong jiangvisionlanguage', 1);('henghui ding chang liu suchen wang xudong jiangvlt visionlanguage', 1);('tpami', 1);('jian ding nan xue guisong xia dengxin dai decoupling', 1);('zeroshot semantic segmentation', 1);('yu', 1);('fangyun wei zihe zhang miaojing shi yue gaoand guoqi li learning', 1);('openvocabulary object detection visionlanguage model', 1);('mark everingham luc van gool christopher ki williamsjohn winn andrew zisserman', 1);('pascal visual objectclasses voc challenge', 1);('yuxin fang shusheng yang xinggang wang yu li chenfang ying bin feng wenyu liu instances', 1);('asqueries arxiv preprint arxiv210501928', 1);('chengjian feng yujie zhong zequn jie xiangxiang chuhaibing ren xiaolin wei weidi xie lin promptdet towards', 1);('openvocabulary detection', 1);('frome gs corrado j shlens', 1);('deep visualsemantic', 1);('golnaz ghiasi xiuye gu yin cui tsungyi lin scaling', 1);('openvocabulary image segmentation imagelevellabels', 1);('springer', 1);('cristina gonz', 1);('nicol ayobi isabela hern', 1);('jos', 1);('ehern andez', 1);('jordi ponttuset pablo arbel', 1);('panopticnarrative', 1);('xiuye gu tsungyi lin weicheng kuo yin cuiopenvocabulary', 1);('vision languageknowledge distillation arxiv preprint arxiv210413921', 1);('kaiming georgia gkioxari piotr doll', 1);('ross girshick mask', 1);('kaiming xiangyu zhang shaoqing ren jian sundeep', 1);('residual learning image recognition', 1);('dat huynh jason kuen zhe lin jiuxiang gu ehsanelhamifar openvocabulary', 1);('robust crossmodal', 1);('jaedong hwang seoung wug oh joonyoung lee bohyung han exemplarbased', 1);('openset panoptic segmentationnetwork', 1);('chao jia yinfei yang ye xia yiting chen zarana parekhhieu pham quoc', 1);('yunhsuan sung zhen li tomduerig scaling', 1);('visual visionlanguage', 1);('noisy text supervision', 1);('alina kuznetsova hassan rom neil alldrin jasper uijlings ivan krasin jordi ponttuset shahab kamali stefan12popov matteo malloci alexander kolesnikov tom duerigand vittorio ferrari', 1);('open images dataset v4', 1);('uniedimage', 1);('classication object detection visual relationshipdetection scale', 1);('boyi li kilian q weinberger serge belongie vladlenkoltun ren', 1);('ranftl languagedriven', 1);('semantic segmentation arxiv preprint arxiv220103546', 1);('liunian harold li pengchuan zhang haotian zhangjianwei yang chunyuan li yiwu zhong lijuan wang luyuan lei zhang jenqneng hwang kaiwei chang', 1);('gao grounded', 1);('xiangtai li shilin xu yibo yang guangliang cheng yunhai tong dacheng tao panopticpartformer learninga', 1);('model panoptic part segmentation', 1);('xiangtai li ansheng zhen zhu houlong zhao maokeyang kuiyuan yang yunhai tong semantic', 1);('ow forfast', 1);('accurate scene', 1);('xiangtai li wenwei zhang jiangmiao pang kai chenguangliang cheng yunhai tong chen', 1);('loyvideo', 1);('baseline videosegmentation', 1);('yanwei li hengshuang zhao xiaojuan qi liwei wangzeming li jian sun jiaya jia fully', 1);('convolutional networks panoptic segmentation', 1);('tsungyi lin piotr doll', 1);('ross', 1);('girshick kaiming hebharath hariharan serge j belongie feature', 1);('pyramidnetworks object detection', 1);('tsungyi lin priya goyal ross girshick kaiming', 1);('doll', 1);('focal', 1);('dense object detection', 1);('tsungyi lin michael maire serge belongie james hayspietro perona deva ramanan piotr doll', 1);('ar c', 1);('lawrencezitnick microsoft', 1);('common objects context', 1);('daqing liu hanwang zhang feng wu zhengjun zhalearning', 1);('neural module tree networks', 1);('ilya loshchilov frank hutter decoupled', 1);('weight decayregularization', 1);('fausto milletari nassir navab seyedahmad ahmadivnet fully', 1);('convolutional neural networks volumetricmedical image segmentation 3dv', 1);('davy neven bert de brabandere marc proesmans', 1);('van gool instance', 1);('spatial embeddings', 1);('adam paszke sam gross francisco massa adam lererjames bradbury gregory chanan trevor killeen zeminglin natalia gimelshein luca antiga', 1);('imperative style highperformance', 1);('learning library arxivpreprint arxiv191201703', 1);('alec radford jong wook kim chris hallacy adityaramesh gabriel goh sandhini agarwal girish sastryamanda askell pamela mishkin jack clark', 1);('transferable visual models', 1);('natural language supervision', 1);('rahman salman khan nick barnes improvedvisualsemantic', 1);('alignment zeroshot object detection', 1);('inaaai', 1);('rahman salman khan fatih porikli zeroshotobject', 1);('andlocalize novel concepts', 1);('accv', 1);('springer2018', 1);('vignesh ramanathan rui wang dhruv mahajan dlwlimproving', 1);('detection lowshot classes', 1);('shaoqing ren kaiming ross girshick jian sunfaster', 1);('towards', 1);('realtime object detection regionproposal networks', 1);('olga russakovsky jia deng hao su jonathan krause sanjeev satheesh sean zhiheng huang andrej karpathyaditya khosla michael bernstein', 1);('imagenet', 1);('largescale visual recognition challenge', 1);('xing shen jirui yang chunbo wei bing deng jianqiang huang xiansheng hua xiaoliang cheng keweiliang dctmask discrete', 1);('cosine transform mask representation instance segmentation', 1);('peize sun rufeng zhang yi jiang tao kong chenfengxu wei zhan masayoshi tomizuka lei li zehuan yuanchanghu wang ping luo sparsercnn endtoendobject', 1);('learnable proposals', 1);('mingxing tan ruoming pang quoc v', 1);('efcientdetscalable efcient object detection', 1);('zhi tian chunhua shen hao chen conditionalconvolutions', 1);('instance segmentation arxiv preprintarxiv200305664', 1);('laurens van', 1);('maaten geoffrey hinton visualizingdata', 1);('jmlr', 1);('oriol vinyals alexander toshev samy bengio dumitru erhan', 1);('neural image caption generator', 1);('huiyu wang yukun zhu hartwig adam alan yuilleand liangchieh chen maxdeeplab endtoend', 1);('panoptic segmentation mask transformers arxiv preprintarxiv201200759', 1);('xinlong wang rufeng zhang tao kong lei li chunhua shen solov2 dynamic', 1);('fast instance segmentation', 1);('yuxin wu alexander kirillov francisco massa wanyenlo ross girshick detectron2', 1);('haiming xu hao chen lingqiao liu yufei yintwostage', 1);('decision improves openset panoptic segmentation', 1);('bmvc', 1);('shilin xu xiangtai li jingbo wang guangliang chengyunhai tong dacheng tao fashionformer', 1);('baseline human fashion segmentation recognition', 1);('keren ye mingda zhang adriana kovashka wei li danfeng qin jesse berent cap2det learning', 1);('amplifyweak caption supervision object detection', 1);('jun yu jing li zhou yu qingming huang multimodaltransformer', 1);('multiview visual representation', 1);('tcsvt', 1);('licheng yu zhe lin xiaohui shen jimei yang xin lumohit bansal tamara', 1);('berg mattnet modular', 1);('attention network', 1);('expression comprehension', 1);('yuhang zang wei li kaiyang zhou chen huang', 1);('loy openvocabulary', 1);('arxiv preprint arxiv220311876', 1);('alireza zareian kevin dela rosa derek hao hu shihfu chang openvocabulary', 1);('hui zhang henghui ding prototypical', 1);('rejection zeroshot semantic segmentation', 1);('haotian zhang pengchuan zhang xiaowei hu yenchunchen liunian harold li xiyang dai lijuan wang luyuan jenqneng hwang jianfeng gao glipv2 unifying', 1);('localization visionlanguage understanding arxivpreprint arxiv220605836', 1);('rufeng zhang zhi tian chunhua shen mingyu', 1);('yan mask', 1);('shot instance segmentation', 1);('wei zhang wenbo nie xinle li yao yu image', 1);('captiongeneration adaptive transformer', 1);('yac', 1);('wenwei zhang jiangmiao pang kai chen', 1);('loy knet towards', 1);('image segmentation', 1);('corr', 1);('wei zhang yue ying pan lu hongyuan zha learning', 1);('longand shortterm user literalpreference multimodal hierarchical transformer network', 1);('aaai', 1);('ye zheng jiahong wu yongqiang qin faen zhang', 1);('cui zeroshot', 1);('bolei zhou hang zhao xavier puig sanja fidler adelabarriuso antonio torralba scene', 1);('throughade20k dataset', 1);('proceedings ieee', 1);('conference oncomputer vision pattern recognition pages', 1);('chong zhou chen', 1);('loy bo dai denseclip extract', 1);('free dense labels clip arxiv preprintarxiv211201071', 1);('xingyi zhou rohit girdhar armand joulin phillipkrahenb', 1);('ishan misra detecting', 1);('imagelevel supervision arxiv preprintarxiv220102605', 1);('pengkai zhu hanxiao wang venkatesh saligramadont', 1);('synthesizing', 1);