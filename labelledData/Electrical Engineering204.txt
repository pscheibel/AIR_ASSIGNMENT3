('tts', 27);('e2e', 23);('hts', 17);('baseline', 7);('hindi', 7);('ieee', 5);('lm', 5);('fig', 5);('waveglow', 5);('hence', 5);('international conference', 4);('icassp', 4);('dmos', 4);('indian languages', 4);('hmm', 4);('data augmentation', 4);('processing icassp ieee', 3);('mos', 3);('tamil', 3);('technical lecture', 3);('error', 3);('language model', 3);('iii', 3);('cmos', 3);('opinion score', 3);('hmmbased', 3);('papers', 2);('annual meeting', 2);('acoustics speech', 2);('interspeech', 2);('system 21hr', 2);('fastspeech', 2);('audio content', 2);('systems', 2);('swayam', 2);('thetacotron2 model', 2);('various systems', 2);('cluster', 2);('hmmstates', 2);('speech data', 2);('hindiand tamil', 2);('htssynthesized', 2);('iv', 2);('ttses', 2);('conversational', 2);('tacotron2based e2e', 2);('english', 2);('indian institute technology', 2);('speech language vol', 1);('computer', 1);('meanopinion score mos scale', 1);('speech quality fortexttospeech systems development assessment', 1);('viswanathan viswanathan measuring', 1);('computational linguistics', 1);('proceedings', 1);('motivations lowresource speech synthesis languagerevitalization', 1);('n brinklow p littell k richmond requirements', 1);('pine', 1);('applied', 1);('international journal', 1);('online exible educationa knowledge survey', 1);('p paul bhuimali kalishankar p aithal r rajesh swayamthe', 1);('speech processing toolkit arxiv preprint arxiv180400015', 1);('espnetendtoend', 1);('watanabe hori karita hayashi j nishitoba unnon e soplin j heymann wiesner n chen', 1);('designand', 1);('markov model toolkit', 1);('young young htk', 1);('toolkit httpshtkengcamacuk29', 1);('resourcesfor', 1);('baby thomas n nishanthi consortium', 1);('linguistics', 1);('association forcomputational', 1);('countsinproceedings 52nd', 1);('h zhang chiang kneserney', 1);('language processing', 1);('seventhinternational', 1);('extensible language', 1);('stolcke srilman', 1);('internationalconference text speech dialogue springer', 1);('indian language text speech synthesizers', 1);('thomas h murthy', 1);('baby n nl', 1);('wavenet mel spectrogram predictions arxiv eprintsarxiv preprint arxiv171205884', 1);('natural tts synthesis', 1);('j shen r pang r j weiss schuster n jaitly z yang z cheny zhang wang r skerryryan', 1);('ssw', 1);('open source neural networkspeech synthesis system', 1);('merlin', 1);('z wu watts', 1);('speech communication', 1);('automatic speech segmentation indianlanguage speech synthesizers', 1);('spectral cues', 1);('baby j j prakash subramanian h murthy signicance', 1);('eighth iscaworkshop speech synthesis', 1);('htsframework speech synthesis indian languages', 1);('common attribute', 1);('christina g rachel v solomi k nandwana k samudravijaya', 1);('ramani', 1);('community httpswwwkagglecomdatasetsrushikeshdargehinditextcorpusselecthi part 2txtgz20 b', 1);('kaggle online', 1);('highquality endtoend text speech arxivpreprint arxiv200604558', 1);('fast', 1);('hu x tan qin zhao z zhao ty liufastspeech', 1);('ren', 1);('bert phonemes graphemes neural tts arxiv preprintarxiv210315060', 1);('jia h zen j shen zhang wu png', 1);('bert modelininterspeech', 1);('english texttospeech synthesis', 1);('kenter k sharma r clark improving', 1);('processingicassp ieee', 1);('ieeeinternational', 1);('owbasedgenerative network speech synthesis', 1);('catanzaro waveglow', 1);('r prenger r valle', 1);('low resource indian languages', 1);('histogram equalizationfor', 1);('texttospeech synthesizer', 1);('hybrid hmmwaveglow', 1);('i45314 r k sudhanshu p anusha h', 1);('processing', 1);('acoustics speechand', 1);('adaptation ttssystems', 1);('li h peng e chang domain', 1);('chu', 1);('expressive texttospeech', 1);('perz r shah j lorenzotrueba lowresource', 1);('g huybrechts merritt g comini', 1);('acousticsspeech', 1);('fast highquality speech synthesis', 1);('jm kim ttsbyttsttsdriven', 1);('mj hwang r yamamoto e', 1);('attention network speechsynthesis', 1);('durian duration', 1);('weng k xu p liu tuo kangg lei', 1);('yu h lu n hu yu', 1);('advanced computational intelligence icaci ieee', 1);('synthesis method', 1);('li qin j zhang speech', 1);('deep learning arxiv preprint arxiv171204621', 1);('effectiveness data augmentation imageclassication', 1);('perez j wang', 1);('iiphdw ieee', 1);('phd', 1);('augmentation improvingdeep learning image classication problem', 1);('mikoajczyk grochowski data', 1);('augmentation methods endtoend speech recognition ondistanttalk scenarios arxiv preprint arxiv210603419', 1);('narisetty kashiwagi watanabedata', 1);('e tsunoo k shibata', 1);('speech', 1);('international conference onacoustics', 1);('recognition outofvocabulary words endtoendasr systems', 1);('synthetic audioto', 1);('x zheng liu gunceler willett', 1);('citeseer', 1);('speech synthesis system hts version 20inssw', 1);('tokuda', 1);('black', 1);('h zen nose j yamagishi sako masuko', 1);('learning httpsnptelacin4', 1);('national programme technology', 1);('prosody texttospeech synthesis ininterspeech', 1);('conversational speechwith', 1);('combining', 1);('lai', 1);('j omahony', 1);('data augmentation arxivpreprint arxiv220714607', 1);('problem lowresource languageagnostic conversational texttospeech', 1);('fastspeechand fastspeech2references1 g comini g huybrechts ribeiro gabrys j lorenzotrueba lowdata', 1);('inthe context nonautoregressive models', 1);('proposedapproach architectureagnostic', 1);('highlight importance proposedmethod lowresource scenario stateoftheart', 1);('andthe synthesis quality', 1);('model novelty workcomes', 1);('quality naturalness', 1);('conversational text', 1);('data augmentationapproach', 1);('conclusionsthis', 1);('approach issuperior endtoend systemsv', 1);('model system 61hr', 1);('evaluated dmosspeech outputproposed', 1);('training data', 1);('systems lowresource scenario', 1);('hindi tts', 1);('vii dmos', 1);('didntreport values tabletable', 1);('e2etacotron2based fastspeech', 1);('scores6for systems evaluation', 1);('vii', 1);('evaluation completelyunseen test sentences', 1);('natural rate basis intelligibility 3systems utterances', 1);('native listeners', 1);('respect theoriginal ground truth audio', 1);('thescore system', 1);('hindiby', 1);('wealso', 1);('tacotron2based fastspeech', 1);('system performs reasonablywell', 1);('able train', 1);('statistical parametric modelsince', 1);('gibberish speech', 1);('hour ofdata', 1);('e2etacotron2 fastspeech', 1);('model trainingamong', 1);('mode alignmentsare', 1);('lowresource training data alignments', 1);('forthe', 1);('teacher model', 1);('tacotron2model', 1);('totrain fastspeech', 1);('data system 21hr', 1);('hour data', 1);('hour datasystem 61hr', 1);('previous experimentsthe', 1);('houroftext speech data', 1);('model experiment', 1);('e2e tacotron2based', 1);('system lowresource settingand', 1);('systems lowresource scenarioin section', 1);('analysis tts', 1);('scores basedon voice quality intelligibilitystatistical signicance pvaluecmos score 00001intelligibility 0019b', 1);('signicance test', 1);('vi statistical', 1);('hence mos', 1);('pvalues lessthan', 1);('vi', 1);('tables iv v', 1);('andintelligibility scores', 1);('statistical signicance', 1);('ptest toprove', 1);('system baseline system', 1);('themos intelligibility comprehension scores', 1);('answers evaluation test', 1);('perceive comprehension scorefor system', 1);('native userscould', 1);('basic questions', 1);('content audio clip', 1);('basedon', 1);('technical lectures stories', 1);('paragraph questions amix', 1);('similar scale of15 comprehension test', 1);('basedon listeners understandability score', 1);('intelligibility', 1);('speech scale', 1);('rate quality', 1);('listeners', 1);('utterances usedin evaluation test', 1);('randomorder focus work', 1);('native evaluators', 1);('thetest', 1);('monotonous listener notswitch b content', 1);('theaudio quality', 1);('various systemslisteners', 1);('crucial topic interest', 1);('technical lectures intelligibility', 1);('andtamil respectivelysince content', 1);('v hindi', 1);('cmosscore', 1);('able comprehend content audio', 1);('proposedsystem subjective evaluation test assessesthe quality speech', 1);('assess system performance andnaturalness voice', 1);('hindi tamil', 1);('test performedfor', 1);('thecomprehension', 1);('repetitions synthetic audio data', 1);('tacotron', 1);('evaluation test', 1);('multiple domainsacross baseline', 1);('subjective evaluations comprehension sentences', 1);('subjective', 1);('tamil ttssystemsevaluatedmosscoreintelligibilitycomprehensionscorebaseline', 1);('v comprehensibility mos', 1);('hindi ttssystemsevaluatedmosscoreintelligibilitycomprehensionscorebaseline', 1);('iv comprehensibility mos', 1);('language model isusedtable', 1);('seethat errors', 1);('comparing fig', 1);('language modelthe language model', 1);('similar trend', 1);('original andsynthetic training data', 1);('tothe mismatch acoustic characteristics', 1);('small increase inthe number word', 1);('e2eaugmented', 1);('htsaugmented', 1);('repetitionsand mispronunciations errors', 1);('analysis word', 1);('typesof errors', 1);('present error statisticsacross', 1);('error statistics', 1);('hindiand', 1);('analysis', 1);('proposede2e hts', 1);('multidomain textsystem', 1);('e2e hts', 1);('multidomain textsystem 4baseline 2e2e', 1);('e2e e2e', 1);('speechsystem 2baseline 1e2e', 1);('tts modelsystem', 1);('systems trainedtag', 1);('iii list', 1);('language modelthe experiments', 1);('language modelfig', 1);('equal amounts data uniform comparisonfig', 1);('speech 85hours', 1);('hours speech', 1);('baseline systemssystem', 1);('foreach dataset text parentheses', 1);('speech data eachlanguage', 1);('lj speechdataset', 1);('building voices default congurations', 1);('andespnet toolkits', 1);('htk', 1);('indicttsdatabase', 1);('hours datasets opensource', 1);('tamilmale', 1);('e xperiments resultsexperiments', 1);('scores bigram pair', 1);('loglikelihood', 1);('system synthesisthis reduces issues', 1);('preprocessor text', 1);('sentences lengthlanguage', 1);('sentence isgreater', 1);('supports thecumulative loglikelihood score', 1);('systemcaptures context', 1);('loglikelihood scores', 1);('loglikelihood scores higherfor', 1);('number wordsin text', 1);('nptellecture', 1);('ii example', 1);('shows average loglikelihood scores structured4table', 1);('loglikelihood score \x00512as threshold experimentsfig', 1);('onthe domain training data', 1);('happensafter0hai0 threshold value', 1);('test sentence probability', 1);('ii', 1);('thenthe', 1);('poor grammatical structure extent', 1);('text point', 1);('aparticular threshold', 1);('bigrampair text score bigram pair', 1);('loglikelihood score', 1);('weobtain', 1);('technique account unseen bigram pairs', 1);('kneserney', 1);('text ortts text multidomain text use', 1);('training text', 1);('nptel', 1);('log likelihood scores', 1);('average', 1);('context dependentpentaphone', 1);('example', 1);('rsonorantfig', 1);('modellnasal axx n tx p lrplosive', 1);('cluster ayes yespentaphone hmm', 1);('ano yescentral', 1);('estimates therelative likelihood sequence words sentence', 1);('srilm', 1);('theerrors synthesis', 1);('language modelinga', 1);('experiments ensure attention weights approximatelydiagonald', 1);('data forfurther', 1);('vocoder adaptationthe model parameters', 1);('raw acoustic waveforms', 1);('phonelevel transcriptions', 1);('indian languagesis', 1);('sequence characters phonemes asinput predicts melspectrograms frame frame anautoregressive manner', 1);('soft attention mechanism', 1);('tacotron2', 1);('system trainingin work', 1);('model parameters occurs leafnodes decision treec', 1);('extrapolate outofdomain word scenarioshowever', 1);('thushts', 1);('unseen phoneme context', 1);('technique ensures', 1);('leaf nodes example', 1);('similar share parameters', 1);('contextdependent pentaphone models', 1);('training data todecide contexts', 1);('topdown approach whichuses phonetic knowledge', 1);('thetechnical domain', 1);('phoneticyesno question', 1);('care unseen context', 1);('htstraining', 1);('mistakes duringsynthesisa decision', 1);('autoregressivee2e model', 1);('duration predictor correspondingto contextdependent pentaphones ensures synthesis isrobust intelligible', 1);('synthesize utterancesthe', 1);('log spectrum approximationmlsa vocoder', 1);('melgeneralized', 1);('number frames', 1);('21the duration model predicts number frames reservedfor phone acoustic model predicts acousticfeatures', 1);('phonehmms', 1);('duration model acoustic model', 1);('contextdependent pentaphone units', 1);('hmmdnn', 1);('phone level', 1);('cls', 1);('thecommon label', 1);('interms constituent phones', 1);('model text rst', 1);('training importanceto train', 1);('sentences \x1915 hours', 1);('totally', 1);('words andacronyms native language', 1);('data uniformitythis step', 1);('special symbols andtext normalization', 1);('text datais rst', 1);('text scripts', 1);('toprepare', 1);('various kinds phonotactics', 1);('diversity text data train thetts model lot context information enablethe', 1);('theintent', 1);('yesno', 1);('wh', 1);('ordinary colloquialconversations', 1);('health lifestyleentertainment science technology', 1);('various domains', 1);('data text data', 1);('web source eachlanguage', 1);('kaggle', 1);('text data collectionwe', 1);('multidomain', 1);('synthesis phases', 1);('training', 1);('outputsplittextmelspectrogramsconcatenatingspeech waveformmultidomaintext datafig', 1);('phasetraining phasedata augment ationconversationaltextlanguage modele2e encoderdecodermodulewaveglowsynthesizedspeech', 1);('tts trainingfinetuninge2e tts retrainingreadtextstudiorecorded', 1);('drop loglikelihood scoreshmmbasedtts systemsyntheticaudiodatasetendtoend', 1);('model circumvent language modelis', 1);('e2etacotron2based', 1);('autoregressive nature', 1);('incorrect phrasessentences', 1);('synthesis mainlydue', 1);('datain instances errors', 1);('highquality speech frommelspectrograms', 1);('awaveglow vocoder', 1);('nale2e model generate melspectrogram frames speechis', 1);('conventional synthesis text', 1);('data restore timbre speakerin', 1);('synthesis theresultant', 1);('utterances morerobotic nature effect', 1);('model trainedsince voice quality', 1);('text audio pairs', 1);('withthe', 1);('speech data synthesize largeamount multidomain text', 1);('training synthesisphases training phase rst train', 1);('system depictedin', 1);('training framework', 1);('p roposed approachthe', 1);('large datasetiii', 1);('autoregressive teacher', 1);('hard cases expense goodduration alignments', 1);('problem word', 1);('fastspeech fastspeech218', 1);('autoregressive models stateoftheart nonautoregressive models', 1);('frameworks tandemwith external language model synthesize conversationaltext', 1);('method rst combinethe', 1);('bestof knowledge', 1);('framework robustthan', 1);('work generatesynthetic data', 1);('containoutofdomain words', 1);('conversational type text', 1);('approaches address challengeof', 1);('system speech domain toenhance prosody pronunciation', 1);('speech synthesisframework', 1);('large amount textcorpus recurrent neural', 1);('bert', 1);('bidirectional encoder representationsfrom transformers', 1);('attempts', 1);('quality speech output', 1);('low resource setting', 1);('heq', 1);('usinghistogram equalization', 1);('htswith', 1);('uses hybrid approach', 1);('hybrid paradigms', 1);('domainspecicspeech unit inventoryparallel efforts', 1);('naturalness oftts systems specic domains', 1);('naturalness andstyle adequacy', 1);('small amount expressivesamples target speaker', 1);('voice conversionfurther', 1);('theavailable recordings', 1);('style top', 1);('usessynthetic data', 1);('quality nonar', 1);('ar', 1);('large amount ofsynthetic utterances', 1);('domain adaptation 13in', 1);('synthetic audio datasets', 1);('address issue data scarcity', 1);('r elated workto', 1);('open questions future researchii', 1);('concludesthe paper', 1);('sectionii', 1);('397the rest paper', 1);('mosscore', 1);('experimentalresults', 1);('subjective evaluations', 1);('cmosand', 1);('conversational text comprehension', 1);('thesystems', 1);('dec', 1);('synthesizedarxiv221211982v1 eessas', 1);('e2e tacotron', 1);('comparison systems alsobuilt', 1);('architecture andwaveglow vocoder', 1);('ar tacotron2', 1);('hindi tamil e2eparadigm', 1);('voices trainedfor', 1);('hts e2e', 1);('especiallyfor conversational textas part work', 1);('repetitions substitutions', 1);('prone errors asword', 1);('degrade gracefullyfor unseen contexts', 1);('owingto', 1);('speech audio', 1);('original text', 1);('framework andaugment', 1);('multidomain text', 1);('current work synthesize alarge', 1);('complement inadequacies inthe training data', 1);('research areas', 1);('popular technique usedin', 1);('systemdata augmentation', 1);('contextrich training data butalso', 1);('tandemwith language model', 1);('speech synthesis system', 1);('novel data augmentation approachwhere synthetic utterances', 1);('inthis', 1);('technical lectures', 1);('synthesis conversationaltext', 1);('text construction', 1);('different scenariosof issues', 1);('text structure', 1);('different typestable', 1);('table shows', 1);('train data', 1);('test dataare', 1);('speech ii contexts', 1);('prone errors', 1);('umm hmm etc', 1);('alsocontain disuencies', 1);('abrupt sentence', 1);('unplannedset words', 1);('text conversational nature', 1);('initial experiment', 1);('vocoderscale conversational speech sentences', 1);('audio synthesis', 1);('systems 2stage pipeline iemelspectrogram generation', 1);('systems not1in paper', 1);('technical lectures usea style speech conversational', 1);('theoriginal video source videos', 1);('content translatedand', 1);('multiple indian languageswhere video', 1);('technical videos', 1);('good quality', 1);('small error inthe audio degrade listeners experience mainobjective paper', 1);('essential applications', 1);('3into languages errorfree', 1);('enhanced learning nptel', 1);('nationalprogramme', 1);('educational classroom lectures', 1);('important task', 1);('thecontext conversational speech synthesis', 1);('recent works highlight', 1);('syllable rate variation prosody variation', 1);('presence disuenciessignicant', 1);('speech scale conversational speech synthesis building conversational speech synthesis systems difcult', 1);('systems1that trainedon', 1);('natural speech', 1);('rapid progress', 1);('synthesis techniques', 1);('advancements texttospeech', 1);('ntroductionwith', 1);('low resourcei', 1);('systems data augmentation language model endtoend', 1);('terms hmmbased', 1);('approachs efcacy lowresource scenariosindex', 1);('frameworks furtheranalysis highlights', 1);('hmm e2e', 1);('synthesisapproach terms intelligibility', 1);('superior baseline', 1);('synthesis errorsfurthersubjective evaluations', 1);('care unseen context outofvocabulary wordsa language model', 1);('contextdependentpentaphone', 1);('due ability model theduration distribution phonemes', 1);('repetitions usuallyabsent', 1);('thework issues word', 1);('voice motivation', 1);('data improvethe timbre', 1);('speech andfurther', 1);('markov', 1);('technical domains usingdata augmentation endtoend', 1);('highquality texttospeech', 1);('madras indiaabstract', 1);('madras india2department electrical engineering', 1);('engineering', 1);('gupta1 anusha prakash2 jom kuriakose1 hema murthy11department computer', 1);('conversational speech synthesis systemsishika', 1);