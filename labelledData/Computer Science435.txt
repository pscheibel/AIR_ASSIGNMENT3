('swin mae', 41);('mae', 24);('fig', 15);('swinunet', 11);('vit', 8);('transformer', 8);('pe', 7);('experimental results', 7);('mask tokens', 6);('computer vision', 5);('international conference', 5);('miou', 5);('imagenet', 5);('learning method', 5);('swin transformer', 5);('swintransformer', 5);('ieeecvf', 4);('iv', 4);('recognition', 3);('de', 3);('loss', 3);('mr', 3);('ablation experiments', 3);('experimental data', 3);('training results', 3);('encoder', 3);('small datasets', 3);('iii', 3);('mri', 3);('natural images', 3);('recent years', 3);('useful semantic', 3);('medical images', 3);('large datasets', 3);('proceedings ieeecvf', 2);('kim', 2);('grant number', 2);('universities', 2);('china', 2);('natural science foundation', 2);('medical dataset', 2);('learning downstreamtasks', 2);('masking', 2);('313decoder ii wo', 2);('dw', 2);('decoder ii', 2);('dsc mpa miou hdnone', 2);('curves test', 2);('position embeddinglayer', 2);('loss curves', 2);('mrimages', 2);('token indexes', 2);('multiple patches', 2);('different decoder designs', 2);('decoder', 2);('absolute position', 2);('swinmae', 2);('data', 2);('mask', 2);('whole image', 2);('method section', 2);('learning results', 2);('cnn', 2);('useful semanticfeatures', 2);('learning models', 2);('ive', 1);('contrastive learning arxiv preprintarxiv220812413', 1);('glandmr image segmentation', 1);('shi parotid', 1);('chen', 1);('wu', 1);('liu', 1);('iv36 z xu dai', 1);('swinunet multimodal images arxivpreprint arxiv220603336', 1);('glandmri segmentation', 1);('shi j fu parotid', 1);('liu li liu', 1);('iiib35 dai z xu', 1);('relativeposition representations arxiv preprint arxiv180302155', 1);('iiib iv34 p shaw j uszkoreit vaswani selfattention', 1);('medical image segmentation arxiv preprint arxiv210505537', 1);('pure transformer', 1);('iia33 h cao wang j chen jiang x zhang q tian wangswinunet unetlike', 1);('deep bidirectional transformers language understanding arxivpreprint arxiv181004805', 1);('iib32 j devlin mw chang k lee k toutanova bert pretrainingof', 1);('strong data augmentations arxivpreprint arxiv210601548', 1);('vision transformers outperform resnets', 1);('gong', 1);('iia iiic31 x chen cj hsieh', 1);('image recognitionat scale arxiv preprint arxiv201011929', 1);('transformers', 1);('beyer kolesnikov weissenborn x zhait unterthiner dehghani minderer g heigold gelly', 1);('iib iiib iiic30 dosovitskiy', 1);('vision', 1);('international conference oncomputer', 1);('vision transformer', 1);('hierarchical', 1);('guo swin', 1);('i29 z liu lin cao h hu wei z zhang lin', 1);('medical image analysis arxivpreprint arxiv220305573', 1);('zhou h liu j bae j samaras p prasanna self', 1);('i28', 1);('image computingand computerassisted intervention springer', 1);('j hu liu g li x wan th changmultimodal', 1);('i27 z chen', 1);('feichtenhofermasked', 1);('wei h fan xie cy wu yuille', 1);('i26', 1);('machinelearning pmlr', 1);('i25 shi n siddharth p torr r kosiorek adversarial', 1);('image modelingarxiv preprint arxiv220513515', 1);('hierarchical vision transformer', 1);('qian yamasakigreen', 1);('wang', 1);('huang zheng', 1);('i24', 1);('computer vision springer', 1);('european conference', 1);('siamese networks forlabelefcient learning', 1);('bordes p vincenta joulin rabbat n ballas masked', 1);('i23 assran caron misra p bojanowski', 1);('video transformersinproceedings', 1);('yuan bevt bert', 1);('iia iiia22 r wang chen z wu chen x dai liu g jiangl zhou', 1);('proceedings ieeecvfconference computer vision pattern recognition', 1);('scalable vision learners', 1);('r girshick masked', 1);('i21 k x chen xie li p doll', 1);('ieee transactions instrumentation measurement', 1);('3d cnnbasedmultichannel contrastive learning alzheimers disease automaticdiagnosis', 1);('xu', 1);('wang q hu liu', 1);('i20 j li wei', 1);('computervision', 1);('vision transformersinproceedings', 1);('joulin emerging', 1);('j mairal p bojanowski', 1);('i19 caron h touvron misra h j', 1);('vision transformers', 1);('empirical study training', 1);('i18 x chen xie k', 1);('simple siamese representation learninginproceedings', 1);('i17 x chen k exploring', 1);('learningadvances neural information processing systems vol', 1);('new approach', 1);('bootstrap', 1);('avila pires z guo gheshlaghi azar', 1);('tallec p richemond e buchatskayac doersch', 1);('e c', 1);('altch', 1);('strub', 1);('jb grill', 1);('ieeetransactions', 1);('zerobias convolutional autoencoders', 1);('adaptation classify', 1);('i15 e ahn kumar fulham feng j kim unsuperviseddomain', 1);('imaging', 1);('current', 1);('learning formedical image analysis', 1);('i14 k raza n k singh', 1);('midwest symposium circuits systemsmwscas ieee', 1);('map 2020ieee 63rd', 1);('ofcovid19 chest xray images', 1);('barve ford r jha unsupervised', 1);('b king', 1);('i13', 1);('appliedintelligence', 1);('covid19 ct infection segmentation network', 1);('i12 h chen jiang loew h ko unsupervised', 1);('imageanalysis', 1);('medical image analysis', 1);('advances clinicalapplications', 1);('zheng qiu recent', 1);('thai k moore r smannel h liu', 1);('i11 x chen x wang k zhang km fung', 1);('springer', 1);('object detection transformers ineuropean conference computer vision', 1);('zagoruyko endtoend', 1);('massa g synnaeve n usunier kirillov', 1);('i10 n carion', 1);('conferenceon machine learning pmlr', 1);('transformerwithout convolution region supervision', 1);('kim vilt visionandlanguage', 1);('b son', 1);('i9', 1);('internationalconference machine learning pmlr', 1);('natural language supervision', 1);('transferablevisual models', 1);('learning', 1);('hallacy ramesh g goh agarwalg sastry askell p mishkin j clark', 1);('i8 radford j', 1);('conference onapplications', 1);('proceedings ieeecvf winter', 1);('medical imagesegmentation', 1);('landman h r roth xu unetr transformers', 1);('i7 hatamizadeh tang v nath yang myronenko', 1);('ieee transactions geoscience remote sensing', 1);('hyperspectral image classication withtransformers', 1);('zhang plaza j chanussot spectralformer rethinking', 1);('gao', 1);('i6 hong z han j yao', 1);('simple robust lidarcamera fusionframework arxiv preprint arxiv220513790', 1);('wangand z tang bevfusion', 1);('i5 liang h xie k yu z xia z lin wang tang', 1);('automatica sinica', 1);('ieeecaa', 1);('longrange learning general image fusion', 1);('fan j huang x mei swinfusioncrossdomain', 1);('tang', 1);('i4 j', 1);('visual media', 1);('baselines pyramid vision transformercomputational', 1);('improved', 1);('shao pvt', 1);('liang lu p luo', 1);('wang e xie x li dp fan k', 1);('i3', 1);('image computing computerassistedintervention springer', 1);('transformer brain tumor segmentation', 1);('zhu nestedformer nestedmodalityaware', 1);('wan han', 1);('yu', 1);('i2 z xing', 1);('inneural information processing systems vol', 1);('advances', 1);('jones n gomez kaiser polosukhin attention', 1);('vaswani n shazeer n parmar j uszkoreit', 1);('grant number 61872075references1', 1);('science foundation', 1);('nationalnatural', 1);('n21240063', 1);('imaging intelligenceresearch', 1);('jc2019025', 1);('grant numberno', 1);('fundamentalresearch', 1);('number 2019zd0751 part', 1);('liaoning provincegrant', 1);('n2019002', 1);('fundamental research', 1);('grant number1161902058 part', 1);('program', 1);('part youth', 1);('conict interestsacknowledgmentsthis research', 1);('competing interestthe', 1);('solveclinical problems issues deserve study andconsideration', 1);('tasks noevidence', 1);('enable network tolearn', 1);('tasks upstream', 1);('practical importancesuch image fusion', 1);('real situationunlike image generation tasks', 1);('images representthe bias dataset', 1);('onthe data', 1);('predicts content', 1);('small data setscan helpful tasksbroader impacts', 1);('complete labels fact morerealistic tasks', 1);('learning solvetasks', 1);('imagenetfurther', 1);('tasks achievingequal', 1);('small datasets andwithout', 1);('paper overcomesthe problems', 1);('incnn making', 1);('lacks inductive bias', 1);('requirement size dataset theother hand', 1);('pure images', 1);('labels assistin training learns', 1);('beena difcult problem', 1);('onclusionunsupervised', 1);('small datasetsv c', 1);('good solution problem', 1);('good resultson', 1);('easy train obtains', 1);('transformernetworks', 1);('common problem', 1);('learning model', 1);('312decoder ii w', 1);('315decoder w', 1);('318decoder wo', 1);('ivtransfer learning evaluation metrics ofdownstream tasksusing different pre trained models training', 1);('outperforms model', 1);('good transfereffects', 1);('swin maethe', 1);('learning model trainedon', 1);('supervised', 1);('evaluation metrics model test', 1);('thefour', 1);('task training', 1);('observewhether performance', 1);('learning networks', 1);('learning models initialization weightsto train', 1);('previous research36', 1);('uses encoder iii decoder usesboth ii addition', 1);('thetransfer learning results', 1);('models experiment', 1);('tasks random initialization', 1);('previous experiments', 1);('comparison', 1);('line graph', 1);('themae paper optimal', 1);('similar conclusion', 1);('learning results ofdownstream tasks', 1);('shows theeffect', 1);('uses encoder iii anddecoder ii experiment settings sameexcept', 1);('medical images differ', 1);('useful latent representationsthus', 1);('easy notconducive', 1);('tasks difcult', 1);('upstream', 1);('ratio ratio mask tokens tokensand hyperparameter affects difculty upstreamtasks', 1);('ratio experimentsthe', 1);('increase difculty ofthe upstream task', 1);('method tomask', 1);('patchpartition layer', 1);('tasktherefore size patches', 1);('betterthan random', 1);('learningresults window', 1);('loss upstream task', 1);('iiithe', 1);('task criterion fourevaluation metrics test', 1);('learning need', 1);('dsc mpa miou hdrandom', 1);('iiitransfer learning evaluation metrics formasking method experiment masking', 1);('method experimenttable', 1);('effectiveness offig', 1);('patchesthis reason', 1);('7b maskingpatches', 1);('low difculty ofits upstream task', 1);('loss ofthe random', 1);('learning results fact', 1);('maysuggest random', 1);('loss curve upstream task', 1);('swin maeusing', 1);('experiments alluse encoder iii decoder ii difference thedifferent', 1);('setof ablation experiments', 1);('effectiveness method', 1);('iiito', 1);('method experimentswe', 1);('learning resultsc', 1);('poor decoder weight', 1);('likely gap thatleads', 1);('classto pixels', 1);('original pixelsof', 1);('thedownstream task', 1);('inthe upstream task', 1);('different task goals', 1);('due tothe', 1);('learning leadto', 1);('decoder weights', 1);('row table show retainingand', 1);('results theexperiment', 1);('output width encoder andthe input width decoder unnecessarydecoder', 1);('complex increases difculty modeloptimization', 1);('320decoder ii w', 1);('315decoder ii w', 1);('dsc mpa miou hddecoder', 1);('iitransfer learning evaluation metrics fordecoder design experiment training', 1);('curves decoder design experimenttable', 1);('decoder embedding9fig', 1);('layer nd', 1);('comparingthe', 1);('thedecoder design', 1);('decoder hasgood', 1);('signicantdifference results decoder ii whichindicates', 1);('abbreviation decoder weightsthe', 1);('ii de', 1);('evaluation metricsare', 1);('anadditional experiment', 1);('results explore question', 1);('pretrainingweights improvement', 1);('downstreamtasks decoder weights', 1);('identicalto decoder', 1);('todownstream tasks', 1);('encoder weights', 1);('autoencoder methods', 1);('results upstream tasks signicantlydifferentas', 1);('different decoders', 1);('different decodersare', 1);('layer ablation experimentthe loss curves training process', 1);('decoderii decoder', 1);('removal thislayer affects effect', 1);('encoder isas input width decoder ii', 1);('output width', 1);('encoder input width 512of decoder implementation', 1);('changethe output width', 1);('layerthe role decoder', 1);('removes decoder', 1);('inthis experiment replaces backbone', 1);('decoder decoder ii', 1);('experiment allencoder iii', 1);('effectof decoders encoders', 1);('design experimentssection', 1);('maeb decoder', 1);('encoder design solution forswin', 1);('thereforeencoder', 1);('iii encoder', 1);('numerous problems', 1);('363encoder iii', 1);('369encoder ii w', 1);('339encoder ii wo', 1);('351encoder w', 1);('343encoder wo', 1);('360none w', 1);('itransfer learning evaluation metrics forencoder design experiment training', 1);('due totable', 1);('encoderii', 1);('part ofthe parameters encoder', 1);('encoder notachieve', 1);('amongthem', 1);('ii betterresults', 1);('encoders', 1);('theabbreviation position embeddingexperimental results', 1);('wherenone', 1);('model test', 1);('evaluation metrics ofthe', 1);('position embeddinglayer network', 1);('forencoder', 1);('random initialization', 1);('tasks encoder design', 1);('curves encoder design experimentfig', 1);('layeraffects training effect network experiments on8fig', 1);('task additionto', 1);('encodersi ii', 1);('thedownstream task gap', 1);('task experiments considerthat encoders ii', 1);('learning results ofdownstream tasksin', 1);('real effect', 1);('terms upstream tasks encoder iii thebest training results', 1);('differentencoders training upstream task shownin', 1);('fig6the', 1);('encoder iii', 1);('mask tokens thedecoder', 1);('iii need', 1);('fig10 encoder', 1);('maedecoder', 1);('encoders ii', 1);('backbone decoder', 1);('ablation experiments thedecoders', 1);('effect thethree encoders', 1);('different encoder architectures', 1);('design experimentsin section', 1);('tptnfntpfptn5miou tpfntpfp6hdab', 1);('metrics followsdsc 2tpfp 2tpfn4mpa', 1);('betterresults equations', 1);('reects contour variability ofthe segmentation results', 1);('hd', 1);('thearea similarity segmentation results', 1);('dsc mpa miou', 1);('miou hausdorff distancehd', 1);('dsc mean pixel accuracy mpamean intersection', 1);('dicesimilarity', 1);('encoder iithe results model test', 1);('segmentation evaluation metrics evaluatefig', 1);('segmentationtask use', 1);('layersevaluation metrics', 1);('frozen training', 1);('noparameters', 1);('random initialization parameters', 1);('connection layer linear projectionlayer', 1);('corresponding layer encoder', 1);('block uses', 1);('onlythe swin', 1);('encoder andbottleneck', 1);('theencoder weights', 1);('general decoder weightsof', 1);('herelrlrmax\x011 cosim\x01\x192 3transfer learning', 1);('data augmentation methods random scalingand', 1);('small angle rotation', 1);('horizontal ippingand', 1);('small datasets variety dataaugmentation methods', 1);('maximum learningratemis total number training epochs iis thecurrent number training epochs alleviate overttingproblems', 1);('number training epochs increasesthe learning rate decreases halfcycle cosine function asshown equation', 1);('1\x0210\x004 40epochs', 1);('maximum learning rate', 1);('batch size isset', 1);('tasks networkstructure', 1);('network structuresegmentation network', 1);('swin mae swin transformerswinunet', 1);('thebackbone encoder', 1);('categoriesi background ii parotid gland iii tumor', 1);('thepixels', 1);('images head neck', 1);('semantic segmentation ofregions interest', 1);('parotid gland tumor segmentation', 1);('weused', 1);('realdownstream task', 1);('effectdownstream tasks', 1);('thenatural image dataset', 1);('medical eld', 1);('sizeof dataset', 1);('images dataset', 1);('learning upstream task thereare', 1);('task atotal', 1);('images layers thethree', 1);('previous study', 1);('approach ofour', 1);('t2 following', 1);('t1and t2weighted', 1);('stir t1weighted', 1);('sequences shorttime inversion recovery', 1);('clinicians patientsmri image contains', 1);('patients parotidtumors parotid tumor segmentation labels', 1);('multicenter multimodal', 1);('experiments sectionis parotid dataset', 1);('settings briey describedbelowdataset dataset', 1);('iii default', 1);('ablation experiments designedto test', 1);('iv iv e xperiments discussionfive', 1);('maepaper', 1);('theexperimental results conclusions', 1);('based', 1);('large maskingratio', 1);('conversely', 1);('learning higherdimensional semantic', 1);('ratio canmake task', 1);('window maskinglayer', 1);('task thespecic', 1);('byy xd\x01d\x01r2 xmodd\x01r 2the', 1);('token twodimensional array tokens isxd\x01rxmodd\x01r', 1);('thetokens sparse list x sparse list turnedinto twodimensional array d\x02d twodimensionalcoordinate index xdxmodd coordinateof', 1);('sparse index', 1);('window contains r\x02rtokens total d\x02dwindows', 1);('leteach', 1);('equal lengths widths twodimensionalarrays', 1);('original imagesare', 1);('lengths widths', 1);('pseudocodeof window', 1);('algorithm', 1);('token indexesthat need', 1);('complete list', 1);('token indexesin windows', 1);('tokens theupperleft corner windows rest', 1);('ratio way', 1);('sparse list indexes need', 1);('aftershufing', 1);('list sparse list', 1);('numindexkeep rangerfor j rangerindexkeepappendindexkeeppart ri jdiscontinuous', 1);('tokens equationindexkeeppart sparsekeep drr sparsekeep r', 1);('indexes part', 1);('indexes list', 1);('tokens tokenssparsekeep sparseshuffle0 dkeepratio', 1);('maskratio ratio', 1);('sparse indexes listkeepratio', 1);('1sparseshuffle argsortnoise', 1);('tokensnoise randd noise', 1);('sparse indexes', 1);('mask indexes', 1);('style number windows r r r number tokens window maskratio ratio mask tokens tokens maskratio', 1);('pythonlike', 1);('pseudocode', 1);('form list', 1);('methodindexes topleft corner window', 1);('diagram window', 1);('schematic', 1);('mriimage', 1);('natural image', 1);('specializedmedical knowledge', 1);('method facilitate understanding readers', 1);('method c', 1);('normal random', 1);('methods originalimage b', 1);('windows tokenfig', 1);('twodimensional array', 1);('cthe practice window', 1);('new method shownin', 1);('methodthe mask results', 1);('method window', 1);('wecall', 1);('smallestunit random mask operation', 1);('shortcut solutions', 1);('easy reconstructionof mask patches', 1);('thesmall area patch', 1);('method causes problems', 1);('method uses patch thesmallest unit mask operation patch divisionsize changes', 1);('part list', 1);('simple efcientthe indexes', 1);('iv window', 1);('experimental data beshown section', 1);('specic', 1);('sensitive tothe design decoder', 1);('good results decoderi ii', 1);('connection layer addedbetween encoder decoderthe', 1);('asmae addition', 1);('map dimensions tokens', 1);('original image dimensions predictor projection layer', 1);('layer restorethe', 1);('nal patch', 1);('predictor headpart', 1);('3072the decoder ii differs', 1);('dimension tokens whichoutput decoder', 1);('\x027 outputof encoder', 1);('number tokens outputby decoder', 1);('token needs', 1);('token decoder', 1);('mask tokens norremove class', 1);('token isnot', 1);('encoder class', 1);('decoderthe decoder', 1);('backbone structure similarto', 1);('decoder ii decoder uses', 1);('different decoder designsis', 1);('backbone structure5fig', 1);('ithe decoder uses', 1);('inthis paper', 1);('tokens isdh\x01w\x01cl1two', 1);('dofthe', 1);('decoder l dimension', 1);('width isw number channels c number', 1);('original image height', 1);('suppose', 1);('original imagesize', 1);('long thenal reconstruction size', 1);('original pixels ne', 1);('reconstruction targetof decoder', 1);('ii', 1);('network training', 1);('batch size otherhand', 1);('hand reducecomputation memory usage', 1);('exiblya lightweight decoder design', 1);('learning fordownstream tasks decoder', 1);('trainingand encoder weights', 1);('designin general decoder weights', 1);('encoder design uses scheme andthe specic', 1);('swin maes', 1);('design iii bestresults', 1);('howeverour', 1);('althoughit', 1);('usageencoder iii', 1);('gpumemory', 1);('enlargement image size lead increase thecomputation network training', 1);('besidesthe', 1);('mayaffect results', 1);('original imagecontent', 1);('\x024 resultsin patch', 1);('uses patch size', 1);('image length width patch partitionoperation', 1);('network parameters', 1);('task parameters patch partitionlayer position', 1);('layer swin transformer block', 1);('learning resultencoder ii', 1);('thedownstream task affects', 1);('block parameters', 1);('layer ofswin', 1);('model lack layer patch', 1);('hasits advantages disadvantages', 1);('encoder designs', 1);('layer isremovedeach', 1);('different encoder designsgains', 1);('relative absoluteposition', 1);('relative position', 1);('inaddition', 1);('original number iii', 1);('number tokens asthe', 1);('original number', 1);('becomesfour times', 1);('length width image sothat number tokens', 1);('layer swin transformerblock', 1);('iremove nal patch', 1);('different encoderdesigns', 1);('tokens end', 1);('mask tokens resultin', 1);('removing', 1);('numberof tokens', 1);('learnable vector', 1);('swin maedoes', 1);('block consistent withthe encoder', 1);('blocks total withno patch', 1);('swint', 1);('layer thevalue', 1);('\x024 sizein patch partition layer length tokens', 1);('decoder design shownin gure', 1);('themask patches', 1);('network training focus', 1);('loss calculationwhich', 1);('mask patches', 1);('original images', 1);('training calculates', 1);('original imagesthe loss function', 1);('tothese latent representations restore', 1);('highdimensional semantic space decoder', 1);('corresponding tokens', 1);('parts encoder decoderthe encoder network', 1);('similar autoencoder methods', 1);('andthe network structure', 1);('p roposed methoda overviewour swin mae', 1);('mae swintransformer', 1);('improves computational efciencyin summary', 1);('number patches', 1);('swmsa', 1);('window multihead selfattention', 1);('different windows', 1);('exchange informationbetween patches', 1);('wmsa', 1);('computes window multiheadselfattention', 1);('excessive patches', 1);('compute theglobal attention', 1);('results imageanalysis tasks addition network', 1);('reduces dependenceon size dataset', 1);('token introduces theinductive biases', 1);('receptive eld', 1);('number tokens expandthe', 1);('swin transformer block patch merginglayer', 1);('\x024 size followedby', 1);('similar tocnn patches rst', 1);('uses network structure', 1);('vitswin transformer', 1);('difcult train', 1);('medical images datasets', 1);('network structureeld', 1);('datasetswith millions images', 1);('models31 eld', 1);('locality translation equivariance', 1);('cnneg', 1);('ontransformer network lacks inductive bias', 1);('efcientstructure good results', 1);('iiib vit swin transformervit', 1);('detail section', 1);('patches window maskingmethod', 1);('small size patches minimumunit', 1);('random way order', 1);('experiments paper', 1);('effect random', 1);('experiments paperiv', 1);('data augmentation usedto train', 1);('relyingon data augmentation', 1);('learnuseful semantic', 1);('original imageiii', 1);('size canbe', 1);('layer needs', 1);('reconstruction result decoderdoes size output', 1);('tokens reconstructiontarget', 1);('original pixels', 1);('good results achievedby', 1);('reconstruction target', 1);('iiiii', 1);('tasksthe specic encoder design', 1);('hasgood performance', 1);('real images', 1);('alarge percentage encoders input training maskpatches case', 1);('increases network computationbut', 1);('mask tokens duringrandom', 1);('briey followsi', 1);('conclusions themae paper', 1);('exampleits network structure diagram', 1);('base version', 1);('vits', 1);('suitablefor problem', 1);('convolutional operations', 1);('traditional cnn', 1);('thewhole image needs', 1);('nlp', 1);('independent objects tokens', 1);('individual words', 1);('encoder autoencodersince images', 1);('input output network originatefrom object method', 1);('original image', 1);('approach input', 1);('nlpas', 1);('bert', 1);('v ii r elated worka maethe swin mae', 1);('work paper section', 1);('iidescribes', 1);('natural imagesthe rest paper', 1);('maeon', 1);('similar reconstruction results', 1);('whole image looksblurrier', 1);('contrast texture details reconstructedimage', 1);('sequence imagesof', 1);('good effect', 1);('swin maeachieves', 1);('regions inthe images', 1);('different colors', 1);('missingboundary contours', 1);('specically', 1);('real situation similarity reconstruction tothe groundtruth', 1);('details reconstructions', 1);('althoughin', 1);('original aspect ratio mask part theimage', 1);('square input thenetwork presentation purposes image', 1);('theimage', 1);('parotid image middle', 1);('leftparotid image', 1);('format composedof', 1);('rgb', 1);('color images gure threechannel images', 1);('network structureare', 1);('dec', 1);('part validation imagesarxiv221213805v1 cscv', 1);('autoencoder toobserve effect', 1);('tasksto visualize role', 1);('models equalor', 1);('dependent onlarge datasets', 1);('problem training', 1);('introduces inductive bias', 1);('compared vit', 1);('applicable small datasetswe', 1);('reconstruction middle groundtruthright', 1);('results validation images triplet show', 1);('example', 1);('studies eld', 1);('autoencoders theeld', 1);('excellent studies', 1);('data augmentation year', 1);('medical image analysismae', 1);('difcult use', 1);('applicable medical images 20which', 1);('natural images eg random', 1);('medical images mostlyintact singlechannel data augmentation methods', 1);('data augmentation', 1);('learning results eldof', 1);('dino', 1);('moco', 1);('simsiam', 1);('contrast learning methods asbyol', 1);('learning methods eld computer vision havealso', 1);('medicalimage analysis problems', 1);('challenging collectlarge datasets', 1);('tremendous pressure onthe healthcare industry making', 1);('global prevalence ofcovid19', 1);('especially', 1);('medical imageanalysis', 1);('howeverfurther', 1);('learning methods eld computervision', 1);('mae swin transformeri ntroductionin', 1);('small dataset', 1);('terms', 1);('available soonindex', 1);('learning results downstreamtasks code', 1);('onimagenet terms', 1);('dataset fewthousand', 1);('applicable small datasets', 1);('tomake', 1);('methods need', 1);('medical imageanalysis problems', 1);('learning notrequire labels', 1);('unsupervised', 1);('lack largesizedand', 1);('learning models medicalimage analysis', 1);('datasetszian xu yin dai fayu liu weibing chen yue liu lifu shi sheng liu yuhang zhouabstract', 1);('mae masked autoencoders', 1);