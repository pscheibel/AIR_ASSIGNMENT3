('attack [', 85);('astfocus', 62);('key frames', 45);('eq', 35);('key regions', 33);('map', 30);('figure', 27);('fr', 26);('spatial agent', 22);('sparse', 22);('query number', 21);('x0', 21);('nq', 21);('temporal agent', 20);('rlsb', 19);('pgd', 16);('geo-trap', 16);('vbad', 16);('heuristic', 15);('motion-sampler', 14);('qn', 14);('threat model', 13);('c3d', 13);('nes', 12);('adversarial', 11);('policy network', 11);('perturbation magnitude', 10);('marl', 9);('sota', 8);('dnns', 8);('specically', 8);('temporal', 8);('adversarial perturbations', 8);('video recognition models', 7);('adversarial videos', 7);('threat models', 7);('multi-agent reinforcement learning', 7);('adversarial robustness', 7);('adversarial video', 7);('common reward', 7);('hmdb-51', 7);('cvpr', 7);('black-box attacks', 6);('spatial redundancy', 6);('key patches', 6);('successful attack', 6);('cnn', 6);('lstm', 6);('tsn', 6);('black-box threat models', 5);('wei', 5);('temporal redundancy', 5);('whole video', 5);('reinforcement learning', 5);('spatial', 5);('eq.', 5);('datasets', 5);('various rewards', 5);('x. wei', 5);('large number', 4);('common rewards', 4);('original video', 4);('video', 4);('black-box', 4);('video data', 4);('temporal domain', 4);('pgd+nes', 4);('policy networks', 4);('ablation study', 4);('video attack', 4);('video frame', 4);('gradient estimators', 4);('patch size', 4);('ground-truth label', 4);('ucf-101', 4);('kinetics-400', 4);('tsm', 4);('slowfast', 4);('test videos', 4);('effects', 4);('neurips', 4);('aaai', 4);('compared', 3);('gradient estimation', 3);('whole query number', 3);('owing', 3);('video recognition', 3);('apis', 3);('china', 3);('technically', 3);('video dimension', 3);('rl', 3);('adversarial examples', 3);('input video', 3);('comparisons', 3);('action recognition', 3);('i-th frame', 3);('video recognition model', 3);('adversarial example', 3);('target label', 3);('attack efciency', 3);('policy network \x19p', 3);('bi', 3);('mg', 3);('foreground objects', 3);('labels condence', 3);('video frames', 3);('q\x19', 3);('mgvia eq', 3);('compute', 3);('agent learning', 3);('attack effect', 3);('maximum query number', 3);('adversarial attack', 3);('various agents', 3);('rl-based', 3);('spatial agents', 3);('comparative results versus', 3);('different threat models', 3);('# denotes', 3);('attack methodsun-targeted', 3);('targeted', 3);('slwofast', 3);('advit', 3);('a. ilyas', 3);('l. engstrom', 3);('a. madry', 3);('eccv', 3);('iccv', 3);('y.-g. jiang', 3);('adversarial attacks', 3);('acmmm', 3);('songping wang', 2);('safety-critical tasks', 2);('high dimension', 2);('huge computational costs', 2);('high dimensions', 2);('efcient gradient estimation', 2);('spatial- temporal', 2);('focus', 2);('performs attacks', 2);('cooperative prediction', 2);('extensive', 2);('reinforcement', 2);('spatial-temporal', 2);('successful attacks', 2);('computer vision', 2);('leveraging', 2);('spatial domain', 2);('black-box setting', 2);('backbone network', 2);('evolution strategy', 2);('] gradient estimator', 2);('generate perturbations', 2);('adversarial perturba- tions', 2);('query numbers', 2);('huge search space', 2);('similarly', 2);('frame attack', 2);('adversarial noise', 2);('temporal structure', 2);('black-box video attacks', 2);('random noises', 2);('video attacks', 2);('select key frames', 2);('search space', 2);('learning framework', 2);('video classication', 2);('spatial-temporal property', 2);('whole algorithm', 2);('black-box video recognition model', 2);('attack step', 2);('markov decision processes', 2);('optimization algorithm', 2);('object localization problem', 2);('action design', 2);('overall', 2);('mobilenet v2', 2);('fully connected layer', 2);('fcl', 2);('optimal action', 2);('eb\x03 i\x001', 2);('h\x19 i\x001', 2);('states output', 2);('reward', 2);('spatial policy network', 2);('policy', 2);('k-th edge groups', 2);('key video frames', 2);('temporal policy network', 2);('special rewards', 2);('reward function', 2);('reward functions', 2);('action-value function', 2);('partially', 2);('ppo', 2);('algorithm', 2);('recognition', 2);('action categories', 2);('human motion recognition', 2);('recognition models', 2);('mmaction2', 2);('ucf101', 2);('fooling rate', 2);('mean absolute perturbation', 2);('state-of-the-art black-box video attack methods', 2);('metricsdifferent', 2);('baseline', 2);('spa-', 2);('full version', 2);('dimension reduction', 2);('random agents', 2);('qualitative example', 2);('ve video attacks', 2);('zoo', 2);('oud', 2);('w. wang', 2);('y. zhu', 2);('x. li', 2);('c. liu', 2);('y. xiong', 2);('s. yang', 2);('d. tsipras', 2);('k. zhou', 2);('d.', 2);('z. wang', 2);('y. qiao', 2);('towards', 2);('deep action recognition', 2);('j. lin', 2);('h. su', 2);('j. zhu', 2);('black-box adversarial attacks', 2);('ieee tp ami', 2);('h. yan', 2);('b. li', 2);('l. jiang', 2);('j. schmidhuber', 2);('s. li', 2);('c.', 2);('h. zhang', 2);('j. yi', 2);('efcient robustness assessment', 1);('adversarial spatial-temporal focus', 1);('videos xingxing wei', 1);('huanqian y', 1);('abstract adversarial', 1);('robustness assessment', 1);('wide applications', 1);('mainstream video recognition models', 1);('action recognition datasets', 1);('attack outperforms', 1);('index terms adversarial', 1);('analysis f', 1);('ntroduction deep neural networks', 1);('remarkable achievements', 1);('various tasks', 1);('object detection [', 1);('action recognition [', 1);('scene understanding [', 1);('recent', 1);('so-called adversarial examples [', 1);('robustness evaluation methods [', 1);('good implementability', 1);('minimum adversarial perturbations', 1);('robustness [', 1);('accurate assessment', 1);('safety-critical systems', 1);('quantitative metric', 1);('adversarial robustness assessment', 1);('practical values', 1);('recognition [', 1);('spatial re- lationship', 1);('video analysis', 1);('advan- tage', 1);('current video recognition models', 1);('wide ap- plications', 1);('security surveil- lance', 1);('nec- essary', 1);('currently', 1);('commercial cloud', 1);('huanqian yan', 1);('articial intelligence', 1);('beihang', 1);('no.37', 1);('xueyuan', 1);('haidian', 1);('beijing', 1);('corresponding author', 1);('xxwei @ buaa.edu.cn', 1);('easy accessibility', 1);('such cases', 1);('high di- mensions', 1);('additional temporal information', 1);('high-dimension video data needs', 1);('accurate gradient estimation', 1);('minimum ad- versarial perturbations', 1);('reasonable attack algorithm', 1);('video dimensions', 1);('attacks efciency', 1);('perturbations magnitude', 1);('sparse video attacks [', 1);('spatial video attacks [', 1);('methods [', 1);('separate steps', 1);('different domains', 1);('wherearxiv:2301.00896v1 [ cs.cv ]', 1);('jan', 1);('overview', 1);('gradient estimation [', 1);('evaluations efciency', 1);('above points', 1);('precise key frames', 1);('black-box attack', 1);('gradient estimator module', 1);('gradient estimator', 1);('local adversarial perturbations', 1);('predictbetter key frames', 1);('feature maps', 1);('input video frames', 1);('lstm-', 1);('] structures', 1);('own characteristic', 1);('optimal actions', 1);('temporal agents actions', 1);('different key frames', 1);('different patch regions', 1);('appear- ance', 1);('whole owchart', 1);('conference version [', 1);('major improvements', 1);('firstly', 1);('spatial redundancy besides', 1);('previous version', 1);('videos spatial-temporal character', 1);('secondly', 1);('cooperative multi-agent', 1);('new idea', 1);('previ- ous version uses single-agent', 1);('thirdly', 1);('experi- ments', 1);('parameter tun-', 1);('experiment sections', 1);('black-box attack method', 1);('adversarial ro- bustness', 1);('adversar- ial perturbations', 1);('key spatial- temporal', 1);('at- tack query numbers', 1);('cooperative multi-agent reinforcement learning module', 1);('specic task', 1);('state-of-the-art video attack al- gorithms', 1);('% query num- ber', 1);('briey review', 1);('astfo-', 1);('cus attack algorithm', 1);('experimental', 1);('whole paper', 1);('r elated works', 1);('videos adversarial', 1);('example [', 1);('wrong output', 1);('human imperceptible', 1);('deliberate conditions', 1);('noise size', 1);('adversarial image attack', 1);('attack space', 1);('image attack algorithms', 1);('such high- dimension video data', 1);('high costs', 1);('especially', 1);('video attack techniques', 1);('nd adversarial videos', 1);('] generate sparse 3d adversarial perturbations', 1);('re- duce', 1);('1-norm regularization', 1);('adversarial pertur- bations', 1);('method shows', 1);('sparse ability', 1);('adversarial video noises', 1);('action recognition systems', 1);('vulnerable frame', 1);('adversarial attack method', 1);('] nds', 1);('black-box video attack methods', 1);('spatial denotes', 1);('jointly', 1);('temporal spatial jointly vbad', 1);('generative adversarial network', 1);('generate adversarial examples', 1);('large misclassication rate', 1);('white-box video attacks', 1);('jiang', 1);('tentative perturbations', 1);('tentative pertur- bations', 1);('image data', 1);('partition-based', 1);('gradient information', 1);('efcient black-box video attack algorithms', 1);('] argues', 1);('intrinsic movement pattern', 1);('regional relative motion', 1);('motion-aware noises', 1);('] search', 1);('recognition model', 1);('salient regions', 1);('spatial reductions', 1);('sparse video attack algorithm', 1);('identify key frames', 1);('poor update mechanism', 1);('unnecessary queries', 1);('] explores', 1);('high computation cost', 1);('saliency maps', 1);('reinforcement learning framework', 1);('recently', 1);('param- eterize', 1);('geo- metric transformations', 1);('temporal search space', 1);('previous work', 1);('on4 key frames', 1);('spatial domain besides', 1);('inherent property', 1);('black- box video attack methods', 1);('videos video', 1);('multiple continuous images', 1);('video processing', 1);('temporal correlations', 1);('simultaneous consideration', 1);('spatial correlation', 1);('research topic', 1);('mainstream algorithms', 1);('image classication', 1);('temporal dimension', 1);('classication performance', 1);('wu', 1);('short- term motion', 1);('long-term temporal clues', 1);('deep neural model', 1);('com- petitive classication performance', 1);('above methods', 1);('spatial- temporal property', 1);('video attack task', 1);('application scope', 1);('ethodology', 1);('baseline video attack algo- rithm', 1);('] attack', 1);('preliminaries', 1);('top-1 information', 1);('category la- bel', 1);('condence score', 1);('x=fxiji=', 1);('mgwith', 1);('ground-truth label ywhere xi2rh\x02w\x023denotes', 1);('mis', 1);('total frame number', 1);('category label', 1);('corresponding condence score', 1);('pro-', 1);('gradient descent', 1);('x0under', 1);('t+ \x01sign', 1);('valid range', 1);('thesign', 1);('cross-entropy loss function', 1);('black-box settings', 1);('patch candidates constitute', 1);('stride equals', 1);('accurate gradient gby', 1);('estimate gby', 1);('g\x191 \x01nnx i=1\x1bi\x01p', 1);('yjx0 t+ \x01\x01\x1bi', 1);('rst samples n=2values\x0eivn', 1);('j2 f', 1);('n=2 +', 1);('gradient gis', 1);('variance \x01', 1);('t\x00 \x01sign', 1);('target category label', 1);('ad- versary', 1);('ground-truth yshould', 1);('target label y0to estimate', 1);('gradients versus', 1);('practial application', 1);('in- efcient', 1);('sample points nis', 1);('large value', 1);('nto compute', 1);('accurate gradient', 1);('iteration t', 1);('small value ofncan', 1);('^x0 t= \x00', 1);('^x0 tis', 1);('proposed astfocus attack', 1);('above idea', 1);('ast- focus', 1);('cooperative multi-agent reinforce- ment learning', 1);('black-box attack process', 1);('mdp', 1);('below.5 3.2.1', 1);('spatial agent spatial', 1);('vision transformer', 1);('candidate patch', 1);('i-th framexi', 1);('bi=fbj', 1);('dgwherebj', 1);('j- th patch region', 1);('total number', 1);('candidate patches', 1);('bj i2rh\x02wdenotes', 1);('patchs size', 1);('optimal patchb\x03 i2biin', 1);('key region', 1);('ap=fb\x03 iji=', 1);('mg.', 1);('dm', 1);('action combinations', 1);('d=', 1);('spatial action apwhen', 1);('sequence video data', 1);('lstm-based', 1);('] structure', 1);('thei-th framexi', 1);('lightweight convolution neural net- work', 1);('users', 1);('cnns', 1);('soft-', 1);('patchs probability pbj i', 1);('categori- cal', 1);('optimal patch region b\x03', 1);('probability values p', 1);('=fpbj ijj=', 1);('dg', 1);('adjacent frames', 1);('local patch', 1);('eb\x03 i\x001of', 1);('patch b\x03 i\x001with', 1);('current frame-level featureseito', 1);('current patch region', 1);('e\x03 i\x001is', 1);('simple multilayer perceptron', 1);('mlp', 1);('corresponding patch', 1);('formally', 1);('=\x19p \x12', 1);('b\x03 i=categorical', 1);('whereh\x19 i\x001denotes', 1);('thei-1-th frame', 1);('state spin', 1);('m times', 1);('optimal action ap=fb\x03 iji=', 1);('attack stops', 1);('parameters \x12p', 1);('reasonable rewards', 1);('multi-agent re- figure', 1);('crucial regions', 1);('learning', 1);('special reward', 1);('intuitive idea', 1);('patchs importance', 1);('performs predictions', 1);('foreground patch', 1);('specic reward', 1);('foreground object', 1);('based', 1);('objectness score', 1);('classic objectness model', 1);('edgeboxes [', 1);('edge response', 1);('ri edgebox reward', 1);('patchb\x03 ican', 1);('ri edgebox =q kwb', 1);('\x01uk 2\x01', 1);('edgebox reward', 1);('redgebox =mx i=1ri edgebox', 1);('patchs width', 1);('large patch', 1);('large edgebox value', 1);('edgebox function', 1);('adversarial patch', 1);('condence score output', 1);('big drop', 1);('condence drop', 1);('common reward rcommon', 1);('rcommon =v', 1);('exponential function', 1);('rep- resents', 1);('ground-truth labels condence', 1);('x0is', 1);('competitive label', 1);('ground-truth la- bel', 1);('different iteration tas', 1);('t-iteration reward', 1);('rt spatial =rt', 1);('common +\x151rt edgebox', 1);('major distinction', 1);('agent aims', 1);('temporal agent aims', 1);('binary classication problem', 1);('key', 1);('whole input videox', 1);('sequence setaf=fo\x03 iji=', 1);('mgjust', 1);('o\x03 i2 f0', 1);('2mdifferent actions', 1);('direct optimization learning', 1);('temporal policy network \x19f', 1);('spatial action afwhen', 1);('skeleton diagram', 1);('current frame-level', 1);('global features eg', 1);('combining', 1);('global video information', 1);('global features egis', 1);('softmax', 1);('probability pito indicateoi=1', 1);('pi=\x19f \x12', 1);('o\x03 i=bernoulli', 1);('bernouli', 1);('h\x19 i\x001denotes', 1);('i-1-th frame', 1);('mtimes', 1);('af=fo\x03 iji=', 1);('temporal policy network interact', 1);('parameters \x12f', 1);('common reward function', 1);('rst specic reward function', 1);('sparse reward rsparse', 1);('rsparse =exp', 1);('mjmx', 1);('l < m', 1);('eval- uate', 1);('representative ability', 1);('video frames need', 1);('semantic information', 1);('whole input video', 1);('representative reward function [', 1);('] rrepis', 1);('mmx', 1);('i=1min t0\x1akjjei\x00et0jj2', 1);('critical video frames', 1);('temporal re- dundancy', 1);('entire video', 1);('key video frames conducive', 1);('successful at- tacks', 1);('thet-th iteration', 1);('corresponding reward', 1);('rt temporal =rt', 1);('common +\x152rt sparse +\x153rt rep', 1);('balance coefcients', 1);('experimental section', 1);('agents interact', 1);('attack.7 3.2.3', 1);('policy network \x19', 1);('backbone f', 1);('construct state s.', 1);('imagenet', 1);('feature extractor', 1);('policy gradient methods', 1);('parameters \x12in order', 1);('av\x19\x12 [', 1);('direction ofr\x12j', 1);('action-value functionq\x19', 1);('policy gradient', 1);('av\x19\x12 [ r\x12log\x19\x12', 1);('actor-critic reinforcement learning framework [', 1);('critic network', 1);('actor', 1);('method focuses', 1);('cooperative multi- agent tasks', 1);('available information', 1);('exam- ple', 1);('de-', 1);('dec-pomdp', 1);('critic approach', 1);('akv\x19k [ r\x12klog\x19k', 1);('k-th agent', 1);('corresponding parameters', 1);('corresponding policy networks', 1);('parameter \x12pand\x19f', 1);('parameter \x12f', 1);('hereq\x19', 1);('state information s= [ sp', 1);('sf ]', 1);('q-value', 1);('agent k.', 1);('com- munication', 1);('own reward', 1);('spatial agent \x19p', 1);('temporal agent \x19f', 1);('proximal policy optimization', 1);('popular single-agent on-policy', 1);('algorithm [', 1);('overall framework', 1);('video ^x0', 1);('key patches height', 1);('black-box video attack algorithm', 1);('input', 1);('clean', 1);('extrac- tor', 1);('max pgd', 1);('learning rate', 1);('output', 1);('initialize', 1);('parameters \x12fand\x12pfor temporal policy network\x19f', 1);('spatial policy network \x19p', 1);('extract', 1);('whilet <', 1);('key regions ap=fb\x03 iji=', 1);('key frames af=fo\x03 iji=', 1);('obtain', 1);('core video ^x=fo\x03 i\x01b\x03 iji=', 1);('estimate', 1);('generate', 1);('x0 x0', 1);('spatial reward rt spatial', 1);('temporal reward rt temporal', 1);('computer\x12fj', 1);('update\x12f', 1);('update\x12p', 1);('m m', 1);('w. astfocus', 1);('utilizes ^x0 t2rm\x02h\x02w\x023to compute', 1);('overall algorithm', 1);('pro- cess', 1);('continuous interaction', 1);('external evalua- tion indicators', 1);('update agents', 1);('e xperiments and results', 1);('public action recognition datasets', 1);('human action classes', 1);('video clips', 1);('datasets divides', 1);('rep- resentative methods', 1);('temporal segment network', 1);('temporal shift module', 1);('network [', 1);('these8', 1);('different modes', 1);('modelsdatasets ucf-101 hmdb-51 kinetics-400 c3d', 1);('% models', 1);('mainstream methods', 1);('video classica- tion task', 1);('open-source toolbox', 1);('video understanding', 1);('pytorch', 1);('au- thors1', 1);('accuracy values', 1);('evaluation', 1);('various sides', 1);('adver- sarial videos', 1);('mag- nitude value', 1);('adversarial perturbation r.', 1);('map=1 mp', 1);('perturbation intensity vector', 1);('query times', 1);('different video attack methods', 1);('threat video model', 1);('average query number', 1);('cost time', 1);('average seconds', 1);('time value', 1);('previous works [', 1);('slight difference', 1);('val- ues', 1);('videos dont', 1);('paper computes', 1);('cost queries', 1);('1. https', 1);('different patch sizes', 1);('state-of-the-art', 1);('attack competitors', 1);('works section', 1);('con- duct comparisons', 1);('fair comparisons', 1);('implementation details', 1);('key metric', 1);('attacks performance', 1);('variance \x01in', 1);('parameter', 1);('patch', 1);('rst hyperparameter', 1);('patch size handwwhen', 1);('spatial agents action', 1);('reasonable patch size', 1);('param- eter', 1);('slight changes', 1);('upper', 1);('lof', 1);('lcan', 1);('minimal key frames', 1);('success- ful video attack', 1);('different upper bounds', 1);('different sample numbers n.', 1);('lis', 1);('lvalue', 1);('big increase', 1);('different evaluation metrics', 1);('4.5.3 sample number', 1);('points nin', 1);('sample number nper', 1);('great inuence', 1);('space changes', 1);('sample number non', 1);('increase ofnvalue', 1);('optimal performance', 1);('weights', 1);('own rewards', 1);('according', 1);('large rewards', 1);('ablation', 1);('different components', 1);('ablation study versus', 1);('different reward weights', 1);('agent versions', 1);('baseline spatial temporal spatial', 1);('temporal fr', 1);('73.3\x062.9 88.3\x062.9 93.3\x062.9 100\x060.0', 1);('6.37\x060.08 4.21\x060.05 4.53\x060.07 3.35\x060.03 recognition model', 1);('gradient estimator module introduces randomness', 1);('ve times', 1);('different metrics', 1);('spatial domains', 1);('agents work', 1);('dimension reduction module', 1);('dense attack', 1);('tial denotes', 1);('number query', 1);('in- deed', 1);('variance value', 1);('comparison experiments', 1);('important role', 1);('video attacks.10', 1);('comparison', 1);('reward versions', 1);('common +edgebox +sparse +representative', 1);('76.7\x062.9 91.7\x062.9 96.7\x062.9 100\x060.0', 1);('3.62\x060.07 3.58\x060.04 3.39\x060.04 3.35\x060.03', 1);('comparison results', 1);('evaluation metrics', 1);('agent outperforms', 1);('random agent', 1);('% \x060 % vs', 1);('% \x062.89 %', 1);('3.35\x060.03 vs 3.62\x060.04', 1);('re- wards', 1);('black-box threat model', 1);('specic rewards', 1);('own agents', 1);('common denotes', 1);('terms +edgebox', 1);('+repre- sentative', 1);('corresponding rewards', 1);('gradu- ally increases', 1);('rightmost column', 1);('rewards improves', 1);('contrast veries', 1);('convergence', 1);('bottom denotes', 1);('target classs condence score', 1);('ground-truth classs condence score', 1);('success- ful', 1);('vice versa', 1);('s values', 1);('stable situation', 1);('good convergence', 1);('s value', 1);('ap- plication', 1);('different iterations', 1);('key cues', 1);('video recognition task', 1);('temporal agent tends', 1);('big changes', 1);('strong representative ability', 1);('shows key frames', 1);('public datasets', 1);('comparative results', 1);('fair comparison', 1);('ucf-101tsm', 1);('big advantage', 1);('clip operation', 1);('proj', 1);('small range', 1);('over-', 1);('accurate evaluation', 1);('models adversarial robustness', 1);('different video models', 1);('% queries', 1);('time metric', 1);('at- tack', 1);('attack integrates', 1);('additional agents', 1);('different gradient estimators', 1);('high efciency', 1);('core idea', 1);('robustness evaluation', 1);('in- depth study', 1);('c3ds', 1);('design robust video recognition models', 1);('integrated', 1);('current gradient estimator', 1);('state-of-the- art gradient estimators', 1);('conduct experi- ments', 1);('prior12', 1);('hmdb-51tsm', 1);('qualitative example output', 1);('bottom rows', 1);('clean video', 1);('convictions [', 1);('perturbation magni- tudes', 1);('only show', 1);('slight variation', 1);('performance versus', 1);('exible framework', 1);('qualitative', 1);('perturbations gener-', 1);('nal adversarial perturbations', 1);('superposition phenomenon', 1);('noise patches gener-', 1);('foreground regions', 1);('attack methods', 1);('imperceptible perturbations', 1);('defense methods', 1);('de- fense methods', 1);('representative video defense methods', 1);('adversarial training', 1);('pgd-at', 1);('network architecture method', 1);('advit2', 1);('kinetics-400tsm', 1);('hmdb-51 metrics pgd-at', 1);('maximum drop', 1);('action recognition models', 1);('onclusion', 1);('novel adversarial spatial- temporal focus attack', 1);('cooperative multi-agent reinforce- ment learning framework', 1);('famous video recognition models', 1);('public action recogni- tion datasets', 1);('acknowledgment', 1);('key r', 1);('d program', 1);('grant no.2020aaa0104002', 1);('national natural science foundation', 1);('no.62076018', 1);('references', 1);('q. lai', 1);('h. fu', 1);('j. shen', 1);('h. ling', 1);('r. yang', 1);('salient', 1);('object detection', 1);('deep learning era', 1);('in-depth survey', 1);('tp ami', 1);('m. zolfaghari', 1);('c. wu', 1);('z. zhang', 1);('j. tighe', 1);('r. manmatha', 1);('m. li', 1);('comprehensive study', 1);('deep video action recognition', 1);('arxiv preprint:2012.06567', 1);('w. deng', 1);('scene', 1);('end-to-end controllers', 1);('autonomous vehicles', 1);('ieee tsmc', 1);('systems', 1);('i. j. goodfellow', 1);('j. shlens', 1);('c. szegedy', 1);('explaining', 1);('arxiv preprint:1412.6572', 1);('s. santurkar', 1);('b. tran', 1);('s.-m. moosavi-dezfooli', 1);('a. fawzi', 1);('o. fawzi', 1);('frossard', 1);('universal', 1);('h. wang', 1);('f.', 1);('z. peng', 1);('t. shao', 1);('y.-l. yang', 1);('d. hogg', 1);('understanding', 1);('s. tang', 1);('r. gong', 1);('y. wang', 1);('a. liu', 1);('j. wang', 1);('x. chen', 1);('f. yu', 1);('x. liu', 1);('a. yuille', 1);('robustart', 1);('benchmarking', 1);('ro- bustness', 1);('architecture design', 1);('arxiv preprint:2109.05211', 1);('s. geisler', 1);('t. schmidt', 1);('h.', 1);('s irin', 1);('d. z', 1);('a. bojchevski', 1);('s. g', 1);('robustness', 1);('graph neural networks', 1);('u.-a', 1);('m. chapman-rounds', 1);('u. bhatt', 1);('e. pazos', 1);('m.-a', 1);('schulz', 1);('k. georgatzis', 1);('fimap', 1);('minimal adversarial perturbation', 1);('k. hara', 1);('h. kataoka', 1);('y. satoh', 1);('spatiotemporal 3d cnns retrace', 1);('l. wang', 1);('d. lin', 1);('x. tang', 1);('l. van gool', 1);('segment networks', 1);('good prac- tices', 1);('c. gan', 1);('s. han', 1);('efcient video understanding', 1);('y. dong', 1);('s. cheng', 1);('t. pang', 1);('query-efcient', 1);('y. guo', 1);('j. yu', 1);('stealthy attack method', 1);('physical world', 1);('s. yuan', 1);('black-box video attack', 1);('ijcv', 1);('j. hwang', 1);('j.-h. kim', 1);('j.-h. choi', 1);('j.-s. lee', 1);('structural', 1);('x. ma', 1);('s. chen', 1);('j. bailey', 1);('z. wei', 1);('j. chen', 1);('t.-s. chua', 1);('f. zhou', 1);('video recogni- tion models', 1);('c. sha', 1);('sparse black-box adversarial attack', 1);('arxiv preprint:2108.13872', 1);('a. athalye', 1);('adversar- ial attacks', 1);('icml', 1);('r. lowe', 1);('y. i. wu', 1);('a. tamar', 1);('j. harb', 1);('o. pieter abbeel', 1);('i. mor-', 1);('multi-agent', 1);('cooperative-competitive environments', 1);('a. makelov', 1);('l. schmidt', 1);('a. vladu', 1);('deep learning models', 1);('arxiv preprint:1706.06083', 1);('d. wierstra', 1);('t. schaul', 1);('j. peters', 1);('natural evo- lution strategies', 1);('ieee congress', 1);('evolutionary computation', 1);('k. greff', 1);('r. k. srivastava', 1);('j. koutn', 1);('b. r. steunebrink', 1);('search space odyssey', 1);('tnnls', 1);('efcient', 1);('sparse attacks', 1);('x. yuan', 1);('q. zhu', 1);('deep learning', 1);('ieee tnnls', 1);('a. neupane', 1);('s. paul', 1);('s. v', 1);('krishnamurthy', 1);('a. k. r. chowdhury', 1);('a. swami', 1);('real-time video classication systems', 1);('ndss', 1);('l. zhu', 1);('y. yang', 1);('motion-excited', 1);('a. aich', 1);('s. zhu', 1);('s. asif', 1);('a. roy-chowdhury', 1);('s. krishnamurthy', 1);('black box video classiers', 1);('geometric transformations', 1);('z. wu', 1);('x. wang', 1);('h. ye', 1);('x. xue', 1);('modeling', 1);('spatial- temporal clues', 1);('l. yuan', 1);('y. chen', 1);('t. wang', 1);('w. yu', 1);('y. shi', 1);('z.-h. jiang', 1);('f. e. tay', 1);('j. feng', 1);('s. yan', 1);('tokens-to-token', 1);('training', 1);('vision transformers', 1);('c. l. zitnick', 1);('doll', 1);('edge', 1);('locating', 1);('object proposals', 1);('t. xiang', 1);('deep', 1);('reinforcement learn-', 1);('video summarization', 1);('diversity- representativeness reward', 1);('konda', 1);('j. tsitsiklis', 1);('actor-critic', 1);('m. t. spaan', 1);('observable markov decision processes', 1);('j. schulman', 1);('f. wolski', 1);('dhariwal', 1);('a. radford', 1);('o. klimov', 1);('proximal', 1);('policy optimization algorithms', 1);('arxiv preprint:1707.06347', 1);('k. soomro', 1);('a. r. zamir', 1);('m. shah', 1);('human actions classes', 1);('arxiv preprint:1212.0402', 1);('h. kuehne', 1);('h. jhuang', 1);('e. garrote', 1);('t. poggio', 1);('t. serre', 1);('hmdb', 1);('large video database', 1);('j. carreira', 1);('a. zisserman', 1);('quo', 1);('new model', 1);('kinetics dataset', 1);('c. feichtenhofer', 1);('h. fan', 1);('j. malik', 1);('k.', 1);('m. contributors', 1);('openmmlabs', 1);('generation video un-', 1);('//github.com/ open-mmlab/mmaction2', 1);('s.-y', 1);('lo', 1);('j. m. j. valanarasu', 1);('m. patel', 1);('overcomplete', 1);('icip', 1);('c. xiao', 1);('r. deng', 1);('t. lee', 1);('b. edwards', 1);('m. liu', 1);('i. molloy', 1);('frames identier', 1);('temporal consistency', 1);('arxiv preprint:1807.07978', 1);('chen', 1);('y. sharma', 1);('c.-j', 1);('hsieh', 1);('zeroth', 1);('order optimization', 1);('deep neural networks', 1);('training substitute models', 1);('aisec', 1);