('ieee', 10);('accessed', 9);('international conference', 9);('motion magnication', 8);('gans', 7);('gan', 6);('figure', 6);('ff', 5);('men', 5);('ieeecvf', 5);('computer vision pattern recognition cvpr', 4);('june', 4);('c iftc', 4);('deepfake source', 3);('fake videos', 3);('faceforensics', 3);('source detection', 3);('international workshop', 3);('york ny usa', 3);('proceedings', 3);('quality quantity', 2);('real motion', 2);('blind', 2);('dec', 2);('overview', 2);('cnn', 2);('fakea vceleb', 2);('detection', 2);('image', 2);('bcd', 2);('traditional deep motion magnication', 2);('phasebased', 2);('sec', 2);('fa vc', 2);('deepfake', 2);('wifs', 2);('iccvw', 2);('umur aybars', 2);('computer vision pattern recognition', 2);('computing machinery', 2);('proceedings ieeecvf', 2);('processing icassp', 2);('sep', 2);('icassp', 2);('justus thies michael zollh', 2);('july', 2);('deepfakes movemotion magnication deepfake source detectionumur aybars', 1);('c iftc ibinghamton', 1);('universityuciftcibinghamtoneduilke demirintel labsilkedemirintelcomabstractwith', 1);('generative models deepfakes', 1);('subtle authenticity signals pristine videosnot', 1);('sota gans', 1);('contrast movement indeepfakes authentic videos motion magnication', 1);('thesubmuscular', 1);('different interpretationsper', 1);('different generative models', 1);('theirgenerative residue approach exploits differencebetween', 1);('deep traditional motion magnication todetect', 1);('video fake source generator ifso', 1);('evaluating', 1);('multisource datasetswe', 1);('video source detectionwe', 1);('complex architectures', 1);('analyze importance magnication', 1);('phase extraction windowbackbone network architecture sample counts sample lengths', 1);('report results', 1);('different skintones assess bias1', 1);('introductionsince', 1);('generative adversarial networks', 1);('deep generative models', 1);('photorealistic results advances transformer', 1);('modules control interpretability ofsuch generators', 1);('zelenskyvideo', 1);('russian invasion', 1);('ukraine', 1);('bruce willis', 1);('tip iceberg desolate digitalfuture', 1);('hand deepfake detection', 1);('efforts 5although deepfake detection', 1);('thanthe generation methods industry', 1);('detection platforms', 1);('trustful futuredeepfake detection research', 1);('main perspectives', 1);('artifacts fakery trainingon', 1);('signals pristine videos', 1);('detectors disadvantages', 1);('datasets trainedon', 1);('prone adversarial attacks', 1);('thusour', 1);('moregeneralizable deepfake detectors dene', 1);('watermark human submuscular motionmoreover deepfake source detection', 1);('deepfake detection anticipate thesemotion cues representative', 1);('onlyvideo authenticity', 1);('generative model behindto', 1);('motion projection generativespaces', 1);('inpristine', 1);('regular human motion emphasis action units othermuscles', 1);('fakevideos observe generative noise overpowers thesubmuscular motion', 1);('motion magniedthe generative noise', 1);('regularhuman motion patterns approach analyzes motion patterns', 1);('real fake', 1);('traditional deep methods', 1);('novel robust', 1);('generalizable deepfakesource', 1);('motion cues improves source detection fake detection', 1);('motion magnication literature', 1);('small temporal motions', 1);('magnication 56which robust', 1);('motion patterns', 1);('inaddition', 1);('dual representation employ 3d', 1);('cnnvariation', 1);('train robust source', 1);('learns human motion extents', 1);('real videos ampliedarxiv221214033v1 cscv', 1);('xedwindow samples extractsand aligns faces samples applies', 1);('outputs trainsa 3d', 1);('source detection aggregates', 1);('sample predictions video predictions classify', 1);('videogenerative noise deepfakes', 1);('different source generators', 1);('addition report deepfake detection results inthe', 1);('wild dataset', 1);('source detection resultsagainst', 1);('complex blind detectors', 1);('importance motion magnication componentswe conduct', 1);('different magnication levels', 1);('simple complex backbones', 1);('different phasewindows', 1);('number minimum frames allskin', 1);('report performance overallsystem', 1);('current deepfake detection workows2', 1);('related workdeepfake generation deepfakes', 1);('generative adversarial networks gans', 1);('theseapproaches', 1);('generate novel', 1);('image domain 2transfer modify facial expressions speech identity ormouth movements reference motion', 1);('entire faces source target media', 1);('approach classify', 1);('deepfake generation techniquesand test datasets', 1);('generators eachcategory', 1);('deepfakes malevolence startsto impact society', 1);('arms race generation detection intensies', 1);('initial', 1);('deepfakedetection research', 1);('blind detectors', 1);('tolearn specic artifacts datasets trainedon', 1);('generalization domaintransfer toany unseen video addition', 1);('adversarial attacks', 1);('62in contrast novel deepfake detectors aim extractunique authenticity signals', 1);('real videos watermarksof humans headpose', 1);('eye gaze properties', 1);('natural physicalor human characteristics consistency correlationof', 1);('interpretable signals', 1);('fake videos sothese approaches', 1);('long asthe', 1);('orthe generative residue rst', 1);('ngerprints synthetic images frequency analysis', 1);('image patterns', 1);('latent representations', 1);('infer modelhyperparameters', 1);('camera attributions', 1);('sensor noise', 1);('source detection deepfakes 20the authors classify deepfakes source', 1);('generative residue biological signal domain approach tackles problem deepfakesource detection', 1);('motion artifactsare representative pristine videos fragile fake videos context', 1);('datasets', 1);('video datasets', 1);('deepfake detection research categorizethese single multi unknownsource datasets', 1);('motion single images', 1);('singlesource', 1);('deepfake datasets createdby easyaccess', 1);('uadfv', 1);('deepfaketimit', 1);('celebdf', 1);('crucial deepfake detection source detection', 1);('multisourcedatasets faceforensics', 1);('generators and6k videos', 1);('dfdc', 1);('generators over100k videos', 1);('generatorsand 20k videos', 1);('diversity consistencyand', 1);('faceforensicsand fakea vceleb', 1);('datasets training', 1);('evaluation approach', 1);('unknownsource deepfakedatasets ie inthewild deepfakes', 1);('understanding model capabilities inthewild setting3', 1);('understanding motion deepfakesfollowing', 1);('authentic representative signals', 1);('real videos', 1);('discussion 19about biological signals', 1);('photoplethysmography ppg', 1);('understanding heart beats deepfakes', 1);('motion veinswould', 1);('actual movement', 1);('inspiredby', 1);('motion consistency deepfakesmotion magnication', 1);('mature research area', 1);('numerous applicationspecic solutions', 1);('counterparts 56motion magnication', 1);('deepfake detection', 1);('negative results', 1);('euler', 1);('video magnication', 1);('explicit motion magnication', 1);('cnnlstm', 1);('claim motion discrepancy usefulnot deepfake detection', 1);('problem nextstep battle deepfakesto analyze motion deepfakes rst', 1);('real fake pairsof videos', 1);('blurs deepmotionmagniedframes structural local', 1);('real videos whereasfake videos experience uniform blur phasebasedmagnication note motion', 1);('blur visual observationcan', 1);('psnr', 1);('realand fake', 1);('different generators', 1);('rst column experience', 1);('supports mainhypothesis motion magnication deepfakes revealtheir source generative model generative noiseis', 1);('motion deepfakes', 1);('row contains', 1);('videos motion', 1);('odd rows methods', 1);('real', 1);('deepfake framesfrom', 1);('different generators4', 1);('motionbased source detectionas', 1);('processing motion magnication neuralnetwork training prediction aggregation41', 1);('frame selectionto', 1);('motion generativeresidue deepfake videos', 1);('select ksample intervals offrames video training samples', 1);('100kthpercentile thevideo intuition', 1);('videos inthese datasets', 1);('training process', 1);('detection everyframe align', 1);('faces extract consistent signalseach', 1);('motion magnicationas', 1);('motion magnicationmay', 1);('deep motion magnicationwhere temporal lters', 1);('small motionsthus', 1);('faces ksamplesofframes', 1);('magnication output k\x02\x023size', 1);('motionmagnication output', 1);('window tframes', 1);('outputs tensor ofw\x02h\x02\x00t\x001\x024for', 1);('corresponding frames persample', 1);('video input network', 1);('thediscussion choices andtto ablation studiesin', 1);('network architecturesource', 1);('detection task', 1);('multiclass classication problem nfake generators datasetplus originals constitute class categories', 1);('spatiotemporal nature data attempt touse transformerlike architectures source detection', 1);('weobserve', 1);('representation powerfulenough transformers', 1);('overt data', 1);('wearchitect simpler 3d convolutional neural network', 1);('similar c3d', 1);('4d tensors rst input', 1);('convolutional kernels size 3x3x3', 1);('batch norm reluand maxpool layers block', 1);('layers size', 1);('supp adepicts', 1);('network selection architecture isalso', 1);('prediction aggregationafter', 1);('sample video wecombine kclass predictions condences avideo prediction use majority', 1);('sample prediction accuracies thehigh side', 1);('long large motion illumination', 1);('majority', 1);('outlier samples grounds aggregation respect possibleartifacts videos5', 1);('resultsour', 1);('python', 1);('image processing pytorch', 1);('openface', 1);('detection alignmentand vitpytorch', 1);('efcient3dcnn', 1);('libraries forexible neural network implementations training', 1);('nvidiageforce rtx', 1);('hoursto train', 1);('applying', 1);('expensive part system', 1);('anofine task', 1);('dataset eachablation study', 1);('unless', 1);('k 4t', 1);('motion magnication frequency coefcients usedasis', 1);('original paper', 1);('bp', 1);('lp', 1);('hp', 1);('fps lters', 1);('main dataset', 1);('sourcegans training', 1);('fake videos each5 source', 1);('approach obtains9403', 1);('overall video source detection accuracy onfa', 1);('vc', 1);('bottom datasets respectively51', 1);('evaluation comparisonthe', 1);('confusion matrices', 1);('oursource detection accuracy', 1);('dataset weobtain', 1);('video source detection accuracy 9592sample source detection accuracy', 1);('fake detectionaccuracy', 1);('video source detection accuracy', 1);('sample source detection accuracyand', 1);('fake detection accuracy', 1);('thatour perclass accuracies', 1);('fake classesthan', 1);('real class model learns ampliedmotion generative residue sense', 1);('real class', 1);('chaotic class', 1);('condent predictions', 1);('intoin addition deepfake source', 1);('inthe literature', 1);('complex network architectures', 1);('deepfake detection inorder', 1);('strength dual motion magnication representation', 1);('approach beatsthe', 1);('simpler thanthe', 1);('inference time', 1);('tospecic generators datasetsmodels', 1);('source det accresnet50', 1);('6325resnet152 6892vgg19 7667inception 7937densenet201 8165xception', 1);('comparison ff source', 1);('detection accuracies', 1);('analysis experimentsas', 1);('different network architectures accordance characteristics data', 1);('accuracies source detection motion', 1);('tensor representation', 1);('forties generative artifactsdeeper', 1);('complex networks', 1);('overt orderto observe phenomenon', 1);('report persamplesource detection accuracies aggregation stepin motion magnication literature', 1);('magnication signicant parameter', 1);('complete loss generativesignals', 1);('magnication coefcients', 1);('notebackbone training acc testing accsimple3dvit', 1);('c3d', 1);('architecture analysis training', 1);('support strength ofour representationthat experiments', 1);('dual representation', 1);('contribution parameter', 1);('motion vectors', 1);('conclude 2x', 1);('frame windows', 1);('magnication arethe sweet spot', 1);('motion pursue', 1);('asobserved', 1);('traditional onlydeep magnication', 1);('generativeartifacts underlines contribution dual motion representationmagnication', 1);('parameter source det accdeep', 1);('2x 9154deep 3x 8686deep 4x 8316deep 10x 7490phase', 1);('6485both 2xandt', 1);('motion magnication parameters', 1);('different motion magnication settings', 1);('traditional anddeep components', 1);('magnication coefcient andphaseextraction interval tin addition quantitative analysis demonstratethe', 1);('different parameter values', 1);('areal video', 1);('real video 10x magnication deteriorates content hand 10frame phase extraction tends converge', 1);('image video whichis', 1);('small motions', 1);('based', 1);('onthese observations experiments', 1);('conclude 2xandt 5valuesas', 1);('detect mitigateany', 1);('possible racial gender bias dataset algorithm end use labels', 1);('dataset toreport', 1);('skin tone source detection accuracies observe', 1);('discrepancy accuraciesfigure', 1);('magnication parameters following', 1);('different magnication parameters depict', 1);('ofdeep motion magnication', 1);('magnication interval tright', 1);('asian women', 1);('american men 8421and', 1);('difference mayrise fact deepfake generators creatingsuch', 1);('detection resultsare', 1);('future workskin', 1);('tone gender', 1);('acc video accafrican', 1);('gender skin tone analysis per', 1);('sample pervideo source detection accuracies', 1);('skin tones', 1);('number samplesper video k', 1);('number frames sample', 1);('accuracy speed memory requirements end', 1);('table 5we document experiments kf1234g concludingthatk', 1);('informative creates diversedataset', 1);('larger', 1);('values werevery incremental contributions k', 1);('conclusion', 1);('workfollowing', 1);('questions deepfakes theiremotions', 1);('howdo', 1);('generative artifacts deepfakes whichkvalue', 1);('ffpp video acc1', 1);('size analysis', 1);('video affects theaccuracy k', 1);('combining', 1);('motionbasedsource detection network', 1);('source detectors support observations andchoices ablation studies experimentsin battle deepfakes', 1);('source detection plays', 1);('crucial role', 1);('continuous deployment andintegration detectors', 1);('emergenceof', 1);('novel generators', 1);('malevolent usesof', 1);('current ones', 1);('source detection timelyprevent deepfakes', 1);('catastrophic events', 1);('explore motion deepfakes multimodal setting', 1);('sound speech gaze gesturesignals motionreferences1', 1);('bruce', 1);('willis denies', 1);('life httpswwwellecomuklifeandculturea30748079deepfakeporn', 1);('video zelenskyy', 1);('tip icebergin info war experts', 1);('deepfake video zelenskyy experts war manipulation ukrainerussia', 1);('deepfakes', 1);('deeptrustalliance', 1);('https www deeptrustallianceorg', 1);('faceswap', 1);('https github com', 1);('marekkowalskifaceswap accessed', 1);('faceswapgan', 1);('incredible series videos swaps', 1);('famous hollywoodfaces', 1);('deepfake techhas', 1);('intel', 1);('intel labs', 1);('new ai methods restore trust inmedia httpswwwintelcomcontentwwwusenresearchblogstrustedmediahtml', 1);('vitpytorch httpsgithubcomlucidrainsvitpytorch', 1);('afchar v nozick j yamagishi echizen mesoneta', 1);('compact facial video forgery detection network 2018ieee', 1);('information forensics', 1);('michael albright scott mccloskey source', 1);('irene amerini leonardo galteri roberto caldelli alberto del bimbo deepfake', 1);('video detection opticalow', 1);('conferenceon computer vision', 1);('vishal asnani xi yin tal hassner xiaoming liu reverse', 1);('engineering generative models', 1);('inferring', 1);('model hyperparameters', 1);('tadas baltrusaitis amir zadeh yao chong lim louisphilippe morency openface', 1);('facial', 1);('behavior analysistoolkit', 1);('automatic face gesture recognition', 1);('fg', 1);('pages 5966ieee', 1);('barni', 1);('bondi n bonettini p bestagini costanzom maggini', 1);('tondi tubaro aligned', 1);('double jpeg detection', 1);('convolutional neural networks', 1);('j vis comun image represent', 1);('g bradski opencv', 1);('dr dobbs', 1);('journal ofsoftware', 1);('tools', 1);('n carlini wagner towards', 1);('robustnessof neural networks', 1);('ieee symposium securityand privacy sp', 1);('los alamitos ca usamay', 1);('ieee computer', 1);('ilke demir lijun yin fakecatcher detection', 1);('synthetic portrait videos', 1);('biological signals', 1);('ieee transactions pattern analysis machine intelligence pami', 1);('ilke demir lijun yin', 1);('fake source detection', 1);('residuals biological signals', 1);('ieeeinternational joint', 1);('biometrics ijcb', 1);('yunjey choi minje choi munyoung kim jungwoo hasunghun kim jaegul choo stargan unied', 1);('generative adversarial networks multidomain imagetoimagetranslation', 1);('proceedings ieee', 1);('francois chollet xception deep', 1);('depthwiseseparable convolutions', 1);('computer vision pattern recognition cvpr july', 1);('david chu ilke demir kristen eichensehr jacob g foster mark', 1);('kristina lerman filippo menczer cailinoconnor edward parson lars ruthotto', 1);('white paper', 1);('deep', 1);('fakery action plan', 1);('technical', 1);('httpwwwipamuclaeduwpcontentuploads202001whitepaperdeepfakerypdf institute', 1);('pure applied mathematics ipam universityof california los angeles los angeles ca jan', 1);('civera', 1);('zanotti fragonara', 1);('surace', 1);('experimental study feasibility', 1);('video magnication damage detection localisation operational deection shapes', 1);('strain', 1);('davide alessandro coccomini nicola messina claudiogennaro fabrizio falchi combining', 1);('efcientnetand vision transformers video deepfake detection', 1);('instan sclaroff cosimo distante marco leo giovanni mfarinella federico tombari', 1);('image analysisand processing iciap', 1);('cham', 1);('rashmiranjan das gaurav negi alan', 1);('smeaton detecting', 1);('deepfake videos', 1);('euler video magnicationelectronic', 1);('imaging', 1);('ilke demir umur', 1);('mixsyn learning', 1);('composition style multisource image synthesis', 1);('corr', 1);('ilke demir umur aybars', 1);('fakeslook synthetic', 1);('acmsymposium eye tracking', 1);('applications', 1);('yuzhen ding nupur thakur baoxin li', 1);('ganleave distinct modelspecic ngerprints', 1);('bmvc', 1);('brian dolhansky russ howes ben paum nicole baramand cristian canton ferrer', 1);('deepfake detection challenge dfdc preview dataset', 1);('jianwei fei zhihua xia peipeng yu fengjun xiao exposing', 1);('videos motion magnication', 1);('multimedia tools appl', 1);('ian j goodfellow jean pougetabadie mehdi mirza bingxu david wardefarley sherjil ozair aaron courville', 1);('bengio generative', 1);('adversarial networks', 1);('luca guarnera oliver giudice sebastiano battiatodeepfake', 1);('convolutional traces', 1);('inproceedings ieeecvf', 1);('e j delp deepfake', 1);('video detection usingrecurrent neural networks', 1);('ieee internationalconference advanced video', 1);('based surveillance avss', 1);('nov', 1);('brian hosler davide salvi anthony murray fabio antonacci paolo bestagini stefano tubaro matthew cstamm', 1);('emotions semantic approachto', 1);('emotional inconsistencies', 1);('computer visionand pattern recognition cvpr', 1);('workshops pages', 1);('shu hu yuezun li siwei lyu exposing', 1);('inconsistent corneal specular highlights', 1);('inicassp', 1);('international conference onacoustics', 1);('speech', 1);('liming jiang ren li wayne wu chen qian', 1);('loy deeperforensics10', 1);('largescaledataset realworld', 1);('forgery detection 2020ieeecvf conference', 1);('computer vision patternrecognition cvpr', 1);('tero karras timo aila samuli laine jaakko lehtinenprogressive', 1);('quality stabilityand variation', 1);('tero karras samuli laine timo aila', 1);('stylebasedgenerator architecture generative adversarial networksinproceedings', 1);('computervision pattern recognition cvpr june', 1);('hasam khalid shahroz tariq minha kim simon swoo fakeavceleb', 1);('novel audiovideo multimodal deepfake dataset', 1);('khodabakhsh r ramachandra k raja p wasnik', 1);('busch fake', 1);('detection methods', 1);('biometricsspecial interest', 1);('biosig', 1);('okan k', 1);('neslihan kose ahmet gunduz gerhardrigoll resource', 1);('efcient 3d convolutional neural networksin2019', 1);('computervision', 1);('p korshunov marcel', 1);('speaker inconsistency detectionin', 1);('european signal', 1);('processingconference eusipco', 1);('alicja kwasniewska jacek ruminski maciej szankinimproving', 1);('accuracy contactless respiratory rate estimationby', 1);('thermal sequences', 1);('nam', 1);('jeanmarc odobez learning', 1);('multimodal temporal representation', 1);('detection broadcast media', 1);('acm', 1);('multimedia mm', 1);('lingzhi li jianmin bao hao yang dong chen fangwen faceshifter towards', 1);('high delity occlusion awareface', 1);('arxiv preprint arxiv191213457', 1);('lingzhi li jianmin bao ting zhang hao yang dongchen fang wen baining guo face', 1);('xray moregeneral', 1);('forgery detection', 1);('yuezun li mingching chang siwei lyu', 1);('in2018 ieee', 1);('information forensicsand', 1);('yuezun li pu sun honggang qi siwei lyu celebdfa largescale challenging dataset deepfake forensicsinieee', 1);('computer vision patten recognition cvpr seattle wa', 1);('j lukas j fridrich goljan digital', 1);('camera identication sensor pattern noise', 1);('ieee transactions', 1);('forensics', 1);('marra gragnaniello', 1);('verdoliva g poggi dogans', 1);('articial ngerprints', 1);('multimedia information processing retrievalmipr', 1);('aman mehra akshay agarwal mayank vatsa richasingh motion', 1);('3d residualindense network fordeepfake detection', 1);('ieee transactions biometrics behavior identity', 1);('science pages', 1);('yisroel mirsky wenke lee', 1);('creation detection deepfakes survey', 1);('acm comput surv', 1);('h h nguyen j yamagishi echizen capsuleforensics', 1);('capsule networks detect', 1);('imagesand videos', 1);('ieee internationalconference acoustics speech', 1);('processingicassp', 1);('ewa nowara daniel mcduff ashok veeraraghavancombining', 1);('magnication measurement noncontactcardiac', 1);('computer vision pattern recognition cvprworkshops', 1);('taehyun oh ronnachai jaroensri changil kim mohamedelgharib fr', 1);('durand william freeman wojciechmatusik learningbased', 1);('video motion magnication arxivpreprint arxiv180402684', 1);('adam paszke sam gross francisco massa adam lererjames bradbury gregory chanan trevor killeen zeming lin natalia gimelshein luca antiga alban desmaison andreas kopf edward yang zachary devito martin raison alykhan tejani sasank chilamkurthy benoitsteiner lu fang junjie bai soumith chintala pytorchan', 1);('imperative style highperformance', 1);('learning libraryinadvances', 1);('neural information processing systems', 1);('curran associates inc', 1);('kr prajwal rudrabha mukhopadhyay vinay namboodiriand cv jawahar', 1);('lip sync expert need speechto lip generation', 1);('multimedia', 1);('jiameng pu neal mangaokar lauren kelly parantapa bhattacharya kavya sundaram mobin javed bolun wang', 1);('viswanath deepfake', 1);('analysis', 1);('andreas r', 1);('davide cozzolino luisa verdoliva', 1);('riess justus thies matthias niener faceforensics largescale video dataset forgery detection', 1);('faces', 1);('arxiv eprints page arxiv180309179', 1);('mar2018', 1);('andreas rossler davide cozzolino luisa verdoliva', 1);('riess justus thies matthias niessner faceforensics learning', 1);('facial images', 1);('theieee', 1);('computer vision iccv october', 1);('sophie r saremsky umur ciftci emily greene', 1);('demir adversarial', 1);('deepfake generation detectormisclassication', 1);('jeremy straub', 1);('brightness assessment todetect', 1);('fakes conference', 1);('presentation nasser kehtarnavaz matthias', 1);('carlsohn', 1);('realtime image processing deep learning', 1);('international society', 1);('optics photonics', 1);('szegedy vincent vanhoucke sergey ioffe jonshlens zbigniew wojna rethinking', 1);('inception architecture computer vision', 1);('ieee conferenceon computer vision pattern recognition cvpr june2016', 1);('shahroz tariq sangyup lee hoyoung kim youjin shinand simon woo detecting', 1);('machine human', 1);('multimedia privacy', 1);('mps', 1);('matthias niener deferred', 1);('neural textures', 1);('acm trans graph', 1);('matthias niener levi valgaerts marc stamminger', 1);('theobalt realtime', 1);('facial reenactment', 1);('acm transgraph', 1);('oct', 1);('j thies zollh', 1);('stamminger', 1);('theobalt mniener face2face realtime face capture reenactment rgb videos proc computer vision patternrecognition cvpr ieee', 1);('ruben tolosana ruben verarodriguez julian fierrezaythami morales javier ortegagarcia deepfakes', 1);('andbeyond survey', 1);('manipulation fake detectioninformation', 1);('fusion', 1);('tran lubomir bourdev rob fergus lorenzo torresaniand manohar paluri learning', 1);('with3d convolutional networks', 1);('neal wadhwa michael rubinstein fr', 1);('durand', 1);('freeman phasebased', 1);('video motion processingacm', 1);('trans graph', 1);('shengyu wang oliver wang richard zhang andrewowens alexei efros cnngenerated', 1);('easy spotfor', 1);('cvpr', 1);('zhaoqiang xia xiaopeng hong xingyu gao xiaoyi fengand guoying zhao spatiotemporal', 1);('recurrent convolutionalnetworks', 1);('spontaneous microexpressionsieee', 1);('transactions multimedia', 1);('x yang li lyu exposing', 1);('deep fakes', 1);('inconsistent head poses', 1);('acoustics speech', 1);('ning yu larry davis mario fritz attributing', 1);('fakeimages gans', 1);('learning', 1);('gan ngerprintsinthe', 1);('computer visioniccv october', 1);('ning yu vladislav skripniuk sahar abdelnabi mariofritz articial', 1);('generative models', 1);('rooting', 1);('deepfake attribution training data', 1);('computer vision iccv', 1);('zhang', 1);('zheng v', 1);('l l', 1);('thing automated', 1);('internationalconference', 1);('image processing icsip', 1);('aug', 1);('p zhou x han v morariu', 1);('davis twostream', 1);('neural networks', 1);('detection 2017ieee conference', 1);('cvprw', 1);