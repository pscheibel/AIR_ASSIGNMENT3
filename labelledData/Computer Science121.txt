('dr', 49);('vit', 36);('beit', 36);('cait', 36);('deit', 34);('fig', 25);('db', 20);('diabetic retinopathy', 17);('fundus images', 12);('severity stages', 12);('image transformers', 11);('xx', 10);('transformers', 10);('deep', 10);('cnn', 10);('eit', 9);('ieee', 6);('aptos-2019', 6);('msa', 6);('transformer encoder', 6);('vol', 5);('no', 5);('xxxx', 5);('transformer', 5);('severity stage detection', 5);('svm', 5);('xception', 5);('mlp', 5);('ln', 5);('eitwm', 5);('cvpr', 5);('generic colorized journal', 4);('bidirectional encoder', 4);('class-attention', 4);('severity stage', 4);('knn', 4);('transformer model', 4);('input image', 4);('ssit', 4);('detecting severity of diabetic retinopathy from fundus images using ensembled transformers', 4);('izis', 4);('z0 l', 4);('grad-cam', 4);('ophthalmology', 4);('automated', 4);('model performance', 3);('retinal images', 3);('data', 3);('efcient image', 3);('rf', 3);('ann', 3);('machine learning models', 3);('bert', 3);('image patches', 3);('dr.', 3);('efcientnet-b5', 3);('neural network', 3);('workow', 3);('< class >', 3);('< distillation >', 3);('iv', 3);('recall', 3);('similarly', 3);('accuracy', 3);('mobilenetv2', 3);('pre-training', 3);('dbi', 3);('n.a', 3);('deep learning', 3);('ieee access', 3);('icml', 3);('retina images', 2);('learning models', 2);('im- age', 2);('image trans-', 2);('fundus photographs', 2);('blindness detection dataset', 2);('c. adak', 2);('dept', 2);('cse', 2);('negative mild', 2);('moderate severe proliferative', 2);('fundus', 2);('blood vessels', 2);('new blood vessels', 2);('multi-head self-attention', 2);('fundus image', 2);('image transformer', 2);('ii', 2);('severity detection', 2);('etdrs', 2);('models [', 2);('cotton-wool spots', 2);('retinal changes', 2);('early detection', 2);('particle swarm optimization', 2);('severity classication', 2);('eye diseases', 2);('zoom-in-net', 2);('attention mechanism', 2);('densenet169', 2);('tan', 2);('tymchenko', 2);('efcientnet-b4', 2);('cot- xnet', 2);('iii', 2);('solution architecture', 2);('fundus photograph', 2);('vision transformer', 2);('trans-', 2);('% samples', 2);('transformer models', 2);('image classication', 2);('individual image transformers', 2);('transformer layers', 2);('positional information', 2);('+z0 l', 2);('total number', 2);('sa', 2);('attention', 2);('vi', 2);('softmax function', 2);('token [', 2);('mish', 2);('ve severity stages', 2);('teacher model', 2);('zs', 2);('distillation procedure', 2);('asandfnblocks', 2);('layerscale', 2);('v ae', 2);('pj', 2);('adamw', 2);('blindness detection', 2);('appendix', 2);('evaluation metrics', 2);('f 1score', 2);('eitmv', 2);('f1-score', 2);('specicity', 2);('comparison', 2);('resnet50', 2);('inceptionv3', 2);('farag', 2);('se-resnext50', 2);('impact', 2);('cot-xnet', 2);('v.', 2);('ablation study', 2);('individual transformers', 2);('messidor', 2);('idrid', 2);('dbm+ dbi', 2);('medical image analysis', 2);('articial', 2);('j. krause', 2);('grader', 2);('reference stan- dards', 2);('online', 2);('microaneurysm', 2);('diabetic retinopa- thy detection', 2);('image recognition', 2);('iccv', 2);('iclr', 2);('computers', 2);('ieee transactions', 2);('rethinking', 2);('detecting severity', 1);('ensembled transformers chandranath adak', 1);('senior member', 1);('tejas karkera', 1);('soumi chattopadhyay', 1);('member', 1);('muhammad saqib abstract diabetic retinopathy', 1);('vision loss', 1);('paper deals', 1);('traditional machine', 1);('convolutional architectures', 1);('essential parts', 1);('retinal image', 1);('crucial features', 1);('sever- ity', 1);('vision trans-', 1);('aptos-', 1);('index terms blindness detection', 1);('diabetic retinopa-', 1);('introduction diabetes mellitus', 1);('patient experiences', 1);('blood sugar levels', 1);('long period', 1);('mi- crovascular complication', 1);('retinas blood vessels', 1);('poor vision', 1);('studies', 1);('diabetes onset', 1);('worldwide presence', 1);('current estimate', 1);('timely treatment', 1);('severity [', 1);('ophthalmologist analyzes fundus images', 1);('soft exudates', 1);('stages [', 1);('iit patna', 1);('india-801106', 1);('t. karkera', 1);('atharva', 1);('engineering', 1);('mumbai', 1);('india-400095', 1);('s. chat-', 1);('iiit guwahati', 1);('india-781015', 1);('m. saqib', 1);('data61', 1);('csiro', 1);('australia-2122', 1);('corresponding', 1);('chandranath @ iitp.ac.in', 1);('blood transportation', 1);('manual', 1);('high number', 1);('unclear lesions', 1);('correct severity grade [', 1);('early-stage detection [', 1);('automated dr', 1);('fundus pho- tographs', 1);('image processing tools', 1);('early 2000s', 1);('random forest', 1);('k-nearest neighbors', 1);('support vector machine', 1);('articial neural network', 1);('ann-based', 1);('introduce errors', 1);('complex fundus images [', 1);('models extract', 1);('convolution operations [', 1);('deep learning architectures', 1);('computer vision community', 1);('severity analysis', 1);('fundus images [', 1);('convolutional neural network', 1);('certain regions/features', 1);('cnns', 1);('contemporary methods', 1);('attention mechanism [', 1);('multiple researcharxiv:2301.00973v1 [ cs.cv ]', 1);('jan', 1);('literature [', 1);('initial stages', 1);('deep learning models', 1);('high performance', 1);('recent days [', 1);('visual transformer', 1);('image classication tasks', 1);('global attention [', 1);('hefty amounts', 1);('image transformer models', 1);('data-efcient', 1);('specic class-attention [', 1);('uses knowledge distillation', 1);('teacher-student hierarchical network [', 1);('bidirectional encoder rep-', 1);('blindness detection dataset [', 1);('in- dividual image transformers', 1);('predictive performance', 1);('encouraging results', 1);('ensemble image transformers', 1);('main contribution', 1);('xii discusses', 1);('relevant literature', 1);('xiv analyzes', 1);('mental results', 1);('xv concludes', 1);('r elated work', 1);('section briey', 1);('research group [', 1);('wavelet transform [', 1);('radon transform [', 1);('machine learning', 1);('deep feature-', 1);('a. hand-engineered feature-based', 1);('acharya', 1);('decision tree', 1);('discrete wavelet/cosine', 1);('casanova', 1);('rffor dr', 1);('severity stage classication', 1);('detect drusen', 1);('dr. tang', 1);('retinal hemorrhage detec- tion', 1);('akram', 1);('gmm', 1);('gaussian mixture model', 1);('identify microaneurysms', 1);('dr. ann', 1);('classify lesions', 1);('osareh', 1);('fcm', 1);('fuzzy c-means', 1);('genetic', 1);('detect exudates', 1);('pso', 1);('ann-based dr', 1);('deep feature-based', 1);('yu', 1);('chudzik', 1);('microaneurysm detection', 1);('gargeya', 1);('leng', 1);('cnn-', 1);('deep residual learning', 1);('identify fundus images', 1);('amd', 1);('age-', 1);('macular degeneration', 1);('alexnet', 1);('vgg', 1);('googlenet', 1);('resnet', 1);('wang', 1);('greedy algorithm', 1);('ar- chitecture', 1);('texture attention net-', 1);('re- calibration mechanism', 1);('se- resnext50', 1);('contextual transformer', 1);('saliency maps', 1);('ethodology', 1);('section rst formalizes', 1);('problem statement', 1);('problem formulation', 1);('icaptured', 1);('fundus photography', 1);('multi-class classication problem [', 1);('severity class labels', 1);('proliferative }', 1);('raw fundus images', 1);('preprocessing', 1);('deep learning mod- els', 1);('raw', 1);('achievable performance', 1);('denite ow', 1);('augmentation techniques [', 1);('raw fundus photographs', 1);('various sizes', 1);('iinto256\x02256', 1);('iz', 1);('data augmentations', 1);('dbtr', 1);('central_fraction =', 1);('horizontal/vertical ip', 1);('random rotations', 1);('[ 0o', 1);('45o ]', 1);('random brightness-change', 1);('max_delta =', 1);('random contrast-change', 1);('interval [', 1);('clahe', 1);('contrast limited adaptive histogram equalization', 1);('ensures over-amplication', 1);('entire image', 1);('transformer networks', 1);('com- puter vision tasks', 1);('convo-', 1);('extract high-level', 1);('convolution operations', 1);('multi-layer perceptron', 1);('clas- sication [', 1);('recent days', 1);('substantial rise', 1);('nlp', 1);('language processing', 1);('performances [', 1);('similar quest', 1);('leverage high-level performance', 1);('tasks [', 1);('lesser image-specic inductive bias', 1);('image transform- ers', 1);('model adopts', 1);('transformer models [', 1);('textual words', 1);('pictorial representation', 1);('internal', 1);('te', 1);('patches xi p', 1);('size wp\x02wp\x02cp', 1);('channels ofiz', 1);('rgb', 1);('results np=', 1);('patch xi pis', 1);('d-dimensional', 1);('latent vector', 1);('trainable linear projection', 1);('z0= [ xclass', 1);('x1 pe', 1);('x2 pe', 1);('xnp pe ] +epos', 1);('eis', 1);('e2 rwp\x02wp\x02c\x02d', 1);('eposis', 1);('position embeddings', 1);('patch embeddings', 1);('epos2r', 1);('xclass =z0 0is', 1);('patch images', 1);('transformer encoders [', 1);('internal view', 1);('asandfn', 1);('theasandfncontainmsa', 1);('] andmlp [', 1);('] modules', 1);('layer normaliza-', 1);('residual connection [', 1);('general semantics', 1);('module comprises', 1);('gelu', 1);('gaussian error linear', 1);('non-linear activation function4', 1);('z0 l=msa', 1);('lis', 1);('transformer blocks', 1);('core component', 1);('scaled', 1);('head i2f1', 1);('hgofmsa calculates', 1);('value [', 1);('qi', 1);('ki', 1);('qi=xwi q', 1);('ki=xwi k', 1);('vi=xwi v', 1);('xis', 1);('wq', 1);('wk', 1);('wvare', 1);('weight matrices', 1);('linear transformation', 1);('tosathat computes', 1);('input image patches', 1);('= \x12qkt pdh\x13', 1);('dh=d=h', 1);('outcomes ofsas', 1);('= [', 1);('sa1', 1);('sa2', 1);('sah', 1);('wl', 1);('weight matrix', 1);('multiple transformer encoder blocks', 1);('] enriches', 1);('contextual information', 1);('image representation y [', 1);('output layer', 1);('ve neurons', 1);('softmax activation function', 1);('probability distribution s', 1);('training data', 1);('memory [', 1);('vit-specic', 1);('teacher-student scheme', 1);('knowledge distillation [', 1);('knowledge distillation mechanism', 1);('student model uses', 1);('employ hard- label distillation [', 1);('hard decision', 1);('true label', 1);('hard-label distillation objective', 1);('lhard', 1);('global = 0:5lce', 1);('+ 0:5lce', 1);('lceis', 1);('cross-entropy loss', 1);('ground-truth labels y', 1);('zsandztare', 1);('teacher models logits', 1);('hard labels', 1);('soft ones [', 1);('< patch > tokens', 1);('transformer encoders', 1);('vits', 1);('ground- truth label', 1);('< class > tokens', 1);('back-propagation [', 1);('linear classier', 1);('computa- tional resources', 1);('flops', 1);('learning parameters [', 1);('transformer [', 1);('leverages layers', 1);('specic class- attention', 1);('diagonal matrix', 1);('m\x15on', 1);('z0 l=m\x15', 1);('\x15l iand\x150l iare learning parameters', 1);('cait.adak', 1);('class-attention layers', 1);('linear classier [', 1);('initial layers', 1);('class-attention stage', 1);('multi-head class-attention', 1);('ac', 1);('fn', 1);('bidirectional encoder representations', 1);('patches xi pand', 1);('backbone transformer', 1);('visual tokensvt= [ vt1', 1);('vtnp ]', 1);('variational auto-encoder', 1);('token learning', 1);('map image pixels xto tokens vt', 1);('input image pixelsxfromvt [', 1);('mim', 1);('masked image modeling', 1);('] task', 1);('corresponding visual tokens', 1);('e [ m ]', 1);('image patchesxm=fxi p', 1);('i =2', 1);('mgsfe', 1);('[ m ]', 1);('mg', 1);('mis', 1);('representation hl iis', 1);('transformer layer', 1);('lforithpatch', 1);('softmax classier', 1);('respective visual', 1);('wmhl', 1);('wmandbmcontain', 1);('learning parameters', 1);('linear transfor- mation', 1);('correct token vtigivenxm', 1);('maxx x2dbtrem', 1);('i2mlogpmim\x00 vtijxm\x01 #', 1);('training [', 1);('token reconstruction', 1);('learning priorpmim', 1);('xm i', 1);('bb', 1);('evti\x18t', 1);('[ logd\x12', 1);('] | { z } stage-1+logpmim\x10 ^vtijxm i\x11 | { z } stage-21', 1);('cca', 1);('ensembled transformers', 1);('im- age transformers', 1);('multiple learning algorithms', 1);('constituent algorithms', 1);('pictorial rep- resentation', 1);('image sample', 1);('softmax probability distribution s', 1);('ncgoverjth transformer [', 1);('pnc', 1);('i=1pj i=', 1);('distinct image transformers', 1);('severity stages/ class_labels jwmandjmv', 1);('combination methods', 1);('jwm=argmaxip\x16 i', 1);('p\x16', 1);('i=pnt j=1 jpj ipnt j=1 j', 1);('ensembled', 1);('choosepnt j=1 j= 1. jmv=mode\x00 argmaxi', 1);('p1', 1);('p2', 1);('pnt', 1);('\x01 =mode\x10 argmaxi', 1);('loss function [', 1);('weight decay regularization effect', 1);('hyper- parameter', 1);('iv-b', 1);('e xperiments and discussions', 1);('experimental results', 1);('database employed', 1);('computational experiments', 1);('available training samples', 1);('kaggle aptos', 1);('asia pacic tele-ophthalmology', 1);('dataset [', 1);('contains fundus image samples', 1);('sample images', 1);('dbtrand dbtsets', 1);('sample counts', 1);('different severity stages/ class_labels', 1);('dbtrand dbtare', 1);('positive classes', 1);('moderate stage', 1);('different number', 1);('various severity stages', 1);('data augmentation', 1);('issue [', 1);('count', 1);('experimental', 1);('section discusses', 1);('model outcome', 1);('major state-of- the-art methods', 1);('experimental settings.1', 1);('experiment settings', 1);('tensorflow-2', 1);('python', 1);('intel', 1);('xeon', 1);('cpu', 1);('@ 2.00ghz', 1);('gb ram', 1);('tesla t4', 1);('gb gpu', 1);('initial_learning_rate =', 1);('exponential decay rates', 1);('1stand 2ndmoment estimates', 1);('zero-denominator removal parameter', 1);('weight_decay = 10\x003=4', 1);('model training', 1);('mini-batch size', 1);('per- formance', 1);('combination schemes', 1);('% accuracy fromeitwmandeitmv', 1);('multiple combinations', 1);('wm scheme', 1);('various types', 1);('respective combinations', 1);('overall', 1);('eitwmattained', 1);('table', 1);('performance over various ensembling of transformers', 1);('ensembled transformersaccuracy', 1);('weighted majority', 1);('2vit +', 1);('3vit +', 1);('4vit +', 1);('cait94.63', 1);('coarse localization maps', 1);('indi- vidual image transformers', 1);('crucial regions', 1);('kappa score', 1);('accuracy [', 1);('cohens', 1);('kappa measures', 1);('precision', 1);('true positive samples', 1);('positive predictions', 1);('sensitivity nds', 1);('true positive rate', 1);('specicity computes', 1);('true negative rate', 1);('eitwmandeitmv', 1);('kappa scores', 1);('perfect agreement', 1);('human rater', 1);('class precision/ recall/ f 1score', 1);('table ii performance of eit over various evaluation metrics metricweighted', 1);('majority', 1);('kappa', 1);('macro precision', 1);('macro recall', 1);('macro', 1);('f 1-score', 1);('macro specicity', 1);('balanced accuracy', 1);('performance', 1);('individual performance', 1);('eitwmandeitmvfor', 1);('table iii performance of eit on every dr severity stage', 1);('comparative analysis', 1);('major contemporary deep learning archi- tectures', 1);('efcient-', 1);('net [', 1);('works [', 1);('oureitwmoutperformed', 1);('major state-of-the-art methods', 1);('eitmvalso', 1);('hyper-parameters', 1);('hyper- parameters', 1);('msa head count', 1);('performance im-', 1);('multi-head self- attention', 1);('iv comparative study methodaccuracy sensitivity specicity balanced', 1);('kassani', 1);('h tillh=', 1);('weights', 1);('weights j', 1);('eqn', 1);('eitwmfor', 1);('1= 2=', 1);('3= 4=', 1);('eitwmduring', 1);('ablation', 1);('different image transformers', 1);('performance degradation', 1);('individual transformer', 1);('datasets', 1);('perfor- mance', 1);('disease grading', 1);('db m.8 generic colorized journal', 1);('table v performance of eitwm by tuning weights', 1);('table vi tuned weights', 1);('transformers ensembled with weighted mean transformers', 1);('training setups', 1);('vii', 1);('dbt', 1);('db mand dbi', 1);('table vii accuracy', 1);('ofeit with pre', 1);('eitwmdbm', 1);('onclusion', 1);('eitwmand eitmv', 1);('combi- nation schemes', 1);('eitwmoutperformed', 1);('major state-of-the- art techniques', 1);('model perfor- mance', 1);('learning techniques', 1);('currently', 1);('lesion segmentation', 1);('implicit characteristics', 1);('qualitative visualization', 1);('references', 1);('s. stolte', 1);('r. fang', 1);('n. asiri', 1);('diagnosis systems', 1);('zheng', 1);('worldwide epidemic', 1);('indian journal', 1);('d. s. w. ting', 1);('deep learning system', 1);('multiethnic populations', 1);('jama', 1);('b. tymchenko', 1);('learning approach', 1);('diabetic retinopathy detection', 1);('icpram', 1);('aptos', 1);('kaggle.com/competitions/aptos2019-blindness-detection [', 1);('g. quellec', 1);('optimal', 1);('wavelet transform', 1);('retina photographs', 1);('l. giancardo', 1);('radon transform-', 1);('embs', 1);('r. casanova', 1);('application', 1);('random forests methods', 1);('diabetic retinopathy classication analyses', 1);('plos', 1);('p. e98587', 1);('m. niemeijer', 1);('digital color fundus photographs', 1);('diabetic retinopathy diagnosis', 1);('investigative', 1);('visual science', 1);('m. u. akram', 1);('identication', 1);('pattern', 1);('d. usher', 1);('digital retinal images', 1);('diabetic medicine', 1);('j. d. bodapati', 1);('appli- cation', 1);('diabetic retinopathy severity level prediction', 1);('image', 1);('video processing', 1);('a. zhang', 1);('z. c. lipton', 1);('m. li', 1);('a. j. smola', 1);('dive', 1);('s. yu', 1);('exudate', 1);('convolu- tional neural networks', 1);('embc', 1);('z. wang', 1);('miccai', 1);('m. m. farag', 1);('automatic', 1);('convolutional block attention mod- ule', 1);('a. dosovitskiy', 1);('a. m. bra', 1);('r. andonie', 1);('visualizing', 1);('brief survey', 1);('int', 1);('conf', 1);('information visualisation', 1);('h. touvron', 1);('going', 1);('training', 1);('data-efcient image transformers', 1);('h. bao', 1);('l. dong', 1);('f. wei', 1);('bert pre-training', 1);('j. devlin', 1);('deep bidirectional transformers', 1);('language understanding', 1);('grading', 1);('stereoscopic color fundus pho- tographsan', 1);('airlie house classication', 1);('report number', 1);('supplement', 1);('u. r. acharya', 1);('diabetic macular edema', 1);('maculopathy index', 1);('k. m. adal', 1);('clas- sication', 1);('red lesions', 1);('longitudinal fundus images', 1);('biomedical engineering', 1);('l. tang', 1);('splat', 1);('retinal hemorrhage detection', 1);('imaging', 1);('a. herliana', 1);('feature', 1);('diabetic retinopathy disease', 1);('citsm', 1);('s. sanrom', 1);('assessment', 1);('diabetic retinopathy risk', 1);('random forests', 1);('esann', 1);('a. osareh', 1);('diabetic retinopathy images', 1);('information', 1);('biomedicine', 1);('p. chudzik', 1);('image processing', 1);('spie', 1);('r. gargeya', 1);('t. leng', 1);('diabetic retinopa- thy', 1);('s. wan', 1);('convolutional neural networks', 1);('electrical engineer-', 1);('s. h. kassani', 1);('diabetic', 1);('retinopathy classication', 1);('xception architecture', 1);('isspit', 1);('m. d. alahmadi', 1);('texture', 1);('attention network', 1);('diabetic retinopathy classication', 1);('m. tan', 1);('efcientnet', 1);('convo- lutional neural networks', 1);('j. hu', 1);('squeeze-and-excitation', 1);('s. zhao', 1);('contextual', 1);('xception network', 1);('physics', 1);('medicine', 1);('biology', 1);('huang', 1);('saliency-guided', 1);('i. goodfellow', 1);('mit', 1);('stimper', 1);('multidimensional', 1);('adaptive histogram equalization', 1);('d. sarvamangala', 1);('convolutional', 1);('neural networks', 1);('medical image understanding', 1);('evolutionary', 1);('t. wolf', 1);('state-of-the-art', 1);('language pro-', 1);('emnlp', 1);('demonstrations', 1);('a. vaswani', 1);('advances', 1);('neural information processing systems', 1);('j. l. ba', 1);('j. r. kiros', 1);('g. e. hinton', 1);('layer', 1);('d. misra', 1);('non-monotonic neural activation function', 1);('bmvc', 1);('paper', 1);('g. hinton', 1);('o. vinyals', 1);('dean', 1);('distilling', 1);('knowledge', 1);('nips deep learning', 1);('representation learning', 1);('a. ramesh', 1);('zero-shot', 1);('text-to-image generation', 1);('l. rokach', 1);('ensemble-based classiers', 1);('intelligence review', 1);('i. loshchilov', 1);('f. hutter', 1);('decoupled', 1);('weight decay regularization', 1);('r. selvaraju', 1);('visual explanations', 1);('deep net-', 1);('gradient-based localization', 1);('m. grandini', 1);('e. bagli', 1);('g. visani', 1);('metrics', 1);('multi-class classi- cation', 1);('arxiv preprint arxiv:2008.05756', 1);('k.', 1);('residual learning', 1);('c. szegedy', 1);('inception architecture', 1);('computer vision', 1);('m. sandler', 1);('inverted', 1);('linear bottle- necks', 1);('f. chollet', 1);('separable convo- lutions', 1);('e. decencire', 1);('feedback', 1);('image database', 1);('image analysis', 1);('stereology', 1);('p. porwal', 1);('diabetic retinopathy image dataset', 1);