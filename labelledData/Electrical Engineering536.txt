('fbne', 30);('nash', 26);('lq', 19);('algorithm', 14);('fig', 13);('kkt', 8);('ilqgames', 7);('gaussian', 5);('dynamic games', 4);('global minima', 4);('timothy', 4);('international conference', 3);('nashequilibrium', 3);('ch', 3);('state trajectory', 3);('olne', 3);('fbneplayer', 3);('state trajectories', 3);('initial condition', 3);('incomplete trajectory data', 3);('proposition', 3);('gradient approximation', 3);('monte carlo', 3);('standard error ie variance', 3);('ieee', 3);('ifacpapersonline', 3);('june', 2);('autonomous agents multiagent systems aamas', 2);('international foundation', 2);('dynamic game theory', 2);('inverse feedback', 2);('conditions feedback', 2);('cost functions', 2);('letbe', 2);('olneplayer', 2);('fbne0', 2);('olne fbne', 2);('visualization', 2);('multiple global minima issue', 2);('approximation', 2);('loss decreases', 2);('scenario bold lines', 2);('square root sample size', 2);('asthe', 2);('noise variance', 2);('red curves', 2);('accurate cost', 2);('partial state observations', 2);('international conference robotics automation', 2);('icra', 2);('springer', 2);('molloy jairo inga charaja sren hohmann tristanperez inverse', 2);('proceedings', 2);('inference feedback dynamic', 1);('partial', 1);('observations incomplete trajectoriesjingqi liuniversity california berkeleyberkeley', 1);('statesjingqiliberkeleyeduchihyuan chiuuniversity california berkeleyberkeley', 1);('stateschihyuanchiuberkeleyedulasse petersdelft', 1);('technologydelft netherlandslpeterstudelftnlsomayeh sojoudiuniversity california berkeleyberkeley', 1);('statessojoudiberkeleyeduclaire tomlinuniversity california berkeleyberkeley', 1);('statestomlineecsberkeleyedudavid fridovichkeiluniversity texas austinaustin', 1);('statesdfkutexaseduabstractin', 1);('equilibrium state trajectory agent', 1);('cost function information pattern game', 1);('cost trajectory eachagent', 1);('unavailable agents', 1);('work usingpartial observations infer costs', 1);('dynamic games assumesan openloop information pattern work demonstratethat feedback', 1);('equilibrium concept expressive andencodes', 1);('complex behavior', 1);('players objectives feedback games', 1);('thereforewe', 1);('dynamic game cost inference problem thefeedback information pattern', 1);('partial state observationsand', 1);('incomplete trajectory data end', 1);('aninverse feedback game loss function', 1);('minimizer yields afeedback', 1);('equilibrium state trajectory', 1);('observation data characterize landscape differentiability theloss function', 1);('exact gradientour', 1);('main contribution', 1);('efficient gradient approximator whichenables novel inverse feedback game solver minimizes theloss', 1);('firstorder optimization thorough empirical evaluations', 1);('algorithm converges', 1);('robustness generalization performance theopenloop baseline method observation data reflects agroup players', 1);('dynamic game theory nash equilibriumacm reference formatjingqi li chihyuan chiu lasse peters somayeh sojoudi claire tomlinand david fridovichkeil', 1);('inference feedback dynamic gamesfrom noisy partial', 1);('observations incomplete trajectories procof', 1);('autonomous agents multiagentsystems aamas', 1);('london', 1);('kingdom may', 1);('ifaamas', 1);('introductionthe', 1);('safety efficiency', 1);('urban traffic relies', 1);('abilityof participant', 1);('actions othersproc 22nd', 1);('ricci', 1);('yeoh n agmon', 1);('b eds', 1);('may', 1);('kingdom', 1);('autonomous agentsand multiagent systems', 1);('wwwifaamasorg rights reserveddecisions', 1);('example drivers highway', 1);('aggressive drivers', 1);('decelerate cars avoidcollision', 1);('driver wishes mergea', 1);('powerful paradigm', 1);('interdependence decisions multiagent settings', 1);('dynamic games213', 1);('equilibrium solution gametheoretic model canbe', 1);('actions agents thescene equilibrium solution', 1);('expressive whenthe game possesses feedback information structure caseeach equilibrium strategy', 1);('available player timedespite theoretical attractiveness', 1);('paradigmin reality autonomous agents', 1);('informationavailable world', 1);('urban traffican autonomous agent', 1);('incomplete knowledge theobjectives players address challenge', 1);('recent worksoninverse', 1);('objectivesfrom past trajectory data', 1);('realistic applications onlynoisy sensor measurements agents states', 1);('thispartial', 1);('observability complicates inverse game problemand', 1);('treats case openloop informationstructurein work', 1);('solver inversedynamic games state feedback information structureour solver', 1);('objectives partial state observationsof', 1);('incomplete trajectories', 1);('common inrobotics', 1);('due noisy perception occlusions', 1);('thatour algorithm converges', 1);('thesuperior robustness generalization performance comparedwith baseline method learns', 1);('functions openloop assumption', 1);('observation data groupof players', 1);('equilibrium strategyour contributions threefold', 1);('firstly', 1);('characterize solution', 1);('dynamic game problem', 1);('particular show', 1);('regularization schemes mitigatethis problem', 1);('secondly', 1);('show differentiability lossfunction linear quadratic games', 1);('computationallyefficient procedure approximate gradient nonlinear', 1);('efficient firstorder coordinatedescent solverarxiv230101398v1 csma', 1);('jan', 1);('2023for inverse feedback game problem', 1);('noisy partial observations', 1);('incomplete expert state trajectory', 1);('experimental', 1);('converges inverse feedbackgames nonlinear dynamics', 1);('cost function', 1);('predictthe feedback', 1);('equilibrium state trajectories', 1);('unseeninitial states2', 1);('related work21 noncooperative dynamic gamesnoncooperative', 1);('strategic interaction multiagent setting', 1);('noncooperative games player minimizesits', 1);('individual cost function', 1);('players costs', 1);('equilibrium behavior generallycompetitive', 1);('different equilibrium concepts', 1);('noncooperative behaviors', 1);('inrealworld multiagent systems', 1);('32recent advances literature aim', 1);('efficient solutions', 1);('equilibrium problems', 1);('thoughthe', 1);('solutions openloop feedback', 1);('equilibrium inlinear quadratic', 1);('nonlineargames closedform solution general work 30characterizes', 1);('solution concept openloop', 1);('feedback setting', 1);('numerous approaches havebeen', 1);('various special cases', 1);('value iteration', 1);('equilibria ofnonlinear games', 1);('recentlya', 1);('equilibria constrainednonlinear games', 1);('computing', 1);('conditions indifferent time stepsour work draws', 1);('framework ateach iteration solves linearquadratic game approximates theoriginal game construction approximate game parallelsthe iterative linearization quadraticization methods iterativelqr', 1);('equations characterize equilibrium strategies linear quadratic', 1);('dynamic games2 approach differs', 1);('algames', 1);('method whichcomputes openloop', 1);('equilibrium strategy22', 1);('inverse noncooperative dynamic gamesin', 1);('game problem', 1);('dynamic games inverse game problem amounts findingobjectives agents', 1);('corresponding strategic egnash equilibrium interactions reproduce expert demonstrationsthe inverse game problem', 1);('important paves wayfor agent', 1);('otheragents behavior', 1);('efficient multiagentinteraction coordinationthe problem inverse infinitehorizon', 1);('games consideredin', 1);('equilibrium strategies coincide expert strategy', 1);('in3136', 1);('twoplayer inverse', 1);('transformingthe problem inverse optimal control assumptionthat control input data', 1);('conditions openloop', 1);('openloop generalsum differential games 24several', 1);('necessary conditions openloop', 1);('inverse game solution forsome classes openloop', 1);('efficient bilevel optimization framework', 1);('basedon openloop', 1);('conditions proposedfor', 1);('inverse games openloop', 1);('assumptionanother line work', 1);('costs openloop games 1711proposes minimize residual violation', 1);('residual framework assumes knowledge completetrajectory data convex problem', 1);('equilibria nonlineargames', 1);('residual method feedbacknonlinear games', 1);('subject numerical difficultya bilevel optimization approach inverse feedback game problem', 1);('assumption expertstate control trajectories', 1);('noise addition inverse game solver', 1);('infer theplayers', 1);('functions assumption expert strategyfollows', 1);('new concept', 1);('maximum entropy nash equilibriumto', 1);('authors knowledge work inferringcost functions nonlinear', 1);('dynamic games feedback', 1);('condition noisy partial state observation andincomplete trajectory data3', 1);('preliminariesconsider', 1);('playerstage deterministic discretetime dynamicgame state', 1);('rand', 1);('control input', 1);('rfor', 1);('dimension thejoint state control input', 1);('rand1rthe', 1);('joint state joint control time', 1);('joint dynamics system', 1);('thedifferentiable dynamics map', 1);('rrr11', 1);('x1andu1to state trajectory control trajectory', 1);('objective agent tominimize overall cost', 1);('costsrrrover time horizonxu1 2define12', 1);('cost functions agents', 1);('horizon minimize', 1);('player uses observations environment design sequence control inputs deploy duringthe discrete time interval information', 1);('available eachplayer time characterizes information pattern thedynamic game plays', 1);('major role', 1);('optimal responses player', 1);('informationpatterns feedback andopenloop', 1);('nash solutions feedback strategiesunder', 1);('state feedback information pattern player observesthe stateat time uses information design afeedback strategy', 1);('rr', 1);('let12rfollowing', 1);('statefeedback strategies player feedbackinformation pattern', 1);('dynamic game isas', 1);('feedback nash eqilibrium fbne', 1);('control strategies 11is', 1);('feedbacknash equilibrium player', 1);('formally\x101\x113\x101\x11whererrris', 1);('optimal stateactionfunction', 1);('xand uto', 1);('fbnecontrol', 1);('state trajectoriesin game', 1);('dynamics fand cost functions gremark', 1);('strong', 1);('consistency fbne', 1);('strong timeconsistency', 1);('def', 1);('equilibrium strategies', 1);('arbitrary feedbackstrategies', 1);('additional condition strategiesmust', 1);('equilibrium subgame', 1);('stagefrom arbitrary state32', 1);('nash solutions openloop strategiesin', 1);('contrast openloop information pattern', 1);('initial state', 1);('case strategy eachplayer map 1to12 wedenote byrr', 1);('allopenloop strategies player correspondingopenloop', 1);('openloop nash eqilibrium olne', 1);('tuple control strategies 1is', 1);('equilibrium player', 1);('unilaterallyalter sequence control inputs', 1);('formally\x10x1111\x115\x10x1111\x111rremark', 1);('strong timeconsistence feedback counterpart', 1);('olne0', 1);('olne1050510px1050510pyexample', 1);('olnefig', 1);('examples', 1);('cost functions yield trajectories', 1);('feedback', 1);('openloop nash equilibriain', 1);('difference openloop feedback', 1);('equilibria show necessity', 1);('specific solutions', 1);('inference problems thefeedback information pattern', 1);('workwith openloop assumption', 1);('end introduce', 1);('games openloop', 1);('nashequilibrium olne', 1);('statetrajectories differ', 1);('games class dynamicgames dynamics player objectives form 6and7 respectively16127where matrices', 1);('positive semidefinite matrix', 1);('positive definite matrix', 1);('appropriate dimensionsfor eachandcase', 1);('game statevector1122 whereandare xand ycoordinates agent', 1);('r2bethe', 1);('control input th agent12 setting weconsider class games', 1);('agent origin', 1);('agent agents joint dynamics costs timeare', 1);('follows1\x142002\x15\x1420\x151\x1402\x15212222221222212221222228where2is 22identity matrix visualize', 1);('fbneand olne', 1);('state trajectories example', 1);('1if modify cost function', 1);('player wantsto lead andposition', 1);('witheach ie12222122 9then', 1);('fbne olne', 1);('observations ofplayers', 1);('noisy practice', 1);('catch firstplayers observation', 1);('players position inaccuratewe modify', 1);('state trajectory isrobust inaccurate observations', 1);('state trajectory notthus', 1);('state strategies', 1);('thisdifference', 1);('expressive power', 1);('strong time consistency property', 1);('thefeedback information structure openloop settingper', 1);('remarks', 1);('similar problem', 1);('cost inferenceproblem', 1);('cost inference algorithms mayfail infer', 1);('cost function feedback games4', 1);('problem statementletxbe', 1);('state trajectory nonlinear dynamics fbut', 1);('unknown cost functions', 1);('lettbethe', 1);('time indices trajectory x', 1);('byyttthe observation data x whereris partialobservation state', 1);('certain coordinates', 1);('noise task infer cost function playersuch', 1);('state trajectorythat', 1);('trajectory parameterize cost player vector', 1);('denote', 1);('cost time basis functions111', 1);('define', 1);('formally', 1);('thisproblem formmin1xytxst xfg111whereis likelihood function', 1);('corresponding knownsensor model fg1represents', 1);('state trajectoriesfrom', 1);('strategy underthe cost', 1);('noisy partial observation 1is', 1);('incomplete trajectoriesfrom', 1);('different initial conditions', 1);('scenariowhere player', 1);('particular lane theroad joint state vector 11112222fig', 1);('examplethe time horizon', 1);('dynamics model player is1111cossin12where time discretization', 1);('r2is', 1);('control input player', 1);('target lanethat player', 1);('parameterize costfunction player byr211112212222122132212122222122222the ground truth solution', 1);('isa period occlusion', 1);('time index 11to19and', 1);('time index', 1);('t12', 1);('difficult human driver measure vehicles velocity', 1);('partialobservation data ytexcludes velocity cars dataset subject', 1);('standard deviation', 1);('initial condition 1is', 1);('wevisualize', 1);('ground truth solution', 1);('andthe noisy', 1);('partialobservation b noisy', 1);('incomplete expert trajectory data cthe difficulty', 1);('objective 11due challenge', 1);('strategy nonlineargames', 1);('sections characterize thecomplexity inverse feedback game problem', 1);('anefficient solution5', 1);('results characterization tocomputationin', 1);('characterize complexity inversefeedback game problem', 1);('particular show nonconvexity loss function existence', 1);('multiple isolatedglobal minima', 1);('based', 1);('regularization schemes mitigate issue', 1);('main contribution isto characterize differentiability inverse feedback gameloss function', 1);('gradient approximationscheme', 1);('firstorder optimization formulationfig', 1);('loss function 1of', 1);('initial condition11', 1);('likelihood function', 1);('yellow hyperplane', 1);('with2regularizationthe', 1);('global minima reduced51', 1);('characterization inverse feedbackdynamic game problemthe', 1);('dynamic game problem 11is constrainedoptimization problem', 1);('due nonconvexity', 1);('slight abuse notation denotebyxfg1fg1a', 1);('state trajectory simplifythe problem transform 11to', 1);('game solution xfg1into likelihoodfunctionytx follows1ytxfg1 14the minimizer 14is', 1);('local optimum', 1);('original problem11and', 1);('global fg1contains singleelementbefore dive nonlinear setting', 1);('case highlight', 1);('withthe optimization loss', 1);('case evaluation theloss14is straightforward exists closedform expressionforytx eg', 1);('observation model', 1);('problem remainsnonconvex', 1);('proposition makesthis challenge', 1);('explicit proof', 1);('appendixproposition', 1);('exists inverse', 1);('game problem 11a', 1);('b existmultiple cost functions', 1);('expert data initialcondition observation noiseremark', 1);('gameproblem suffer', 1);('insteadproposition', 1);('cost vector doesnot rule possibility', 1);('multiple global solutions isthere', 1);('cost parameter vectors', 1);('independentbut generate', 1);('initialstate noninjective', 1);('cost parameter space tothe', 1);('state trajectory space', 1);('fundamental problem inversefeedback games', 1);('particular formulation', 1);('inpractice', 1);('3though nonconvex loss function 1is', 1);('differentiable respect and1under condition', 1);('theorem32', 1);('implicit function theorem', 1);('methods nonconvexoptimization', 1);('differentiable objective functions', 1);('onenatural idea', 1);('gradient descent minimize', 1);('inwhat', 1);('efficient ways', 1);('differentiate1in nonlinear games52', 1);('efficient computation fbne statetrajectory nonlinear gamesit', 1);('games dynamics arenonlinear objectives nonquadratic problem becomesmore', 1);('games challenge', 1);('approximate local', 1);('smooth nonlq', 1);('dynamic gamesgiven effectiveness approximation scheme domains', 1);('akin ilqr', 1);('step theilqgames algorithm system dynamics 1andthe costs11are', 1);('trajectory xand control trajectory u', 1);('afbne', 1);('strategy player', 1);('game usedto update state control trajectories iteration continuesuntil convergence criterion satisfiedto', 1);('specific approximate 1by', 1);('new lossfunction', 1);('as11\x00ytxfg1\x0115where xfg1represents', 1);('state trajectory initialcondition1', 1);('dynamics fdepend', 1);('state trajectory fis linearizedthis trajectory', 1);('feedback policy', 1);('byilqgames policy', 1);('costs g53', 1);('differentiating loss inversefeedback game problemthe', 1);('equilibrium strategynot', 1);('evaluation loss function 1hard butalso renders differentiation', 1);('difficult work approximatethe gradient', 1);('similar idea', 1);('previous section words', 1);('approximation nonlinear game', 1);('approximation gradient', 1);('rrris', 1);('cost basis function chain rule wehave1xytx xfg1xfg1xfg1\x10fxfg1f gxfg1g\x11the complexity', 1);('1comes fact thatthe', 1);('total derivative', 1);('hard computewe', 1);('approximate gradient', 1);('cost basis function asconstants respect', 1);('fand compute partial derivative respect', 1);('totalderivative1 xytx xfg1xf1111this', 1);('observation convergence theforward', 1);('good approximation', 1);('full nonlinear dynamics f', 1);('long costparameter', 1);('asimilar approximation gradient 11by', 1);('partialderivative respect 1in summary approximate 1by1 practice1can', 1);('automatic differentiation27', 1);('descent direction', 1);('true gradient', 1);('inverse feedback game solverin', 1);('present solver inverse feedbackgame problem', 1);('wethen', 1);('noisy partial observation', 1);('full initial condition noisefree stateinput trajectoryas', 1);('procedure joint reconstruction', 1);('player costs', 1);('substantial partial observability', 1);('objective function inversefeedback game problem', 1);('initial condition thecost stateinput trajectory', 1);('coordinategradient descent method gradient descent steps firsttaken', 1);('costparameter update estimate noisefree', 1);('full stateinputtrajectory', 1);('state trajectory inferredinitial condition costwe summarize', 1);('th iteration', 1);('compute approximate', 1);('approximation estimate', 1);('update initialcondition1by step gradient descent stepsizeis', 1);('suitable linesearch technique', 1);('thatthe loss 1is', 1);('new approximate', 1);('state trajectoryalgorithm', 1);('inverse iterative lq', 1);('gamesdata horizon0', 1);('initial solution 0r', 1);('timeindex sett observation data yt max iterationnumber toleranceresult', 1);('inferred', 1);('cost parameter 11for01 do2x11fg', 1);('ilqgamesfg1311', 1);('section 53411111with line search 511fg', 1);('ilqgames\x00fg11\x01611', 1);('section 537111with line search', 1);('return111if12orreturn1', 1);('wherearg min', 1);('ifiteration number reaches9endvia', 1);('estimate11via procedure section', 1);('gradient update', 1);('step gradient descent linesearchwe repeat procedure convergence', 1);('locallyoptimal solution16', 1);('experimentsin', 1);('openloop solution method', 1);('asthe baseline method', 1);('studies aimto', 1);('aligns adescent direction loss functionalgorithm', 1);('robust openloop baselinemethod', 1);('respect noise', 1);('incomplete observations expert demonstration trajectorythe cost functions', 1);('trajectories unseen', 1);('initial conditionsalgorithm', 1);('infer nonconvex costs nonlinear games61', 1);('gradient approximation qualitywe', 1);('12and13 measure performance', 1);('incomplete expert trajectory data noisy partial state observationand', 1);('complete expert trajectory data noisy', 1);('full observationin', 1);('case players partial observation containsits xposition yposition', 1);('angle time index setof', 1);('incomplete trajectory', 1);('t1112', 1);('thesecond case expert data', 1);('noisy observation allthe states players ground truth expertstate trajectory', 1);('initial condition1005211021and target lane 00at variance level', 1);('generate10 noisy observations ground truth expert trajectory withisotropic zeromean', 1);('noise noisy expert data setyt minimize', 1);('negative loglikelihood objective', 1);('iet22 whererrmaps state itspartial observationas', 1);('gradient approximation proposedin section', 1);('reliable descent direction inversefeedback game problem', 1);('challenging onlypartial state observation', 1);('incomplete trajectory data thequality', 1);('degrade observation noiseis high62', 1);('robustness generalization abilityto infer nonconvex costswe', 1);('previous 2vehicle example', 1);('study infer thecosts', 1);('different levels', 1);('noise increasingvariance', 1);('thedistance noisy expert data', 1);('state trajectory results players', 1);('costs b distancebetween', 1);('costs ground truth expert data example ofsuch comparison', 1);('c thedistance', 1);('fbnestate', 1);('trajectory ground truth costs', 1);('initial conditions', 1);('collectively', 1);('robustnessand generalization performance openloop baseline whenthe expert data', 1);('assumptionto show', 1);('infer nonconvex cost functions weextend', 1);('previous 2vehicle', 1);('thatthe 2vehicle team encounters', 1);('vehicle follower wantsto stay', 1);('close leader', 1);('vehiclewe model scenario 3vehicle game', 1);('dimensionalstate space horizon', 1);('dynamics vehicle isthe', 1);('costs follows11112212222122212221222212222222222122222212log2322232222233131222322where ground truth', 1);('r5is04042', 1);('ground truthexpert state trajectory', 1);('strategy initialcondition1012203022050522 lastfour elements encode state', 1);('vehicle target lanein expert data 02similar 2vehicle experiment', 1);('settingsincomplete trajectory data partial state observation', 1);('complete trajectory data', 1);('full state observation partial stateobservation', 1);('states vehicle', 1);('thevelocity vehicles time indices', 1);('incomplete trajectory ist1112', 1);('nonconvex costof player', 1);('causes numerical problems baseline', 1);('kkt olnefig', 1);('convergence algorithm', 1);('onthe average bold lines', 1);('squareroot sample size respectivelyfig', 1);('loss value increases asshown', 1);('able learna', 1);('generalization error baseline', 1);('blue yellow curves respectivelyfig', 1);('full partial noisy observation expert', 1);('trajectories result', 1);('solid lines ground truth trajectories', 1);('ground truth baselinesolver', 1);('2regularization 10422to loss1and summarize', 1);('cost functions reflectingthe', 1);('true intentions vehicle feedback games', 1);('incomplete trajectory datafig', 1);('generalization', 1);('performance comparison target laneposition player', 1);('partial observations', 1);('incomplete trajectorydata', 1);('different noise variance', 1);('subplotthe trajectories', 1);('groundtruth baselinefig', 1);('loss value increases onthe average', 1);('generalizationerror baseline', 1);('blue yellow curves respectively7', 1);('conclusionin', 1);('efficient cost inference algorithm forinverse feedback nonlinear games partial state observation', 1);('empirical', 1);('solver converges', 1);('inverse games nonconvex costs', 1);('superior generalization performance astateoftheart openloop baseline method expert demonstration reflects group agents', 1);('dynamic feedbackgame', 1);('future directions', 1);('underwhat conditions', 1);('feedback gamesthe', 1);('active online inference', 1);('promising directions', 1);('inaddition', 1);('work settings closedloopinteraction', 1);('players information', 1);('autonomous agent sceneappendixproof', 1);('claims existsan inverse', 1);('state trajectories solutions', 1);('expertdemonstration show counterexample supports', 1);('consider', 1);('2player horizon3', 1);('game thelinear dynamics112', 1);('16and cost112122122', 1);('ground truth solutions 1121we show', 1);('extra solution 112and 22which yields', 1);('state trajectory ground truth forany', 1);('definition variable3211as', 1);('following', 1);('condition incorollary', 1);('feedback matrices 2211\x1412\x15\x141111121221\x15 z \x141121\x1512 18where matrix invertible det2212110 analysis suggests', 1);('state trajectory 10and20are', 1);('weconsider', 1);('time instant', 1);('observe\x141222\x15\x14111222\x151\x1412\x1512212\x14212\x1519we closedloop dynamics', 1);('positive variables12and12', 1);('necessary condition thesame', 1);('similarly', 1);('forthe time instant', 1);('necessary condition 12to', 1);('statetrajectory as12is', 1);('equations satisfied2122122\x001121222122\x0122222221222\x001121222122\x01222222212220we substitute 1121and 2321into', 1);('2degree polynomial', 1);('thefundamental theorem algebra', 1);('dimension thestateis', 1);('initial states 1r', 1);('state trajectoriesunder costs', 1);('parameters 11and122coincide', 1);('references1chaitanya awasthi andrew lamperski inverse', 1);('differential gameswith', 1);('inequality constraints', 1);('american control conferenceacc pages', 1);('baar geert jan olsder dynamic noncooperative gametheory siam', 1);('boyd stephen p boyd lieven vandenberghe convexoptimization cambridge', 1);('university press 20044augustinlouis', 1);('cauchy cours', 1);('lecole royale polytechnique 1re partie', 1);('analyse', 1);('debure', 1);('paris', 1);('cleach mac schwager zachary manchester algames', 1);('fast solver', 1);('dynamic games arxiv preprintarxiv191009713 20196jb', 1);('cruz jr survey', 1);('nash stackelberg equilibrim strategies indynamic games', 1);('annals', 1);('measurement volume4', 1);('nber', 1);('englert ngo anh vien marc toussaint inverse', 1);('learning', 1);('cost functions manipulation tasks demonstrations', 1);('theinternational', 1);('robotics', 1);('fridovichkeil ellis ratner lasse peters anca dragan', 1);('j tomlin efficient iterative linearquadratic approximationsfor nonlinear multiplayer generalsum differential', 1);('pages14751481 20209volker', 1);('gabler tim stahl gerold huber ozgur oguz dirk wollherr', 1);('gametheoretic approach adaptive action selection closeproximity humanrobotcollaboration', 1);('ieee201710 jorge herrera', 1);('cruz benjamin ivorra', 1);('ramos analgorithm', 1);('class multiplayer feedbacknash differentialgames', 1);('mathematical problems engineering', 1);('jairo inga esther bischoff florian kpf sren hohmann inversedynamic', 1);('maximum entropy inverse', 1);('arxiv preprint arxiv191107503', 1);('jairo inga esther bischoff timothy', 1);('molloy michael flad', 1);('hohmann solution sets inverse noncooperative linearquadratic differential', 1);('systems', 1);('rufus isaacs differential', 1);('games mathematical theory applications warfare pursuit control optimization', 1);('courier', 1);('georgios kossioris michael plexousakis anastasios xepapadeas aartde zeeuw kg mler feedback', 1);('nash equilibria nonlineardifferential games pollution control journal', 1);('dynamicsand', 1);('steven george krantz harold r parks', 1);('implicit function theorem history theory applications', 1);('businessmedia', 1);('forrest laine david fridovichkeil chihyuan chiu claire tomlin computation approximate generalized feedback nashequilibria', 1);('arxiv preprint arxiv210102900', 1);('kang woo lee jeonghoon hwang humanrobot', 1);('cooperative game', 1);('trends intelligent systems computerengineering', 1);('weiwei li emanuel todorov iterative linear quadratic regulatordesign nonlinear biological movement systems icinco', 1);('david mayne', 1);('secondorder gradient method', 1);('optimal trajectories nonlinear discretetime systems', 1);('internationaljournal', 1);('negar mehr mingyu wang mac schwager maximumentropymultiagent dynamic', 1);('forward inverse solutions arxiv', 1);('optimal control inverse noncooperative dynamicgame theory', 1);('molloy jason j ford tristan perez inverse', 1);('ifac', 1);('congress23 timothy', 1);('molloy grace', 1);('tristan perez ingo schiffner debajyoti karmaker mandyam v srinivasan', 1);('inverse differential game approach', 1);('bird midair collision avoidancebehaviours', 1);('molloy jairo inga michael flad jason j ford tristan perezand sren hohmann inverse', 1);('openloop noncooperative differentialgames inverse optimal control', 1);('ieee transactions automaticcontrol', 1);('noncooperative differential games', 1);('inverse optimalcontrol inverse noncooperative dynamic game theory', 1);('yurii nesterov', 1);('convex minimizationproblem rate convergence 1k', 1);('doklady', 1);('ussr volume', 1);('jorge nocedal stephen wright numerical optimization springerscience', 1);('media', 1);('lasse peters david fridovichkeil vicen rubiesroyo claire j tomlin cyrill stachniss inferring objectives continuous dynamicgames noisecorrupted partial', 1);('observations', 1);('arxiv preprintarxiv210603611', 1);('lasse peters david fridovichkeil claire j tomlin zachary nsunberg inferencebased strategy alignment generalsum differential', 1);('page 10371045richland', 1);('sc', 1);('autonomous agentsand multiagent systems30 lillian j ratliff samuel burden shankar sastry', 1);('thecharacterization local nash equilibria', 1);('continuous games', 1);('ieeetransactions', 1);('automatic control', 1);('simon rothfu jairo inga florian kpf michael flad srenhohmann inverse', 1);('optimal control identification noncooperative differential games', 1);('wilko schwarting alyssa pierson javier alonsomora sertac karaman daniela rus', 1);('social behavior autonomous vehicles', 1);('national academy', 1);('wilko schwarting alyssa pierson sertac karaman daniela russtochastic', 1);('dynamic games belief space', 1);('ieee transactions robotics', 1);('ilya sutskever james martens george dahl geoffrey hinton onthe', 1);('importance initialization momentum', 1);('ininternational', 1);('conference machine learning pages', 1);('pmlr201335 aneel tanwani quanyan zhu feedback nash', 1);('differentialalgebraic games', 1);('ieee transactionson automatic', 1);('chengpu yu yao li shukai li jie chen inverse', 1);('linear quadratic', 1);('automatica', 1);