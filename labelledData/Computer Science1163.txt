('gt', 13);('ol', 11);('figure', 10);('bev', 8);('l1', 6);('unknown spaces', 5);('unknown space', 5);('urban environments', 4);('pix2pix', 4);('kitti360', 4);('ol im', 4);('im', 3);('international conference', 3);('us research', 2);('novel framework planning', 2);('intersections occlusions', 2);('unknown', 2);('sensor measurement', 2);('lr', 2);('pix2pixhd', 2);('comparison', 2);('loss terms', 2);('adam', 2);('angle difference', 2);('original lidar', 2);('gttrajectory', 2);('deepfillv2', 2);('ground truth', 2);('frechet distance', 2);('hard easy data', 2);('rows', 2);('result column bold', 2);('model', 2);('angledifference', 2);('ieee', 2);('proceedings', 2);('proceedings ieee', 2);('imagetoimage translation', 2);('computer vision', 2);('paths occlusions urbanenvironmentsyutao han\x03oppo', 1);('centerfyutaohanginnopeaktechcomyouya xia\x03cornell universityfyx454gcornelleduguojun qioppo', 1);('centerfguojunqiginnopeaktechcommark campbellcornell universityfmc288gcornelleduabstract', 1);('urban spaces', 1);('impact navigability approach uses', 1);('modelto sparse', 1);('semantic lidar point cloud plans', 1);('feasible paths vehicle traverse', 1);('wedemonstrate', 1);('cars lidar data realtime occlusions andshow', 1);('areas plan', 1);('paths turnoptions', 1);('addition approach closelyfollows paths', 1);('planner occlusions', 1);('state art approachescode httpsgithubcomgenplanninggenerative planningkeywords navigation', 1);('occluded environments semantic scene understanding1 introductionplanning', 1);('challenging topic robotics limitthe speed travel decision making realtime', 1);('objectssuch cars road buildings trees fences limitations sensor range resolutionthe number extent', 1);('unknown spaces increase', 1);('environmentssuch airport', 1);('urban city', 1);('traditionally', 1);('path planners types', 1);('spaces limits speed navigability assumesunknown space', 1);('free increases chances', 1);('collisionsconsider example car turning', 1);('intersection pedestrians thecorner truck intersection space', 1);('ifa', 1);('path planner plans', 1);('spaces planner range plan path throughthe intersection planner assumes', 1);('similar examples', 1);('comparatively', 1);('insuch environment', 1);('objects order tonavigate', 1);('objects drivers slowdown', 1);('furtherour approach', 1);('addresses problem', 1);('techniques dene', 1);('unknown spaces regions', 1);('sensor measurements obstacles buildings work predicts', 1);('static structure', 1);('unknown spaces example', 1);('intersection road', 1);('path planning', 1);('birds eye view', 1);('datadriven image', 1);('model lls occludedspaces', 1);('feasible path specicallyfocus', 1);('impact navigation\x03equal contribution6th conference', 1);('robot learning corl', 1);('auckland', 1);('zealandarxiv221214138v1', 1);('dec', 1);('initial', 1);('lidar scan', 1);('purple road', 1);('output', 1);('initial lidar scan unknownpixels', 1);('semantic labels', 1);('blue dots', 1);('multiple edges', 1);('white pixels', 1);('pink dot', 1);('initial pose green dot goal', 1);('blue dots path sequencethe', 1);('main contributions paper predictive', 1);('model navigation', 1);('urban outdoor environments lls inunknown spaces', 1);('perception range', 1);('environments predictive modelis', 1);('path planning methods', 1);('task dataset training models', 1);('urban environmentsthe', 1);('planner use', 1);('experimental', 1);('novel framework', 1);('traversability graphwhich', 1);('matches ground truth ie path', 1);('feasible trajectory planning', 1);('related workspath', 1);('problem robotics', 1);('gridbased', 1);('map representations', 1);('optimal algorithms', 1);('spacesdue occlusions', 1);('approaches', 1);('replan online', 1);('optimistic assumption', 1);('free 5ref', 1);('shows range path planner outdoor', 1);('usingsemantic segmentations approach demonstrates', 1);('trajectory length therobot navigates', 1);('traditional metric grid plannerthis approach', 1);('address planning', 1);('spacesdatadriven predictive', 1);('recent work previouswork', 1);('similar outdoor environments', 1);('uses image', 1);('unknown spaces fromsensor measurements', 1);('map pixelswhich', 1);('label pixels', 1);('inpaintedas pixel', 1);('datadriven approach', 1);('considers dynamics thevehicle', 1);('refs', 1);('unknown spaces planningbut scope', 1);('indoor environments9', 1);('foreground objects background classes', 1);('howeverthese', 1);('path planninggenerative', 1);('adversarial networks gans', 1);('powerful tool', 1);('variety tasks suchas', 1);('natural language processing', 1);('super resolution', 1);('image translation', 1);('generallygans', 1);('aim model', 1);('target data domain', 1);('traditional gansfor', 1);('categories rst', 1);('gans', 1);('pairedimagetoimage translation', 1);('gansconsidered', 1);('stateoftheart image', 1);('freeform rectangularmasks', 1);('technical approachfigure', 1);('shows pipeline', 1);('semantic lidar point cloud derivedfrom lidar scan', 1);('point cloud', 1);('model llsin', 1);('traversable road pixels', 1);('graph withwaypoints', 1);('feasible path', 1);('vehicle pose', 1);('dataset generationour', 1);('dataset vehicleis', 1);('karlsruhe germany', 1);('sensor data', 1);('wespecically', 1);('focus semantic lidar data work', 1);('lidar', 1);('reliable depth stereocameras', 1);('suffers issues', 1);('semantic annotations', 1);('lidar point clouds routefor work transform point clouds birds eye view', 1);('bev bev', 1);('spaces project semantic annotations', 1);('lidarpoint clouds', 1);('individual lidar scan', 1);('point clouds theindividual semantic lidar scans', 1);('complete dataset', 1);('points classlabel vegetation', 1);('vegetation obscure', 1);('road sidewalks', 1);('unknownspaces underneath', 1);('vegetation points impact', 1);('image inpaintingin', 1);('lidar measurements', 1);('theorange', 1);('oval shows semantic annotations region', 1);('theseoccluded', 1);('spaces function obstacles buildings fences', 1);('sensor resolutionto', 1);('unknown spaces employ', 1);('generation model recoverthe', 1);('semantic information321', 1);('baseline paired generation algorithmfor', 1);('image xnin source domainxxis', 1);('2d lidar space imageynin target domainyyis', 1);('2d ground truth semantic space rst introduce abaseline', 1);('generation algorithm', 1);('isola', 1);('assumes training data', 1);('loss pixel space compares xnandynl1gxy 1nxn1knxijkgxnij\x00ynijk1 1wheregxnijandynijare pixel values ijlocation', 1);('knis', 1);('number pixelsin imageynnrefers number images training', 1);('additionally', 1);('gan', 1);('loss restore', 1);('realistic image', 1);('gan322 implementationto', 1);('generation model restores semantics', 1);('lidar space proposea modication', 1);('coarsetone generator', 1);('gand', 1);('amultiscale discriminator', 1);('dfrom pix2pixhd', 1);('lossalthough generative model restores', 1);('unknown semantics lidar space', 1);('original semantics', 1);('extraction process', 1);('due sparsityof', 1);('extractable features ensure input semantics', 1);('specically', 1);('input image xn2x theoutput image', 1);('gxn2y', 1);('asl1gx 1nxn1kxnxij2x\x03nkgxnij\x00xnijk1 2wherekxnrefers number nonzero pixels input lidar image xnandij2x\x03nrefers pixel location ijin nonzero', 1);('original input lidar image', 1);('fromthe loss function denition', 1);('loss aims ensure nonzero', 1);('original input image xnstill', 1);('gxn figure', 1);('shows anablation study ofl1gx', 1);('performance model', 1);('sec', 1);('input lidar', 1);('semantics inference resultsfrom model', 1);('l1gx sparse', 1);('semantics faraway region theroad', 1);('original lidar map', 1);('red circle', 1);('l1gx', 1);('rankingbased loss overcome large stochastic variationsthe', 1);('compensates semantics', 1);('featureextraction stage', 1);('small details', 1);('aboveto address employ loss function', 1);('local features ie image patches 20patches', 1);('target images position', 1);('similar structuresand content similarity', 1);('different positions', 1);('similar patchnce loss', 1);('hbe', 1);('hsbe', 1);('thefeature spatial location son', 1);('map usage patchnce loss', 1);('asfollowsxshsgxhsyfhs0yjs06sg 3wherevvfv\x00s0g \x00log\x14expv\x01v expv\x01v', 1);('ps0expv\x01v\x00s0', 1);('\x15 4here', 1);('constant scalar', 1);('loss respect', 1);('hsgxandhsyto', 1);('inner product similarity', 1);('hsgxand', 1);('loss training pairs havelpatchnce', 1);('ghxy', 1);('1nxs\x10hsgxnhsynfhs0ynjs06sg\x11 5in implementation', 1);('multiple layers325', 1);('final training objectivecombining', 1);('sections', 1);('training objective islgangdxy', 1);('lpatchnce ghxy l1gx', 1);('minibatch stochastic gradient descent', 1);('gandhto', 1);('minimize theobjective learning', 1);('dto', 1);('dataset', 1);('splits images image inpaintingroute', 1);('train set val set test setroute', 1);('path planningprevious', 1);('spaces order plan', 1);('account vehicle dynamics uses planner planwith pixels', 1);('possible states paper use hybrid planner 22which plans optimal', 1);('feasible pathsfigure', 1);('originallidar scan', 1);('image map', 1);('im gt', 1);('top row', 1);('mask tothe road pixels', 1);('vehicle navigates road dilate erode roadmask order', 1);('individual road points lidar scan', 1);('zhangs', 1);('skeletonize road intersections theskeleton dene waypoints wfor planner navigate', 1);('middle rowgiven nal goal location point way', 1);('3top row green dot', 1);('waypoint wto goal', 1);('local goal plan hybrida planner plans', 1);('feasible path vehicle pose goal planner statesarepxpy\x12 wherepxandpyare pixelwise coordinates \x12is orientation world framewe', 1);('focus predictive', 1);('static structures unknownspaces road', 1);('full planningstack', 1);('generate predictive model', 1);('present highlevel planner evaluation', 1);('experimental section', 1);('offtheshelf lowlevelobstaclecollision avoidance module', 1);('addition planner4', 1);('experimental evaluation41 network trainingto', 1);('train network', 1);('generate 2d lidar maps correspondingsemantic maps', 1);('traversals sequences', 1);('table 1shows number images training test', 1);('train test', 1);('locations train model 200epochs training', 1);('initial learning ratelr', 1);('rst 100epochs', 1);('decreases tozero use', 1);('generator discriminator', 1);('nvidia rtx3090 gpu', 1);('baselines section 45we use dataset', 1);('network parameters lr', 1);('optimizer training epochs42', 1);('dataset descriptionwe', 1);('intersections test', 1);('weidentify', 1);('regions vehicle', 1);('method regions eachturn dataset frames', 1);('model planning', 1);('intersections whichare difcult regions plan example rst', 1);('fty frames usedfor evaluation frame path', 1);('current vehicle location', 1);('nodes paths consist', 1);('evaluation', 1);('metricsfrechet distance', 1);('popular metric', 1);('itis', 1);('shortest pairwise distance', 1);('able traverse', 1);('paths 2d', 1);('frechet', 1);('tomeasure similarity', 1);('orientation \x12 world frame plannedtrajectories', 1);('map trajectory', 1);('tfrom', 1);('\x12 path node \x12', 1);('average angle differences trajectory evaluates', 1);('average angle difference aad', 1);('calculation isintroducedaad ingt 1nxi2t \x12ini\x00\x12gti 7where\x12inirefers ithnode', 1);('\x12gtirefers ithnode', 1);('mapnrefers number', 1);('trajectory nodes', 1);('im olaccuracy', 1);('branch prediction', 1);('skeleton', 1);('road graphs', 1);('middle row', 1);('comparing', 1);('evaluation improvement', 1);('ims', 1);('range planner', 1);('end locations number road branches', 1);('intersection skeleton metric', 1);('possible range planning hypotheses compute road', 1);('prediction accuracywe calculate percentagenimngt\x02100wherenimandngtare number branches', 1);('imand gt', 1);('olpath length', 1);('reects planner plans', 1);('goal location', 1);('length trajectories', 1);('l2', 1);('distances path nodeswe', 1);('limwith', 1);('lgtusing', 1);('evaluation length trajectory', 1);('olplanning ahead frames', 1);('map sparse', 1);('turning behaviour doesnot', 1);('existence road', 1);('intersection planner plans turning behavior44', 1);('qualitative evaluationwe', 1);('show evaluation results', 1);('top row thesemantic', 1);('map top', 1);('orange oval', 1);('region occludedfrom', 1);('scan top', 1);('road section', 1);('orange oval occursafter', 1);('buildings obstacles scene occlude road', 1);('inpaintingmodel top middle', 1);('roads existence', 1);('restof intersection pixels', 1);('scanthe middle row compares', 1);('road maps planner', 1);('regions map', 1);('similar road', 1);('gt olthe', 1);('bottom row compares', 1);('paths hybrid', 1);('scan bottom', 1);('orange oval top', 1);('plan path', 1);('straight forwards', 1);('bottom middle planner', 1);('able predictthe', 1);('model plans path', 1);('matches thegt path45', 1);('quantitative evaluationto', 1);('model planningunderocclusions task', 1);('different stateoftheart', 1);('conduct baseline6figure', 1);('planner performance model baselinespix2pixhd', 1);('gt columns leftmost', 1);('original lidarol', 1);('fourth pix2pixhd', 1);('rightmost deepfillv2', 1);('rows top', 1);('semantic point cloud', 1);('white dot vehicle pose green dotis end point', 1);('orange oval top row', 1);('semantic map highlights section ofthe road', 1);('road waypoints', 1);('blue dotsbottom', 1);('pink goal green', 1);('nodes inbluecomparisons', 1);('model evaluation results', 1);('original lidarmaps', 1);('show generative networks predictive capabilities improvement', 1);('easy setincludes', 1);('simple navigate', 1);('hard setincludes', 1);('intersections difcult navigate', 1);('objects allowsfor evaluation framework performs environments', 1);('different levels', 1);('difcultytable 3the evaluation results', 1);('model outperforms', 1);('olscans', 1);('baselines path planning task', 1);('metrics thepath planner', 1);('scans means', 1);('useful path planning model', 1);('means model plans', 1);('similar paths', 1);('gtusing gt', 1);('map reference model', 1);('accuracy major branchprediction', 1);('path length', 1);('shows model generates road networkthat', 1);('ground truththe evaluation results', 1);('hard easy subsets demonstratethe', 1);('model improves performance', 1);('complex scenes', 1);('ourmodel improves', 1);('foraverage angle difference', 1);('\x0e accuracy', 1);('prediction improvement', 1);('note frames', 1);('framework especiallybenecial', 1);('complex navigation scenarios', 1);('intersections path lengththe improvement difference', 1);('complex scenarios', 1);('large difference', 1);('olwe', 1);('list inference time', 1);('nvidia rtx3090', 1);('column shows ourmodel', 1);('acceptable inference speed', 1);('fps', 1);('available computation resources5', 1);('limitationsour', 1);('paper assumes pose vehicle', 1);('accurate community', 1);('large body ofwork', 1);('slam', 1);('evaluation baselines model', 1);('aremodels columns metrics', 1);('nmetricfrechet distancepixelaverage', 1);('majorbranch prediction frame plannedahead path', 1);('inference timefpsol', 1);('nadeepfillv2', 1);('evaluation data', 1);('easy subsets', 1);('models andcolumns metrics', 1);('entries', 1);('hardeasy results', 1);('nmetricfrechet distance', 1);('hard easy pixelaverage', 1);('hard easy \x0eaccuracy major', 1);('branchprediction', 1);('frame plannedahead', 1);('path', 1);('semantic segmentations', 1);('raw lidar point clouds', 1);('real time', 1);('futurework', 1);('real time semantic lidar segmentations addition weassume online deployment data domain training datawhile', 1);('reasonable assumption', 1);('large amount availabledata', 1);('future framework', 1);('scenarios online training data arefrom', 1);('domain adaptation techniques', 1);('conclusionthis', 1);('outdoorurban environments', 1);('feasible paths', 1);('model predictions introduce', 1);('pix2pixnetwork', 1);('dataset planningthroughocclusions problem specicallyfocus', 1);('intersections evaluation regions navigation', 1);('experiments', 1);('validate framework model', 1);('show planner plans paths muchcloser ground truth', 1);('original sensor measurement8acknowledgmentswe', 1);('reviewers comments feedback work', 1);('onrunder', 1);('n000141712699 nsf', 1);('nsf iis1830497references1 p isola jy zhu zhou efros imagetoimage', 1);('translation conditionaladversarial networks', 1);('computer vision pattern recognition cvpr', 1);('p e hart n j nilsson', 1);('raphael', 1);('formal basis heuristic determination ofminimum cost paths', 1);('ieee syst sci cyb', 1);('stentz optimal', 1);('efcient path planning', 1);('procicra', 1);('han h lin j ban k bala campbell deepsemantichppc hypothesisbasedplanning', 1);('uncertain semantic point clouds', 1);('proc icra', 1);('han j ban e campbell', 1);('unknown space imaginingwhat', 1);('corl', 1);('ryll j ware j carter n roy semantic', 1);('trajectory planning', 1);('aerial vehicle navigation', 1);('ieeersj', 1);('intelligent robots systems iros', 1);('g georgakis', 1);('bucher arapin k schmeckpeper n matni k daniilidisuncertaintydriven', 1);('planner exploration navigation', 1);('conferenceon robotics automation icra', 1);('narasimhan e wijmans x chen darrell batra parikh singh seeingthe', 1);('learning', 1);('amodal semantic maps room navigation', 1);('computer vision eccv', 1);('cham', 1);('springer', 1);('isbn', 1);('lu g dubbelman semantic', 1);('weak supervision', 1);('ieee ral', 1);('p purkait', 1);('zach reid seeing', 1);('extending', 1);('semantic segmentation', 1);('proc iros', 1);('schulter zhai n jacobs k chandraker learning', 1);('objects fortopview representations outdoor scenes', 1);('arxiv', 1);('goodfellow j pougetabadie mirza', 1);('xu wardefarley ozair courvilleand bengio generative', 1);('adversarial nets', 1);('advances', 1);('neural information processing systems', 1);('croce g castellucci r basili ganbert generative', 1);('adversarial learning robusttext classication bunch', 1);('annual meetingof association computational linguistics pages', 1);('ledig', 1);('theis', 1);('husz', 1);('j caballero cunningham acosta aitken tejani j totz z wang', 1);('photorealistic', 1);('image superresolution', 1);('generativeadversarial network', 1);('conference computer vision patternrecognition pages', 1);('jy zhu', 1);('p isola efros unpaired', 1);('cycleconsistent adversarial networkss', 1);('computer vision iccv', 1);('tc wang liu jy zhu tao j kautz', 1);('catanzaro highresolution', 1);('image synthesis semantic manipulation conditional gans', 1);('proceedings ieeeconference', 1);('computer vision pattern recognition pages', 1);('j yu z lin j yang x shen x lu huang generative', 1);('withcontextual attention arxiv preprint arxiv180107892', 1);('j yu z lin j yang x shen x lu huang freeform', 1);('liao j xie geiger kitti360', 1);('novel dataset benchmarks', 1);('3d arxiv preprint arxiv210913410', 1);('xia j monica wl chao', 1);('hariharan k q weinberger campbell imagetoimage', 1);('translation autonomous', 1);('image pairs arxiv preprintarxiv220911673', 1);('efros r zhang jy zhu contrastive', 1);('european conference', 1);('springer202022 dolgov thrun montemerlo j diebel practical', 1);('search techniques path planning autonomous', 1);('symposium searchtechniques articial intelligence robotics stair08', 1);('zhang', 1);('suen', 1);('fast parallel algorithm thinning digital patterns', 1);('communacm', 1);('issn', 1);('url', 1);('p kingma j ba adam', 1);('method stochastic optimization', 1);('internationalconference learning representations iclr', 1);('h alt godau computing', 1);('fr echet distance', 1);('polygonal curves', 1);('international journal', 1);('computational geometry applications', 1);('h durrantwhyte bailey simultaneous', 1);('part', 1);('theessential algorithms', 1);('ieee robotics automation magazine', 1);('milioto vizzo j behley', 1);('stachniss rangenet fast accurate lidarsemantic segmentation ieeersj intl conf intelligent robots systems iros', 1);('g csurka r v', 1);('olpi b', 1);('chidlovskii unsupervised', 1);('domain adaptation semantic imagesegmentation', 1);('comprehensive survey arxiv preprint arxiv211203241', 1);('liu', 1);('zhang j wang sourcefree', 1);('domain adaptation semantic segmentation', 1);('inproceedings ieeecvf', 1);('computer vision pattern recognition', 1);