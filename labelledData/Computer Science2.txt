('lidar', 37);('cmt', 34);('computer vision', 28);('bev', 21);('proceedings', 21);('pattern recognition', 18);('ieee/cvf', 15);('nds', 14);('3d object detection', 14);('bevfusion', 11);('detr', 11);('lc', 11);('multi-modal tokens', 10);('transfusion', 10);('ieee', 10);('object queries', 9);('masked-modal training', 9);('tab', 9);('point clouds', 8);('fig', 8);('point cloud', 8);('petr', 8);('sota', 7);('3d space', 6);('] l', 6);('nds/map', 6);('springer', 6);('xiangyu zhang', 6);('jian sun', 6);('different modalities', 5);('transformer decoder', 5);('strong robustness', 5);('cem', 5);('uvtr', 5);('dn-detr', 5);('pqd', 5);('3d points', 4);('3d coordinates', 4);('detr3d', 4);('futr3d', 4);('anchor points', 4);('negative queries', 4);('map mate mase maoe', 4);('radar', 4);('european conference', 4);('zeming li', 4);('different', 3);('camera images', 3);('recently', 3);('position', 3);('inspired', 3);('multi-modal fusion', 3);('lidar-only', 3);('object detection', 3);('point cloud tokens', 3);('3d positions', 3);('li- dar', 3);('bevdet', 3);('point-based', 3);('pointnet', 3);('multi-view images', 3);('im pe', 3);('pc pe', 3);('query generator', 3);('oxelnet [', 3);('dino', 3);('anchor boxes', 3);('noise scale', 3);('ve', 3);('] c', 3);('cmt-l', 3);('pointpillars', 3);('image size', 3);('% map', 3);('attention maps', 3);('alex h lang', 3);('sourabh v', 3);('alexander kirillov', 3);('yue wang', 3);('tiancai wang', 3);('international conference', 3);('deep', 3);('feng li', 3);('hao zhang', 3);('shilong liu', 3);('lei zhang', 3);('hao su', 3);('leonidas j guibas', 3);('modal transformer', 2);('robust 3d', 2);('complementary information', 2);('state-of-the-art', 2);('two-stage pipeline', 2);('end-to-end pipeline', 2);('pc transformer', 2);('high response regions', 2);('one-to-one assignment', 2);('cams', 2);('cross-modal transformer', 2);('coordinates encoding module', 2);('specically', 2);('relative coordinates', 2);('similar performance', 2);('multi- modal tokens', 2);('based', 2);('works [', 2);('image plane', 2);('lss', 2);('bevdepth', 2);('raw point clouds', 2);('3d anchor points', 2);('multi-modal', 2);('3d detection', 2);('deformable attention [', 2);('dab-detr', 2);('multi-view', 2);('suppose', 2);('mlp', 2);('ce', 2);('corresponding 3d points', 2);('k =', 2);('pointpillar', 2);('3d world space', 2);('noise queries', 2);('roi', 2);('center noise', 2);('noise query', 2);('performance', 2);('pointpainting', 2);('pointaugmenting', 2);('fusionpainting', 2);('cmt lc', 2);('decoder layer', 2);('qi', 2);('nuscenes val', 2);('experiments', 2);('metrics', 2);('fps', 2);('key frames', 2);('resnet', 2);('oxel size', 2);('cbgs', 2);('multi-modal method', 2);('vanilla training', 2);('ablation studies', 2);('resnet-50', 2);('major modality', 2);('com-', 2);('voxel number', 2);('visualization', 2);('foreground objects', 2);('petrv2', 2);('image frames', 2);('global attention', 2);('foreground tokens', 2);('xinge zhu', 2);('yilun chen', 2);('robust', 2);('holger caesar', 2);('oscar beijbom', 2);('nicolas carion', 2);('francisco massa', 2);('gabriel synnaeve', 2);('nicolas usunier', 2);('sergey zagoruyko', 2);('end-to-', 2);('end object detection', 2);('european confer- ence', 2);('qiang chen', 2);('xiaokang chen', 2);('jingdong wang', 2);('fast', 2);('bo li', 2);('tianyuan zhang', 2);('hang zhao', 2);('bin dong', 2);('fangao zeng', 2);('yichen wei', 2);('advances', 2);('feng wang', 2);('naiyan wang', 2);('junjie huang', 2);('guan huang', 2);('multi-camera 3d object detection', 2);('lionel', 2);('ni', 2);('jiaya jia', 2);('jifeng dai', 2);('multi-camera images', 2);('hang su', 2);('jun zhu', 2);('yingfei liu', 2);('gang yu', 2);('charles r qi', 2);('xiaogang wang', 2);('tai wang', 2);('jiangmiao pang', 2);('dahua lin', 2);('robot learning', 2);('justin solomon', 2);('end-to-end', 2);('end-to-end object detection', 2);('coordinates encoding', 1);('object dectection junjie yan yingfei liu jianjian sun fan jia shuailin li tiancai wang xiangyu zhang megvii', 1);('abstract', 1);('end-to-end 3d multi- modal detection', 1);('explicit view transformation', 1);('point clouds tokens', 1);('accurate 3d', 1);('spatial alignment', 1);('multi-modal fea- tures', 1);('core design', 1);('nuscenes benchmark', 1);('strong robust- ness', 1);('code', 1);('introduction multi-sensor', 1);('great superiority', 1);('au- tonomous', 1);('system [ 1,8,20,24,28 ]', 1);('camera captures information', 1);('perspective view', 1);('image contains', 1);('rich semantic fea- tures', 1);('geometry information', 1);('full advantage', 1);('differ- ent sensors', 1);('robust prediction', 1);('sensor', 1);('large discrepancy', 1);('birds-eye- view', 1);('representation [ 20,24,28 ]', 1);('to- kens [', 1);('] explores', 1);('fu- sion', 1);('supplementary information', 1);('prediction renement', 1);('multi-sensor fusion', 1);('end-to-end object detec- tion', 1);('perception tasks', 1);('instance segmentation [', 1);('image quries', 1);('step1 image', 1);('transformer', 1);('pc', 1);('bev encoder vt', 1);('ours', 1);('pefigure', 1);('comparison', 1);('view transform', 1);('rst generates', 1);('ob- ject queries interact', 1);('multi modality', 1);('pe', 1);('vt', 1);('view transformation', 1);('visual 3d detec- tion [', 1);('ef- fective thanks', 1);('different instances', 1);('elegant end-to- end pipeline', 1);('image to- kens', 1);('3darxiv:2301.01283v1 [ cs.cv ]', 1);('jan', 1);('[ % ]', 1);('lidar petr cmt-l71.9', 1);('68.6drop resultfigure', 1);('con- dition', 1);('similar detection performance', 1);('detec- tor', 1);('camera input', 1);('slight drop', 1);('cmt-l.', 1);('netune process', 1);('intuitive way', 1);('im- age', 1);('corresponding locations', 1);('effective end-to-end pipeline', 1);('high- performance 3d object detection', 1);('frustum space', 1);('3d reference point', 1);('reference points', 1);('in- troduce', 1);('inductive bias', 1);('query denoising', 1);('firstly', 1);('sim- ple', 1);('ex- plicit cross-view', 1);('secondly', 1);('basic operations', 1);('feature sam-', 1);('complex 2d-to-3d view transformation', 1);('multi- modal', 1);('thirdly', 1);('extremely', 1);('visual 3d object detectors [', 1);('end- to-end framework', 1);('complex operations', 1);('state-of-the-art 3d detection perfor- mance', 1);('nuscenes dataset', 1);('simple base- line', 1);('future research', 1);('related', 1);('object detection camera-based', 1);('basic tasks', 1);('early', 1);('dense prediction pipeline', 1);('rst localize', 1);('relevant 3d at- tributes', 1);('redundant predictions', 1);('3d ob- ject detection', 1);('atten- tion', 1);('fuse information', 1);('multiple camera', 1);('depth distri- bution', 1);('3d frustum meshgrid', 1);('bev-', 1);('] project', 1);('im- ages', 1);('transformer attention', 1);('above methods ex-', 1);('local image', 1);('2d perspective view', 1);('spa-', 1);('tialdetr [', 1);('camera poses', 1);('lidar based', 1);('object detection lidar-based', 1);('3d object detection aims', 1);('3d ob- ject', 1);('existing', 1);('methods process', 1);('dif- ferent representations', 1);('methods [', 1);('pre- dict 3d', 1);('rst archi- tecture', 1);('end-to-end man- ner', 1);('spatial characteristics', 1);('methods project', 1);('3d voxels [', 1);('pillars [', 1);('range im- ages [', 1);('bevfigure', 1);('back- bone networks', 1);('camera rays', 1);('image position', 1);('point cloud position', 1);('right part', 1);('model convergence', 1);('standard 2d backbone', 1);('] rst di- vides', 1);('regular voxel grids', 1);('voxel grid', 1);('object detection multi-sensor', 1);('great at- tention', 1);('recent years', 1);('dene object queries', 1);('predic- tion', 1);('] applies', 1);('lift-splat- shoot', 1);('] generates', 1);('3d voxel space', 1);('] denes', 1);('3d reference points', 1);('transformer-based object detection', 1);('hand-craft compo- nents', 1);('3d detection [', 1);('detr-like', 1);('meth- ods', 1);('slow convergence', 1);('various aspects', 1);('2d detection', 1);('transformer layers [', 1);('informative object queries [ 19,25,53 ]', 1);('label assignment mech- anism [', 1);('de-formable attention', 1);('local regions', 1);('sam-detr', 1);('semantic aligner', 1);('] formulates', 1);('dynamic anchor boxes', 1);('noisy ones', 1);('contrastive way', 1);('method', 1);('overall architecture', 1);('individual backbones', 1);('extract multi-modal tokens', 1);('in- teract', 1);('object class', 1);('whole framework', 1);('end-to- end manner', 1);('en- code', 1);('3d position information', 1);('position encodings', 1);('pes', 1);('image tokens', 1);('letp', 1);('thefeature map f', 1);('in- dicates', 1);('feature map', 1);('fis', 1);('output position', 1);('multi-layer perception', 1);('images', 1);('per- spective view', 1);('epipolar line', 1);('camera frustum space', 1);('per- form', 1);('fim', 1);('points fpk', 1);('camera frustum coordinates', 1);('depth axis', 1);('pim k', 1);('=tl cik\x001 ipk', 1);('wheretl ci2r4\x024is', 1);('transformation matrix', 1);('i- th camera', 1);('ki24\x024', 1);('intrinsic matrix', 1);('i-th camera', 1);('= im', 1);('fpim k', 1);('clouds', 1);('point cloud to- kensfpc', 1);('intuitively', 1);('pin eq', 1);('z-axis', 1);('coordi- nates', 1);('h k', 1);('k-th points', 1);('ppc k', 1);('height axis', 1);('= pc', 1);('fppc k', 1);('position-guided query generator following anchor-detr', 1);('nanchor points', 1);('a=fai=', 1);('uniform dis- tribution', 1);('linear transformation', 1);('> < >', 1);('+xmin ay', 1);('+ymin az', 1);('box center anchor pointadd noise noisy querydecoder box center anchor pointadd noise noisy querydecodernonepositive negativefigure', 1);('illustration', 1);('box center', 1);('ground- truths', 1);('positive', 1);('ground-truths boxes', 1);('[ xmin', 1);('zmax ]', 1);('ato', 1);('corresponding point', 1);('\x00qof object queries', 1);('\x00q= pc', 1);('apc', 1);('+ im', 1);('aim', 1);('positional embed- ding\x00qare', 1);('query content', 1);('q0', 1);('point-based query denoising', 1);('fast convergence', 1);('noisy anchor points', 1);('box scale', 1);('3d ground-truths box', 1);('rst sample', 1);('random ratio \x151', 1);('noise anchor points', 1);('noise an- chor point', 1);('intro- duce', 1);('negative noisy queries', 1);('random ratios \x151', 1);('positive query ifp \x152 1+\x152 2+\x152', 1);('< \x18', 1);('nuscenes testset', 1);('methods modality nds', 1);('mate # mase # maoe # ma', 1);('# maae #', 1);('centerpoint', 1);('mvp [', 1);('nuscenes valset', 1);('methods', 1);('decoder', 1);('loss', 1);('original transformer decoder', 1);('ldecoder', 1);('queries interact', 1);('feed-forward networks', 1);('ffns', 1);('prediction process', 1);('^bi= reg', 1);('^ci= cls', 1);('ffn', 1);('qiis', 1);('i-th decoder layer', 1);('figure', 1);('system robustness', 1);('test period', 1);('sensor errors', 1);('focal loss', 1);('l1', 1);('box regression', 1);('loss terms', 1);('robustness', 1);('important concern', 1);('ideal system', 1);('solid perfor- mance', 1);('specic modality', 1);('sensor failure', 1);('how-', 1);('scan range', 1);('model need', 1);('extreme failures', 1);('actual scene', 1);('quantitative', 1);('metricvanilla', 1);('masked-modal', 1);('cams cmt', 1);('cams nds', 1);('training process', 1);('strategy ensures', 1);('model weight', 1);('experimental results', 1);('fusion model', 1);('range-view 3d detectors [', 1);('datasets', 1);('nuscenes [', 1);('large-scale multi-modal dataset', 1);('700/150/150 scenes', 1);('cameras', 1);('20svideo frames', 1);('nuscenes', 1);('common practice', 1);('current frame', 1);('nuscenes ofcial metrics', 1);('detection score', 1);('average precision', 1);('average translation error', 1);('average scale error', 1);('average orien-', 1);('error', 1);('average velocity error', 1);('average attribute error', 1);('details', 1);('ovnet [', 1);('image backbone', 1);('2d image', 1);('c5', 1);('c4', 1);('p4', 1);('region-of- interest', 1);('[ \x0054:0m', 1);('54:0m ]', 1);('[ \x005:0m', 1);('3:0m ]', 1);('world space', 1);('feature dimension', 1);('decoder layers', 1);('batch size', 1);('a100 gpus', 1);('adamw', 1);('] optimizer', 1);('ini- tial learning rate', 1);('cycle learn-', 1);('rate policy [', 1);('mask ratios \x111and\x112are', 1);('threshold \x18is', 1);('tolerance \x15that', 1);('gt', 1);('sample augmentation', 1);('rest epochs', 1);('loss weights', 1);('default setting', 1);('state-of-the-art comparison', 1);('comparable results', 1);('state-of-the-art methods', 1);('nuscenes test', 1);('sota bevfusion', 1);('benets', 1);('large receptive eld', 1);('met- rics', 1);('multi-modal fu- sion outperforms', 1);('large performance improvements', 1);('lidar-only cmt-l', 1);('% /5.8 %', 1);('% /7.0 %', 1);('var- ious', 1);('harsh environments', 1);('cam- era', 1);('different components', 1);('im pc nds', 1);('x0.665', 1);('x x', 1);('point-based query denoise', 1);('backbone.nds map mate mase maoe', 1);('resnet-101', 1);('image', 1);('input', 1);('image backbone.nds map mate mase maoe', 1);('ne- tune process', 1);('pre- dict', 1);('ab- sence', 1);('camera modalities lead', 1);('similar re- sults', 1);('single-modal training settings', 1);('degrade sig-', 1);('especially', 1);('compara- ble', 1);('experimental', 1);('result shows', 1);('slight perfor- mance drop', 1);('% performance', 1);('oracle ver- sion', 1);('important role', 1);('camera sensors', 1);('large eld', 1);('multi-modal frame- work facilitate', 1);('im- age domains', 1);('robust performance', 1);('ablations', 1);('experi- ments', 1);('rst ablate', 1);('gen- eration', 1);('% =8:70 %', 1);('performance drop', 1);('% =1:5 %', 1);('effective- ness', 1);('overall perfor- mance', 1);('% =5:7 %', 1);('input size', 1);('over-', 1);('model size', 1);('interest-', 1);('voxel size', 1);('similar improvements \x191:5 %', 1);('image size increases', 1);('+3.2 %', 1);('+1.7 %', 1);('performance improvements', 1);('small ob- jects', 1);('conduct experiments', 1);('ov-99 [', 1);('image back- bones', 1);('ov-99 backbone', 1);('% =1:8 %', 1);('oxelnet out- performs', 1);('% =4:3 %', 1);('analysis cmt', 1);('easy pipeline', 1);('multi-modal fu- sion', 1);('] framework', 1);('training schedule', 1);('data', 1);('multi-frame', 1);('common setting infigure', 1);('blue points', 1);('red points', 1);('corresponding centers', 1);('box predictions', 1);('3d object detection [', 1);('multi frames', 1);('typical occlusion problem', 1);('multi-frame alignment', 1);('high memory cost', 1);('ex- periment', 1);('800\x02320image resolution', 1);('image frame', 1);('by0:2 % =0:7 %', 1);('per- formance', 1);('long range detection', 1);('ro- bustness', 1);('extreme weather', 1);('following futr3d', 1);('stack points', 1);('pipeline degrades', 1);('attention map', 1);('cross-modal interaction', 1);('initial anchor points', 1);('center points', 1);('anchor points focus', 1);('accurate center points', 1);('+frame +', 1);('radar nds', 1);('conclusions', 1);('end-to-end framework', 1);('multi-modal 3d object detection', 1);('effec- tive', 1);('end-to-end learning', 1);('simple pipeline design', 1);('end-to-end 3d object detection', 1);('limitation', 1);('computation cost', 1);('large number', 1);('individual network [', 1);('pos- sible solution', 1);('efcient attentions', 1);('small set', 1);('queries correspond', 1);('empty objects', 1);('references', 1);('xuyang bai', 1);('zeyu hu', 1);('qingqiu huang', 1);('hongbo fu', 1);('chiew-lan tai', 1);('lidar-camera fusion', 1);('transform- ers', 1);('vision', 1);('varun bankiti', 1);('venice erin liong', 1);('qiang xu', 1);('anush krishnan', 1);('yu pan', 1);('gi-', 1);('baldan', 1);('multi- modal dataset', 1);('gang zeng', 1);('group detr', 1);('training convergence', 1);('one-to-many label assignment', 1);('arxiv preprint arxiv:2207.13085', 1);('jian wang', 1);('chuchu han', 1);('shangang zhang', 1);('zexian li', 1);('jiahui chen', 1);('xiaodi wang', 1);('shumin han', 1);('gang zhang', 1);('haocheng feng', 1);('kun yao', 1);('junyu han', 1);('errui ding', 1);('group detr v2', 1);('strong', 1);('xiaozhi chen', 1);('huimin ma', 1);('ji wan', 1);('tian xia', 1);('3d object detection network', 1);('xuanyao chen', 1);('yilun wang', 1);('sensor fusion framework', 1);('arxiv preprint arxiv:2203.10642', 1);('simon doll', 1);('richard schulz', 1);('lukas schneider', 1);('viviane ben-', 1);('markus enzweiler', 1);('hendrik lensch', 1);('spatialdetr', 1);('multi-view camera images', 1);('global cross-sensor atten- tion', 1);('solq', 1);('segmenting', 1);('neural information processing sys-', 1);('lue fan', 1);('xuan xiong', 1);('zhaoxiang zhang', 1);('rangedet', 1);('range view', 1);('yuxin fang', 1);('shusheng yang', 1);('xinggang wang', 1);('yu li', 1);('chen fang', 1);('ying shan', 1);('bin feng', 1);('wenyu liu', 1);('instances', 1);('proc', 1);('ieee conf', 1);('comp', 1);('vis', 1);('patt', 1);('recogn', 1);('kaiming', 1);('shaoqing ren', 1);('residual learning', 1);('image recognition', 1);('proceed-', 1);('bevdet4d', 1);('exploit', 1);('tempo- ral cues', 1);('arxiv preprint arxiv', 1);('zheng zhu', 1);('dalong', 1);('high-performance', 1);('arxiv preprint arxiv:2112.11790', 1);('ding jia', 1);('yuhui yuan', 1);('haodi', 1);('xiaopei wu', 1);('haojun yu', 1);('weihong lin', 1);('lei sun', 1);('chao zhang', 1);('han hu', 1);('detrs', 1);('arxiv preprint arxiv:2207.13080', 1);('lubing zhou', 1);('jiong yang', 1);('youngwan lee', 1);('jongyoul', 1);('centermask', 1);('real-', 1);('time anchor-free instance segmentation', 1);('jian guo', 1);('accelerate', 1);('detr training', 1);('yanwei li', 1);('xiaojuan qi', 1);('unifying', 1);('arxiv preprint arxiv:2206.00630', 1);('yinhao li', 1);('zheng ge', 1);('guanyi yu', 1);('jinrong yang', 1);('zengran wang', 1);('yukang shi', 1);('jianjian sun', 1);('acquisition', 1);('reliable depth', 1);('multi-view 3d object detec- tion', 1);('arxiv preprint arxiv:2206.10092', 1);('zhichao li', 1);('universal 3d object', 1);('zhiqi li', 1);('wenhai wang', 1);('hongyang li', 1);('enze xie', 1);('chong-', 1);('sima', 1);('tong lu', 1);('qiao yu', 1);('bevformer', 1);('learning', 1);('birds-eye-view representation', 1);('spatiotemporal transformers', 1);('arxiv preprint arxiv:2203.17270', 1);('tingting liang', 1);('hongwei xie', 1);('kaicheng yu', 1);('zhongyu xia', 1);('zhiwei lin', 1);('yongtao wang', 1);('tao tang', 1);('bing wang', 1);('zhi tang', 1);('robust lidar-camera fusion framework', 1);('arxiv preprint arxiv:2205.13790', 1);('xiao yang', 1);('xianbiao qi', 1);('dynamic', 1);('arxiv preprint arxiv:2201.12329', 1);('multi-view 3d object detection', 1);('arxiv preprint arxiv:2203.05625', 1);('junjie yan', 1);('fan jia', 1);('shuailin li', 1);('qi gao', 1);('tian-', 1);('wang', 1);('3d perception', 1);('arxiv preprint arxiv:2206.01256', 1);('zhijian liu', 1);('haotian tang', 1);('alexander amini', 1);('xinyu yang', 1);('huizi mao', 1);('daniela rus', 1);('han', 1);('multi-', 1);('task multi-sensor fusion', 1);('birds-eye view repre- sentation', 1);('arxiv preprint arxiv2205.13542', 1);('ilya loshchilov', 1);('frank hutter', 1);('decoupled', 1);('weight decay regularization', 1);('arxiv preprint arxiv:1711.05101', 1);('tim meinhardt', 1);('laura leal-taixe', 1);('christoph feichtenhofer', 1);('trackformer', 1);('multi-object', 1);('arxiv preprint arxiv:2101.02702', 1);('chao peng', 1);('tete xiao', 1);('yuning jiang', 1);('kai jia', 1);('megdet', 1);('large mini-batch object', 1);('con- ference', 1);('jonah philion', 1);('sanja fidler', 1);('lift', 1);('encoding', 1);('arbitrary camera rigs', 1);('wei liu', 1);('chenxia wu', 1);('frustum', 1);('rgb- d data', 1);('kaichun mo', 1);('3d classication', 1);('charles ruizhongtai qi', 1);('li yi', 1);('pointnet++', 1);('metric space', 1);('neural information processing systems', 1);('shaoshuai shi', 1);('hongsheng li', 1);('pointr-', 1);('3d object proposal generation', 1);('com- puter vision', 1);('leslie n smith', 1);('cyclical', 1);('learning rates', 1);('training neural networks', 1);('winter conference', 1);('wacv', 1);('pei sun', 1);('weiyue wang', 1);('yuning chai', 1);('gamaleldin el-', 1);('alex bewley', 1);('xiao zhang', 1);('cristian sminchisescu', 1);('dragomir anguelov', 1);('rsn', 1);('range sparse net', 1);('ef- cient', 1);('accurate lidar 3d object detection', 1);('bassam helou', 1);('oscar bei-', 1);('sequential', 1);('3d object de- tection', 1);('chunwei wang', 1);('chao ma', 1);('ming zhu', 1);('xiaokang yang', 1);('cross-modal', 1);('zhu xinge', 1);('probabilistic', 1);('geometric depth', 1);('detecting', 1);('per- spective', 1);('pmlr', 1);('fcos3d', 1);('fully', 1);('convolutional one-stage monocular 3d objectdetection', 1);('yulin wang', 1);('zhaoxi chen', 1);('haojun jiang', 1);('shiji', 1);('yizeng han', 1);('gao huang', 1);('adaptive', 1);('efcient video recognition', 1);('alireza fathi', 1);('abhijit kundu', 1);('david', 1);('ross', 1);('caroline pantofaru', 1);('tom funkhouser', 1);('pillar-based', 1);('guizilini vitor campagnolo', 1);('3d-to-2d queries', 1);('confer-', 1);('yingming wang', 1);('tong yang', 1);('anchor', 1);('query', 1);('arxiv preprint arxiv:2109.07107', 1);('shaoqing xu', 1);('dingfu zhou', 1);('jin fang', 1);('junbo yin', 1);('zhou bin', 1);('liangjun zhang', 1);('multimodal', 1);('adaptive attention', 1);('intelligent', 1);('systems', 1);('itsc', 1);('yan yan', 1);('yuxing mao', 1);('sparsely', 1);('convolutional detection', 1);('sensors', 1);('zetong yang', 1);('yanan sun', 1);('shu liu', 1);('3d single stage object', 1);('tianwei yin', 1);('xingyi zhou', 1);('philipp krahenbuhl', 1);('center-', 1);('yuang zhang', 1);('xi-', 1);('zhang', 1);('motr', 1);('multiple- object', 1);('gongjie zhang', 1);('zhipeng luo', 1);('yingchen yu', 1);('kaiwen cui', 1);('shijian lu', 1);('accelerating', 1);('detr convergence', 1);('ieee/cvf confer-', 1);('cvpr', 1);('june', 1);('heung-yeung shum', 1);('arxiv preprint arxiv:2203.03605', 1);('yin zhou', 1);('oncel tuzel', 1);('pattern recog- nition', 1);('benjin zhu', 1);('zhengkai jiang', 1);('xiangxin zhou', 1);('class-balanced', 1);('point cloud 3d object detection', 1);('arxiv preprint arxiv:1908.09492', 1);('xizhou zhu', 1);('weijie su', 1);('lewei lu', 1);('bin li', 1);('deformable detr', 1);('deformable trans-formers', 1);('arxiv preprint arxiv:2010.04159', 1);