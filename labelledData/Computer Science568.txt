('sdc', 17);('fcam', 16);('url', 15);('proceedings', 13);('ft', 12);('figure', 9);('international conference', 7);('xu', 6);('error', 6);('attention models', 5);('sparsemax', 5);('mil', 4);('softmax sm', 4);('spherical sm', 4);('hard', 4);('inner product', 4);('proceedings machine learning', 3);('wiegre', 3);('pinter', 3);('selective dependence classi', 3);('trained', 3);('algorithm', 3);('br\x13', 3);('entropy', 3);('cnn', 3);('conference track', 3);('the2019 conference', 3);('ne', 3);('mlp', 3);('interpretability attention', 2);('attention mechanisms', 2);('attention mechanism', 2);('fcam sdc', 2);('interpretability attention networks0', 2);('heatmap', 2);('coco', 2);('tables', 2);('xy', 2);('focus model', 2);('fcams', 2);('focus network', 2);('mosaic training points', 2);('mode illustration', 2);('focus model foverlaid scatterplot base distributions b', 2);('decision', 2);('various error modes', 2);('100no epochs050100data percentage0', 2);('martins astudillo', 2);('classi cation network', 2);('attention accuracy', 2);('ft nnz dist ent', 2);('layer mechanismsm0 zeroth', 2);('mosaic instance', 2);('fraction', 2);('test data focus score j\x03for', 2);('true foreground indexj\x03is threshold', 2);('function threshold', 2);('nnz', 2);('yoshua bengio yann lecun', 2);('learning representations iclr', 2);('north american chapter association', 2);('computationallinguistics', 2);('language technologies', 2);('short papers', 2);('minneapolis minnesota', 2);('computational linguisticsdoi', 2);('machine learning', 2);('research pages', 2);('pmlr', 2);('advances neural information processing systems', 2);('language processing', 2);('foreground classes', 2);('adam', 2);('optimizer learning rate', 2);('learning rate search space', 2);('zeroth layer', 2);('vashisht ramaswamycategory id label words', 2);('hot dog', 2);('acml', 1);('interpretability attention networkslakshmi narayan pandeylnpandeyiitmgmailcomdepartment cse iit madras chennai indiarahul vashishtrahulcseiitmacindepartment cse iit madras chennai indiaharish g ramaswamy', 1);('cse iit madras chennai indiaeditors emtiyaz khan mehmet g\x7f', 1);('onenabstractattention mechanisms form core component', 1);('successful deep learning architectures', 1);('key idea output', 1);('small unknownsegment input', 1);('practical applications', 1);('language translation', 1);('models attention mechanism theoutputs intermediate module encodes segment input', 1);('responsible theoutput', 1);('way peek reasoning network', 1);('sucha notion precise variant classi cation problem term selective dependence classi cation', 1);('attention model architectures sucha setting', 1);('various error modes attention model accuratebut', 1);('interpretable show models', 1);('result trainingwe', 1);('various situations accentuate mitigate behaviour', 1);('finallywe', 1);('nition interpretability', 1);('attention model learning algorithms', 1);('deep learning1 introductionattention', 1);('devlin', 1);('seo', 1);('vaswani', 1);('al2015 phenomenal success', 1);('stateof art model', 1);('particular machine translation handwriting synthesisimage text generation audio classi cation text summarization audio synthesis taskshave', 1);('state art performances', 1);('bahdanau', 1);('chorowski', 1);('graves', 1);('2015the intuitive idea attention', 1);('extensiblethe output', 1);('small unknown segment input havebeen', 1);('deep attention models', 1);('variants analysingperformance', 1);('appealing debatable property attention models thatthe part network focuses segment input', 1);('interpretablethe rst', 1);('ln pandey r vashisht hg ramaswamyarxiv221214776v1', 1);('dec', 1);('vashisht ramaswamyin', 1);('wrong predictions', 1);('wang', 1);('jainand wallace', 1);('subjective studiesstatements attention', 1);('jain wallace', 1);('knowledgethere quantitative study', 1);('interpretability attention thispaper', 1);('framework quantitative study11', 1);('contributionsthe', 1);('contributions paper', 1);('ne crude quanti', 1);('able measures interpretability', 1);('task show', 1);('moreinterpretable random network2', 1);('ne introduce', 1);('new type machine learning problemtask wecall selective dependence classi cation', 1);('problem captures essence ofproblems attention mechanisms', 1);('reasonable solution3', 1);('ne simpli', 1);('focusclassify attention modelfcam', 1);('anatural objective notion interpretability4 describe', 1);('various modes operation', 1);('tasksand example conditions attention model trains', 1);('generalises wellbut', 1);('poor interpretability5', 1);('analyse variants attention models', 1);('toimprove performance interpretability', 1);('related worksjain wallace', 1);('study relationship betweenthe attention vector', 1);('real world explanationsthere links', 1);('multiple instance learning', 1);('mil maron', 1);('andlozanop\x13 erez', 1);('sabato tishby', 1);('ilse', 1);('2018attention models', 1);('good tool', 1);('essence attention models', 1);('practical architectureslatent', 1);('variable alignment', 1);('deng', 1);('standard problem', 1);('analysis ofattention models', 1);('theoretical basis', 1);('various loss', 1);('maximum likelihood', 1);('nedin paper', 1);('special case latent', 1);('variable alignment extraassumptions', 1);('measurement interpretability easier13', 1);('nlp', 1);('tasks domains neural attention', 1);('stateoftheart results', 1);('primary reason results oftenon', 1);('attention analysis', 1);('original', 1);('box dogobject b', 1);('overlay visualisation attention vector', 1);('worddog output c', 1);('overlay random sparse attention vector 0dheatmap overlay sparse version model output', 1);('ability models', 1);('speci c part input thedownstream task part', 1);('performance attention models', 1);('particular task2', 1);('measure interpretability attention modelsthe', 1);('main character play attention mechanism attention', 1);('attention vector speci es part input', 1);('responsible thedownstream task paper analyse attention vector', 1);('theideal selection chooses relevant input segment2', 1);('interpretability image captioning case studylet', 1);('sequencetosequence encoder decoder attention model', 1);('convolutional neural network', 1);('cnnis', 1);('annotation vectors ai2rd wherei2mrepresents segmentpatch image decoder outputs', 1);('word time', 1);('certain patches image', 1);('subset annotation vectors size', 1);('\x0214\x02512 corresponds 196annotation vectors', 1);('dimensional representation patch ofan image', 1);('\x14i\x14196 attention mechanism generates', 1);('positive weight iwhich', 1);('probability location iis', 1);('right place focus togenerate', 1);('current word', 1);('word caption', 1);('dimensionalattention vector', 1);('part image model', 1);('onwe use', 1);('method measure interpretability model', 1);('lin', 1);('theimage captions', 1);('additional metadata form 80objects', 1);('box information', 1);('occurrence objects imagesthis', 1);('additional information', 1);('vashisht', 1);('quanti', 1);('attention validation dataattention weight', 1);('full random', 1);('top 20average', 1);('attention', 1);('0429in objective way', 1);('people class words manwoman guy boy girl people', 1);('words associatedwith di erent objects image', 1);('box ofthese objects', 1);('\x03224 50176dimensional f01gvector v attentionvector 201196when', 1);('model predicts words', 1);('withany objects image', 1);('version vector', 1);('align vector', 1);('box correspondingobject good interpretability', 1);('appendix section', 1);('c1', 1);('example cosine ofthe angle', 1);('occurrences object wordsoutput model validation', 1);('comparison theaverage cosine vector vwith random vector 0that', 1);('coordinatesat random', 1);('average cosine vectorvwith vector 00that', 1);('coordinates vector', 1);('rest to0', 1);('support idea attentionvector aligns signi', 1);('ground truth location relevant object despitethe training data model', 1);('location cues', 1);('figure1', 1);('focusclassify attentionmodelsin', 1);('example analysis section', 1);('theinterpretability goodness attention model illde', 1);('end considera', 1);('new task', 1);('basic philosophy attention31', 1);('sdca', 1);('selective dependence classi cation', 1);('problem kclass classi cation problem witha', 1);('special structure', 1);('function instance x2rd\x02m containsmparts segments', 1);('rd', 1);('instance xis calleda mosaic instanceimage', 1);('foreground segment rest', 1);('lrd\x02mk', 1);('labels mosaic instance', 1);('function uses foreground segmentof inputmore formallylx1x2xm g\x03xi\x03on', 1);('interpretability attention networkswherei\x03is', 1);('index foreground segment g\x03rdk function givesthe', 1);('true label', 1);('foreground segment input training data task', 1);('collection pairs xywithout knowledge foreground segment index i\x03the', 1);('function speci c structure uses portion inputfor', 1);('instance toy problem analogous image classi cationproblem image', 1);('small object', 1);('fractionof pixels key di\x0eculty problem identity foregroundsegment', 1);('training data principle', 1);('extra structure ignoredand', 1);('multiclass classi cation problem input domainof dimension dm', 1);('model triesto', 1);('direct classi cation problem good training performance performclose random test', 1);('inherent invariance class labelwhen segments mosaic instance', 1);('encodingexplicitlyfor concreteness', 1);('problem wellde', 1);('segments givenmosaic instance', 1);('thesegment foreground backgroundwe', 1);('d1d2d', 1);('koverrddenote classconditional distribution ofthe foreground segments class label 1k letd0denote classconditionaldistribution background segments generative model mosaic instancelabelpair', 1);('additional details illustration', 1);('sdcproblem', 1);('generative model instancelabel pair selective dependenceclassi', 1);('probleminput number', 1);('base distributions d1d', 1);('randomf12mgy randomf12kgfori', 1);('independentdraw d0xi\x03 independentdraw dyreturn', 1);('task cartoonlike nature unrealistic', 1);('real data egimage patches', 1);('full label dependence single foregroundpartsegment independence background partssegments', 1);('thesdc task', 1);('tool study', 1);('parts attention mechanismthe', 1);('enable understanding', 1);('crucial aspects optimisation generalisation interpretability attention models', 1);('real world data32', 1);('focusclassify attention', 1);('fcamthe sdc', 1);('prime candidate application attention mechanism', 1);('thefocusclassify attention model fcam', 1);('simple attention model', 1);('focus network scores segments chance foregroundpandey', 1);('vashisht ramaswamysegment', 1);('score high model linearcombination segments', 1);('focus networks score', 1);('aclassi cation network attempts classify single ddimensional', 1);('kpossible classes', 1);('simpler thana', 1);('direct model', 1);('full mosaic data input outputs', 1);('functions fandg wherefrdris focusmodel grdrkis classi cation model focus model fand classi cationmodel gare family functions', 1);('fandg', 1);('practicefandgcorrespond neuralarchitectures output focus model forms', 1);('natural intermediate output x', 1);('softmax', 1);('fx1f xmwhich', 1);('focus attention vector', 1);('softmax0g0mxj1', 1);('combination segments expmj1 jxxj2rdis', 1);('inputdata pointif', 1);('reasonable intuitive focus vector x', 1);('corresponding foreground segment', 1);('point part input', 1);('responsible output', 1);('hencea', 1);('natural measure interpretability', 1);('fraction mosaic instances thefocus network fscores foreground segment', 1);('background segmentsftf', 1);('e1fxmmaxfx1f xm\x001where', 1);('x1x', 1);('d0xmis', 1);('dywithybeing', 1);('label distribution', 1);('sideinformation foreground index', 1);('available heldout data', 1);('f objectivemeasure interpretability', 1);('free subjective biases', 1);('scope andapplies', 1);('tasks learnt', 1);('fcama fcam', 1);('con dence enduser', 1);('x explanationfor decision', 1);('nal model decision trulymade', 1);('relevant foreground component measures', 1);('gradient sensitivity', 1);('gradcam selvaraju', 1);('local heuristics guaranteein rest paper', 1);('problems learnt', 1);('afcam model', 1);('accuracy imply interpretabilitythe fcam', 1);('training data evencontain foreground segment index i\x03', 1);('accurate practice', 1);('attention models alsoon', 1);('mode illustrations', 1);('focus model foverlaid heat mapover scatter plot points base distributions', 1);('d0d1d2andd3', 1);('bdecision boundaries', 1);('classi cation model goverlaid scatterplot', 1);('input exwith focus model', 1);('interpretable output focus module', 1);('equivalent objectis', 1);('explanation class outputin section', 1);('natural question', 1);('weshow', 1);('distinct modes', 1);('error modes', 1);('failto examples section', 1);('synthetic examples ofd0d1d kwith base dimension', 1);('easy visualization failure modes41', 1);('error modefigure', 1);('2a shows example scatter plot samples base distributions', 1);('d0d1d2andd3with', 1);('base dimension', 1);('number foreground classes k', 1);('mosaic', 1);('consider', 1);('fcamgiven', 1);('byfx1x2 x1x2 focus network', 1);('foreground segment higherscore background segment class label', 1);('corresponding tothe', 1);('blue green points', 1);('red points focus model f', 1);('howeverwheny', 1);('background segment', 1);('corresponding theobservation', 1);('orange points score', 1);('red points focus modelf results distribution', 1);('inputpmj1 jxxjto', 1);('d1ord3wheny', 1);('input distribution', 1);('signi cantlythe focus network e', 1);('foreground classes background butthere', 1);('simple linear multiclass classi er classify', 1);('full accuracy', 1);('section 32the focus model fand classi cation model', 1);('figures', 1);('2a 2b', 1);('corresponding linear models', 1);('fandgon sdctask', 1);('segments shows whilethere', 1);('linear functions fg', 1);('sgdpandey vashisht ramaswamy4', 1);('classi cationmodel goverlaid scatter plot', 1);('data exoptimisation', 1);('fas aninsight mosaic instance xis', 1);('certain class', 1);('fcamusing', 1);('helpful eg', 1);('reason image classi edas dog patch', 1);('blue sky42', 1);('error modewith', 1);('simple hypotheses class', 1);('fandgfor', 1);('focus classi cation network possiblethere exists', 1);('good focus model classi cation model', 1);('fcammodel', 1);('wrong fand', 1);('wrong g', 1);('wrongs rightingeach otherfigure', 1);('illustrates example', 1);('fandgarelinear', 1);('exists linear separator', 1);('thebackground foreground', 1);('focus model fand classi cation model', 1);('accurate attention modelthe', 1);('mosaic trainingpoints', 1);('reasonhowever di erent rst error mode focus net', 1);('linear architecture', 1);('f43', 1);('error modeone', 1);('potential error mode result', 1);('accurate noninterpretable attention model classi cation network', 1);('classify attendedinputexpmj1 jxxjeven focus model', 1);('close initial parameter itis e', 1);('jx 1mfor alljandx', 1);('suchan example 2k', 1);('good focus classi cation networkeven iffandgare linear models strict necessity focus model tobe', 1);('focus function fthat', 1);('zero resultson', 1);('interpretability attention networks14', 1);('classi cationmodel gwith scatter plot', 1);('data exin jx 1mfor xj', 1);('bya classi cation network gfigure 4ab', 1);('focus scatter plot samples base dataand classi cation net scatter plot', 1);('focus neton', 1);('thefcam', 1);('linear model', 1);('fand', 1);('relu', 1);('g fcam', 1);('model asa', 1);('focus model chooses focus background segmentover foreground segment class label', 1);('corresponding blue orangeand green points', 1);('simple goodfocus model eg fx1x2 \x00x1 classi cation model glearns distinguishthe', 1);('class label', 1);('good focus model learntthe', 1);('illustrations error modes aregiven', 1);('converges modelwith', 1);('convergence rst error mode', 1);('modes acombination', 1);('main error modes', 1);('accurate attention modelto', 1);('investigating', 1);('future work5', 1);('architectures loss', 1);('interpretabilitywe', 1);('accurate interpretablethis', 1);('practical question changes architecturemodelobjectivecan', 1);('accuracy modelas identity foreground segment', 1);('training data suchmodi cation', 1);('common approach', 1);('zhang', 1);('sparsity constraints attentionpandey', 1);('vashisht ramaswamy0', 1);('100no epochs050100data percentageftpt', 1);('ffpt ftpfffpf figure', 1);('training', 1);('fraction mosaic instance', 1);('ftpt', 1);('true predicted true ffpt', 1);('focus false predicted true ftpfstands focus true predicted false ffpf', 1);('focus false predictedfalse', 1);('mode b', 1);('mode c', 1);('intuitive choice', 1);('maximumscore foreground segment', 1);('preliminary experiments', 1);('attention vector x nonsparse situations focus modelis incorrect', 1);('whole accuratewe test impact', 1);('modi cation loss function', 1);('anentropy regulariser \x15ent x term', 1);('standard crossentropy loss entropy function', 1);('ent', 1);('value attention vector sparse hyperparameter\x15is', 1);('balance sparsity regulariser cross entropy loss functionanother approach', 1);('introduce sparsity attention vector', 1);('activation functions softmax results sparse probabilitydistribution sparsemax', 1);('duchi', 1);('lahaet', 1);('spherical softmax', 1);('ollivier', 1);('vincent', 1);('ebisson andvincent', 1);('laha', 1);('2018sparsemax function', 1);('euclidean', 1);('projection input vector zon probabilitysimplex', 1);('sparse posterior distribution', 1);('\x1az argminp2\x01kjjp\x00zjj2where \x01 kis probability simplexspherical softmax spherical', 1);('alternative softmax activation', 1);('producessparse probability distribution components ziare', 1);('close zero', 1);('sphericalsoftmax', 1);('\x1aiz z2ipmi1z2iwe', 1);('mnih', 1);('2015which chooses', 1);('patch jat random probability jx', 1);('additivecombination training corresponds', 1);('log loss gon xjy', 1);('jxin prediction phase patch j\x03 argmaxj jx', 1);('classi cation network factor mcostlier', 1);('hard attention softattention mosaic data point', 1);('corresponds mdata points x1y xmyon', 1);('interpretability attention networksalgorithm', 1);('10272er0 zeroth', 1);('08111spmax0 zeroth', 1);('04866ssm0 zeroth', 1);('1064ha0 zeroth', 1);('performance cifarsdc dataset', 1);('variantsanother architectural e ect study layers inputis', 1);('practical attention models input', 1);('classi cation model ispmi1 ix xi', 1);('layer thelast convolutional layer', 1);('focus network analysis till wehad', 1);('x xor zeroth layer output simplicity analysiscan', 1);('version x output', 1);('layer focusnetwork6', 1);('experimentswe', 1);('cifar10', 1);('details synthetic data experiment', 1);('cifarsdc dataset architecture usedthe cifarsdc', 1);('semisynthetic dataset', 1);('cifar10 krizhevsky hinton2009', 1);('segment image', 1);('number foreground classesk', 1);('foreground segments', 1);('classes car plane andbird background segments', 1);('classes numberof segments', 1);('points testingwe use convolutional neural network', 1);('convolutional layers', 1);('layers illustration ofthis dataset architecture', 1);('vashisht ramaswamy00', 1);('10threshold values 020406080100percentage data threshold value alpha wrt algorithmsalgorithmssm0sm6er0er6spmax0spmax6ssm0ssm6ha0ha6figure', 1);('experimental resultsthe', 1);('encouraging sparsity', 1);('sdcproblems', 1);('appendix', 1);('shows fraction instances attention vector scores', 1);('true foreground index threshold', 1);('report average sparsityof vector methods', 1);('1mpmj11 j0012', 1);('dist', 1);('min j2mk \x00ejk2where ej201mis thejthcoordinate vector3', 1);('ent pmj1\x00', 1);('jlog jin', 1);('cifarsdc', 1);('dataset results', 1);('observe algorithms achievehigh test accuracy', 1);('model softmax', 1);('increase sparsity dohave e ect terms', 1);('entropy values e ect terms', 1);('ftnumbers', 1);('sparsemax spherical softmax activation functions', 1);('entropy regularisation methods register anyimprovementsome attention mechanism variants', 1);('eg sparsemax', 1);('increase performance vanilla attention mechanism', 1);('large data', 1);('interpretability attention networksie', 1);('true foreground segment experimentsdemonstrate sparsemax spherical softmax activation functions improveinterpretability', 1);('situations accuracy improvement signi cantone', 1);('noticeable small improvement interpretability', 1);('table2', 1);('layer focus network', 1);('input inthe', 1);('data point ex', 1);('vanilla softmax entropy regularisationmethods e ect', 1);('lowdimensional synthetic dataset', 1);('table1 appendix', 1);('hypothesize datasets patches', 1);('corresponding tobackground foreground', 1);('similar signi cant advantage', 1);('nal layer focus network', 1);('input directlythe', 1);('hard attention paradigm', 1);('natural advantage terms interpretability input', 1);('patcheshowever improvement', 1);('hard attention', 1);('cost oflower accuracy', 1);('hard attention algorithm performs', 1);('synthetic datasetresults', 1);('good candidate', 1);('practical applications addition training', 1);('hard attention models signi', 1);('complexcomputationallymore details experiments', 1);('conclusionin', 1);('present type classi cation problem', 1);('suitable analysis ofattention models', 1);('objective way measure aspect interpretability inattention models', 1);('accurate attentionmodel', 1);('benchmark empirical study theinterpretability attention models learnt', 1);('various algorithms', 1);('performance interpretability', 1);('encouraging modi cationsacknowledgmentslnp', 1);('rv hgr', 1);('robert bosch centre data', 1);('science andarti cial', 1);('intelligence iit madras lnp', 1);('acknowledges support', 1);('samsung iitmpravartak fellowshipreferencesdzmitry bahdanau kyunghyun cho yoshua bengio neural', 1);('machine translation', 1);('learning align', 1);('san diego causa may', 1);('jan chorowski dzmitry bahdanau kyunghyun cho yoshua bengio endtoendcontinuous', 1);('speech recognition', 1);('recurrent nn', 1);('nips2014', 1);('deep learning december', 1);('vashisht ramaswamyalexandre', 1);('pascal vincent', 1);('exploration softmax alternatives', 1);('spherical loss family', 1);('editors 4thinternational conference', 1);('san juan puertorico may', 1);('yuntian deng yoon kim justin chiu demi guo alexander rush latent', 1);('alignment variational attention', 1);('international conference onneural', 1);('information processing systems nips18', 1);('hook ny usa2018 curran associates incjacob devlin mingwei chang kenton lee kristina toutanova bert pretrainingof', 1);('deep bidirectional transformers language understanding', 1);('john duchi shai shalevshwartz yoram singer tushar chandra e\x0ecient', 1);('projectionsonto thel1\x00ball learning high dimensions', 1);('internationalconference machine learning icml', 1);('york ny usa', 1);('computing machinery isbn', 1);('alex graves generating', 1);('sequences recurrent neural networks', 1);('corr', 1);('maximilian ilse jakub tomczak max welling attentionbased', 1);('sarthak jain byron', 1);('wallace attention', 1);('alex krizhevsky geo', 1);('hinton learning', 1);('multiple layers', 1);('tiny imagestechnical', 1);('toronto toronto ontario', 1);('laha saneem chemmengath priyanka agrawal mitesh khapra karthiksankaranarayanan harish g ramaswamy', 1);('controllable sparse alternatives tosoftmax', 1);('neural information processing systems nips18', 1);('hook ny usa', 1);('curran associatesincon interpretability attention networkstsungyi lin michael maire serge belongie lubomir bourdev ross girshick jameshays pietro perona deva ramanan', 1);('lawrence zitnick piotr doll\x13', 1);('microsoftcoco', 1);('common objects context', 1);('oded maron tom\x13 lozanop\x13', 1);('erez framework multipleinstance learning', 1);('inm jordan kearns solla', 1);('advances neural information processingsystems', 1);('mit', 1);('andre martins ramon astudillo', 1);('softmax sparsemax sparse model ofattention multilabel classi cation', 1);('maria florina balcan kilian q weinberger', 1);('yorknew york usa', 1);('jun', 1);('pmlr url', 1);('volodymyr mnih nicolas heess alex graves', 1);('koray kavukcuoglu', 1);('recurrent', 1);('modelsof visual attention', 1);('z ghahramani welling', 1);('cortes n lawrence k qweinberger', 1);('volume 27pages', 1);('curran associates inc', 1);('ollivier riemannian', 1);('metrics neural networks feedforward networks arxiv', 1);('neuraland evolutionary computing', 1);('sabato naftali tishby multiinstance', 1);('learning hypothesis class', 1);('jmach learn res', 1);('r selvaraju michael cogswell abhishek das ramakrishna vedantam deviparikh dhruv batra gradcam visual', 1);('ieee', 1);('computer vision iccv', 1);('doi 101109iccv201774min', 1);('joon seo aniruddha kembhavi ali farhadi hannaneh hajishirzi bidirectionalattention', 1);('ow machine comprehension 5th', 1);('learningrepresentations iclr', 1);('toulon france april', 1);('proceedings openreviewnet', 1);('ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan ngomez', 1);('l ukasz', 1);('kaiser illia polosukhin attention', 1);('guyonu v luxburg bengio h wallach r fergus vishwanathan r garnett', 1);('pages 59986008curran', 1);('associates inc', 1);('pascal vincent alexandre', 1);('xavier bouthillier e\x0ecient', 1);('exact gradientupdate training', 1);('large sparse targets', 1);('neural information processing systems', 1);('nips15', 1);('cambridge usa', 1);('mit presspandey vashisht ramaswamyyequan wang minlie huang xiaoyan zhu li zhao attentionbased lstm', 1);('aspectlevel sentiment classi cation', 1);('empirical methodsin', 1);('austin texas', 1);('association forcomputational', 1);('linguistics', 1);('doi 1018653v1d161058', 1);('sarah wiegre', 1);('yuval pinter attention', 1);('empirical methods', 1);('joint', 1);('language processing emnlpijcnlp', 1);('hong kong china', 1);('computational linguistics', 1);('kelvin xu jimmy ba ryan kiros kyunghyun cho aaron courville ruslan salakhudinov rich zemel yoshua bengio', 1);('neural', 1);('image captiongeneration visual attention', 1);('conferenceon machine learning proceedings machine learning', 1);('urlhttpproceedingsmlrpressv37xuc15html jiajun zhang yang zhao haoran li chengqing zong attention', 1);('sparsityregularization neural machine translation summarization', 1);('ieeeacm transaudio speech lang proc', 1);('issn', 1);('interpretability attention networkson interpretability attention networks supplementary materialappendix codes reproducing resultsall', 1);('datasets codes', 1);('available hereappendix b', 1);('illustrates data', 1);('example 1dimensional base distribution twoforeground classes', 1);('2dimensional mosaic distribution', 1);('resultof havingm', 1);('symmetric structure scatter plot themosaic data', 1);('symmetry ie foreground segment', 1);('foreground backgroundare', 1);('mosaic datacan signi', 1);('generative modelfor instancelabel pair', 1);('sampled', 1);('d0brownd1blued2orange', 1);('mosaicinstancesremark', 1);('mil ilse', 1);('good tool solvesuch problems', 1);('apt problem study intricacies attentionmodels', 1);('mosaic instances containingno foreground segment mosaic instances', 1);('foreground segmentthis distinct', 1);('existence foreground segmentbut', 1);('class label foreground segmentappendix c', 1);('experimental setupc1 illustration interpretability image captioning', 1);('case studyas', 1);('standard method', 1);('a224\x02224 image', 1);('\x0214 image', 1);('\x0214 vector correspondsto square patch', 1);('\x02224 imagepandey', 1);('vashisht ramaswamydeershipcatcarhorsetruckdeerfrogdogfocus ne', 1);('tsoftmaxclassif cation', 1);('left', 1);('cifarsdc dataset right fcam architecture cifarsdc', 1);('layerhere', 1);('toy example', 1);('interpretability measure', 1);('table 1consider', 1);('word woman', 1);('rst wordand object category person', 1);('present image', 1);('metadata withthe', 1);('box object top', 1);('quarter image vvector herewould be26641', 1);('image patchesparts disjoint', 1);('\x022 subimages the4\x024 imagea', 1);('perfect attention model', 1);('vwould 1a', 1);('bad attention model', 1);('be266433333333222222223775 vwould approximately06a random baseline', 1);('average correspondingto', 1);('chance 75also', 1);('words class', 1);('words chosenfrom vocabulary captions', 1);('appendix shows associatedwords object categoryappendix', 1);('synthetic sdc datasetwe', 1);('2dimensional base data k', 1);('di erent', 1);('identitycovariance background segments', 1);('d0', 1);('gaussianson interpretability attention networksalgorithm', 1);('0677er0 zeroth\x03entropy reg', 1);('0479spmax0 zeroth', 1);('0394ssm0 zeroth', 1);('1038ha0 zeroth', 1);('performance synthetic sdc dataset', 1);('variantswe havem', 1);('segments mosaic instance instance x2r2\x029in mosaic datais', 1);('label y23 sample', 1);('mosaic instances', 1);('rest training', 1);('fcam algorithm', 1);('usedto generate mosaic instancesthe', 1);('focus', 1);('model fis multilayer perceptron', 1);('\x00hidden layerseach', 1);('classi', 1);('cation model gis', 1);('architecture single hiddenlayer', 1);('layers focus network', 1);('ateither input level 2dimensional rst', 1);('layer 50dimensionalan illustration dataset architecture', 1);('appendixwe generate synthetic data', 1);('d0background', 1);('gaussian d1foreground', 1);('d2foreground', 1);('d3foreground', 1);('gaussian', 1);('distribution meanand', 1);('standard deviation', 1);('gure 3a illustration mosaicdata segments', 1);('base synthetic data', 1);('synthetic dataset', 1);('mosaic instance synthetic dataset', 1);('onepatch fg2pandey', 1);('vashisht ramaswamyd01 experiments synthetic sdc datasetfigure', 1);('layers focusand classi cation modules', 1);('001000300005for entropy experiments', 1);('di erent random seeds', 1);('shows thefraction instances attention vector scores', 1);('true foreground index abovea threshold table', 1);('entropy regularisation average over4 runs5', 1);('tclassif cation', 1);('architecture synthetic dataset', 1);('layer00', 1);('10threshold values 020406080100percentage data threshold value alpha wrt algorithmsalgorithmssm0sm2er0er2spmax0spmax2ssm0ssm2ha0ha2figure', 1);('table 1on', 1);('interpretability attention networksappendix e details experiments synthetic cifar10datasetfor cifar', 1);('data use', 1);('linear layers infocus classi cation modules', 1);('entropy experimentswe', 1);('models 3di erent random seeds', 1);('f012g table', 1);('entropyregularisation average', 1);('associated1 man man men woman women child children kid kids girlgirls boy boys', 1);('male female person2 bicycles bicycles bicycle cycles bike3 car car cars van volkswagon vehicles bmw automobile suv4 motorcycle motorcycle motorcycles bike bikes', 1);('motor scooters motorbikes5 airplane airplane plane bomber airplanes air crafts jetsglider biplane aircraft jet cargo airliner6 bus bus school bus double decker busses vehicles7 train train train engine cargo train rails locomotivesteam engine train car diesel train engine engine8 truck truck re trucks tow truck trucks pickup truck trailervehicles9 boat boat canoe cargo boat ship trawler sailboats rafts10 tra\x0ec', 1);('light tra\x0ec', 1);('red light green', 1);('light tra\x0ec sign11 re hydrant re hydrant rehydrant hydrant13', 1);('meter meter15 bench bench seat chairs lounge16 bird bird', 1);('red robin parrot ostrich swans ducks geese owlbirds swan duck seagull', 1);('amingos pigeonstoucan seagulls17 cat cat cats kitten kittens animal animals18 dog dog dogs bulldog puppy pup animal animals19 horse horse carriage animal animals horses20 sheep sheep cattle animal animals lamb lambs21 cow cow cows calf calfs calves animal animals cattleoxen ox22 elephant elephant elephants animal animals23', 1);('bears cub cubs animal animals24 zebra zebra zebras animal', 1);('word association table case study section 2on', 1);('interpretability attention networkscategory id label words', 1);('associated25 gira e gira e gira es animal animals27 backpack backpack bag bags backpacks luggage', 1);('pack28 umbrella umbrealla umbrellas31 handbag handbag handbags bag bags luggage32 tie tie ties33 suitcase suitcase suitcases luggage suit case34 frisbee frisbee frisbees frizbee frizbees frisk bee35 skis skis', 1);('skier skiers ski spikes ski36 snowboard snowboard', 1);('snowboarder snow boardski boarder37 sports ball sports ball ball soccer baseball tennis ball footballvolleyball basketball soccer ball soccer balls38 kite kite object kites39 baseball bat baseball bat bat bats40 baseball glove baseball glove baseball gloves gloves glove catchercatch mitt41 skateboard skateboard skateboarders skateboarder skate', 1);('skate boarding42 surfboard surfboard surf board surfer boogie board wakeboardsur ng43 tennis racket tennis racket tennis racket tennis rackets rackets44 bottle bottle bottles soda soda drinks', 1);('bottlewater jars46 wine glass wine glass wine glasses glass glasses drink drinkingdrinks47 cup cup cups mug mugs drink co ee tea48 fork fork forks silverware49 knife knife knives silverware50 spoon spoon spoons silverware51 bowl bowl bowls', 1);('dish cup cups52 banana banana bananas fruit fruits53 apple apple apples fruit fruits54 sandwich sandwich hamburger hamburgers burgers sandwichesburger bun55', 1);('orange orange oranges fruit fruits56 broccoli broccoli vegetables', 1);('vegetable food meal57 carrot carrot carrots', 1);('vegetable vegetables food meal58', 1);('hot dogs hotdog hotdogs sandwich sandwichesbun59 pizza pizza bread', 1);('pizzas food60 donut donut donuts cookies', 1);('pastries doughnuts doughnutfood dessert pie61 cake cake cakes pastries pastry dessert', 1);('word association table case study section 2pandey', 1);('associated62 chair chair chairs furniture furnitures63 couch couch couches furniture furnitures recliner recliners64', 1);('plants pot pots plants plant vases owers ower leaves leaf65 bed bed beds furniture furnitures67', 1);('table table tables furniture furnitures dinner table70 toilet toilet bathroom restroom toilette seat72 tv tv screen tv television monitor monitors televisions73 laptop laptop computer monitor computers monitors laptops74 mouse mouse75', 1);('remote remote remotes controller76 keyboard keyboard key board keyboards77 cell phone cell phone cell phone phones mobiles mobile78 microwave microwave appliances appliance79 oven oven appliances appliance80 toaster toaster appliances appliance81', 1);('sink82 refrigerator refrigerator fridge refrigerators fridges84 book book books85 clock clock clocks86 vase vase vases bouquet pot87 scissors scissors88 teddy', 1);('soft toy stu', 1);('animal teddypanda', 1);('teddy bears stu', 1);('animalsstu bearsstu', 1);('doll dolls stu', 1);('bears89 hair drier hair drier hair dryer hairdryerhair products hair product blow dryer90 toothbrush toothbrush brush object tooth', 1);('word association table case study section', 1);