('vit', 8);('ff', 7);('forgery detection', 5);('ffdf', 4);('proceedings', 4);('international conference', 4);('teacher network', 3);('mim', 3);('cnn', 3);('computer vision', 3);('specically', 2);('experiments', 2);('fig', 2);('mha', 2);('recent works', 2);('rgb', 2);('f0and', 2);('overall', 2);('performances', 2);('celebdf', 2);('fff2f', 2);('ffnt', 2);('effectiveness', 2);('different architectures', 2);('learningrepresentations', 2);('acm', 2);('proceedings ieeecvf', 2);('learning mask towards generalized face forgery detectionjianwei fei1 yunshu dai1 huaming wang2 zhihua xia12', 1);('information', 1);('science technology', 1);('nanjing china2jinan', 1);('guangzhou chinaabstractgeneralizability', 1);('unseen forgery types', 1);('crucial faceforgery detectors', 1);('recent', 1);('signicantprogress terms generalization synthetic forgery dataaugmentation work explore', 1);('generalization goal', 1);('training phase', 1);('specic forgery types', 1);('inour method teacher network', 1);('imagesand generates attention map', 1);('diverse multihead attention', 1);('attention map', 1);('toguide student network focus', 1);('mixup strategy', 1);('synthesize forgeriesin', 1);('withoutdata augmentation method', 1);('promisingperformances unseen forgeries', 1);('terms face', 1);('deepfake generalization multihead', 1);('deep', 1);('introductionrecent', 1);('impressive progress terms generalizability', 1);('data augmentation reproduces', 1);('general pipelineof', 1);('synthesize training data', 1);('bytraining', 1);('representative synthetic forgery', 1);('unseen forgery typesin paper', 1);('alternative route bettergeneralization attribute', 1);('poor generalization faceforgery detectors', 1);('training data', 1);('thuswe', 1);('generalization training externaldata contrast', 1);('toy example data space toshow method improves generalization trainingdomain refers training forgery unseen domainsindicate forgeries', 1);('1ashows generalization', 1);('unseen domainsfig 1b shows', 1);('basic motivation approach', 1);('corresponding', 1);('simple visualization generalization', 1);('different approaches', 1);('gure shows thegeneralization', 1);('gure shows generalization boundis', 1);('domain removedwe', 1);('training domain', 1);('easiest part tot model', 1);('generalizationbound performance unseen domains betterto end introduce teacherstudent framework forface forgery detection teacher network', 1);('cnnvithybrid', 1);('generate attention map diverse multihead attention', 1);('degree inuence local', 1);('thebinary classication', 1);('mask highlyattendedlocal', 1);('student model student network onlylearns', 1);('normal samples', 1);('introduce deepmixup mixes samples', 1);('level whichcan', 1);('training distribution linear interpolations', 1);('contributions summarizedinto 3folds', 1);('iwe', 1);('novel teacherstudent basedface forgery detection framework student network learns detect', 1);('forgery lowattendedfeatures', 1);('iiwe', 1);('mixup interpolates', 1);('training distribution', 1);('iiiexperiments', 1);('generalization method', 1);('asthe robustness compressionarxiv221214309v1 cscv', 1);('dec', 1);('overview', 1);('related workin', 1);('part briey review', 1);('forgery detectionwith', 1);('particular focus', 1);('great success generalizability', 1);('basic conceptsof vision transformer', 1);('image modeling21', 1);('generalized face forgery detectiondata', 1);('method mainstream', 1);('current face forgery detection methods', 1);('good generalizability methods synthesize data', 1);('thegeneral process', 1);('general face forgery pipeline', 1);('ichoose', 1);('proper target source', 1);('iicrop', 1);('strategies conduct transformations', 1);('iiiswap', 1);('faces employ', 1);('isthe rst use data augmentation detect', 1);('observation visual artifacts forgedfaces', 1);('subsequently', 1);('achievebetter generalization data augmentation thesemethods', 1);('additional learning', 1);('forgery boundary localization', 1);('type prediction2 incorporationof synthetic data encourages models', 1);('vision transformer masked image modelingvision transformer vit', 1);('transformer', 1);('image sequence patches', 1);('incredible performances', 1);('various vision tasks', 1);('basic component', 1);('transformer encoder block multihead attention modules transform patch embeddings', 1);('vectors queries keys values model relationship', 1);('promising results', 1);('masked image modelingmim', 1);('learning approach pretrainingvit backbones', 1);('patches input', 1);('full input', 1);('visible patches', 1);('attractedconsiderable attention', 1);('superiority visual', 1);('paper use', 1);('generate spatial attention maps', 1);('raw input3', 1);('proposed method31 overviewfig', 1);('shows overview', 1);('image size', 1);('h\x02w\x023wherehw', 1);('standfor height width', 1);('cnnsfor', 1);('mapxt2rh\x02w\x02c vanilla transformer imageis', 1);('patch sequences', 1);('layers generate vector sequencein work', 1);('xtas', 1);('vector sequencewhich', 1);('encoder end', 1);('xtis', 1);('vector sequence x1x2x h\x02wwherexi2rc prepend sequence', 1);('learnable classembeddingx02rcwhose state class representationat output', 1);('sequenceto generate input', 1);('vit xvit2rh\x02w\x02c meantimethe vit', 1);('generates attention map', 1);('nal decision fake orreal details', 1);('student network', 1);('attentionmap student network', 1);('synthesize data32', 1);('attention based mask generation', 1);('mhafor', 1);('block transformer encoder diverse', 1);('mhawithhheads', 1);('xvitintoqkv', 1);('mlplayers', 1);('head attention mapaisoftmax', 1);('qikipch', 1);('1then nal attention map average hhead attentionmatricesa1hhxi1ai 2meantime', 1);('diversity loss', 1);('toencourage diversity', 1);('different heads', 1);('mask featuresinstead', 1);('raw input', 1);('top khighestelements attention map', 1);('aas', 1);('collection ka whereijis spatial position index rst calculate binarymaskmwithmij0ifaij2ka1otherwise4for student network', 1);('xs2rh\x02w\x02cismasked', 1);('bym average', 1);('generate nal', 1);('fpooling xs', 1);('m 2rc33', 1);('deep mixupfollowing', 1);('interpolations synthesize data', 1);('differing', 1);('donot employ mixup', 1);('input contrast applythe operation', 1);('trainingbatch generate', 1);('corresponding labely0with', 1);('fifjand', 1);('labels mixup factor\x15201f0\x15fi 1\x00\x15fj 5y0\x15yi 1\x00\x15yj 6then', 1);('mlp', 1);('training ofour frameworkltotalltclsltvit', 1);('ldiversity ls', 1);('7whereltclsltvit andlsare binary classication lossesfor classier', 1);('teacher network andstudent network', 1);('evaluations41 settingsdatasets', 1);('faceforensics ff', 1);('deepfakes df face2face f2f faceswapfs', 1);('nt celebdf', 1);('wilddeepfake wdf13', 1);('01by dividing255implementation', 1);('details cnn', 1);('xception', 1);('imagenet', 1);('weights fordefault', 1);('transformer blocks 6head', 1);('module withlatent dimension', 1);('sgdoptimizer', 1);('initial learning rate', 1);('andexponential decay factor', 1);('batch size', 1);('auc', 1);('area curve evaluation metric mask ratio 25and', 1);('experimental', 1);('original papers42', 1);('indataset evaluationsfirst', 1);('heavy video compression', 1);('shows indataset results method', 1);('methods train test method', 1);('challenging scenarioin', 1);('real world', 1);('clear method', 1);('obvious improvement', 1);('baseline model', 1);('ouroverall performances outperform stateoftheart methodby', 1);('promising robustness compressionmethods', 1);('df f2f fs ntxception', 1);('c40 indataset evaluationmore results indataset performances', 1);('ffcelebdf wdf', 1);('various datasetsour method', 1);('competitive results', 1);('tothe stateoftheart methods', 1);('different datasets', 1);('thebest single dataset overall accuracy', 1);('celebdf wdf avgspsl', 1);('rfm', 1);('indataset evaluation', 1);('ffc23 celebdf wdf43 generalizability evaluationsthe', 1);('results crossdomain evaluations', 1);('setting models', 1);('ondifferent datasets', 1);('existing', 1);('test unseen datasets', 1);('ourmethod', 1);('present theresults methods', 1);('different subsets', 1);('ffc23', 1);('ffdf fff2f ffnt compared', 1);('thexception baseline', 1);('crossdataset accuracy', 1);('considerable improvement', 1);('trainingdistribution data single domainmethods', 1);('train indataset celebdfxception', 1);('8141ours wo mixup', 1);('7492ours wo mixup', 1);('7652ours wo mixup', 1);('cross evaluations', 1);('method trainedon subset', 1);('ff44 ablation studiesfirst', 1);('different maskingstrategies results', 1);('highstands default setting lters', 1);('random denotes random', 1);('strategieshave mask ratio', 1);('ffc23 wdf', 1);('indataset setting results ofcelebdf models', 1);('c23 cansee', 1);('compromisethe indataset performances', 1);('considerable gap', 1);('random maskingthe performances', 1);('wdf celebdfhigh', 1);('previous experiments', 1);('homogeneous studentand teacher networks', 1);('contribute prediction', 1);('results indataset performanceon', 1);('different architecturesthe overall accuracy', 1);('crossarchitecture framework behaves', 1);('random maskingstudentteacherresnet18', 1);('resnet34 xceptionresnet18', 1);('different architectures studentand teacher networks5', 1);('conclusionthis', 1);('particular introduce ateacherstudent framework student network learnson', 1);('teacher network toobtain', 1);('deep mixup', 1);('enhance generalization', 1);('challenging datasets', 1);('method shows', 1);('good generalization andis robust compression', 1);('stateoftheart worksacknowledgement work', 1);('part bythe', 1);('key', 1);('research development plan', 1);('chinaunder grant', 1);('2020yfb1005600 part', 1);('national natural science foundation', 1);('china', 1);('grant numbers62122032', 1);('u1936118', 1);('qinglan project', 1);('province', 1);('jiangsu provincethis', 1);('china scholarship', 1);('csc', 1);('no2021090400296 references1 lingzhi li jianmin bao ting zhang hao yang dongchen fang wen baining guo face', 1);('xray formore general', 1);('ieeecvf', 1);('conference computer vision pattern recognition', 1);('kaede shiohara toshihiko yamasaki detectingdeepfakes', 1);('proceedingsof ieeecvf', 1);('recognition', 1);('liang chen yong zhang yibing', 1);('lingqiao liuand jue wang selfsupervised', 1);('learning adversarial example', 1);('towards', 1);('good generalizations deepfakedetection', 1);('proceedings ieeecvf conferenceon computer vision pattern recognition', 1);('tianchen zhao xiang xu mingze xu hui ding yuanjun xiong wei xia learning', 1);('selfconsistency fordeepfake detection', 1);('proceedings ieeecvfinternational', 1);('conference computer vision', 1);('yuezun li siwei lyu exposing', 1);('deepfake videosby', 1);('artifacts arxiv preprintarxiv181100656', 1);('alexey dosovitskiy lucas beyer alexanderkolesnikov dirk weissenborn xiaohua zhai thomasunterthiner mostafa dehghani matthias minderergeorg heigold sylvain gelly', 1);('image isworth', 1);('transformers', 1);('image recognition scale', 1);('sohail ahmed khan hang dai video', 1);('transformerfor deepfake detection incremental learning inproceedings', 1);('conferenceon multimedia', 1);('ping wang kunlin liu wenbo zhou hang zhouhonggu liu weiming zhang nenghai yu adtantideepfake', 1);('icassp', 1);('acoustics speechand', 1);('processing icassp ieee', 1);('heliang zheng jianlong fu zhengjun zha jieboluo learning', 1);('deep bilinear transformation', 1);('image representation', 1);('advances neural information processing systems', 1);('hongyi zhang moustapha cisse yann n dauphin', 1);('lopezpaz', 1);('empirical risk minimization', 1);('andreas rossler davide cozzolino luisa verdolivachristian riess justus thies matthias nienerfaceforensics learning', 1);('facial images', 1);('yuezun li xin yang pu sun honggang qi siweilyu celebdf', 1);('challenging dataset fordeepfake forensics', 1);('proceedings ieeecvfconference computer vision pattern recognition', 1);('bojia zi minghao chang jingjing chen xingjun maand yugang jiang wilddeepfake', 1);('challenging realworld dataset deepfake detection', 1);('international conference multimedia', 1);('franc', 1);('chollet xception deep', 1);('learning depthwise', 1);('separable convolutions', 1);('theieee conference computer vision pattern recognition', 1);('honggu liu xiaodan li wenbo zhou yuefeng chenyuan hui xue weiming zhang nenghai yuspatialphase', 1);('shallow learning', 1);('forgerydetection frequency domain', 1);('theieeecvf conference computer vision patternrecognition', 1);('chengrui wang weihong deng representativeforgery', 1);('conference computer visionand pattern recognition', 1);('yuyang qian guojun yin lu sheng zixuan chen', 1);('shao thinking', 1);('face', 1);('frequencyaware clues', 1);('europeanconference', 1);('springer', 1);