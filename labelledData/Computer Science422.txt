('theorem', 46);('lemma', 45);('proposition', 37);('rkhs', 34);('eq', 32);('lipschitz', 25);('denition', 14);('relu', 13);('assume', 12);('corollary', 12);('ntk', 11);('assumption', 10);('kls', 10);('algorithm', 10);('gd', 9);('excess risk', 8);('international conference', 6);('cauchyschwartz', 6);('rademacher', 6);('gdtrained', 6);('neural networks', 6);('consider', 5);('euclidean', 5);('machine learning', 4);('machine learing icml', 4);('neural information processing systems neurips', 4);('suppose', 4);('gdtrained kls', 4);('sobolev', 4);('krzy', 4);('ntf', 4);('pmlr', 3);('training samples', 3);('gram', 3);('hoeffdings', 3);('remark', 3);('excess', 3);('rwy', 3);('optimal rates', 3);('erm', 3);('recall', 3);('hilbert', 3);('neuralinformation processing systems nips', 2);('inconference computational learning theory colt', 2);('learning representations iclr', 2);('computational learning theory colt', 2);('cambridgeuniversity', 2);('learning', 2);('annals statistics', 2);('springer', 2);('ininternational', 2);('universal constant c15 t\x14bt', 2);('time btgiven rule', 2);('positive solution', 2);('fis', 2);('prediction shallow neural network', 2);('thenminr\x15c5\x032\x08xar2yr', 2);('forar\x03c5dened lemma', 2);('i\x00i\x002\x11nkt', 2);('letf\x14tf\x14tbegdtrained kls', 2);('norm sides', 2);('recursion st\x001 1by', 2);('neural', 2);('lemmata', 2);('initial parameters \x120are', 2);('1\x002e\x00\x17\x17 0by', 2);('wp', 2);('observe', 2);('predictor step tis', 2);('iterate sequence', 2);('c0', 2);('step size', 2);('design setting', 2);('fixed', 2);('withkhk2h\x14rand moreover', 2);('rulein section', 2);('number steps btis', 2);('width mis', 2);('consider assumption', 2);('kernel function', 2);('ris', 2);('complete proof', 2);('gdupdate', 2);('function fwhich', 2);('gdoperating rkhs', 2);('mercer', 2);('main result', 2);('smooth activation functions', 2);('complexity ball', 2);('gdthe', 2);('mercers', 2);('optimal rate', 2);('hu', 2);('gdusing', 2);('zero empirical risk', 2);('similarly', 2);('gradient flow', 2);('ntktheory', 2);('unseen sample', 2);('regression function', 2);('functions neural networks', 2);('gdwhich', 2);('r following', 1);('1by requirement', 1);('r\x15c5\x032 thusxar2xc25\x032\x10yx\x112d\x001\x002d\x002ln2\x10yx\x111d\x0012c25ln2\x10\x10yx\x111d\x0012\x11\x032x1\x002dy2dwhere', 1);('obtainr \x032\x00yx\x012d\x001and', 1);('rwe', 1);('ar approximately', 1);('\x141 c25ln2\x10\x10zx\x111d\x0012\x11\x032x1\x002dy2dproof', 1);('12kf\x14bt\x00hk2n\x142rkhk2h 10rwhich', 1);('high probability t2btkf\x14t\x00hk2n\x141e\x11tkhk2h 5\x1b2\x11tr2\x001p\x11t\x01by', 1);('p 352now', 1);('critical radius rdenition 1we \x11bt\x001\x142\x111 bt\x001\x142r', 1);('rule empirical', 1);('tocomplete', 1);('proof work assumes khk2h\x141', 1);('biashas factor biaskhk2h', 1);('1\x00e\x00c9nrvt\x145\x1b2\x11tr21p\x11t41the lemma', 1);('universal constant c9such t\x14bt probability', 1);('variance estimator', 1);('vtis', 1);('shows thatkf\x14t\x00hk2n\x14b2tvt t2nwereb2tis', 1);('universal constant c9such thatpkf\x14bt\x00hk2n\x142khk2h 5r\x151\x00e\x00c9nrproof', 1);('critical radius rbe', 1);('3and letthe', 1);('supplementary', 1);('relu networksmachine', 1);('descent optimizes', 1);('zou cao zhou q gu gradient', 1);('communications acm', 1);('deep learning', 1);('recht vinyals understanding', 1);('zhang bengio hardt', 1);('nonparametric regression withsobolev kernels arxiv preprint arxiv210203594', 1);('zadorozhnyi p gaillard gerschinovitz rudi online', 1);('constructiveapproximation', 1);('gradient descent learning', 1);('rosasco caponnetto', 1);('yao', 1);('analysis separation twolayer neural networks andlinear methods journal', 1);('wu j', 1);('statistics nonasymptotic viewpoint volume', 1);('j wainwright highdimensional', 1);('squares regression', 1);('scovel optimal', 1);('steinwart hush', 1);('fast rates conference', 1);('low noise', 1);('n srebro k sridharan tewari smoothness', 1);('overparameterization shallow neural networks conference', 1);('ramezanikebrya pethick eftekhari v cevher subquadratic', 1);('c song', 1);('network approximation terms intrinsic parameters', 1);('z shen h yang zhang deep', 1);('conferenceon articial intelligence statistics aistats', 1);('spectral analysis dotproduct kernels', 1);('scetbon z harchaoui', 1);('information processing systems nips', 1);('conference onneural', 1);('properties learning random', 1);('rosasco generalization', 1);('rudi', 1);('convergence guarantees shallow neural networks arxiv preprintarxiv221202323', 1);('razborov improved', 1);('rule journal', 1);('nonparametric regression optimaldatadependent', 1);('yu early', 1);('g raskutti j wainwright', 1);('kernels highdimensionalphenomenon conference', 1);('laplace', 1);('rakhlin x zhai consistency', 1);('largescale kernel machines conference', 1);('recht', 1);('rahimi', 1);('neural information processing systemsneurips', 1);('multiple passes conference', 1);('optimality stochastic gradient descent', 1);('bach statistical', 1);('pillaudvivien rudi', 1);('selected areas information theory', 1);('ieee', 1);('global convergence guarantees training shallow neural networks', 1);('moderate overparameterization', 1);('oymak soltanolkotabi towards', 1);('relu networks', 1);('eigenvalue neuraltangent kernel', 1);('montufar tight', 1);('q nguyen mondelli g', 1);('relu networks linearwidths', 1);('global convergence gradient descent', 1);('q nguyen', 1);('plenty pantry arxiv preprintarxiv190510686', 1);('dnns', 1);('steinwart global', 1);('deep neural network regressionestimates', 1);('rate convergence', 1);('kohler langer', 1);('arxivpreprint arxiv191203925', 1);('deep neural networks generalize', 1);('overparametrized', 1);('ieeetransactions information theory', 1);('hierarchical interaction models', 1);('nonparametric', 1);('statistics', 1);('regression estimation multilayer feedforward neural networksnonparametric', 1);('adaptive', 1);('kohler krzy', 1);('smalltest error shallow', 1);('width sufces gradient descent', 1);('z ji telgarsky polylogarithmic', 1);('tangent kernel convergence generalization neuralnetworks conference', 1);('hongler neural', 1);('gabriel', 1);('jacot', 1);('articial intelligence statisticsaistats', 1);('neural network', 1);('matters nonparametric perspective', 1);('lin g cheng regularization', 1);('wang', 1);('distributionfree theory nonparametric regression', 1);('h walk', 1);('gy k', 1);('sample complexity neural networks', 1);('n golowich rakhlin shamir sizeindependent', 1);('optimizes overparameterizedneural networks', 1);('poczos singh gradient', 1);('x zhai', 1);('annalsof statistics', 1);('large stepsizes', 1);('stochastic approximation', 1);('bach nonparametric', 1);('springer199621 dieuleveut', 1);('probabilistic theory pattern recognition volume', 1);('gy g lugosi', 1);('devroye', 1);('neural information processing systemsnips', 1);('understanding neural networks power ofinitialization dual view expressivity conference', 1);('daniely r frostig singer toward', 1);('representations gradientdescent conference', 1);('damian j lee soltanolkotabi neural', 1);('theory approximation theory viewpoint volume', 1);('cucker x zhou learning', 1);('neural information processingsystems nips', 1);('learning conference', 1);('saul kernel', 1);('cho', 1);('spectral lter learningalgorithms journal', 1);('discrepancy principle', 1);('celisse wahl analyzing', 1);('neuralinformation processing systems neurips', 1);('inductive bias neural tangent kernels conference', 1);('bietti j mairal', 1);('singleindex models shallow neuralnetworks conference', 1);('sanford j', 1);('bietti j bruna', 1);('articial intelligence statistics aistats', 1);('statistical optimalityininternational conference', 1);('data interpolation contradict', 1);('tsybakov', 1);('belkin rakhlin', 1);('curse dimensionality nonparametricregression', 1);('bauer k', 1);('acta numerica', 1);('statistical viewpoint', 1);('bartlett montanari rakhlin deep', 1);('research 3nov463482', 1);('bounds structuralresults journal', 1);('risk', 1);('gaussian complexities', 1);('bartlett mendelson rademacher', 1);('20179p l', 1);('neural information processing systems nips', 1);('bounds neuralnetworks conference', 1);('bartlett j foster j telgarsky spectrallynormalized', 1);('20028p l', 1);('learning theory colt', 1);('rademacher complexities conference oncomputational', 1);('bartlett bousquet mendelson localized', 1);('20177p l', 1);('machinelearning', 1);('curse dimensionality convex neural networks journal', 1);('bach breaking', 1);('machine learingicml', 1);('twolayer neural networks', 1);('analysis optimization generalizationfor', 1);('hu z li r wang finegrained', 1);('arora', 1);('cambridge universitypress', 1);('theoretical', 1);('network learning', 1);('bartlett neural', 1);('anthony p', 1);('song convergence theory', 1);('allenzhu li z', 1);('layers conference', 1);('allenzhu li liang learning', 1);('elsevier', 1);('r adams j fournier sobolev', 1);('highprobability boundsreferences1', 1);('failure probability', 1);('9c6\x10402\x1b2dd2 1\x11n\x00dd2now', 1);('rrinto abovekf\x14bt\x00hk22\x141', 1);('eigenvalue decay rate \x16k\x14c1k\x00 c6\x10402\x1b2dd2 1\x11zc16n\x00dd2where', 1);('withb 1we haverr\x14c6\x10402\x1b2', 1);('critical radii rr', 1);('basic inequality xy2\x142x2 2y237boudingr rnow', 1);('brandusing', 1);('empirical norm', 1);('6rrrwhere acomes', 1);('rr\x149rr', 1);('erkf\x14bt\x00hk22\x142kf\x14bt\x00hk2nbr2rwp\x151\x00c13e\x00c14nra\x144r', 1);('inequality applytheorem', 1);('10rad\x00prf\x01\x14p2r\x00pr\x01\x14r r0and', 1);('positive solution inequalityradprf\x14rin terms ofr', 1);('function classfx7jfx\x00hxjbr fh2hkfk2h\x143 2rkhk2h\x14rand', 1);('pkf\x14t\x00hk22\x15xjeb', 1);('bpeb\x14pkf\x14t\x00hk22\x15xjebe\x00c15nrto end control', 1);('pkf\x14t\x00hk22\x15xje', 1);('eventebfkf\x14t\x00hk1\x14brg anyx0pkf\x14t\x00hk22\x15xpkf\x14t\x00hk22\x15xjebpeb', 1);('t\x14btkf\x14t\x00hk1\x14kf\x14tk1khk1\x14kf\x14tkhkhkh\x14br wherebr p3 2rprwith probability', 1);('inequalities combination withthe fact supx2sd\x001\x14xx\x141and', 1);('triangle cauchyschwartz', 1);('thatfunctions consideration', 1);('2we use', 1);('sokf\x14tk2h\x14khk2h', 1);('high probability wehavekk2mt\x142andjhhnimtj\x14khkh', 1);('ghkhkh getkhnk2mt\x14khk2h', 1);('facts holdkgnk2mt\x141pkk2mt\x142', 1);('letgn gx1g xnthen exists', 1);('forg2hkgkh\x141', 1);('extract', 1);('abovewe useproposition', 1);('9kf\x14tk2hk yk2mtkhnk2mt 2hhnnimtkk2mtwhere identity denition hn hx1h xn', 1);('mtk\x0012i\x00i\x002\x11nkt proposition', 1);('proof t2n', 1);('throughout', 1);('facts holdpkf\x14tk2h\x143 2khk2h\x151\x00e\x00c15nrproof', 1);('critical radius rbe asin', 1);('training sample xiyini1 whereyihxi', 1);('letf\x14tbe gdtrained kls', 1);('probability least1\x00c10exp\x10\x00c11nc6402\x1b2 1n\x00 1\x11we haver\x14c6402\x1b2 1n\x00 1lemma', 1);('simple corollary', 1);('p14r\x14r\x14r\x151\x00c10e\x00c11nrnotably', 1);('constants c10andc11such', 1);('prop', 1);('population onelemma', 1);('critical radius', 1);('handy lemma establishes connection empirical', 1);('c1and thatrbc6b2 1n\x00', 1);('constant c6which', 1);('constant c1 exists', 1);('polynomial eigenvalue decay rate \x16k\x14c1k\x00', 1);('assume rkhs', 1);('positive solutiontorprb\x14rbb', 1);('fixb0and', 1);('rpr\x14r', 1);('witheigenvalues \x16i1i1 forr\x01given', 1);('unit ball', 1);('letfff2hjkfkh\x141gbe', 1);('rcomplexity rkhs35lemma', 1);('rst step', 1);('classes subsets', 1);('population complexity whichdepends spectrum kernel function \x16i1i1rx 1n1xi1minfx2\x16ig x0we', 1);('empirical complexity', 1);('universal constantsnow', 1);('kfk22\x00kfk2n \x1412kfk22x22for allf2fwherec13c14are', 1);('positive solution inequalityradprf\x14rbthen x\x15pr probability', 1);('function class f letrbeany', 1);('class andwhich', 1);('relationship 2and empirical function norms', 1);('n\x18uniff\x061gnare iid', 1);('supf2fkfk2\x14pr 1nnxi1 ifxi r\x150where x1xn\x18pnxare iid', 1);('complexity functions class', 1);('in39 fact', 1);('atan optimal rate purpose employ', 1);('gdlearns rkhs', 1);('essential part proof', 1);('lemmataan', 1);('hold\x0fnbt2 c1\x15202d\x001\x15c5\x0321 14which', 1);('x\x102 c1\x1520\x11andy\x0fnbt isminr\x15c5\x032cr\x14polylog1\x0fnbt1\x150c12 c1\x15201\x002d\x032\x0fnbt2d34where polylogarithmic term ispolylog1\x0fnbt1\x150c1', 1);('c1pnthe tradeoff', 1);('cr\x0fnbt', 1);('bya functioncr14kfbt\x00fk22\x14poly4b2yn\x150\x17pm2 c1\x1520ar2r\x0fnbtz', 1);('randar2', 1);('ofrwe observe need control tradeoff', 1);('r\x0fnbtand', 1);('function function hrkhs approximator', 1);('high probabilitytermkh\x00fk22is approximation error', 1);('predictor learning approximatorh term', 1);('high probabilitytermkf\x14t\x00f\x14tk22is gap', 1);('ne\x00\x17\x00e\x00\x17\x17\x151 \x120x1xntermkft\x00f\x14tk22is', 1);('1for anyt2n decomposition14kft\x00fk22\x14kft\x00f\x14tk22kf\x14t\x00f\x14tk22kf\x14t\x00hk22kh\x00fk22\x14poly4b2yn\x150\x17pm1 c1\x1520ar2c1pnkf\x14t\x00hk22ar2which', 1);('inequality xar2\x1520gives us\x03\x142\x002\x150 4\x150p\x17\x171\x01ar2\x15201pnand sokf\x14t\x00f\x14tk22\x14ar2 2c2\x002\x150 4\x150p\x17\x171\x01ar2\x15201pnthe proof', 1);('4ar2\x1520\x150ar\x150\x17ar\x150pn\x17ar\x150pn\x14\x002\x150 4\x150p\x17\x171\x01ar2\x1520ar\x150ar\x150pnar\x150pnnow algebra', 1);('z \x03now\x03 2\x1504\x1520ar2ar\x17ar\x150pn\x17ar\x150pn', 1);('ar2pn\x150arpnspn\x150ar\x17n4pn\x150ar2npn\x150ar\x17n', 1);('thuskf\x14t\x00f\x14tk22\x14ar2', 1);('9kf\x14t\x00f\x14tkhki\x00i\x002\x11nkty\x00 ykk\x001\x14kk\x001kopki\x00i\x002\x11nktkopky\x00 yk\x14pn\x150ar \x1aby', 1);('usingproposition', 1);('characterize class radius \x1a', 1);('result function f\x14t\x00f\x14t', 1);('high probabilitykf\x00fk22\x14kf\x00fk2n c2kf\x00fkn2\x1apn\x1a\x17n4\x1a2n\x1a\x17nnow', 1);('inequality applyingtheorem', 1);('22radf\x1a\x142\x1apnandb supx2sd\x001jfx\x00fxj\x14kf\x00fkh\x14\x1aby', 1);('classf\x1ax7fx\x00fx ff2hkf\x00fkh\x14\x1a\x1a\x150and note', 1);('loss function xy', 1);('log32n2 log3nc12and wherec12is', 1);('niid\x18uniff\x061gwhere c2', 1);('asradf supx1xn2sd\x001esupf2f 1nnxi1 ifxi', 1);('allf2f simultaneouslykfk22\x14kfk2n c2kfknradf b\x17nrad2f b\x17nwhere worstcase empirical', 1);('someb1 probability least1\x00e\x00\x17\x17', 1);('letf\x08fsd\x0010b', 1);('complexity boundtheorem', 1);('particular proof', 1);('itspopulation analogue uniform convergence argument', 1);('similar result', 1);('log32n2 log3nc12\x002\x150 4\x150p\x17\x171\x01and wherec12is', 1);('1\x00e\x00\x17\x17 0over inputskf\x14t\x00f\x14tk22\x141 c1\x1520ar2c1pnwherec1', 1);('yifxi iandyihxi t2n probability', 1);('f\x14tf\x14tbegdtrainedkls predictors', 1);('leth2 h', 1);('y\x00 ylemma', 1);('ykk\x001identity forkf\x14t\x00f\x14tkhcomes', 1);('kkf\x14tkhki\x00i\x002\x11nkt', 1);('identity \x08\x03\x08', 1);('asf\x14t\x08k\x001i\x00i\x002\x11nkty f\x14t\x08k\x001i\x00i\x002\x11nkt ythus', 1);('gdtrained klspredictors', 1);('adjoint \x08by\x08\x03 \x08\x03\x08', 1);('\x08 nxi1p\x15iuiviwhereabdenotes tensor product elements ab2h abuahbuihfor everyu2h', 1);('rnh', 1);('t2nkf\x14tkhki\x00i\x002\x11nktykk\x001kf\x14tkhki\x00i\x002\x11nkt ykk\x001kf\x14t\x00f\x14tkhki\x00i\x002\x11nkt y\x00ykk\x00131proof spectral theorem exists sequence nonnegative eigenvalues \x151\x15\x15\x15n anorthonormal system u1un2h orthonormal basis v1vn2rnsuch linearoperator \x08', 1);('norms distancesproposition', 1);('necessary proof', 1);('present lemmata', 1);('1in section', 1);('random design', 1);('assumptionb\x0fnbt2d\x001\x15c5\x0321to hold proof', 1);('x 2andyb\x0fnbt getminr\x15c5\x032cr\x142\x101 c25ln2\x10b\x0fnbt1d\x0012\x11\x11\x032b\x0fnbt2db\x0fnbtwhich', 1);('rb\x0fnbtusing proposition', 1);('minimizingcr 2ar2', 1);('complete theproof need control tradeoff', 1);('rb\x0fnbtand', 1);('finallykh\x00fk2n\x14ar2by lemma', 1);('approximation error handfand', 1);('training sample', 1);('klspredictor', 1);('heretermkft\x00f\x14tk2nis', 1);('samplexiyini1with yihxi isee section', 1);('decomposition14kft\x00fk2n\x14kft\x00f\x14tk2nkf\x14t\x00f\x14tk2nkf\x14t\x00hk2nkh\x00fk2n\x14poly3n\x150\x17pmar2kf\x14t\x00hk2nar2with probability', 1);('sd\x001whose', 1);('3leth2h approximator finsupnorm', 1);('\x141 c25ln2\x10\x10zx\x111d\x0012\x11\x032x1\x002dy2d3055', 1);('relationship \x032\x00zx\x012d\x001\x15c5\x032holds', 1);('aproposition', 1);('simple proposition', 1);('7to end approximationestimation tradeoff', 1);('2opky\x00 yk2cauchyschwartz inequality\x14kf\x00hk2n\x14ar2', 1);('y 2\x141n', 1);('i\x00i\x002\x11nkty\x00', 1);('yand step tkf\x14t\x00f\x14tk2n1n', 1);('recursion usingeq', 1);('usf\x14s1f\x14s\x002\x11nkf\x14s\x00y 0\x14s\x14t\x001where recall f\x14s f\x14sx1f\x14sxn', 1);('rule fromdenition', 1);('step t2n', 1);('gdpredictions', 1);('t2nkf\x14t\x00f\x14tk2n\x14arproof rst step characterize', 1);('ardened lemma', 1);('yifxi iandyihxi', 1);('particular training sample gap', 1);('predictors f\x14sts0trainedon samples xiyini1 yihxi ikhk2h\x14rin', 1);('introduce sequence virtual', 1);('f noth gap controlledthrough', 1);('fact notimmediate', 1);('learns approximator h', 1);('function frdrsuch x x2bdqsupx2bdqjfxj\x14\x03andjfx\x00f xj\x14\x03kx\x00 xkq exists h2h thatkhk2h\x14randsupx2bdq1jfx\x00hxj\x14ar', 1);('forrlarger', 1);('functions ball', 1);('approximation lipschitz', 1);('result approximation', 1);('end provesubsequent results', 1);('rkhsh', 1);('nal goal learna', 1);('control excess risk', 1);('predictorf\x14t input x2sd\x001 point canleverage analysis', 1);('shallowneural network ftto', 1);('relate prediction', 1);('common toolstheorem', 1);('risk analysis proof idea', 1);('togetherfrftx\x00f\x14tx\x14\x17mbyn\x15024n\x15012and sojftx\x00f\x14txj\x1484pm4b2yn\x150p\x17256n\x150 9\x17mbyn\x15024n\x1501254', 1);('1\x00ne\x00\x17\x17 0maxi2nj\x14xix\x00 xi xj maxi2nj x xi\x00e x', 1);('1m probability', 1);('independent random variables', 1);('xxi2sd\x001 x xi 1mmxk1ifw0kx0gifw0kxi0gxxiis sum', 1);('inequalityand union', 1);('close kernel function', 1);('bit show therandom', 1);('6nxi1\x16 ti\x00 ti xi x\x00nxi1 ti\x14xix\x00 xi x\x14pnk\x16 t\x00 tkk tkpnmaxi2nj\x14xix\x00 xi xjin bounds k\x16 t\x00 tkandk tkcome', 1);('havefrftx\x00f\x14tx x\x16\x12t\x00nxi1 ti\x14xixnxi1\x16 ti xi x\x00nxi1 ti\x14xix \x16\x12s\x00\x120\x08\x16 sas', 1);('inequality andthe fact thatk xk\x141proposition', 1);('3jftx\x00frftxj tx\x00 x\x12t x\x12t\x00\x16\x12t \x141pm4b2yn\x150p\x1784pm4b2yn\x150p\x1732n\x150 1\x1414pm4b2yn\x150p\x17256n\x150 928where rst inequality', 1);('denition frftand', 1);('rst part rhs', 1);('decomposition step t2nand arbitrary point x2sd\x001jftx\x00f\x14txj\x14 ftx\x00frftx frftx\x00f\x14tx', 1);('high probability\x1502k s\x00\x16 sk\x148by\x17mn15\x150 4n\x17mbypn\x150532', 1);('k\x001y', 1);('tk\x14k 1k2\x11n 1xs0i\x002\x11nk2sky 2\x11n 2\x11nk2\x001ky', 1);('finallyk', 1);('sk s\x00\x16 s\x1502k s\x00\x16 ska\x14\x15minkk s\x00\x16 sk\x14kf\x14s\x00frfskkk\x00kkopk skwhere aholds', 1);('k\x00k', 1);('\x16 s2rnsuch \x16\x12s\x00\x120\x08\x16 s havef\x14s\x00frfsk s\x00k\x16 s', 1);('\x16\x12s\x00\x1202span x1 xnandso', 1);('ntf gdsequence', 1);('\x16\x12s\x00\x120\x08\x16 s andmoreoverk t\x00\x16 tk2\x1424by2\x17mn3\x1540in addition t2nk tk\x14bypn\x15027proof denition', 1);('exists sequence vectors \x16', 1);('t2n underconditions', 1);('kls rfparameter', 1);('9k\x01tk\x14\x11\x0f1txs11\x00\x11\x1502nt2\x00s2\x14\x0f14n\x150having\x0f14n\x150\x1464pm4b2yn\x150p\x17232n\x150 12completes prooflemma', 1);('atk\x01s1k\x14k \x01sk\x11\x0f11\x00\x11\x1502nt2where\x0f12by4pm4b2yn\x150p\x171232n\x150 1now', 1);('fact k\x08kop\x14k\x08kf\x14pnproposition', 1);('inequalitiesk\x01s1k\x14k \x01sk2\x11nk\x08frfs\x00fsk2\x11nk\x08\x00\x08sfs\x00yk\x14k\x01sk2\x11nk\x08kopkfrfs\x00fskzi2\x11nk\x08\x00\x08skopkfs\x00ykzii26now', 1);('form\x01s1 \x01s2\x11n\x08frfs\x00fs', 1);('that\x01s1 \x01s\x00\x11rlrf\x16\x12s\x00rl\x12s \x01s\x002\x11nnxi1\x16rsi xi\x00rsi sxi \x01s2\x11nnxi1\x16rsi\x00rsi xi 2\x11nnxi1rsi xi\x00 sxiand', 1);('4k\x16\x12t\x00\x12tk2\x1464pm4b2yn\x150p\x17232n\x150 12proof step s2n abbreviate \x01s\x16\x12s\x00\x12sand introduce residual terms rsi fsxi\x00yiand\x16rsi frfsxi\x00yi', 1);('anyt2n\x17\x151 conditions', 1);('rfparameter', 1);('thuskfrft\x00f\x14tk2n1nkfrft\x00f\x14tk2\x14161n2bypn2n2\x17mn\x1502lemma', 1);('cauchyschwarz', 1);('sofrfs1\x00f\x14s1frfs\x00f\x14s2\x11nkf\x14s\x00y\x00kfrfs\x00yfrfs\x00f\x14s2\x11nk\x00kf\x14s\x00y\x00kfrfs\x00f\x14si\x002\x11nkfrfs\x00f\x14s2\x11nk\x00kf\x14s\x00yunrolling', 1);('entire trainingsample', 1);('andkls predictors', 1);('evident update rules', 1);('sample anyt2n conditions', 1);('rf kls', 1);('\x11\x1412\x144n\x11\x150the proof completelemma', 1);('\x17\x1511pnkft\x00frftk\x14txs11\x00\x11n\x150t\x00s 4\x111pm4b2yn\x150p\x17by1\x00\x112n\x150s2 2\x1114pm4b2yn\x150p\x1712by1\x00\x112n\x150s2\x146\x11by14pm4b2yn\x150p\x17121\x00\x112n\x150t2txs11\x00\x112n\x150t2\x00s2where', 1);('4thus1pnk sk\x142\x1114pm4b2yn\x150p\x1712by1\x00\x112n\x150s224now turning', 1);('1\x002e\x00\x17\x17 0\x141pm4b2yn\x150p\x17b2y1\x00\x112n\x150s', 1);('individual terms norm i2n12\x112 sxi2\x141nnxj1r2sj xi xj\x00 sxj2jensens inequality\x14k xik21nnxj1r2sjk xj\x00 sxjk2\x141pm4b2yn\x150p\x17l\x12s', 1);('k skby rst', 1);('8namely1pnk sk1pnk\x08s1\x00\x08s\x12s1k\x144\x111pm4b2yn\x150p\x17l\x12s\x144\x111pm4b2yn\x150p\x17by1\x00\x112n\x150s2', 1);('norm scomes', 1);('attention k skandk sk', 1);('opk s sk 12\x14txs11\x002\x11n\x15minkt\x00sk skk sk\x14txs11\x00\x11n\x150t\x00sk skk sk', 1);('i\x002\x11nkt\x00s', 1);('inequalities getkft\x00frftk\x14txs1', 1);('2norm sides', 1);('elementwiseft\x00frfttxs1i\x002\x11nkt\x00s s sin', 1);('i\x002\x11nkfs\x00frfs', 1);('vector form inputs x1xn introducesome vector abbreviations s sx1 sxn s sx1 sxn sxi 2\x11nnxj1rsj xi xj\x00 sxj23namelyfs1\x00frfs1', 1);('that\x01sx 2nnxj1\x16rsj x xj\x00rsj x sxj2nnxj1\x16rsj\x00rsj x xj 2nnxj1rsj x xj\x00 sxj\x002nnxj1fsxj\x00frfsxj x xj 2nnxj1rsj x xj\x00 sxjnow', 1);('residual terms rsj fsxj\x00yjand\x16rsj frfsxj\x00yj', 1);('introduce', 1);('sx\x12s1 s1x\x00 sx\x12s1\x00 x\x16\x12s1 sx\x12s\x00\x11rl\x12s s1x\x00 sx\x12s1\x00 x\x16\x12s\x00\x11rlrf\x16\x12sfsx\x00frfsx \x11\x10rlrf\x16\x12s x\x00rl\x12s sx z \x01sx\x11 s1x\x00 sx\x12s1z sx 11now express \x01sxin terms offsx\x00frfsx', 1);('s1x\x12s1\x00 x\x16\x12s1', 1);('decomposition arbitrary input xfor steps2nfs1x\x00frfs1x', 1);('sample anyt2n\x17\x151 conditionsof', 1);('rfpredictor', 1);('vector notation predictions fsfrfsf\x14son inputs x1xn anys2nfs fsx1fsxnfrfs frfsx1frfsxnf\x14s f\x14sx1f\x14sxnlemma', 1);('forasbsxsts0withasbsxs2r3xttxs1bstyks1ak', 1);('recursive relationshipxs1asxsbsandx0', 1);('5in section', 1);('t2n\x17\x151supx2sd\x001ftx\x00f\x14tx2\x1464pm4b2yn\x150p\x172256n\x150 92\x17mb2y24n\x15012422531', 1);('thatn\x150\x151 conditions', 1);('shallow neural network', 1);('1gap prediction', 1);('main result section', 1);('coupling', 1);('high probabilitybounds', 1);('satisfy\x00\x11\x150n16\x11en2m4\x11en2 npm\x14\x00\x11\x1502n\x00\x150n8\x11en2m4en2 npm\x14\x00\x1502nusing\x11\x14128en2m4en2 npm\x14\x1502n\x0016en2 8en2 n\x01n\x150\x14pm\x004en2 8en2 n\x012n\x1502\x14mthus induction step', 1);('getl\x12t1\x1416\x112en2ml\x12t 24\x11enpm\x101\x00\x11n\x15minkt\x1112l\x12t 1\x00\x11\x150n4\x11nenpml\x12t\x141\x00\x11\x150n16\x11en2m8\x11enpm4\x11nenpml\x12t\x141\x00\x11\x1502nl\x12tby', 1);('thus1nk\x08t\x00\x08t1\x12t1k2\x1416\x112en2ml\x12t', 1);('2jp\x12t1xij\x14m\x1ap\x17m\x144b2ynpm\x150p\x17m 7enpmwhere', 1);('fact iiiof', 1);('due triangle inequality', 1);('update namelykwt1k\x00wtkk2\x11n nxi1ftxi\x00yirwkftxi \x141pm2\x11nnxi1jftxi\x00yij\x142\x11l\x12tm21while cis', 1);('basic consequence', 1);('andcauchyschwartz inequality bis', 1);('chain inequalities acomes', 1);('inner summand i2n mxk1ukit1ki\x00itkixiwt1k \x141pmmxk1jit1ki\x00itkijjxiwt1kja\x141pmmxk1jit1ki\x00itkijkwt1k\x00wtkkb\x142\x11l\x12t1mmxk1jit1ki\x00itkijc\x142\x11l\x12tm mxk1jit1ki\x00i0kijmxk1ji0ki\x00itkij\x142\x11l\x12tmjp\x12t1xijjp\x12txijwherep\x01\x01is', 1);('abbreviate itkiifwtkxi0g namely1nk\x08t\x00\x08t1\x12t1k21nnxi1', 1);('6\x141\x00\x11\x150n4\x11nenpml\x12t 6where', 1);('takingk\x01k2n usingcauchyschwartz inequality fact x2\x14xforx2011nk\x08t\x12t1\x00yk2\x141\x002\x11n\x15minktl\x12t\x141\x002\x11n\x15mink\x002n2pmenl\x12t', 1);('apsd matrix ensure \x11\x1412n\x15maxkt\x1412', 1);('i\x002\x11nktis', 1);('dynamics update\x08t\x12t1\x00y\x08t\x12t\x00y\x002\x11n\x08t\x08t\x08t\x12t\x00yi\x002\x11nkt\x08t\x12t\x00yobserve', 1);('iito analyze iiwe', 1);('convenient abbreviateendef', 1);('small whenever width mis largethroughout proof', 1);('numberof pattern changes', 1);('decomposition empirical riskl\x12t1 1nk\x08t1\x12t1\x00yk251nk\x08t1\x12t1\x00\x08t\x12t1\x08t\x12t1\x00yk2\x141nk\x08t\x00\x08t1\x12t1k2zi2nk\x08t\x00\x08t1\x12t1kk\x08t\x12t1\x00yk1nk\x08t\x12t1\x00yk2ziihere term ican', 1);('vector predictions fton training sample', 1);('1casel\x12t1\x14b2y1\x00\x11\x1502nt1by fact iof', 1);('induction hypothesis base case isimmediate', 1);('assumption lemma', 1);('1\x00\x0el\x12t\x14b2y1\x00\x11\x1502ntproof proof', 1);('network width satisesm\x156424b2yn\x150p\x1724b2yn\x150p\x172 n2n\x1502then probability', 1);('step size obeys\x11\x1412', 1);('ne\x00\x17for any\x17', 1);('failure probability \x120be\x0e', 1);('gdassume', 1);('convergence', 1);('ideas 22theorem', 1);('\x1500the proof', 1);('ktfor', 1);('eigenvalue empirical', 1);('sufcient overparameterization highprobability', 1);('\x150\x004np\x17m\x1512\x150completes proofremark', 1);('inequality union', 1);('inequality\x15mink\x15\x15mink\x00kk\x00kkop19on hand fact k\x01k op\x14k\x01kf', 1);('p\x120\x15mink\x1512\x150\x151\x00\x0eproof weyls', 1);('failure probability \x120be\x0e 2ne\x00\x17for any\x17', 1);('initial parameters \x120are sampledas', 1);('concentration', 1);('j\x15minkt\x00\x15minkj\x14kkt\x00kkopcompletesthe proofproposition', 1);('weyls', 1);('5\x142n2\x1a\x17mby fact iiiof', 1);('abbreviate itkiifwtkxi0g thenkk\x00ktkop\x14kk\x00ktkf\x14xijjkij\x00ktijj\x14xij1mmxk1ji0kii0kj\x00itkiitkjjjxixjjxij1mmxk1ji0ki\x00itkii0kjitkii0kj\x00itkjjjxixjj\x14xij1mmxk1ji0ki\x00itkijxij1mmxk1ji0kj\x00itkjj\x142n2maxi2njp\x12txijmwithp\x01\x01dened proposition', 1);('1\x002e\x00\x17\x17 0over\x120\x15minkt\x15\x15mink\x002n2pm4b2yn\x150p\x17proof', 1);('drift', 1);('x2sd\x001and anyt2n probability least1\x002e\x00\x17\x17\x151ik tx\x00 xk2\x141pm4b2yn\x150p\x17ii tx\x00 x\x12t\x141pm4b2yn\x150p\x17proposition', 1);('implies followingcorollary', 1);('basic facts', 1);('4before need', 1);('goal section show assumption', 1);('then\x1at1\x141pm4b2yn\x15018the', 1);('assume l\x12t\x14b2y1\x00\x11\x1502ntfor', 1);('parameter', 1);('by\x1at maxk2mkw0k\x00wtkk t2nlemma', 1);('step tby single neuron initializationis', 1);('convergence relu network parameter driftin', 1);('wkx0g\x00ifw0kx0g j wk\x00w0kxjby', 1);('\x12x\x00 x\x12mxk1ukif wkx0g\x00ifw0kx0gx wk\x141pmmxk1', 1);('thatk \x12x\x00 xk21mmxk1if wkx0g\x00ifw0kx0g2kxk2\x141mjp\x12xj\x14\x1a\x17m', 1);('facticomes', 1);('1\x002e\x00\x17\x17 0ik \x12x\x00 xk2\x14\x1ap\x17mii \x12x\x00 x\x12\x14\x1apm\x1ap\x17proof', 1);('x2sd\x001 probability', 1);('pjw01xj\x14\x1acompletes', 1);('fact iito control', 1);('union boundp mxk1ijw0kxj\x14\x1a\x00mpjw01xj\x14\x1a\x14pm\x17\x151\x002e\x00\x17\x17', 1);('inequalitypm2xk1ijw0kxj\x14\x1a\x00m2pjw01xj\x14\x1a\x14m\x174\x151\x00e\x00\x17\x17 017and', 1);('w0km2k1are iid vectors secondhalf copy rst', 1);('4cauchyschwartz inequality maxk2mk wk\x00w0kk\x14\x1aproof iii', 1);('variable acomes', 1);('gaussian', 1);('absolute value', 1);('wkx0g\x00ifw0kx0g6 0a\x14mxk1eijw0kxj\x14\x1ampjw01xj\x14\x1a\x142\x19m\x1aby integration', 1);('nowejp\x12xjmxk1eiif', 1);('inequalityproof ii', 1);('factiis', 1);('1\x002e\x00\x17for any\x17 0jp\x12xj\x14m\x1apm\x17proof', 1);('facts holdi allk2p\x12xjw0kxj\x14k wk\x00w0kkiiejp\x12xj\x14m\x1aiii probability', 1);('\x1a\x150 x2sd\x001', 1);('maxkk wk\x00w0kk\x14\x1afor', 1);('wkx0g\x00ifw0kx0g6 0\x122rdmx2sd\x001then \x12whose components', 1);('activation patterns input x when\x120is replacedby parameters \x12 w1 wmp\x12x k2m', 1);('indices neurons', 1);('uand\x120 w01w0mare', 1);('activation', 1);('j wxj\x14jw\x00 wxjproposition', 1);('w wx2rdifwx0g\x00if wx0g6', 1);('shows fact iiiproposition', 1);('jensens', 1);('gradient loss rf\x12x\x00y2 2f\x12x\x00yrf\x12x sokrf\x12x\x00y2k2\x144f\x12x\x00y2krf\x12xk2\x144f\x12x\x00y2the', 1);('normkrf\x12xk21mmxk1i\x08wkx0 2kxk2\x14116now', 1);('thatf\x12x mxk1ukwkxmxk1uki\x08wkx0 xwkrf\x12x\x12factiicomes', 1);('thatrf\x12x u1ifw1x0gxumifwmx0gx2rdmfacticomes', 1);('any\x122rdmand x2sd\x001we haveif\x12x rf\x12x\x12ii x2sd\x001we havekrf\x12xk2\x141iiikrl\x12k2\x144l\x12proof', 1);('neural networksproposition', 1);('asf\x14tx nxi1 t\x14xix51 facts shallow', 1);('1nnxi1 nxi1 i\x14xix\x00yi2 2rnand moreover', 1);('l\x14', 1);('t1 t\x00\x11rl\x14 t', 1);('klsgd', 1);('sequence \x14tt\x001t0with \x1400', 1);('gdtrained ntf', 1);('1nnxi1 xi\x12\x00\x120\x00yi2and moreover', 1);('lrf\x12', 1);('ntfgd', 1);('sequence \x16\x12tt\x001t0with\x16\x120\x120', 1);('satises 0\x14\x11\x1412we', 1);('fixx2sd\x001 suppose', 1);('ntfkls', 1);('\x11 0\x08\x11\x080k\x11k0denition', 1);('matrixin tindex', 1);('ntf gram', 1);('kt\x08t\x08t2rn\x02nis', 1);('sample is\x08t tx1 txn2rdm\x02n15symmetric square matrix', 1);('matrix notation', 1);('tx u1ifwt1x0gxumifwtmx0gxx2sd\x001we', 1);('tx rf\x12tx', 1);('operator step tis', 1);('ntf ntf', 1);('forthcoming proofsdenition', 1);('weintroduce', 1);('respect parameter vector ie r\x11r\x12', 1);('stoppingrulethroughout proofs subgradient operator', 1);('summarize proofs', 1);('andrandom design cases', 1);('main results', 1);('proofs', 1);('results neural network kernel predictors areshown section', 1);('neural networksnecessary show', 1);('basic facts convergence results', 1);('proofsin', 1);('width m\x15poly6b2yn\x150\x17\x01n42dwith high probability d1kfbt\x00fk2nop\x101 \x032\x1b2dd2n\x002d2\x11asn1this recovers minimax optimal rate n\x0022dfor learning', 1);('corollary proposition', 1);('universal constantsc10c11c60such probability', 1);('critical empirical radius rbe', 1);('proposition reveals behavior ras functionof sample sizecorollary', 1);('aboutrwithout making distributional assumptions inputs sanitycheck briey', 1);('involves datadependent quantity r point', 1);('sample sizedependent ratebut', 1);('2c25ln2\x0010 r\x0012\x01as', 1);('probability least1\x0021 ne\x00\x17\x00e\x00c9nr\x17\x151over\x1201n14kfbt\x00fk2n\x14c0\x03210 r2d', 1);('constant c5depends conditions', 1);('rsatises10 r2d\x001\x15c5\x032114where', 1);('universal constant c9such thatpkf\x14bt\x00hk2n\x142r 5r\x151\x00e\x00c9nrthen corollary', 1);('critical radius rbe indenition', 1);('sample xiyini1 thestep size\x11and number steps', 1);('targets generatedasyihxi', 1);('leth2h', 1);('design sense seeappendix prooflemma', 1);('gdin', 1);('appendix dthe', 1);('positive solution inequalityrpr\x14r2e\x1bquantity rexists', 1);('critical radius rthe', 1);('empirical complexityr\x01given', 1);('let\x151\x15\x01\x01\x01\x15\x15nbe', 1);('critical', 1);('empirical quantity dependson spectrum kernel matrixdenition', 1);('explicitlydepend sample size', 1);('rule results datadependent excess risk', 1);('example rwy', 1);('constant c5depends probability', 1);('moreover suppose sample size nis', 1);('gdsatises\x11\x1412and', 1);('theorem isshown section 55theorem', 1);('overall rate n\x0022d1343', 1);('satises assumptions', 1);('rn\x00dd2with', 1);('universal constants c6c7c80such thatkf\x14bt\x00hk22\x149c6\x001 402\x1b2dd2\x011', 1);('sample xiyini1 step size \x11and thenumber steps', 1);('yihxi isuppose f\x14btis', 1);('fixh2h', 1);('section 57theorem', 1);('rule consistent', 1);('specic empirical', 1);('cop\x10poly1d2ln2nd2d\x11421 example rwy', 1);('pdas', 1);('rate \x032n\x0022dwhich isa minimax optimal ratethe example', 1);('on\x00dd2', 1);('scales as\x0fnbt', 1);('namelywhen', 1);('nonparametric rate learning', 1);('term \x032\x0fnbt2dis', 1);('neural network predictor', 1);('price pay', 1);('role terms boundthe term', 1);('c1\x15201 c25ln22\x0fnbthere', 1);('c2', 1);('1\x00\x0e14kfbt\x00fk22\x14poly4b2yn\x150\x17pmc\x032\x0fnbt2d\x0fnbt c1pnwhere', 1);('2ne\x00\x17\x00\x0e\x150 probability', 1);('\x17\x151 having\x0e', 1);('\x0fnbtsatisfy technicalassumption', 1);('\x0fnbtgiven assumption', 1);('gdsatises\x112012and', 1);('2assume step size', 1);('main resulttheorem', 1);('n stateour', 1);('excess risk instancehaving\x0fnbt n\x00', 1);('rules lead', 1);('910c5isc dof', 1);('constant c5depends', 1);('large sample size nsuch that\x0fnbt\x14\x10c5\x0321\x11d2\x00d2 c1\x150where', 1);('andassume exists', 1);('rkhs letd2 consider\x0fnbtgiven assumption', 1);('decreasing', 1);('technical assumptionassumption', 1);('rst result need', 1);('consistency optimal rates learning', 1);('rule guarantees consistency optimal rates inthe case', 1);('classes sense', 1);('neural network learningin', 1);('excess risk shallow', 1);('gdfor', 1);('establishes relationship excess risk', 1);('random designthe', 1);('rb\x0fnbt42', 1);('exists b\x0fn2rsuch thatkf\x14bt\x00hk2n\x141', 1);('design case', 1);('r\x0fnbtmoreover', 1);('exists \x0fn2rsuch thatkf\x14bt\x00hk22\x141', 1);('objectivef71nnxi1hf\x14xi\x01ih\x00yi2f2hin random design case', 1);('step size \x112012and number steps bt', 1);('gdwiththe', 1);('anyh2h withkhk2h\x14randmoreover', 1);('gdminimizing kls fix', 1);('excess risk bounds learning', 1);('gdlearning rkhs', 1);('excess risk bounds', 1);('technical assumption', 1);('\x17\x151where failure probability \x120is ordere\x00\x17 assumethat network width satisesm\x1584b2yn\x150p\x17', 1);('1assume thatn\x150\x151', 1);('network', 1);('network width', 1);('assumption states', 1);('k\x154 lnnlnd 12in', 1);('integer k\x152p\x15mink\x15c2 kd\x151\x00ne\x00c3d\x00n2e\x00c4dn\x0042k\x001where k 1p2\x19\x001k\x0022k\x003pk k\x152for instance', 1);('constants c2c3c40such', 1);('probability measure onsd\x001', 1);('concrete example state result 3411proposition', 1);('high probabilityto', 1);('pdwith', 1);('family input distributions\x15mink \x02', 1);('dwith probability least1\x00e\x00onin random design setting', 1);('c\x150', 1);('isotropicgaussian n\x14dcfor activation functiondependent', 1);('shows inputs', 1);('has\x150\x15\x0e100n2in random design setting', 1);('satisfying aseparation mini6jkxi\x00xjkkxixjk\x15\x0e', 1);('claims inputs', 1);('shows distributionfree', 1);('distinct inputs parallelmore', 1);('shows \x1500whenever', 1);('designwe have\x150\x15minkremark', 1);('assumption random design setting', 1);('smallest', 1);('kassumption', 1);('x xjx', 1);('clear \x14x x', 1);('x r\x12f\x12x\x120which arandom', 1);('subgradient theneural network', 1);('neural tangent kernel', 1);('\x14the kernel function \x14is', 1);('kij\x14xixjthroughout', 1);('k2rn\x02nwith', 1);('matrix symmetric matrix', 1);('kernel analytic form \x14x x x x\x19\x00arccos x x16192642supx x2sd\x001\x14x x\x141eigenvalues \x14satisfy\x16k\x14c1k\x00d2fork2n6 42the', 1);('activation\x14x x x xzrdifwx0gifw x0gndwj0id x x2sd\x001the', 1);('kernel', 1);('proposition summarizes properties kernel function', 1);('preliminariesthe', 1);('technical preliminaries assumptions41', 1);('main resultsbefore', 1);('critical analysis104', 1);('special case', 1);('resultkfbt\x00fk22opn\x0022d asn19we', 1);('rkhs9\x0fnbt opn\x00d2d', 1);('minimaxoptimal rate', 1);('rate minimax optimal need', 1);('control tradeoff minimizingr7ar2r\x0fnbt', 1);('r\x0fnbtassumption', 1);('exists function \x0fn2r thatkf\x14bt\x00hk22\x141', 1);('arto', 1);('approximation error', 1);('ensure ball', 1);('desirable rate theradiusr', 1);('gdkf\x14t\x00hk22grows', 1);('error decomposition t2nkft\x00fk22kft\x00f\x14tk22kf\x14t\x00f\x14tk22kf\x14t\x00hk22kh\x00fk22poly4ndpmar2c1pnkf\x14t\x00hk22ar2it', 1);('kf\x14t\x00f\x14tk22ar21pnwith high probabilitysee', 1);('randomdesign setting', 1);('time uniform convergence argument', 1);('simple application', 1);('samples xiyini1 yihxi ikhk2h\x14rnow', 1);('introduce sequenceof virtual', 1);('f noth gap', 1);('learnsapproximator hin ball', 1);('approximatefwell approximator h2h', 1);('large ball', 1);('r\x03dd\x002pr\x002d\x002the lemma', 1);('exists h2h withkhk2h\x14rsuch thatsupx2sd\x001jfx\x00hxj\x14ar', 1);('forr', 1);('function unit sphere', 1);('letfbe', 1);('explicit result9lemma', 1);('relu theorem', 1);('large ball therkhs approximates', 1);('approximation theorem', 1);('nal goal', 1);('howeverour', 1);('control excess risk f\x14t', 1);('andproposition 28supx2sd\x001jftx\x00f\x14txj2\x14poly4ndpmat point', 1);('t2n high probability initialization inputs', 1);('cost step polynomial overparameterization neural network respect tothe sample size', 1);('gdtrained kernel leastsquares kls', 1);('neural network ftto', 1);('rst step analysis relate predictionsof', 1);('section sketch proof', 1);('l2px3 sketch analysisin', 1);('claims suitableconditions \x14 spectral decomposition\x14x x 1xi1\x16i\x08ix\x08i x x x2sd\x001where\x161\x15\x162\x15\x150are eigenvalues kernel \x081\x082 eigenfunctions form anorthonormal basis', 1);('f2hfx hf\x14x\x01ih', 1);('x2sd\x001 function \x14x\x01belongs tohand reproducingrelation', 1);('withoutloss', 1);('sense thatpij i j\x14xixj\x150for anyfxigni1\x1asd\x001 2rn anyn2n', 1);('psdin', 1);('continuous symmetric', 1);('inner product h\x01\x01ihunder whichhis completea function\x14sd\x001\x02sd\x001ris', 1);('spaceh\x1al2pxis familyof functions fsd\x001rfor whichkfk21and', 1);('rkhs hilbert', 1);('spacewe recall basics', 1);('reproducing', 1);('respect inputskfk2n1n\x00fx12\x01\x01\x01fxn2\x01hfgin1nfx1gx1 \x01\x01\x01fxngxnat time 2population seminorm', 1);('normfor functions fgsd\x001rwe dene empirical seminorm innner product isalways', 1);('frobenius', 1);('spectral norm kmkfis', 1);('mkmkopdenotes', 1);('seminorm thenkxk2mhxxim matrix', 1);('inner product', 1);('positive semidenite psd', 1);('norm kxk1 maxijxij', 1);('parentheses w1wm w1wm vector normk\x01k', 1);('paper lnx maxln x08concatenation vectors', 1);('throughoutthe', 1);('polyk\x01stands polynomial degree k', 1);('symbol', 1);('the2norm unit sphere', 1);('sd\x001\x08x2rdkxk2', 1);('basic denitions notation', 1);('notationin section introduce', 1);('denitions', 1);('complete statements theorems proofs', 1);('present assumptionsand', 1);('present sketch analysis', 1);('organizationin', 1);('neural networks13', 1);('small number parameterssometimes linear sample size', 1);('small approximation error', 1);('deepneural networks', 1);('width requirement endsome approximationtheoretic results', 1);('gdwith', 1);('interesting open problem whetheroptimal nonparametric rates', 1);('current work tangentialto', 1);('similar goal', 1);('builton proof', 1);('prediction gap context generalization', 1);('constant time', 1);('step size initialization scaleand normalization targets', 1);('aforementioned prediction gapmoreover', 1);('convergence globalminima empirical risk work', 1);('smooth activations poly32\x0144 forsmooth activations linear order', 1);('shallow neural networks smalleroverparameterization requirement instance poly2\x0135', 1);('l\x01for', 1);('requirement overparameterization matches', 1);('rkhsdirectly', 1);('poly8ndin order control gap pay predictions neural network', 1);('networks polynomialwidth m\x15poly61 1dnand addition width scale', 1);('class neuralnetworks shows', 1);('minimizers empirical risk', 1);('parametric rate polynomial link functions sametime literature', 1);('multiindex model discussedbefore', 1);('regression function onlysensitive rdimensional subspace input space', 1);('curse dimensionality', 1);('possible way', 1);('stochastic variantsanother', 1);('practical algorithmsuch', 1);('interesting possibility showthis kind adaptivity higherorder smoothness regression function', 1);('constraints parameters', 1);('theerm procedure', 1);('possible neural networks', 1);('shows rates', 1);('large end', 1);('minimax optimal rates n\x002p2pd', 1);('f ptimes differentiability', 1);('considers notion additionalregularity', 1);('nondifferentiable regression functions nonparametric literature', 1);('additional structure regression function work focus general', 1);('unavoidable unlesswe impose', 1);('minimax optimal rate n\x0022dis extremelyslow highdimensional problems manifestation curse dimensionality', 1);('rates fwith structure', 1);('parameter xinrxdetermines cutoff', 1);('simpler functions lie thelowdimensional subspace', 1);('span kernel eigenbasis', 1);('77since functions', 1);('controlthe approximation error', 1);('space argument', 1);('excess risk order n\x0022dforan', 1);('needs tocontrol approximation error', 1);('extreme case', 1);('nondifferentiable boundedfunctions', 1);('spaces space', 1);('learning scenariorelationship analysis', 1);('discussion suggests thatgdis', 1);('example', 1);('estimation error', 1);('reasonable approximation error', 1);('nd function exponential2norm order', 1);('gdwould', 1);('constant c', 1);('approximation error infkhk2h\x14rkh\x00fk2lnr\x00c sr\x151with', 1);('exponential spectral decay orderexp\x00k', 1);('namely', 1);('approximation error ssobolev classes suchrkhs', 1);('smooth activation function', 1);('sec42', 1);('approximate f end', 1);('need understandthe regularity', 1);('question viewpoint', 1);('approaching', 1);('suchsmooth activation functions', 1);('gdwhile', 1);('efcient algorithm', 1);('results approximationtheoretic interestingto', 1);('consistency withminimax optimal rates', 1);('activation functions sigmoid x7ex1 ex', 1);('respect shallow', 1);('works nonparametric statistics', 1);('numerous', 1);('regression', 1);('directionslearnability', 1);('discussion limitations', 1);('optimal excess risk \x0fnbtn\x00dd2 werecover optimal rate', 1);('high probability', 1);('raskutti', 1);('theoptimal rate', 1);('sanity check', 1);('unreasonable andcan', 1);('knowledge \x1b2', 1);('training sample rule', 1);('gdinterpolates', 1);('thatbt1 as\x1b0 suggests noisefree regime', 1);('withrespect noise rate \x1b2', 1);('data simplicity', 1);('possible functions', 1);('gdto', 1);('restrictthe solution', 1);('functions7thus number steps', 1);('theargumentx simpler class', 1);('rxcaptures', 1);('r1p\x11t2e\x1b\x11t\x001\x001with rx', 1);('btsteps wherebt mint2n', 1);('particular rule suggests', 1);('analysis comparison kernel', 1);('ntf gram5see', 1);('empirical approximation', 1);('downto access eigenvalues', 1);('controls complexity predictor class', 1);('raskuttiwainwrightyu rwy', 1);('specically', 1);('acomprehensive overview', 1);('possible ratehere', 1);('havean adaptive', 1);('learning case decay rate eigenvalues', 1);('approximation reasonablemodel', 1);('instance multilayer', 1);('complex neural network', 1);('extrapolate situation', 1);('settingof paper', 1);('neural networks hand', 1);('decay rate kernel spectrum thecase learning shallow', 1);('results suboptimal excess risk kfbt\x00fk22op\x032n\x0023dempirical', 1);('btn13 high probability excess risk order', 1);('statesthat number steps', 1);('gdby yao rosasco caponnetto', 1);('classical analysis', 1);('instance wecan', 1);('decay rate eigenvalues', 1);('loss high probability guaranteeit', 1);('markovs', 1);('result d2', 1);('excess risk ordere\x0fnbtn\x00', 1);('step size \x1112n\x0011 andbtn', 1);('tohave decay rate order k\x00d26521', 1);('polynomialdecay rate order k\x00', 1);('smooth functions', 1);('standard regularity condition theeigenvalue decay rate kernel function', 1);('whichrequires knowledge regularity', 1);('dieuleveut bach', 1);('rule whichyields optimal rate', 1);('concrete example', 1);('till poly3\x01', 1);('inputs x1xnare xedwith polynomial term', 1);('design scenario', 1);('rate sufcient', 1);('gdachieves', 1);('large thiswork identify whenever', 1);('norm approximator h2h', 1);('complex functions aswe', 1);('bach', 1);('smooth functions hand', 1);('suggests learning', 1);('observation consistent rates', 1);('differentiable boundedderivatives', 1);('function sphere', 1);('bietti mairal2019', 1);('complex functionsthan', 1);('knowledge of\x034here polyk\x01stands polynomial degree k5the rate', 1);('expense agnostic algorithm', 1);('thisworse', 1);('\x0322din place \x032', 1);('constant \x03as', 1);('optimal sample size input dimensionhowever suboptimal', 1);('gd2235', 1);('standard assumption literature training ofshallow networks', 1);('neural network d\x152 weachieve optimal nonparametric ratekfbt\x00fk22op\x10\x032n\x0022d\x11asn1 2polynomial overparameterization', 1);('concrete rulesthen', 1);('guarantees minimax optimal rate ofexcess risk learning', 1);('sketch analysisfor suppose', 1);('term poly4\x01pmis gap payfor prediction neural network', 1);('learning function', 1);('function fby function inrkhs term\x0fnbtis', 1);('neural network widthm\x15poly61 1dn4with high probability havekfbt\x00fk22op\x032\x0fnbt2d\x0fnbt poly4ndpmasn1 1here term \x032\x0fnbt2dis price pay approximation', 1);('r\x0fnbt theorem', 1);('rule step btachievesexcess risk', 1);('gdstopped', 1);('anyfunctionh2h withkhk2h\x14r', 1);('rule learning', 1);('rkhshinduced relu ntk', 1);('regression functions four rst result reduction theorem', 1);('minimaxoptimalnonparametric rate learning', 1);('neural networks consistent presence noise', 1);('explicit penalization training', 1);('gdwithout', 1);('approximate minimumon validation sample reached11 contributionin work show', 1);('trackthe performance heldout validation sample', 1);('stochastic variant', 1);('gdor', 1);('shows timepractitioners', 1);('absolute continuity input distribution', 1);('results adaptive interpolation results', 1);('gdindeed', 1);('able adapt noise', 1);('approach problem', 1);('nonparametric literature', 1);('severalworks', 1);('presence noise', 1);('penalization theystill', 1);('apractical setting neural networks', 1);('employ 2penalization', 1);('exponentialdependence rall', 1);('differentiable link4functions multiindex models minimax optimal rate n\x002p2pr29', 1);('polynomialregularity assumption', 1);('nonparametric setting', 1);('surprisingly', 1);('polynomial link functions', 1);('excess risk orderdrpnfor network width mrpwhich nearoptimal', 1);('empirical risk time', 1);('themultiindex model regression function fmix gh\x121xi\x01\x01\x01h\x12rxiandgis polynomialof degreep', 1);('damian', 1);('similar line work', 1);('till n\x0045in', 1);('chap', 1);('procedure attains aminimax optimal rate order n\x002p2p1when link function ptimes', 1);('paper case', 1);('rate thegeneral case', 1);('additional structure optimal rate excess risk', 1);('n\x0014 singleindexmodel thanks', 1);('rate excess risk', 1);('empirical risk', 1);('gdthey', 1);('link function \x12areunknown parameters', 1);('singleindex model regression function isgiven asfsix gh\x12xi wheregrris', 1);('bietti', 1);('tothis', 1);('regression models fmight', 1);('recent works', 1);('balls \x02n\x00dd246 6several', 1);('knownthat minimax optimal rate learning', 1);('exponential dependence', 1);('theclass offwe analyze', 1);('rate excess riskop\x10n\x00d2d\x001\x11asn1note class regression functions 2ball', 1);('rkhs gdwith', 1);('recent workshuet', 1);('minimize empirical risk yield optimal rate convergence partial progressin direction', 1);('gdused', 1);('gdrather erm', 1);('f\x1b2s work focus', 1);('standard penalty function norm parameters', 1);('herea', 1);('appropriate choice penalization', 1);('respect shallow neural networks is\x122arg min\x12fl\x12 pen\x12g matches', 1);('risk minimization erm', 1);('minimaxoptimal rate excess risk setting \x02pn\x0022d24', 1);('able estimate f', 1);('nonparametric general number parameters width mhas increase number observations', 1);('setting learning suchcomplex functions', 1);('literature work focus case \x1b 0and complexregression functions f', 1);('atomic distributionfocus work', 1);('respect inputs', 1);('pxwith', 1);('universal constant c0 distribution', 1);('pwith', 1);('nthere exists distribution', 1);('l\x12t', 1);('implies thatas', 1);('zero empirical riskare general inconsistent', 1);('hardmargin classication setting 27at time \x1b0', 1);('similar spiritwere', 1);('theregression function fis shallow polynomial neural network innite width', 1);('examples norm', 1);('universal constant c0such', 1);('k2pnasn13throughout paper use fgto', 1);('opkminimalnorminterpolant', 1);('thenorm minimalnorm 2kernel interpolant predictor', 1);('noisefree setting \x1b', 1);('forexample arora', 1);('implicit bias', 1);('responsible animplicit complexity control', 1);('gdalgorithm', 1);('possible explanations thecomplexity control', 1);('itthrough lens learning kernels number', 1);('question risk behavior', 1);('going', 1);('interesting results', 1);('neural network learning', 1);('41thentk theory', 1);('feature rf', 1);('particular case', 1);('theory extent connection notcome surprise', 1);('kernelhilbert space', 1);('space gains approximation power', 1);('appropriate conditions', 1);('space time', 1);('neuraltangent feature ntf', 1);('gradient network', 1);('large featurespace', 1);('linear predictor', 1);('observation sufcient overparameterizationm polynd predictor f\x12tbehaves', 1);('exponential convergence rate', 1);('particular works', 1);('able minimize empirical risk inthe', 1);('gdis', 1);('tangible progress', 1);('explicit complexitycontrolto end optimization viewpoint', 1);('algorithms nearzero empirical risk results mild', 1);('gdtype', 1);('training neuralnetworks', 1);('zhang', 1);('l\x12t0should', 1);('statistical perspective', 1);('error training sample', 1);('exceeds sample size n', 1);('common knowledge overparameterizedneural networks width mby', 1);('precision general hand nowadays', 1);('minimize till', 1);('gdcan', 1);('nonconvex nature nonobvious', 1);('minimization objective', 1);('close noise rate \x1b2', 1);('couldkeep risk', 1);('network complexity control', 1);('minimize empirical risk', 1);('norm parameters 2l\x12t\x14l\x12t cnetworkcomplexity \x12tpnthus', 1);('algorithm ts thesample complexity solution', 1);('end givesus highprobability bounds risk', 1);('gdwe', 1);('concrete algorithm', 1);('riskof predictor', 1);('due generality', 1);('clearly', 1);('complexity ormetric entropy', 1);('vcdimension rademacher', 1);('notion capacity class', 1);('members agiven class neural networks data distributions algorithmfree analysis bounds are2without loss generality mis', 1);('classical approachto problem considers uniform bounds risk hold', 1);('topic interest', 1);('risk neural network learning', 1);('l\x12\x00\x1b2study', 1);('l\x12 ef\x12x\x00y2j\x12', 1);('statistical risk aka risk', 1);('learning ability algorithms training neural networks', 1);('understanding', 1);('l\x120\x14b2yprior', 1);('ensures f\x120x', 1);('initial parameters u\x120in', 1);('0idfor eachk\x14m2 andw0m2kw0kotherwise3fort 1t do4\x12t \x12t\x001\x00\x11rl\x12t\x0015end forremark', 1);('layer \x12t1setu u1umasuk\x001pmfork\x14m2anduk1pmforkm22set\x120 w01w0masw0kiid\x18', 1);('trained', 1);('constant step size network widthensure', 1);('training shallow neural networksrequires training sample number steps \x112012', 1);('gradient descent', 1);('parameters ownthat number steps step size\x11 width neural network m2results', 1);('gdhas', 1);('gdprocedure', 1);('particular thispurpose employ', 1);('function \x01', 1);('nonconvex function', 1);('l\x01is', 1);('byminimization empirical riskl\x12 1nnxi1f\x12xi\x00yi2note', 1);('goal parameters', 1);('class regression functions minimax excess risk behaves kf\x12n\x00fk22 \x02pn\x0022d24in paper', 1);('nonasymptotic sense', 1);('consistent meaningthatkf\x12n\x00fk220asn1 probability', 1);('parameters \x12nis', 1);('atthe', 1);('excess riskkf\x12\x00fk22zsd\x001f\x12x\x00fx2dpxthe goal learning procedure minimize excess risk', 1);('regression function abilityis', 1);('sto', 1);('noisy sample', 1);('2022of shallow neural network', 1);('dec', 1);('1arxiv221213848v1 cslg', 1);('describe setting', 1);('parametervector output layer', 1);('layer andu2f\x06 1pmgmis', 1);('tunable parameter vector', 1);('activation function mis width ofthe network\x12is', 1);('rectied linear', 1);('asf\x12x mxk1ukwkx\x12 w1wm2rdmx2sd\x001here x maxfx0gis', 1);('learning fby theshallow neural network predictor', 1);('throughoutthe paper jyij\x14byfor nite', 1);('differentiable implies targets', 1);('satises jfx\x00f xj\x14\x03kx\x00 xkfor x x2sd\x001for 0\x14\x031', 1);('lipschitzmeaning', 1);('ande2ijxi \x1b2here function fis', 1);('eijxi', 1);('noise variables', 1);('regression modelyifxi i2nwhere1nare', 1);('unknown probability measurepxoversd\x0011and targets', 1);('training sample xiyini1consistingofinputs xiandtargetsyi input xiis', 1);('setting learner', 1);('introductionin', 1);('rules yield optimal rates1', 1);('datafreeand datadependent', 1);('minimax optimal rate', 1);('activation function rule', 1);('optimal rate excess risk', 1);('nitewidth neural network show whenever', 1);('neural tangentkernel ntk', 1);('particular explore problem viewpoint', 1);('show consistencyand optimal rates', 1);('zero training errorare inconsistent class focus', 1);('problem presence noise neural networks', 1);('gradient descent gd toavoid', 1);('functions additive noise', 1);('explore ability', 1);('alberta edmontonszepideepmindcomabstractwe', 1);('canada', 1);('learning lipschitz functions gdtrained shallowoverparameterized relu neural networksilja kuzborskijdeepmind londoniljakdeepmindcomcsaba szepesv', 1);