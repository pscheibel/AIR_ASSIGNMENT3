('lidar', 101);('computer vision', 41);('point cloud', 28);('fig', 26);('pattern recognition', 26);('atex', 25);('j.', 25);('robust lidar', 24);('tab', 23);('l.', 23);('h.', 22);('proceedings', 22);('specically', 20);('semantic segmentation', 20);('nature', 20);('point clouds', 19);('d.', 19);('clean data', 18);('rlseg', 18);('zhou', 18);('s.', 18);('c.', 18);('minkowskinet', 17);('ieee/cvf conference', 15);('dai', 14);('li', 14);('x.', 14);('z.', 14);('m.', 14);('b.', 14);('liu', 13);('zhang', 13);('sec', 13);('van gool', 12);('fog simulation', 12);('mix3d', 12);('yan', 11);('wang', 11);('hahner', 11);('local distortion', 11);('bev', 11);('yu', 10);('international conference', 10);('r.', 10);('sakaridis', 9);('kpconv', 9);('w.', 9);('benchmarking', 8);('zhao', 8);('cenet', 8);('pointhead', 8);('a.', 8);('t.', 8);('adverse weather', 7);('3d space', 7);('mlps', 7);('snowfall rate', 7);('salsanext', 7);('mlp', 7);('randla-net', 7);('k.', 7);('f.', 7);('semantickitti-c', 6);('hu', 6);('pan', 6);('semantickitti', 6);('noisy points', 6);('range image', 6);('cartesian', 6);('local aggregation', 6);('eqn', 6);('ieee conference', 6);('n.', 6);('p.', 6);('springer nature', 5);('robustness', 5);('lidar semantic segmentation', 5);('future research', 5);('behley', 5);('ren', 5);('hendrycks', 5);('graham', 5);('van der', 5);('maaten', 5);('recent', 5);('cross-device discrepancy', 5);('adverse weathers', 5);('meth- ods', 5);('kpconv thomas', 5);('jia', 5);('data augmentation', 5);('hua', 5);('yue', 5);('xiao', 5);('snowfall simulation', 5);('3d object detection', 5);('cheng', 5);('gfnet qiu', 5);('transformation function', 5);('transformer', 5);('cylinder3d', 5);('rmiou', 5);('o.', 5);('lin', 5);('measurement noise', 4);('different representations', 4);('zheng', 4);('distortion', 4);('raw point clouds', 4);('tang', 4);('xu', 4);('model robustness', 4);('inversely', 4);('compared', 4);('koltun', 4);('point-based', 4);('qi', 4);('yeung', 4);('keutzer', 4);('recently', 4);('hybrid-representation architecture', 4);('imagenet', 4);('fog', 4);('concretely', 4);('rst row', 4);('z value', 4);('clean point cloud', 4);('sun', 4);('polarnet y', 4);('cvpr', 4);('transformer zhao', 4);('grid', 4);('u-net', 4);('decoder layers', 4);('polarnet', 4);('spvcnn', 4);('analysis', 4);('common corruptions', 4);('% performance', 4);('knowledge distillation', 4);('kl', 4);('zhu', 4);('q.', 4);('proceed-', 4);('wu', 4);('p.r', 3);('china', 3);('semantic segmentation models', 3);('noisy data', 3);('above observations', 3);('comprehensive analysis', 3);('cui', 3);('semantickitti-c.', 3);('kamann', 3);('rother', 3);('instance segmentation', 3);('altindis', 3);('milioto', 3);('stachniss', 3);('thomas', 3);('3d point clouds', 3);('image size', 3);('guibas', 3);('jiang', 3);('adverse weather conditions', 3);('adaptive weight', 3);('projection-based', 3);('liong', 3);('tao', 3);('sparseconv', 3);('robustness benchmarks', 3);('object detection', 3);('models robustness', 3);('extra noisy points', 3);('% points', 3);('jitter distortion \x1b=', 3);('gong', 3);('dong', 3);('perfor- mance', 3);('certain range', 3);('global outliers', 3);('beam number', 3);('cenet h.-x', 3);('han', 3);('spvcnn tang', 3);('voxel point cloud', 3);('eccv', 3);('wei', 3);('beam labels', 3);('candidate methods', 3);('salsanext cortinhal', 3);('typical approaches', 3);('rv', 3);('architectures', 3);('range images', 3);('congurations', 3);('gfnet', 3);('randla-net hu', 3);('illustration', 3);('visualization results', 3);('sparse', 3);('robust- ness', 3);('cylindrical', 3);('pointbranch', 3);('mixup', 3);('pseudo label', 3);('chen', 3);('robust', 3);('advances', 3);('e.', 3);('proc', 3);('g.', 3);('international journal', 3);('machine learning', 3);('european conference', 3);('pro-', 3);('chinese university', 2);('hong kong', 2);('shenzhen', 2);('safety-critical applications', 2);('various corruptions', 2);('new benchmark', 2);('cross-device discrep- ancy', 2);('different input representations', 2);('network architectures', 2);('crucial role', 2);('state-of-the-art methods', 2);('recent studies', 2);('unal', 2);('clean validation', 2);('zaech', 2);('original data', 2);('examples', 2);('real-world deployment', 2);('basart', 2);('steinhardt', 2);('dalva', 2);('dundar', 2);('3d shapes', 2);('lidars', 2);('there-', 2);('different devices', 2);('semantic', 2);('vizzo', 2);('geometric details', 2);('mod- els', 2);('modelnet40', 2);('lai', 2);('semantic segmentation dataset', 2);('semantickitti behley', 2);('robust benchmark', 2);('out-of-domain corruptions', 2);('voxel representation', 2);('yi', 2);('su', 2);('torr', 2);('hybrid-representation architecture improves', 2);('training', 2);('mix3d nekrasov', 2);('schult', 2);('litany', 2);('leibe', 2);('engelmann', 2);('superior robustness', 2);('semantic segmen- tation', 2);('input representation', 2);('hierarchical architecture', 2);('local group', 2);('fan', 2);('xiang', 2);('fuxin', 2);('tran', 2);('attention mech- anism', 2);('engel', 2);('belagiannis', 2);('dietmayer', 2);('raw point cloud', 2);('tatarchenko', 2);('spherical projection', 2);('b. wu', 2);('wan', 2);('nguyen', 2);('widjaja', 2);('sharma', 2);('chong', 2);('riazuelo', 2);('montesano', 2);('murillo', 2);('qiu', 2);('voxel-based', 2);('engelcke', 2);('razani', 2);('taghavi', 2);('hybrid-representation', 2);('dietterich', 2);('diverse corrup- tions', 2);('roelofs', 2);('schmidt', 2);('shankar', 2);('preliminary attempts', 2);('yamada', 2);('otani', 2);('porav', 2);('musat', 2);('bruls', 2);('michaelis', 2);('beta =', 2);('moderate', 2);('devicedense reduce lidar', 2);('sparse reduce lidar', 2);('robustness benchmark', 2);('existing', 2);('wachs', 2);('clean dataset', 2);('point cloud classiers', 2);('noisy point clouds', 2);('bai', 2);('lidar-camera', 2);('wide range', 2);('foggy weather', 2);('large areas', 2);('spurious returns', 2);('global noisy points', 2);('global', 2);('unit sphere', 2);('formally', 2);('gaussian', 2);('global noises', 2);('local noises', 2);('geiger', 2);('lenz', 2);('urtasun', 2);('domain gap', 2);('beam label', 2);('tzelepis', 2);('aksoy', 2);('iccv', 2);('choy', 2);('gwak', 2);('savarese', 2);('azimuth angles', 2);('zenith angles', 2);('beam numbers', 2);('cenet h.- x. cheng', 2);('birds- eye-view', 2);('image plane', 2);('fischer', 2);('brox', 2);('hybrid-representation manner', 2);('initial stage', 2);('fea- tures', 2);('ofcial architectures', 2);('target point', 2);('according', 2);('point-wise mlp', 2);('adaptive', 2);('pseudo', 2);('% miou', 2);('vaswani', 2);('aggregation function', 2);('point transformer layer', 2);('minkowskinet choy', 2);('non-empty voxels', 2);('aggregate point-wise', 2);('benchmark results', 2);('robustness performance', 2);('local distortion corruption', 2);('furthermore', 2);('original performance', 2);('local noise', 2);('clean robustness fog snowfall global outliers', 2);('32-beam 16-beam', 2);('mr miou', 2);('detailed', 2);('performance', 2);('x-axis denotes', 2);('local geometric', 2);('diverse corruptions', 2);('snow simulation', 2);('voxel architecture', 2);('minkowsk-', 2);('comprehensive', 2);('global out- liers', 2);('global noise', 2);('cross-device scenarios', 2);('ablation study', 2);('voxel', 2);('voxel partition', 2);('con-', 2);('voxel size [', 2);('similarly', 2);('2dpass w/o', 2);('observation-11', 2);('point- branch', 2);('cisse', 2);('dauphin', 2);('lopez-paz', 2);('existing mixup', 2);('instance cutmix', 2);('kd', 2);('cylindrical partition', 2);('hinton', 2);('vinyals', 2);('dean', 2);('ding', 2);('semantic seg- mentation', 2);('i.', 2);('learning', 2);('luo', 2);('fast', 2);('lidar point clouds', 2);('point transformer', 2);('synthetic data', 2);('ieee', 2);('bijelic', 2);('heide', 2);('yang', 2);('markham', 2);('xie', 2);('b.-s.', 2);('s.-k.', 2);('point-', 2);('vision', 2);('c.r.', 2);('l.j', 2);('deep', 2);('neural information processing systems', 2);('national conference', 2);('ma', 2);('xu yan1,2', 1);('chaoda zheng1,2', 1);('zhen li2,1', 1);('shuguang cui2,1,4and dengxin dai3', 1);('* 1fnii', 1);('informatics', 1);('germany', 1);('cheng laboratory', 1);('corresponding', 1);('e-mail', 1);('ddai @ mpi-inf.mpg.de', 1);('lizhen @ cuhk.edu.cn', 1);('contributing', 1);('xuyan1 @ link.cuhk.edu.cn', 1);('chaodazheng @ link.cuhk.edu.cn', 1);('shuguangcui @ cuhk.edu.cn', 1);('abstract', 1);('autonomous driv-', 1);('large range', 1);('semantic seg- mentation models', 1);('current approaches', 1);('11lidar semantic segmentation models', 1);('input represen- tation plays', 1);('specic corruptions', 1);('segmentation model', 1);('effective modications', 1);('keywords', 1);('out-of-distribution', 1);('clouds', 1);('introduction autonomous', 1);('promising appli- cations', 1);('impressive progress', 1);('semantic segmentation plays', 1);('current', 1);('share thesame data distribution', 1);('corresponding train-', 1);('similar time', 1);('weather condition', 1);('inac- curate data acquisition', 1);('complex sce- narios', 1);('diverse weather conditions', 1);('1arxiv:2301.00970v1 [ cs.cv ]', 1);('jan', 1);('cross-device simulation', 1);('data', 1);('global outliers data', 1);('snowfall simulation data', 1);('fog simulation data', 1);('road sidewalk car vegetation trunk terrain building other-obj', 1);('comprehensive robustness benchmark', 1);('fog simulations', 1);('suf- fer', 1);('severe corruptions', 1);('safety-critical appli- cation', 1);('ood', 1);('important part', 1);('understanding', 1);('image corruption', 1);('dif- ferent tasks', 1);('diet-', 1);('stud- ies simulate corruption', 1);('rgb', 1);('original image', 1);('different kinds', 1);('dense pixel arrays', 1);('previous works focus', 1);('different architectures', 1);('different type', 1);('occlu- sion', 1);('data acquisi- tion', 1);('segmentation models', 1);('sce- narios', 1);('diverse representations', 1);('different requirements', 1);('2d pixels', 1);('normal 2d-cnns', 1);('approaches conduct voxelization', 1);('3d voxel grids', 1);('cap- ture', 1);('3d information', 1);('analyze robustness', 1);('3d vision', 1);('corruption robustness', 1);('3d point cloud', 1);('synthesis datasets', 1);('cad', 1);('stand-alone objects', 1);('ndings inspringer', 1);('real-world applications', 1);('complex environments', 1);('real- world data', 1);('coarse comparison', 1);('full models', 1);('inner structures', 1);('input rep- resentations', 1);('real-world point clouds', 1);('rst time', 1);('pop- ular', 1);('following', 1);('pre- vious studies', 1);('term robustness refers', 1);('introduce diverse corruptions', 1);('speci-', 1);('corrup- tions', 1);('subclass corruptions', 1);('adverse weather class contains', 1);('fog simula- tions', 1);('independent levels', 1);('different snowy', 1);('foggy inten- sities', 1);('built', 1);('semantic segmenta- tion methods', 1);('different represen- tations', 1);('various aspects', 1);('representation', 1);('range projection improves', 1);('vulnera- ble', 1);('different weather conditions', 1);('impres- sive robustness', 1);('cylin- der voxel partition', 1);('traditional grids', 1);('architecture', 1);('pseudo kernel local aggregation', 1);('mlps qi', 1);('transformer architectures', 1);('empirically', 1);('combi- nation', 1);('input representations', 1);('model architectures', 1);('data augmen- tation strategies', 1);('segmenta- tion model', 1);('effective manner', 1);('rst large-scale robustness bench- mark', 1);('point cloud semantic segmentation', 1);('semantickitti- c.', 1);('dataset contains', 1);('sensor measurement bias', 1);('diverse device collections', 1);('diverse architectures', 1);('effective observations', 1);('related', 1);('process input point clouds', 1);('gen-', 1);('2d vision', 1);('rst conduct', 1);('local aggregation function', 1);('studies design', 1);('different operators', 1);('segmentation local geometrics', 1);('mlp qi', 1);('w. wu', 1);('pseudo grid', 1);('extract local', 1);('nonlocal operators', 1);('permutation-invariant dependency', 1);('2d image plane', 1);('pre-', 1);('vious works project points', 1);('plane projec- tion', 1);('projection process', 1);('alonso', 1);('segmentation results', 1);('impressive per- formance', 1);('rst conduct voxelization', 1);('raw points', 1);('different voxel grids', 1);('conduct 3d convolution', 1);('input volumetric', 1);('sparse con- volution', 1);('core technique', 1);('large proportion', 1);('vox- els', 1);('huge computational burden', 1);('conduct operation', 1);('non-empty grids', 1);('hash', 1);('design diverse architectures', 1);('original grid voxels', 1);('cylindrical ones', 1);('asymmet- rical network', 1);('r. cheng', 1);('multi-branch component', 1);('kernel sizes', 1);('different receptive eld', 1);('attention mechanism', 1);('superior performance', 1);('hence', 1);('multi- representation fusion', 1);('mul- tiple representation inputs', 1);('projection images', 1);('designs point-voxel', 1);('cnn', 1);('com- bines point-wise', 1);('sparse convolution block', 1);('adopts neural architecture search', 1);('nas', 1);('powerful architecture', 1);('range-point-voxel fusion network', 1);('applies cross-modal knowledge distilla- tion', 1);('color images', 1);('images', 1);('comprehensive robustness benchmarks', 1);('2d image processing', 1);('different tasks', 1);('robust image classica- tion', 1);('imagenet-c hendrycks', 1);('imagenet deng', 1);('s test', 1);('motion blur', 1);('objectnet barbu', 1);('imagenetv2 recht', 1);('natural distribu- tion', 1);('imagenet-a', 1);('imagenet-r', 1);('bench- marks classiers robustness', 1);('natural adver- sarial examples', 1);('diverse tasks', 1);('cityscapes cordts', 1);('new-', 1);('acdc sakaridis', 1);('categories', 1);('intensity', 1);('description', 1);('fog simulationlight fog', 1);('moderate fog', 1);('snowfall simulationlight snowfall', 1);('moderate snowfall', 1);('snowfall', 1);('global outlierslight', 1);('distortionlight', 1);('cross 32-beam', 1);('cross 16-beam', 1);('common adverse conditions', 1);('real-world cor- ruptions', 1);('2d- 3d data', 1);('model architecture', 1);('huge demands', 1);('comprehensive 3d robustness bench- mark', 1);('point cloud classication task', 1);('z. zhang', 1);('rotation invariant', 1);('state-of-the-art performance', 1);('models robust- ness', 1);('adversarial corruptions', 1);('h. liu', 1);('local relative position', 1);('point cloud classi- cation', 1);('robustpointset taghanaki', 1);('pointcloud-c ren', 1);('different corruptions', 1);('approaches test robust- ness', 1);('synthesis dataset', 1);('experienceand conclusions', 1);('pointasnl yan', 1);('adap- tive shifts', 1);('outlier points', 1);('objects surfaces', 1);('recent year', 1);('different adverse weathers', 1);('object detection models', 1);('adverse weather data', 1);('investi- gate', 1);('robustness issue', 1);('fusion methods', 1);('transfusion bai', 1);('different fusion strategies', 1);('deepfusion y', 1);('reec- tions', 1);('camera pixels', 1);('robustness scenarios.springer', 1);('fog moderate fog', 1);('fog fig', 1);('foggy point clouds', 1);('= 0:06and = 0:2are', 1);('robust semantic segmentation model', 1);('corruptions taxonomy real-world lidar', 1);('measure- ment noise', 1);('severity lev- els', 1);('point cloudpis', 1);('pointsfpjgn j=1', 1);('nis', 1);('xyz', 1);('point j', 1);('snowfall moderate snowfall', 1);('snowfall fig', 1);('snowfall point clouds', 1);('snowfall rates 1mm/h', 1);('set-to-set function', 1);('rn\x02', 1);('rn0\x02', 1);('p=fpjgn', 1);('j=1and itsd-dimensional', 1);('p0=fpjgn0', 1);('intensity value ij2r', 1);('return strength', 1);('laser beam', 1);('common weather con- ditions', 1);('clean- weather point clouds', 1);('disturbing points positions', 1);('valid rules', 1);('clean weather', 1);('rst calculate', 1);('response ihard', 1);('\x002 \x02k', 1);('ego frame andiis', 1);('attenuation coefcient', 1);('kdenotes thespringer', 1);('point pand', 1);('following hahner', 1);('fog simu- lation', 1);('simulation terms', 1);('max- imum fog response isoftand', 1);('conduct fog simulation', 1);('dif- ferent levels', 1);('point position', 1);('isoftifisoft > ihard', 1);('ifisoft > ihard', 1);('over- shadow', 1);('solid object point p', 1);('isoft > ihard', 1);('fog response', 1);('otherwise', 1);('original response', 1);('overall idea', 1);('sim- ilar', 1);('opaque particles', 1);('sample snow particles', 1);('function samples snow particles', 1);('simulate light/mod- erate/heavy snowfall', 1);('different characteris- tics', 1);('objects sparser', 1);('remote objects', 1);('fog increases', 1);('pres- ence', 1);('respective pulses', 1);('solid object exists ata', 1);('moderate range', 1);('explicit characteristics', 1);('snow par- ticles', 1);('opaque spheres', 1);('snowfall conditions', 1);('snowy par- ticles', 1);('thin water layer increases', 1);('specular component', 1);('ground surface', 1);('corruptions impact', 1);('remote points sparser', 1);('different patterns', 1);('corruption occurs', 1);('data transmission', 1);('such data disturbance', 1);('random noises', 1);('point coordinates', 1);('sample noises', 1);('such noises span', 1);('whole scene', 1);('clean point cloudp', 1);('rn\x023', 1);('p02rn0\x023is', 1);('p0=p', 1);('n0=ng+n', 1);('noise intensity', 1);('nfrom', 1);('% ]', 1);('coor- dinates', 1);('additional points', 1);('local noises jitter', 1);('local neighborhood', 1);('orig- inal points', 1);('noisy disturbance', 1);('data collection', 1);('local distortion pointspringer', 1);('noise global outliers', 1);('clean datazoom-out zoom-out zoom-in noisy datazoom-in', 1);('noisy lidar', 1);('psub=randomsample', 1);('nl', 1);('p0=', 1);('psub+o', 1);('pnp', 1);('randomsample', 1);('nlpoints', 1);('p.o2rnl\x023denotes', 1);('random offsets', 1);('.+andnare element-wise addition', 1);('\x1bfrom [', 1);('different levels', 1);('ideal segmentation algorithm', 1);('various specica- tions', 1);('multiple factors', 1);('cross- device domain shifts', 1);('ensure high-quality data annotation', 1);('large-scale datasets', 1);('high- resolution', 1);('prohibitive costs', 1);('practical vehicles', 1);('low- beam sensors', 1);('kitti geiger', 1);('64-beam 32-beam 16-beam', 1);('cross-device lidar', 1);('64- beam', 1);('beam contains', 1);('param- eters', 1);('nuscenes caesar', 1);('ideal seg- mentation model', 1);('differ- ent data distributions', 1);('different sensors', 1);('previous subsec- tions', 1);('robustness analysis', 1);('benchmark dataset', 1);('high-beam data', 1);('low-beam data', 1);('e.g ..', 1);('beam-level downsam-', 1);('necessary information', 1);('zenith value', 1);('\x12= arctanzp x2+y2', 1);('= arcsinyp x2+y2', 1);('semantic segmentation approaches', 1);('mainstream method', 1);('main representation', 1);('extra', 1);('reference projection-basedsalsanext cortinhal', 1);('arxiv', 1);('icme', 1);('images point cloud', 1);('tmlr', 1);('point-basedkpconv thomas', 1);('randlanet hu', 1);('cylinder3d zhou', 1);('cylinder', 1);('fol-', 1);('k-means', 1);('actual beam number', 1);('high-beam point cloud', 1);('pre-dene zenith range', 1);('different datasets', 1);('high- beam point cloud', 1);('beam num- ber', 1);('downsample point clouds', 1);('downsample points', 1);('above simulation', 1);('hybrid-representation methods', 1);('indepen- dent mainstream', 1);('incorporate addi- tional representations', 1);('auxiliary learning', 1);('main input representation', 1);('projection-based methods', 1);('projection-base method', 1);('models project', 1);('2d images', 1);('2d convolutional neural networkfor semantic segmentation', 1);('above meth- ods', 1);('conduct sphere projection', 1);('adopts polar projection', 1);('birds-eye- view', 1);('sphere', 1);('spherical projection maps', 1);('\x12ur vr\x13 =\x121', 1);('[ 1\x00arctan', 1);('\x19\x001 ] w [ 1\x00arsin', 1);('fov\x001 ]', 1);('h\x13', 1);('thei-th point', 1);('range image plane', 1);('pointp x2+y2+z2andfov = fovup+fovdown', 1);('vertical eld-of-view', 1);('arange image', 1);('h\x02w\x02c', 1);('intensity andrange', 1);('polar', 1);('top-down orthogonal pro- jection', 1);('spatial distribu- tion', 1);('polar projection rst transforms', 1);('polar coor- dinate system', 1);('\x12up vp\x13 =\x12p x2+y2+z2cos', 1);('p x2+y2+z2sin', 1);('polar system', 1);('raw point cloudraw point cloud semantic segmentation', 1);('semantic segmentationspherical projection re-projection', 1);('methods rst conduct spherical projection maps', 1);('2d convolution', 1);('u-net-like', 1);('h\x001', 1);('w\x001', 1);('typical 2d semantic segmentation networks', 1);('u-nets ronneberger', 1);('specic modications', 1);('previous methods', 1);('approaches', 1);('height dimen- sion', 1);('large width-height ratio', 1);('additional pixel-shufe layer', 1);('con- ducts multiscale supervision', 1);('original points', 1);('conducts semantic segmentation', 1);('u-nets', 1);('geometric flow', 1);('gf', 1);('dif- ferent scales', 1);('point-wise predictions', 1);('salsanext1', 1);('cenet2', 1);('polarnet3and gfnet4', 1);('//github.com/tiagocortinhal/salsanext 2https', 1);('//github.com/huixiancheng/cenet 3https', 1);('//github.com/edwardzhou130/polarseg 4https', 1);('//github.com/haibo-qiu/gfnet points', 1);('local points', 1);('aggregation', 1);('1st scale', 1);('scale ...', 1);('approaches sample', 1);('target points', 1);('red color', 1);('original point cloud', 1);('aggregate local', 1);('hier- archical architecture', 1);('receptive eld', 1);('method increase', 1);('multi-stage strategy', 1);('64\x02512range image', 1);('and64\x022048 ones', 1);('ofcial codes', 1);('check- point', 1);('congura- tions', 1);('model on64\x022048 range images', 1);('rst crops points', 1);('dis- cretize points', 1);('480\x02360bev plane', 1);('point-based methods point-based', 1);('approaches aim', 1);('methods rst', 1);('select target points', 1);('original point clouds', 1);('conduct local aggregation', 1);('mine local geometrics', 1);('methods gain', 1);('global semantic infor- mation', 1);('input point cloud', 1);('general formulation', 1);('letpi', 1);('i-th point', 1);('local aggregation func- tion rst transforms', 1);('neighbor pjwith', 1);('neighborhood index', 1);('previous local aggregation approaches', 1);('rst class', 1);('pointnet++ qi', 1);('tandaare mlp', 1);('\x08is concatenation operation', 1);('sim- ple point-wise', 1);('previous studies', 1);('methods design diverse convolution l- ters', 1);('relative positions', 1);('com- putes weights', 1);('neighbor points', 1);('euclidean', 1);('center points', 1);('aggre- gates', 1);('rst calculates', 1);('representative pseudo grid', 1);('generates pseudo', 1);('regular grid points', 1);('regular convolution meth- ods', 1);('normal role', 1);('spherical grid points', 1);('fp kon thek-th grid point', 1);('fp k=x j2n', 1);('grid point pkhave strict', 1);('relative position', 1);('center point', 1);('hyperparame- ter', 1);('tin', 1);('=wk fp k', 1);('convo- lution operator', 1);('grid point', 1);('local neighbors', 1);('tra- ditional local aggregation', 1);('recent transformer', 1);('vector self- attention', 1);('subtraction relation', 1);('attention vec- tor', 1);('transforma- tion functiont', 1);('local structure', 1);('summation function', 1);('ato', 1);('unet-like', 1);('encoder-decoder architecture', 1);('extract per-point fea- tures', 1);('encoder', 1);('semantic label', 1);('corresponding local aggregation', 1);('encoder layer', 1);('combina- tion', 1);('method interpolate', 1);('uses random', 1);('sample points', 1);('indoor semantic segmentation', 1);('original architecture', 1);('ve encoders', 1);('kpconv5', 1);('randla-net6follow', 1);('ofcial congurations', 1);('rst conduct grid', 1);('grid size', 1);('mto gain', 1);('small sub-cloud', 1);('crop patches', 1);('training iteration', 1);('small patches util', 1);('transformer7', 1);('voxel-based methods', 1);('popular mainstream', 1);('cylin-', 1);('vox- elization', 1);('3d voxels', 1);('3d convolutions', 1);('local coor- dinate system', 1);('geometric center', 1);('gn i', 1);('voxel size vs', 1);('f\x03 mis', 1);('p\x03 i=', 1);('x\x03 i', 1);('y\x03 i', 1);('z\x03 i', 1);('f\x03 m=1', 1);('nmnx', 1);('i=1i [ x\x03 i= ^xm', 1);('y\x03 i= ^ym', 1);('z\x03 i= ^zm ] \x01pi', 1);('oor function', 1);('binary indi- cator', 1);('p\x03 ibelongs', 1);('m-th voxel grid', 1);('m-th voxel', 1);('original point coordinates', 1);('nm', 1);('hash table', 1);('convolution operation', 1);('con- ducts', 1);('computational efciency', 1);('//github.com/huguesthomas/kpconv-pytorch 6https', 1);('//github.com/qingyonghu/randla-net 7https', 1);('//github.com/postech-cvlab/point-transformercylindrical partition', 1);('cylinder partition', 1);('non-empty proportion', 1);('point distribution', 1);('grid parti- tion', 1);('farther-away regions', 1);('rst transforms', 1);('conducts voxelization', 1);('spvcnn8', 1);('dif- ference', 1);('parallel point-wise', 1);('cylinder3d9proposes', 1);('asymmet- rical 3d convolution networks', 1);('asymmetrical blocks', 1);('unit components', 1);('similar encoder archi- tecture', 1);('decoder part', 1);('multiscale concate- nation', 1);('of- cial architectures', 1);('batch size', 1);('test- time augmentation', 1);('tta', 1);('rst introduce', 1);('experiment setting', 1);('eval- uation metrics', 1);('different representation', 1);('corruption intensity', 1);('data augmenta- tion', 1);('robust architecture', 1);('//github.com/mit-han-lab/spvnas 9https', 1);('//github.com/xinge008/cylinder3d 10https', 1);('experiment setting dataset', 1);('valid classes', 1);('scan spans', 1);('\x18105 points', 1);('val- idation', 1);('available ofine', 1);('annotation', 1);('new noisy points', 1);('original annotations', 1);('corruption data', 1);('snow- fall simulations', 1);('annotate labels', 1);('noisy corruption', 1);('annotate noisy points', 1);('cross-device scenario', 1);('ignore class', 1);('evaluation', 1);('relative perfor- mance degradation', 1);('benchmark datasets', 1);('evaluation metrics', 1);('specif-', 1);('intersection', 1);('different intensities', 1);('certain corrup- tionc2ccan', 1);('sc=x', 1);('sc', 1);('total intensities', 1);('num- ber', 1);('corruption c.sc idenotes', 1);('corruption cand intensity iandscare', 1);('corrup- tionc', 1);('rc=sc=s', 1);('robustness miou', 1);('clean data jitter data foggy datafig', 1);('local deviation', 1);('relative performance', 1);('different corruption', 1);('=x c2csc=6', 1);('benchmark', 1);('observation-1', 1);('foggy simulation', 1);('% metric', 1);('pure range image', 1);('above observation', 1);('local corruption', 1);('range images messy', 1);('local corrup- tion', 1);('% andspringer', 1);('semantickitti-c. r', 1);('method', 1);('rprojectionsalsanext', 1);('trans', 1);('44.2v oxelminkowskinet', 1);('salsanextkpconvminkowskinetmiou fig', 1);('different fog simulation intensities', 1);('different values', 1);('observation-2', 1);('traditional', 1);('com- mon corruptions', 1);('table illustrates', 1);('espe-', 1);('% perfor- mance', 1);('common performance', 1);('local distortion protects', 1);('observation-3', 1);('transformer-based', 1);('low- est result', 1);('corruption scenarios', 1);('r. observation-4', 1);('pure', 1);('method shows', 1);('superior robustness cross', 1);('cross-devices scenario', 1);('methods loss', 1);('cor- ruption', 1);('hybrid-representation architec- tures', 1);('salsanextkpconvminkowskinetmioufig', 1);('different snow simulation intensities', 1);('different snowfall rates', 1);('% per- formance', 1);('16-beam cross-device scenario', 1);('introduces point-wise', 1);('par- allel', 1);('16- beam cross-device corruptions', 1);('cylinder3d zhu', 1);('poor generalization ability', 1);('extra representation', 1);('specic', 1);('specic corruption', 1);('experi- ment', 1);('typical method', 1);('comprehensive results', 1);('denser fog', 1);('superior robustness crossing', 1);('different fog intensities', 1);('observation-5', 1);('perfor- mance decay', 1);('method decreases', 1);('method decreases slowest', 1);('snow', 1);('observation-6', 1);('snow simulation hampers', 1);('diverse noisy corruptions', 1);('noise', 1);('ratio', 1);('salsanext kpconv minkowskinet', 1);('salsanext kpconv minkowskinet lidar', 1);('sparseness', 1);('inverse tendency', 1);('slight performance boosts', 1);('large snowfall', 1);('voxel-base meth- ods', 1);('3d scene', 1);('noisy', 1);('different noisy corrup- tions', 1);('robust method', 1);('sce- nario', 1);('poor generalization abil- ity', 1);('proportionof noisy points', 1);('great robustness', 1);('local distortion noises', 1);('cross-device', 1);('concrete results', 1);('cross- device scenarios', 1);('poor robustness', 1);('16-beam devices', 1);('interesting discovery', 1);('observation-7', 1);('32-beam devices', 1);('sparse cases', 1);('dense ones', 1);('convolution operations', 1);('point numbers', 1);('local aggre- gations', 1);('model', 1);('design v.s', 1);('rela- tionships', 1);('different model designs', 1);('size', 1);('different sizes', 1);('observation-8', 1);('exploiting', 1);('range projection', 1);('512\x0264range image', 1);('% robustness drop', 1);('miou dramati-', 1);('range images improves', 1);('above phenomenon', 1);('small images', 1);('noise points', 1);('valid pixels', 1);('anal-', 1);('ysis b', 1);('naive point-wise', 1);('generalization ability', 1);('different voxel partitions', 1);('conduct experiments', 1);('network architecture', 1);('rst transform', 1);('corresponding axes', 1);('observation-9', 1);('corrup- tion', 1);('cylindrical voxeliza- tion', 1);('local corruptions', 1);('such improvement', 1);('out-of-distribution data', 1);('cross-device deployment scenario', 1);('dif- ferent voxelization', 1);('important discovery', 1);('different voxel sizes', 1);('analysis d', 1);('observation-10', 1);('larger', 1);('global-level corruptions', 1);('voxel parti- tion', 1);('global-level corruption', 1);('small voxel size', 1);('sat- isfactory performance', 1);('large grid', 1);('origi- nal points', 1);('inanalysis e', 1);('relation- ship', 1);('systematic', 1);('architecture design', 1);('c-d', 1);('baseline models', 1);('analysis method descriptions', 1);('r acenet', 1);('brandla-net', 1);('attentive pooling', 1);('cminkowskinet', 1);('dminkowskinet', 1);('e2dpass', 1);('fminkowskinet', 1);('inscutmix', 1);('point-wise mlps', 1);('sparse convolutionfusion', 1);('... voxel network encoder/decoder layer', 1);('current state- of-the-arts', 1);('in-domain performance', 1);('point-wise repre- sentation', 1);('pointnet', 1);('individual voxel grids', 1);('voxel archi- tecture', 1);('similar components', 1);('previous works', 1);('conduct ablation', 1);('hybrid-representation architectures', 1);('in- domain', 1);('16-beam device', 1);('% robustness drops', 1);('directly', 1);('different data augmentation', 1);('general augmentation strategies', 1);('previous', 1);('diverse data augmentation', 1);('conduct rotation', 1);('aug- mentation', 1);('jitter augmentation', 1);('generate in-domain training data', 1);('mixup h. zhang', 1);('image classication', 1);('robust representation', 1);('3d computer vision', 1);('recent years', 1);('semantic segmentation task', 1);('instance cutmix xu', 1);('lasermix kong', 1);('instance-level objects', 1);('experimental results', 1);('observation-12', 1);('signicant boosts', 1);('% improve- ments', 1);('local distortion corruptions', 1);('model decreases', 1);('ablation', 1);('pl', 1);('model mix3d kd pl', 1);('fog snowfall global', 1);('local 32-beam 16-beam', 1);('minkowskinet66.3', 1);('x x', 1);('x x x', 1);('ground truth errors', 1);('errors', 1);('visualization', 1);('black color', 1);('error maps', 1);('ground truth', 1);('16-beam data', 1);('domain dis- crepancies', 1);('augmentation utilizes denser', 1);('sparse point clouds', 1);('boosting', 1);('robustness summarize', 1);('design amore robust model', 1);('useful information', 1);('teacher minkowskinet', 1);('original data prediction', 1);('training process', 1);('certain corruption', 1);('method performs', 1);('appropriate voxel size', 1);('appropriate voxel size increase', 1);('single-representation', 1);('illus- trates', 1);('based', 1);('single-representation nature', 1);('fur-', 1);('cylindrical partition hampers', 1);('rst train', 1);('grid voxel parti- tion', 1);('voxel size', 1);('teacher-student framework', 1);('output logits', 1);('rls', 1);('student model', 1);('divergence constrains', 1);('j. li', 1);('student network', 1);('clean validation data', 1);('pseudo labels', 1);('concrete', 1);('effec- tive manner', 1);('outperforms exist-', 1);('different designs', 1);('architecture improves', 1);('performance drop', 1);('huge performance boost', 1);('promising improvement', 1);('per- formance boost', 1);('future work', 1);('poor performance network', 1);('model performs', 1);('robust prediction', 1);('small objects', 1);('red circles', 1);('promising future', 1);('conclusion', 1);('semantic segmen- tation models', 1);('previous approaches', 1);('obser- vations', 1);('critical applications.springer', 1);('references alonso', 1);('a.c.', 1);('represen- tation', 1);('efcient 3d lidar semantic segmentation', 1);('arxiv preprint arxiv:2002.10893', 1);('s.f.', 1);('benchmark-', 1);('instance segmentation models', 1);('arxiv preprint arxiv:2109.01123', 1);('huang', 1);('fu', 1);('tai', 1);('c.- l.', 1);('transfusion', 1);('lidar-camera fusion', 1);('barbu', 1);('mayo', 1);('alverio', 1);('gutfre-', 1);('katz', 1);('objectnet', 1);('object recognition models', 1);('neural information processing systems ,32', 1);('garbade', 1);('quenzel', 1);('behnke', 1);('gall', 1);('semantic scene understanding', 1);('lidar sequences', 1);('caesar', 1);('bankiti', 1);('lang', 1);('a.h.', 1);('beijbom', 1);('multi- modal dataset', 1);('h.-x.', 1);('x.-f.', 1);('g.-q', 1);('toward', 1);('efcient lidar semantic segmen- tation', 1);('ieee interna- tional conference', 1);('af2-s3net', 1);('attentive', 1);('adaptive fea- ture selection', 1);('sparse semantic segmentation net- work', 1);('4d spatio-temporal convnets', 1);('minkowski', 1);('convolutional neural networks', 1);('cordts', 1);('omran', 1);('ramos', 1);('rehfeld', 1);('enzweiler', 1);('benenson', 1);('schiele', 1);('cityscapes dataset', 1);('urban scene under-', 1);('e.e', 1);('sal-', 1);('uncertainty-aware semantic segmenta- tion', 1);('arxiv preprint arxiv:2003.03653', 1);('deng', 1);('socher', 1);('l.-j.', 1);('fei-fei', 1);('large-scale hierarchical image database', 1);('self-robust', 1);('3d point recognition', 1);('gather-vector guidance', 1);('ieee access', 1);('autonomous driving', 1);('kitti vision benchmark suite', 1);('ieee conf', 1);('3d semantic segmentation', 1);('submanifold sparse convolutional networks', 1);('ieee con- ference', 1);('submani-', 1);('fold sparse convolutional networks', 1);('arxiv preprint arxiv:1706.01307', 1);('j.-n.', 1);('foggy scenes', 1);('international confer- ence', 1);('intelligent transportation systems', 1);('lidar snowfall simu-', 1);('ieee/cvf', 1);('con- ference', 1);('snowfall simula- tion', 1);('robust 3d object detection', 1);('real lidar point clouds', 1);('neu- ral network robustness', 1);('arxiv preprint arxiv:1903.12261 .springer', 1);('natural adversarial examples', 1);('distilling', 1);('neural network', 1);('neurips', 1);('khalid', 1);('trigoni', 1);('sensaturban', 1);('seman- tics', 1);('urban-scale photogrammetric point clouds', 1);('rosa', 1);('guo', 1);('efcient', 1);('large-scale point clouds', 1);('m.-k.', 1);('wise convolutional neural networks', 1);('kong', 1);('lasermix', 1);('arxiv preprint arxiv:2207.00026', 1);('stratied', 1);('3d point cloud segmentation', 1);('ieee/cvf con- ference', 1);('self-distillation', 1);('a.w.', 1);('meng', 1);('caine', 1);('ngiam', 1);('peng', 1);('deepfusion', 1);('deep fusion', 1);('multi-modal 3d object detection', 1);('t.n.t.', 1);('z.j', 1);('amvnet', 1);('assertion-based', 1);('multi- view fusion network', 1);('arxiv preprint arxiv:2012.04934', 1);('n.z', 1);('pointguard', 1);('prov-', 1);('robust 3d point cloud classication', 1);('relation-', 1);('shape convolutional neural network', 1);('point cloudanalysis', 1);('mitzkus', 1);('geirhos', 1);('rusak', 1);('bringmann', 1);('ecker', 1);('a.s.', 1);('brendel', 1);('autonomous', 1);('arxiv preprint arxiv:1907.07484', 1);('rangenet++', 1);('accurate lidar semantic seg- mentation', 1);('ieee/rsj intl', 1);('intelli- gent robots', 1);('nekrasov', 1);('out-of-context data augmenta-', 1);('scenes', 1);('v.-n.', 1);('newman', 1);('rainy', 1);('collecting', 1);('rainy datasets', 1);('arxiv preprint arxiv:2003.04742', 1);('metric space', 1);('geo-', 1);('metric ow network', 1);('3d point cloud semantic segmentation', 1);('transactions', 1);('retrieved', 1);('recht', 1);('imagenet classiers generalize', 1);('inter-', 1);('point cloud classication', 1);('interna-', 1);('tional conference', 1);('icml', 1);('ronneberger', 1);('volutional networks', 1);('biomedical image segmen- tation', 1);('medical image', 1);('seman-', 1);('tic foggy scene understanding', 1);('acdc', 1);('adverse conditions dataset', 1);('scene understanding', 1);('kretzschmar', 1);('dotiwalla', 1);('chouard', 1);('pat-', 1);('tsui', 1);('scalability', 1);('waymo', 1);('open dataset', 1);('taghanaki', 1);('s.a.', 1);('jayaraman', 1);('p.k.', 1);('jatavallabhula', 1);('k.m', 1);('robustpointset', 1);('arxiv preprint arxiv:2011.11572', 1);('searching', 1);('efcient 3d architectures', 1);('sparse point-voxel convolution', 1);('q.-y', 1);('tangent', 1);('dense prediction', 1);('deschaud', 1);('j.-e.', 1);('marcotegui', 1);('goulette', 1);('october', 1);('flexible', 1);('deformable convolution', 1);('scribble-supervised', 1);('shazeer', 1);('parmar', 1);('uszkoreit', 1);('jones', 1);('gomez', 1);('a.n.', 1);('polosukhin', 1);('atten-', 1);('sarma', 1);('s.e.', 1);('bronstein', 1);('m.m.', 1);('solomon', 1);('j.m', 1);('dynamic', 1);('graph cnn', 1);('acm transactions', 1);('graphics', 1);('tog', 1);('rao', 1);('lu', 1);('bridging', 1);('squeezeseg', 1);('convolutional', 1);('neural nets', 1);('recurrent crf', 1);('real- time road-object segmentation', 1);('3d lidar point cloud', 1);('squeezesegv2', 1);('improved', 1);('model structure', 1);('domain adaptation', 1);('road-object segmen- tation', 1);('lidar point cloud', 1);('pointconv', 1);('convo- lutional networks', 1);('triangle-net', 1);('towards', 1);('point cloud learning', 1);('ieee/cvf winter conference', 1);('dou', 1);('pu', 1);('rpvnet', 1);('efcient range-point-voxel fusion network', 1);('lidar point cloud segmentation', 1);('does', 1);('gao', 1);('pointasnl', 1);('point clouds processing', 1);('non- local neural networks', 1);('xia', 1);('lidar- camera fusion', 1);('arxiv preprint arxiv:2205.14951', 1);('empirical risk minimization', 1);('arxiv preprint arxiv:1710.09412', 1);('david', 1);('xi', 1);('foroosh', 1);('grid representation', 1);('online lidar point clouds semantic segmentation', 1);('ieee/cvf confer- ence', 1);('riconv++', 1);('effective', 1);('rotation invariant convolutions', 1);('com-', 1);('p.h.', 1);('ieee/cvf inter-', 1);('fang', 1);('dup-net', 1);('denoiser', 1);('upsampler network', 1);('3d adversarial point clouds defense', 1);('effective 3d framework', 1);('driving-scene lidar semantic segmentation', 1);('preprint arxiv:2008.01550', 1);('hong', 1);('asymmetri- cal 3d convolution networks', 1);('lidar segmentation', 1);