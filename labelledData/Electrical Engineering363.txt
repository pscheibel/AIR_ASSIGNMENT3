('mg', 93);('fmadrl', 35);('mmg', 30);('mgs', 29);('fl', 18);('mg1', 17);('ref', 10);('fig', 10);('ba', 9);('mg2', 8);('madrl', 6);('mdp', 5);('cg', 5);('mg2 mg3', 5);('mg3', 5);('drl', 4);('eq', 4);('ieeetransactions smart grid', 4);('oak ridge', 3);('ornlmg', 3);('energy management', 3);('reg', 3);('cgs', 3);('regs', 3);('mgagents', 3);('ieee transactions', 3);('ieee transactions power systems', 3);('economic costs', 2);('reinforcement learningmadrl', 2);('reinforcement learning', 2);('fmadrlalgorithm', 2);('self energysufciency', 2);('data security', 2);('national laboratory', 2);('university science technology', 2);('wuhan', 2);('recent years', 2);('mgs mmg', 2);('physical characteristic', 2);('iii', 2);('energy management center', 2);('energymanagement center', 2);('cartpole', 2);('algorithm', 2);('calculate', 2);('update', 2);('lemma', 2);('applying lemma', 2);('pv', 2);('standard variation', 2);('reward curve', 2);('energyselfinsufcient state', 2);('cg ba', 2);('ppomadrl a2cmadrl trpomadrl', 2);('a2cmadrl', 2);('ieee transactions power delivery', 2);('informatics', 2);('energy', 2);('meeting', 2);('ieee transactions smart grid', 2);('z li li liu p wang r lu h', 2);('gooi deep', 2);('network load', 2);('online', 2);('multiagent deep reinforcementlearning approach', 1);('physicsinformed rewardfor multimicrogrid energy managementyuanzheng li member ieee shangyang yang li senior member ieee yang shi fellow ieee zhigang zeng fellow ieeeabstract', 1);('utilization largescale', 1);('renewableenergy promotes development multimicrogrid', 1);('mmgwhich', 1);('raises need', 1);('effective energy management method minimize', 1);('selfenergysufciency multiagent', 1);('energy managementproblem realtime scheduling ability', 1);('massive energy operation data microgridsmgs gathering data', 1);('wouldthreaten privacy data security', 1);('challenging issue', 1);('reward algorithm', 1);('ensures privacy securityof data addition', 1);('andthe energy', 1);('agentwhich aims minimize', 1);('reward rstmgs', 1);('local energyoperation data train local agent models theselocal models', 1);('server theirparameters', 1);('global agent', 1);('local agents waythe experience', 1);('energyoperation data', 1);('energycontrol communication lab microgrid', 1);('test systemand comparisons', 1);('mechanism outperformance', 1);('fmadrlindex terms multimicrogrid', 1);('learning proximal policy optimizationthis work', 1);('national natural science', 1);('foundationof china grant', 1);('key project', 1);('sciencefoundation china grant', 1);('key scientic', 1);('andtechnological research', 1);('project', 1);('grid', 1);('china grantno', 1);('corresponding', 1);('yang liy z li z g zeng', 1);('articial intelligence', 1);('key laboratory image information processing intelligentcontrol ministry', 1);('huazhong', 1);('chinabelt', 1);('joint laboratoryon measurement', 1);('control technology', 1);('wuhan china', 1);('emailyuanzheng lihusteducn', 1);('chinaeu', 1);('clean', 1);('energyhuazhong', 1);('chinaemail', 1);('li', 1);('electrical engineering', 1);('poweruniversity jilin', 1);('china emailliyangneepueducny shi', 1);('mechanical engineering', 1);('university ofvictoria', 1);('victoria bc v8p', 1);('canada emailyshiuviccai ntroductionin', 1);('renewable energy', 1);('power photovoltaic', 1);('traditional power plants resources', 1);('distributedtherefore microgrids', 1);('attentionto utilize', 1);('works localarea', 1);('small entitysuch school hospital community', 1);('main target', 1);('selfsufciency energy', 1);('howeverdue', 1);('risk ofpower shortage', 1);('specically', 1);('user demand', 1);('reare', 1);('dependent user behavior weather conditionthe power demand', 1);('whilere generation', 1);('numerous adjacent', 1);('form multimicrogrid', 1);('mg mmg', 1);('besidesalthough mgs', 1);('different entities energyis', 1);('mgcan', 1);('surplus power power generationexceeds demand purchase power', 1);('whenthe generation insufcient', 1);('energy selfsufciency', 1);('mghowever', 1);('complexity energy managementof', 1);('effective scheme', 1);('thepresent', 1);('types ie', 1);('centralizedenergy management center', 1);('energy information', 1);('decisions achievethe energy selfsufciency', 1);('different entities andit difcult', 1);('management center acquireoperation data', 1);('awareness ofprivacy protectiontherefore', 1);('popular research direction', 1);('management scheme instance', 1);('ng', 1);('control uses themultiagent approach', 1);('control ofeach', 1);('yang', 1);('multiplearxiv230100641v1 eesssy', 1);('dec', 1);('20222selfdecision agents', 1);('energy management centerfor energy selfsufciency', 1);('liuet', 1);('distributedoptimization model', 1);('proposeda multiagent', 1);('individual agent ofeach', 1);('data local units performsoptimization', 1);('themg agents', 1);('optimal energy management', 1);('mmgthe', 1);('aforementioned literature focuses building accurateoptimization models', 1);('essential drawbackie', 1);('scheduling solution', 1);('realtime decisionin words', 1);('scheduling difcult tohandle emergencies', 1);('systemto tackle problem', 1);('approach hasbeen', 1);('beneting', 1);('fromthe development', 1);('learning techniques outputs blackbox model', 1);('representative approaches multiagent', 1);('energymanagement problem', 1);('real world', 1);('forinstance madrl', 1);('observes temperature energy generation', 1);('physical parameters tocontrol', 1);('soft load transaction', 1);('mmg theexperiments', 1);('convergence algorithmsand', 1);('outperformance actorcritic algorithm', 1);('energy management approachthat', 1);('advantage multiagent modelfree', 1);('hierarchical decisionmechanism', 1);('increases energy selfsufciency ofmmg', 1);('torealize postdisaster resilience', 1);('increase income system', 1);('madrlshows', 1);('strong adaptability', 1);('different conditions throughexperiments', 1);('increase autonomy', 1);('23for instance', 1);('deep neuralnetwork', 1);('operationalperformance autonomy participant', 1);('mg ref', 1);('23sets agents', 1);('autonomy balance benets ofthe', 1);('24proposes equilibrium selection multiagent', 1);('qlearning', 1);('massivedata train', 1);('agent concern user privacy', 1);('data users', 1);('analyze theirhabits', 1);('life tracks case', 1);('energymanagement train', 1);('effective agent high generalization', 1);('massive energy operation data', 1);('aims pursure abetter performance experiences', 1);('willing submit processing data privacyawareness', 1);('hand security datatransmission', 1);('guaranteedto tackle issues introduce', 1);('learning approach', 1);('flfor', 1);('madrl mmg', 1);('user privacy', 1);('mmgsystem specically mg', 1);('agent whichdeploys', 1);('recent deep reinforcement model', 1);('proximalpolicy optimization', 1);('ppo', 1);('local energy operation dataof', 1);('reward iethe', 1);('economic operation self energysufciency', 1);('thenthe', 1);('agents upload local model parameters theweights biases model server theseparameters', 1);('server construct globalmodel', 1);('thelocal model way agents', 1);('experiences throughthe', 1);('local training', 1);('model parameters operation data eachmg', 1);('user privacy datasecurity guaranteedthe', 1);('main contributions paper', 1);('system model', 1);('fl mg', 1);('conventional generatorscgs batteries', 1);('bas', 1);('renewable energy generators', 1);('regsload', 1);('energy management center server', 1);('mechanism communicate', 1);('aggregates parameters', 1);('mgagent', 1);('weight bias neural networkmodels', 1);('center ofmmg guides decisions', 1);('mg mgs', 1);('wouldendow high autonomy suffer', 1);('risk privacyleakage2', 1);('reinforcement learningalgorithm', 1);('energy managementof', 1);('theoperation data', 1);('agent parametersare', 1);('global agentafterwards agent', 1);('globalone way privacy', 1);('user protected3', 1);('agent ie', 1);('economic operation theself energysufciency', 1);('interpretation action consideration physicaltargets1since', 1);('different kinds entities localoperation data manifest perference local users', 1);('agent trainedby local data', 1);('case', 1);('energy control communication lab microgridornlmg test system', 1);('proposedfmadrl algorithm', 1);('effective different demandsand', 1);('renewable energy scenarios', 1);('outperforms stateoftheart', 1);('modelthe remainder paper', 1);('ii', 1);('introduces theoretical basis', 1);('model builtsection', 1);('iv', 1);('algorithm providesits overall structure', 1);('technical details section', 1);('comprehensive case studies', 1);('viconcludes', 1);('heoretical basis reinforcement learningnormally markov', 1);('decision process', 1);('bya vetuplehsapr i wheresis nite state spacethat stands', 1);('valid states', 1);('arepresents', 1);('transitionprobability state sttost1 andrrstatr 2rs\x02a', 1);('ris', 1);('reward function', 1);('action 201indicatesthe discount factor', 1);('importance thepresent reward', 1);('policy \x19should', 1);('toprovide probability', 1);('action awhen observingthe states ie\x19ajs', 1);('patajsts', 1);('aim \x19is maximize', 1);('cumulative reward thenite timet', 1);('return functionuttxkt k\x00trskak 1whererskakis reward function calculates thereward value state skwith action ak 201isthe discount factor', 1);('importance futurereward', 1);('kinds value functions', 1);('decisions rst thestate value function', 1);('v\x19sand', 1);('action valuefunctionq\x19as', 1);('e\x19utjstsxa\x19ajsxs0pass0rsa v\x19s02q\x19as e\x19utjstsataxs0pass0rss0ja xa0q\x19a0s03wherev\x19sstands', 1);('future reward atthe states theq\x19asrepresents future expectedreward', 1);('action aat statess0anda0standfor', 1);('state action state spass0isthe transition probability stos0undera factv\x19sandq\x19asare', 1);('quality state sand actionstate pair', 1);('policy \x19decidewhether', 1);('hedecentralized multi microgrid energymanagement modelthe', 1);('mgsthat', 1);('distribution power network', 1);('usuallyan', 1);('whichperforms agent conduct', 1);('thedispatchable elements', 1);('conventional generators', 1);('cgsbatteries bas', 1);('etc section describe energymanagement model', 1);('isolated microgrid energy management modelfig', 1);('illustrates structure', 1);('modeland realworld', 1);('system case', 1);('normally', 1);('fig1a mg', 1);('types elements renewablepower generators', 1);('ba cg', 1);('conventional load', 1);('cl', 1);('bas cgs', 1);('dispatchablesince outputs', 1);('management centeron contrary high uncertainties theoutputs', 1);('additionally', 1);('thesedispatchable elements', 1);('structure oak ridge', 1);('energy control communication lab microgrid testsystem', 1);('realworld case thispaper', 1);('conventional generator', 1);('diesel engine generator micro turbinewhich generate power fossil', 1);('cost functionsof', 1);('followscpcgi acgip2cgibcgipcgiccgi 4pmincgi\x14pcgi\x14pmaxcgi 5wherecpcgirepresents generation cost ith', 1);('andpcgiis generation power acgibcgiandccgidenote thecost coefcients ith', 1);('cgpmincgiandpmaxcgiare', 1);('upper bounds ith', 1);('cg2', 1);('energy generator fig', 1);('turbine photovoltaic generation', 1);('natural environmentsuch', 1);('speed temperature weather solar irradiance30', 1);('consume fossil', 1);('theirgeneration costs', 1);('battery', 1);('energystorage devices', 1);('store energy', 1);('andregs release', 1);('twooperation states', 1);('transition state charge', 1);('followssoct1 1\x00\x0esoct\x00ptba\x11chcba6soct1 1\x00\x0esoct\x00\x11dchptbacba7wheresoctandsoct1denote', 1);('baat', 1);('timetandt 1pbais', 1);('power ofba', 1);('pba0when ba', 1);('efciencies \x0edenotes', 1);('02cbarepresents thecapacity', 1);('bathe', 1);('purchase maintenance', 1);('equation 31cpbaj abajpbaj 3pmaxbaj1\x00soc 2bbajpbaj 3pmaxbaj1\x00soc cbaj8pmaxbajp', 1);('bajpmaxbaj', 1);('baabajbbajandcbajare', 1);('cost coefcients jth', 1);('bapmaxbajandpminbajare', 1);('output power4', 1);('network power loss mg practically', 1);('exists thepower loss operation generators thetransmission energy', 1);('power loss usuallycorresponds', 1);('active generation power', 1);('32\x15cgplosspcg\x15regplosspreg\x15baplosspba10where\x15cg\x15regand\x15barepresent power loss coefcientsof', 1);('cg reg ba', 1);('according ref', 1);('paperthen power loss', 1);('plosscan', 1);('followingequation 32plossncgxi1\x15cgpcginregxj1\x15regpregj nbaxk1\x15bapbak 11wherencgnregandnbaare numbers', 1);('cgs regs', 1);('isolated mg energy management model', 1);('rewardsince', 1);('mgmodel', 1);('physical feasibility agent denitionof reward', 1);('follows1 state paper', 1);('24hour schedulingof', 1);('t2f1224gthe state', 1);('time tincludes energy operationinformation', 1);('followsstfpt\x001lpt\x001reg1pt\x001regnregsoct\x001et\x001\x15g 12wherestindicates state', 1);('time tpt\x001landpt\x001registand load demand ith', 1);('time t\x001', 1);('inaddition et\x001\x15is', 1);('electricity price transactionbetween', 1);('distribution power network2 action actionatis', 1);('agent whichcontrols power outputs', 1);('cgs bas', 1);('state st study', 1);('followsatfptcg1ptcgncgptba1ptbanbag 13in', 1);('neural network isdifcult', 1);('fulll outputconstraints', 1);('eqs', 1);('9ptcgiclipptcgipmincgipmaxcgii21ncg 14ptbajclipptbajpminbajpmaxbajj21nba 15where clip ttmintmaxis clip function returns tmaxiftt max andtminiftt min3', 1);('reward', 1);('design reward', 1);('impactsthe performance', 1);('training specic', 1);('endow interpretability strategyof agent', 1);('atari', 1);('34the design rewards', 1);('independent physicalcharacteristic problem instance', 1);('available intuitivedesign reward', 1);('mislead agent', 1);('interpretability agentstrategy', 1);('normally mg', 1);('reward designedas', 1);('explicit targets iethe training agent', 1);('requirements of5operation cost self energysufciency', 1);('thereward', 1);('followsrt\x00wc ncgxi1cptcgi nbaxj1cptbaj\x00wdeelt\x02absptde16wherertis reward value time andelt\x150indicatesthe price', 1);('electricity distribution powergridwc201andwde201indicate weights limitthe order magnitude reward abs \x01stands absolutefunctionptdeevaluates deviation load demand andreal generation', 1);('byptdeptl\x00 ncgxi1ptcginregxj1ptregj nbaxk1ptbak\x00ptloss17in study', 1);('physical targets', 1);('ie operationcosts self energysufciency', 1);('pnbaj1cptbaj\x11', 1);('order magnitude rewardconsistent self energysufciency', 1);('ptdetimeselt', 1);('physical valuables ieptcgiptbajandptde', 1);('physical meaningin way reward', 1);('agent producea series actions minimize generation costs', 1);('cgsand bas', 1);('self energysufciencyc', 1);('decentralized multimicrogrid energy management modelas', 1);('model thatcontainsnpmgs', 1);('mgsare', 1);('distribution power network theenergy transaction', 1);('mgis', 1);('agent observes state stof', 1);('mgand', 1);('action atfig', 1);('reward rtfor', 1);('energy selfsufciency andeconomic operation target', 1);('themaximum systematic rewards rsyst', 1);('sum rewards', 1);('byrsystnpxi1ritnpxi1\x00\x0fi\x02absptide 18whereritrepresents reward', 1);('agent attimet\x0fiandptideare shrinkage coefcient deviationof', 1);('mgibesides', 1);('load demand', 1);('excessive insufcient power generation', 1);('energy transaction themmg system', 1);('energy transactionmechanism', 1);('isgiven belowthat', 1);('conduct energy transactions withthe distribution power network', 1);('iexceeds load demandat timet excess energy', 1);('witha priceeit demand', 1);('themg purchase electricity', 1);('j lowestprice', 1);('mgsj', 1);('arg minlelt\x02lll212np 19wherellindicates', 1);('lexceedsits demand', 1);('llis', 1);('1if demand', 1);('orset innite', 1);('purchasethe surplus power', 1);('mgs mggenerations', 1);('distribution power networkwill', 1);('power price', 1);('edpnt', 1);('higherthaneltl212npiv f', 1);('ederated multi agent deepreinforcementlearning algorithmas', 1);('eachmg agent high autonomy', 1);('decentralizedstructure threatens generalization performance agentbecause diversity data', 1);('trap local optimato tackle issue', 1);('multiagent deepreinforcement learning', 1);('generalization agent trainingwhile', 1);('data privacythere', 1);('theparticipantjj21np', 1);('neural networkmodelfjwj conducts', 1);('local uploadsits parameters wjto collaborator', 1);('npisthe number participants', 1);('data privacy participant fjwjonlytrains', 1);('local dataset', 1);('capacity diversity data limitedthe', 1);('tackle problem followingsteps', 1);('training epoch ee21ne modelofjth participant', 1);('fjwej conducts', 1);('parameters wej whereneis totalnumber training epoches participant uploadsits parameters collaborator constructs parameterlistwehwe1we2wenpi collaborator calculatesthe weight average weto estimate', 1);('global model fe1gwith parameters we1g aggregation collaboratorbroadcasts we1g participants replaces ownparameters ie we1g we11 we12we1np', 1);('the6aggregating', 1);('followingequationswe1jweg\x00\x11rfjwej8j 20we1gnpxj11npwe1j21where\x11andfj\x01are learning rate local loss functionof thejth participant respectivelyin paper participant', 1);('collaborator server', 1);('distributedoptimization modelminwegfweg npxj1pjfjwej 22wheref\x01is', 1);('global loss function pjrepresents therelative weight', 1);('global model andpj0pnpk1pj', 1);('setpjjdjjpnpj1jdjj wherejdjjis data size', 1);('local training jth', 1);('mg notethatf\x01', 1);('participantthe overall structure', 1);('3at epoch e agent', 1);('global agent e\x001th epoch threemg agents conduce', 1);('parameters whichare', 1);('server aggregation', 1);('server parameters', 1);('agents e', 1);('th epochfig', 1);('reinforcement learningalgorithmit', 1);('fmadrlcontains', 1);('subsections respectivelya', 1);('fmadrl server partthe fmadrl', 1);('agent parameters itsprocedure', 1);('beginning training epoch', 1);('global agent parameter w0gwhich', 1);('agent selftrainingsince agents update parameters parallel serveraggregates parameters list we1we2wenpby', 1);('eq21 furthermore', 1);('parameters we1g usedto update', 1);('global model parameters broadcast themg agents training epoch e 1algorithm', 1);('algorithm server1execute server2initialize model parameters w0gand broadcast themto', 1);('agents3forglobal epoch e', 1);('tonedo4 formg agentj', 1);('update mg', 1);('parameter wejat local agent6', 1);('store', 1);('upload', 1);('wejto server8 end for9', 1);('receive', 1);('agent andconstruct10 we1we2wenp11', 1);('aggregating', 1);('model parameters through12 we1gpnpj11npwe1j13', 1);('broadcast', 1);('agents14end forb', 1);('fmadrl mg agenton', 1);('agent adopts', 1);('inthe procedure', 1);('cooperates serverwhen', 1);('parameter wegfrom globalmodel epoch e parameters', 1);('agent executes', 1);('niindividualselftraining', 1);('epochs parallel', 1);('parameters ofthe', 1);('serverin paper', 1);('agent performs', 1);('reinforcement learning algorithm', 1);('ppoto', 1);('optimal policy \x19', 1);('types deepneural networks', 1);('actor critic', 1);('themg agent', 1);('actor', 1);('\x12 aims toproduce action critic', 1);('v\x16', 1);('\x16the overall training process', 1);('4first experiment tuples', 1);('tare', 1);('sampledtfhs0a0r0s1ihs1a1r1s2ihsuaurusu1igwhereuindicates length loss functionof actor kth episodes', 1);('asfollowslcesa\x18t\x14min\x19\x12kajs\x19\x12k\x001ajsa\x19\x12ksaclip\x19\x12kajs\x19\x12k\x001ajs1\x00\x0f1 \x0fa\x19\x12ksa\x15 23where', 1);('esa\x18t\x01represents', 1);('empirical average', 1);('experiment tuples', 1);('the\x19k\x001and\x19kstand', 1);('previous new policy', 1);('\x0fis clipparametera\x19ksastands advantage measures ifthe action', 1);('action value andstate valuea\x19kstate', 1);('ujs0sta0at\x00vst qstat\x00vst24however a\x19ksacannot', 1);('sinceqstatis difcult', 1);('advantage estimation method', 1);('thisstudya\x19\x12ksa\x0ev0 \x15\x0ev1 \x152\x0ev2 \x15u\x00t1\x0evu\x00125where 201and\x15201represent discount factorand hyperparameter adjusts tradeoff biasand variance estimation', 1);('variance wouldbe', 1);('\x15while bias', 1);('according', 1);('v\x16kst1\x00v\x16kst', 1);('loss function', 1);('lvlvesa\x18t\x02 v\x16kst1', 1);('rstat\x00v\x16kst2\x03 27with equations parameter \x12and\x16of actorand critic', 1);('equations\x12k1\x12k\x11\x19r\x12klc28\x16k1\x16k\x11vr\x16klv29where\x11\x19and\x11vare learning rates actor criticsince bothlcandlvare', 1);('agent ofthe', 1);('algorithm local lossfunctions construct', 1);('global loss', 1);('server canbe', 1);('theoretical convergence analysis fmadrlin', 1);('section convergence', 1);('thefkislsmooth8ww0k\x01fkw\x00\x01fkw0k2\x14lkw\x00w0kfkw\x14fkw0', 1);('l2kw0\x00wk22algorithm', 1);('global epoch e3receive parameters server wej weg4forindividual training epoch', 1);('collect', 1);('experience tuple', 1);('tfhs0a0r0s1ihs1a1r1s2ihsuaurusu1ig6 compute', 1);('factor7\x0evk rk', 1);('v\x16kst1\x00v\x16kst8 estimate', 1);('advantage9a\x19\x12ksa \x0ev0 \x15\x0ev1 \x152\x0ev2 \x15u\x00t1\x0evu\x00110', 1);('loss function actor11lc', 1);('esa\x18t\x14min\x19\x12iajs\x19\x12i\x001ajsa\x19\x12isaclip\x19\x12iajs\x19\x12i\x001ajs1\x0012\x0f1', 1);('actor parameter14\x12i1 \x12i\x11\x19rsa\x18tlc15', 1);('loss function critic16lv', 1);('esa\x18t\x02 v\x16ist1', 1);('critic parameter18\x16i1 \x16i\x11vr\x16ilv19end for20store network parameters wej f\x12ni\x16nig21upload parameters wejto serverassumption', 1);('thefkis\x16strongly', 1);('convex 8ww0fkw\x00\x162kfkk2is convex', 1);('fkw\x15fkw0', 1);('assumptions', 1);('fis\x16strongly', 1);('lsmoothproof straightforwardly assumption', 1);('line denition convex', 1);('fis', 1);('nitesumof thefk', 1);('lsmooth', 1);('welllemma 28ww02rnandwtwtw\x00w0fort201', 1);('thenfw\x00fw0 z10rfwttw0\x00wdt', 1);('fundamental theorem ofcalculus', 1);('subtractingrfwtw0\x00wfrom sides equationlemma', 1);('iffis', 1);('convex \x160then w\x03 arg minwfw12\x16krfwk22\x15fw\x00w\x03\x15\x162kw\x00w\x03k22 328proof', 1);('havefw\x15fw\x03 rfw\x03tw\x00w\x03', 1);('fact rfw\x03', 1);('yieldfw\x00fw\x03\x15\x162kw\x03\x00wk22 34which', 1);('side 33note thatfw\x03\x15minyfy rfwty\x00w \x162kw\x00yk2235sinceyw\x001\x16krkfwminimizes', 1);('right side theabove inequality yieldminyhfy rfwty\x00w \x162kw\x00yk22i\x15fw\x0012\x16krfwk2236namely12\x16krfwk22\x15fw\x00fw\x03 37theorem', 1);('fislsmooth', 1);('w\x03 arg minwfw andwis parameter thekth iteration', 1);('thenfwk\x00fw\x03\x14\x101\x00\x16l\x11kfw0\x00fw\x03', 1);('requiresl\x16logfw0\x00fw\x03\x0fiterations tond\x0foptimal solutionproof', 1);('assumption', 1);('wt\x00wtw\x00w0 havejfw\x00fw0\x00rfwtw0\x00wj\x14z10rkfwt\x00rfwkkw0\x00wkdt\x14l2kw\x00w0k2240note thatwk1wk\x00\x11rfwk 41where\x110represents learning rate yieldfwk1\x00fwk \x11krfwkk22\x14\x112l2krfwkk2242if pick\x111l thenfwk1\x14fwk\x0012lkrfwkk22from', 1);('whenputting', 1);('fact 1x\x14ex convergence rate givenby', 1);('k\x15l\x16logfw0\x00fw\x03\x0f where\x0ffwk\x00fw\x03', 1);('error loss epoch kandthe optimal onev c', 1);('ase studya experiment setupin', 1);('section conduct case studies', 1);('laboratory distributed energycontrol communication', 1);('lab microgrid test system', 1);('algorithmwithout loss generality', 1);('form themmg system parameters elements', 1);('mgare', 1);('tablei', 1);('panel areset', 1);('corresponding power data referredfrom', 1);('gaussian', 1);('distribution a15', 1);('addition time horizon ofthe experiment', 1);('24hour schedule time intervalis', 1);('total load demands dayahead market price', 1);('iiand', 1);('error load', 1);('thegaussian distribution', 1);('load data power demandsof', 1);('maximum capacity', 1);('mg1operates', 1);('energy selfinsufcient state contrarythe', 1);('energy selfsufcient stateas', 1);('training epoch', 1);('1500moreover and\x15are', 1);('famous neural network optimizer', 1);('adam', 1);('learning rate actor \x11\x19andcritic\x11vare', 1);('python', 1);('pytorch', 1);('itheparameters setting mgakwbkwckwpminkwpmaxkwmg1cg', 1);('analysis fmadrl', 1);('algorithmin section', 1);('themmg system performance evaluation', 1);('fig5', 1);('whole training epochs', 1);('epochs training process', 1);('mechanism averagesthe parameters', 1);('agents reward value each9table', 1);('iithe forecasting wind pv power trading price loads three mg shour', 1);('12wind power kw', 1);('3020pv outputs kw', 1);('anddistribution network kw865', 1);('24wind power kw', 1);('4412pv outputs kw', 1);('anddistribution network kw2682', 1);('agent b', 1);('agent c', 1);('mg3agent', 1);('adjacent phasesand', 1);('benets thisfor instance', 1);('parameter setting eachmg', 1);('agent wouldnt converge rst phasehowever', 1);('mechanism reward raisesat 500th epoch converges', 1);('end ofphase', 1);('agent converges phase1', 1);('renews parameters andfurther raises reward', 1);('asfor mg3', 1);('agent benet', 1);('mechanism mainlyshown', 1);('fromthe local optimal', 1);('reward end training summary thefl mechanism', 1);('rid local optimumwhich', 1);('insufcient training data', 1);('privacyconstraintsthen policies', 1);('todetermine scheduling', 1);('mg specically figs', 1);('\x188denote scheduling', 1);('mg1 mg2 mg3', 1);('respectivelyeach gure', 1);('kinds graphs abovegraph scheduling solution', 1);('graph showsfig', 1);('difference generation load demands', 1);('positive unbalanceddemands', 1);('surpasses loaddemands means demands', 1);('means demands unsatisedas', 1);('arehigher capacity', 1);('scheduling ofba generation', 1);('considers thepower balance', 1);('1sthour power demand', 1);('kw higherthan capacity', 1);('agent chooses dischargethe battery demand', 1);('theenergy selfinsufcient state', 1);('external power fromother', 1);('distribution power system achievedby transaction mechanism', 1);('kw 2000these power shortages', 1);('thedistribution power network reason', 1);('mg1agent', 1);('theagent', 1);('learns energy transaction', 1);('power itself10fig', 1);('algorithmthe scheduling policies', 1);('work energy selfsufcient state power generations', 1);('almostsatisfy demand way', 1);('similar strategy operationof', 1);('hours power outputsof', 1);('alternatively', 1);('wouldchange demands', 1);('example 15thand', 1);('hours generation demand', 1);('demands inthese', 1);('absolute values unbalanceddemands', 1);('accordingto transaction mechanism', 1);('way theexcess powers', 1);('work selfinsufcient state power shortages', 1);('bythe power', 1);('distribution power networkthe experiments', 1);('learning mechanism', 1);('solutions regardless', 1);('operatesin energy selfsufcient selfinsufcient statefig', 1);('changes decomposition', 1);('training iterationsc', 1);('interpretation agents performanceit', 1);('interpretation strategy agents tosome degree', 1);('aspects reward function ie thecosts', 1);('demand illustratedalong iterations study changes sectionsix iterations', 1);('different phase training', 1);('500th 700th 900th 1400thiterations', 1);('wherein', 1);('presentthe training performance', 1);('stages 500th iterationis', 1);('end rst', 1);('phase otherthree iterations', 1);('convergent state rewardvalue', 1);('values reward increase', 1);('withthe increase', 1);('illustrates changes', 1);('subgure b', 1);('decreases 5500kw 3000kw atthe 1400th iteration', 1);('mg2 mg3also', 1);('present downward trend', 1);('3000kw and1000kw 1st iteration descend', 1);('500kw after1400 iterations means agents', 1);('strategiesfor energy selfsufciency', 1);('fig9b', 1);('present different strategies', 1);('energy selfsufcient energy selfinsufcient state', 1);('raises similarsituation', 1);('9c costs', 1);('bafor mg1', 1);('increase 900th 1400th iterationsoverall', 1);('system namelythe energy selfsufcient', 1);('physicsinformedreward algorithm', 1);('agents angleof', 1);('performance comparisonin', 1);('section effectiveness', 1);('flmechanism', 1);('performance ofthe', 1);('algorithms merelyimplement', 1);('agents algorithmsinclude', 1);('numerous wellknown deep reinforcement learningalgorithms', 1);('ppo a2c trpo', 1);('agents comparative algorithms', 1);('respectivelythe comparisons', 1);('aspects ie theconvergence generalization', 1);('convergences ofthe', 1);('reward curves', 1);('besidesto', 1);('agents testingrewards', 1);('theagents energy selfsufcient selfinsufcientstates', 1);('local optimasince', 1);('local operation data merelycontain perference local user', 1);('conesequently', 1);('generalization ofthe', 1);('reward asufcient index performance comparison', 1);('theeconomic cost power balance', 1);('training reward', 1);('compares convergence algorithm andthe subplots b c', 1);('training process ofthe', 1);('agent respectivelyas', 1);('performs theworst learning rate training epoch theagents', 1);('convergedin addition', 1);('ppomadrl trpomadrlare', 1);('able train converge agents rewards lowerthan', 1);('informationin addition reward curves generalization', 1);('agent energy selfsufcient andtable', 1);('iiithe test rewards mg agentsworking', 1);('agent fmadrl ppomadrl a2cmadrl trpomadrlenergy', 1);('5691energy selfinsufcientmg1', 1);('3842selfinsufcient state gure value', 1);('testreward algorithm bold learnt thetest rewards', 1);('agents energy selfsufcientstate surpasses comparative algorithms', 1);('besidesthe', 1);('test rewards', 1);('comparative algorithms aswell addition', 1);('isbetter comparative algorithms energyselfsufcient selfinsufcient states concludedthat', 1);('generalization performancethe comparisons clarify introduction', 1);('performance diversity proposedfmadrl', 1);('local operation data', 1);('mgdue', 1);('limitation privacy', 1);('diversity training data', 1);('decline introduction thefl mechanism alleviates drawback', 1);('threateninguser privacy data security way generalizationability agent', 1);('theabove experiments', 1);('inthis section', 1);('thefl mechanism', 1);('abetter generalization', 1);('fmadrlvi', 1);('onclusionthis', 1);('reinforcement learning algorithm multimicrogrids systemenergy management', 1);('model builtrst', 1);('dispatchable elements', 1);('mgto', 1);('privacyprotection data security', 1);('implementedto train agents', 1);('agent adopts selftrainingthen', 1);('globalagent aggregates parameters', 1);('local agents onthe server replaces', 1);('agent globalone', 1);('experiences agent sharedwithout', 1);('privacy data securitythe case studies', 1);('convergence performance', 1);('rst explanations strategy', 1);('different iterations', 1);('ppomadrl a2cmadrl', 1);('test rewardswhich', 1);('theperformance enhancement', 1);('demonstrates effectiveness ofour', 1);('paper uncertainty', 1);('ofrenewable energy', 1);('difculties training', 1);('reducethe accuracy', 1);('agent strategy issue', 1);('future workreferences1', 1);('g liu q sun r wang x hu nonzerosum', 1);('voltagerecovery consensus optimal control nonlinear microgrids systemieee', 1);('transactions neural networks learning systems', 1);('q sun li zhang qin model', 1);('predictive directpower control threeport solidstate transformer hybrid acdc zonalmicrogrid applications', 1);('vol 37no', 1);('h zhang yue', 1);('dou x xie k li g p hancke resilientoptimal', 1);('defensive strategy', 1);('tsk', 1);('microgrids system', 1);('novel reinforcement learning approach', 1);('ieee transactionson neural networks learning systems', 1);('li zhao p wang h', 1);('gooi', 1);('wu liu j ye optimal', 1);('operation multimicrogrids', 1);('cooperative energy', 1);('liu', 1);('gu j wang', 1);('yu x xi game', 1);('theoretic noncooperative', 1);('coordination control multimicrogrids', 1);('h farzin r ghorani fotuhifiruzabad moeiniaghtaie amarket', 1);('mechanism quantify emergency energy transactions value ina multimicrogrid system', 1);('arefar ordonez ar mohamed energy', 1);('management multimicrogrid systemsdevelopment assessment', 1);('ieeetransactions power systems', 1);('li p wang h', 1);('gooi j ye', 1);('wu multiobjective', 1);('optimaldispatch microgrid uncertainties', 1);('interval optimizationieee', 1);('transactions smart grid', 1);('e j ng r elshatshat multimicrogrid', 1);('control systems inieee', 1);('pes', 1);('x yang h zhang chen g weng interactive', 1);('power balances multimicrogrids', 1);('liu li h', 1);('gooi jian h xin x jiang j pandistributed', 1);('robust energy management multimicrogrid system inthe realtime energy market', 1);('jiang k yang j yang r mao n xue z zhuo', 1);('hierarchical energy management strategy maximization', 1);('renewable energy consumption', 1);('ieeeaccess', 1);('v h bui hussain hm kim', 1);('hierarchicalenergy management strategy multimicrogrids', 1);('adjustablepower demand response', 1);('vol 9no', 1);('li ding liu yang p wang j wang', 1);('yaodense', 1);('deep learning dayahead electricity', 1);('huang j wang applications', 1);('neuralnetworks power systems review', 1);('ieee transactions powersystems', 1);('li intelligent', 1);('multimicrogrid energy management basedon', 1);('neural network modelfree reinforcement learning', 1);('yu qin zhang', 1);('shen jiang x guan', 1);('reinforcement learning smart building energy managementieee', 1);('internet', 1);('things journal vol', 1);('nakabi p toivanen deep', 1);('reinforcement learning energymanagement microgrid exible demand', 1);('energygrids networks', 1);('e samadi badri r ebrahimpour decentralized', 1);('energy management microgrid', 1);('reinforcement learninginternational journal', 1);('electrical power energy systems', 1);('h nie chen xia huang', 1);('liu optimizing', 1);('postdisaster control', 1);('microgrid multiagent', 1);('ieee access', 1);('x fang q zhao j wang han li multiagent', 1);('deepreinforcement learning', 1);('energy management strategyoptimization microgrid market', 1);('cities', 1);('society inpress23 w', 1);('liu z wen shen z zhang reinforcement', 1);('secondary optimal control multimicrogrids', 1);('ieeeconference energy internet energy', 1);('integration', 1);('x fang j wang g', 1);('han q zhao z cao multiagent', 1);('reinforcement learning approach', 1);('residential microgrid', 1);('energies', 1);('lee dh choi federated', 1);('reinforcement learning energymanagement', 1);('multiple smart homes', 1);('energy resourcesieee', 1);('transactions', 1);('j schulman', 1);('wolski p dhariwal radford klimovproximal', 1);('policy optimization algorithms arxiv170706347 cs inpress27', 1);('distributed', 1);('energy communications controls laboratoryactivities', 1);('available httpsenergygovsitesprodlessg2010peerreviewdistributedenergycommunicationsandcontrolsthomasrizyornlpdf28', 1);('li g hao liu yu z ni zhao manyobjectivedistribution', 1);('network reconguration', 1);('deep reinforcement', 1);('optimization algorithm', 1);('r sutton g barto reinforcement', 1);('learning introduction', 1);('mit', 1);('n li', 1);('chen h low optimal', 1);('demand response', 1);('onutility maximization power networks', 1);('ieee power', 1);('andenergy society', 1);('r mudumbai dasgupta', 1);('b b', 1);('cho distributed', 1);('control optimal', 1);('economic dispatch network heterogeneous power generatorsieee', 1);('transactions power systems', 1);('nagendra n podila r ugarakhod k george comparison', 1);('ofreinforcement learning algorithms', 1);('cartpole problem ininternational conference', 1);('advances computing communicationsand informatics icacci', 1);('v mnih k kavukcuoglu silver graves antonogloud wierstra riedmiller playing', 1);('available httparxivorgabs1312560235', 1);('wang tuor salonidis k k leung', 1);('makaya', 1);('chan adaptive', 1);('learning resource', 1);('ieee', 1);('selected areas communications', 1);('logenthiran srinivasan khambadkone h n aungmultiagent', 1);('system realtime operation microgrid realtimedigital simulator', 1);('g liu xu k tomsovic bidding', 1);('strategy microgrid indayahead market', 1);('hybrid stochasticrobust optimization', 1);('g liu starke', 1);('xiao x zhang k tomsovic microgrid', 1);('optimal scheduling', 1);('electricpower systems', 1);('research vol', 1);