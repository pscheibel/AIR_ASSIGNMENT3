('bagformer', 26);('muge', 6);('late interaction', 6);('clip radford', 4);('liet', 4);('cls', 4);('albef', 4);('figure', 4);('crossmodal retrieval', 3);('khattab zaharia', 3);('early', 3);('imagetext retrieval', 3);('international conference', 3);('machine learning', 3);('pmlr', 3);('advances', 3);('cheng', 2);('dualencoder', 2);('align jiaet', 2);('yao', 2);('object detectors', 2);('roi', 2);('furthermore', 2);('encoder models', 2);('colbert khattab zaharia', 2);('textual bags', 2);('bagformers', 2);('clstoken', 2);('late', 2);('method imagetotext retrieval texttoimage retrieval mrr1 r5 r10 r1 r5 r10flickr30kcnabagformerbase', 2);('vitb', 2);('bagformerbase', 2);('ablation', 2);('proceedings ieeecvf', 2);('vision', 2);('proceedings', 2);('neural information processing systems', 2);('learning', 2);('bagwise interactionhaowen', 1);('hou1xiaopeng yan1yigeng zhang2fengzong lian1and zhanhui kang11tencent inc shenzhen china2university houston houston usahaowenhouunusedu', 1);('chopinyantencentcom yzhang168uheduabstractin eld crossmodal retrieval single encoder models', 1);('dual encoder models suffer high latencyand', 1);('low throughput paper', 1);('present adual encoder model', 1);('utilizesa cross modal interaction mechanism improverecall performance', 1);('latency andthroughput', 1);('theuse bagwise interactions', 1);('thetransformation text', 1);('appropriate granularity incorporation entity knowledgeinto model experiments', 1);('results comparableto stateoftheart single encoder models crossmodal retrieval tasks', 1);('introductioncrossmodal', 1);('faghri', 1);('zeng', 1);('retrieval task', 1);('different modalitiessuch imagetext textimage', 1);('important multimodal understanding tasks', 1);('leeetal', 1);('performance retrieval task', 1);('visual representation', 1);('imagetext alignment', 1);('recently', 1);('visionlanguage pretraining vlp', 1);('capable learning visual textual representations millions images texts', 1);('internet', 1);('havesuperior zeroshot ability robustness', 1);('kim', 1);('li', 1);('types crossmodal retrieval architectures singleencoder dualencoder', 1);('singleencodermodels', 1);('visualbert liet', 1);('albef lietal', 1);('feed visual', 1);('textual embeddings', 1);('separate encoders vision language', 1);('ingeneral', 1);('dual encoder models', 1);('effective thansingle encoder models hand singleencodermodels outperform dualencoder models recall metric butthey', 1);('generallyspeaking', 1);('dualencoder models lack modal interaction aretherefore', 1);('effective singleencoder models', 1);('khattaband zaharia', 1);('adualencoder model bagwise interaction mechanism forcrossmodal retrieval', 1);('reduces recall metricgap singleencoder models dualencodermodelscrossmodal interaction crossmodal alignment image text key', 1);('crossmodal interaction alignment', 1);('previous approaches', 1);('kinds methods aseries works', 1);('leeet', 1);('featuresfrom images', 1);('text approach bit', 1);('large numberof', 1);('zeroshot ability theseapproaches', 1);('classes performance', 1);('series ofwork introduce interaction modalities', 1);('single', 1);('tokenwise patchwise representationsand', 1);('crossattention orselfattention', 1);('efcient terms training inference', 1);('particularly', 1);('training crossattention needs tobe', 1);('encoderdecoder structure whereas selfattention', 1);('complex concatenatedwith image text', 1);('sequences inference imagetext pair', 1);('order compute crossattention selfattention', 1);('singleencoder models', 1);('dualencoder models', 1);('jiaet', 1);('crossattention', 1);('expensive computation', 1);('santhanam', 1);('late interaction mechanisminto dual encoder models', 1);('efcient effectivepassage retrieval', 1);('filip yaoet', 1);('introduces ideaof', 1);('late interaction multimodal domainour paper aims optimize crossmodal interaction sothat dual encoder models performance', 1);('close thearxiv221214322v1 csir', 1);('dec', 1);('transformerbased', 1);('image encoder text encodertextual tokens bag', 1);('layer representations textual bags visual tokens', 1);('multimodal joint space', 1);('novel bagwise interaction method', 1);('maximum similaritybetween visual tokens textual bagssingle encoder models', 1);('latency andhigher throughput end', 1);('adual encoder model bagwise interaction', 1);('cross modal interaction alignment', 1);('bagformeradopts', 1);('bagwise interaction mechanism transform text', 1);('appropriate granularity', 1);('introduceentity knowledge model', 1);('uses bagwise', 1);('maximum similarity visualand textual tokens', 1);('contrastive objective thisway', 1);('image patches textual words', 1);('ability precompute image andtext representations offlineseveral experiments', 1);('bagformerslearning', 1);('bag representations', 1);('topof class imagetext retrieval', 1);('art single encoder modelbut latency', 1);('times throughput', 1);('times addition', 1);('outperforms dual encoder models', 1);('onlarger datasets', 1);('visualizations word patchalignment', 1);('promising localization capabilities2', 1);('related workvision', 1);('mainstream paradigmin multimodal understanding vision language pretraininghas', 1);('various visionand language tasks majority approaches', 1);('architectures categorizedas singleencoder dualencoder single encoder architectures', 1);('albef liet', 1);('process images text forhighperformance interactions computation cost theseapproaches', 1);('impractical largescale crossmodal retrieval tasks contrast dual encoder architecturessuch', 1);('encode images text', 1);('possibleto calculate imagetext similarities linear time', 1);('althoughthe', 1);('millionscale imagetext contrastive', 1);('greatlyimproves dual encoder architecture performance gapstill exists', 1);('encoder architecture', 1);('bycontrast bagformer', 1);('incorporates bagwise interaction intodual encoder architecture', 1);('performance gap', 1);('inference speeddense retrieval', 1);('dense', 1);('retrieval involves', 1);('queries documents', 1);('inner product cosine similarity measuretheir similarity', 1);('wang', 1);('research area', 1);('bert devlin', 1);('roberta liuet', 1);('dense representationsfor queries documents', 1);('search relevant documents approximate', 1);('neighbor algorithmssuch kdimensional trees', 1);('bentley', 1);('datar', 1);('malkovand yashunin', 1);('retrieve documents insublinear time addition', 1);('colbert khattab zaharia2020 colbertv2 santhanam', 1);('alate interaction paradigm uses', 1);('maxsim', 1);('operator querydocument interaction boost search qualitycrossmodal retrieval', 1);('crossmodal', 1);('retrieval taskof', 1);('relevant images text descriptions', 1);('textor image query', 1);('recent years visual representation forcrossmodal retrieval', 1);('cnns faghri', 1);('anderson', 1);('radford', 1);('thesame time advances methods aligningimages text', 1);('use attention mechanisms', 1);('chen', 1);('relationship reasoning', 1);('liuet', 1);('late interaction mechanism', 1);('filip yaoetal', 1);('borrow idea', 1);('late interaction mechanism fromcolbert', 1);('tokenwise interaction', 1);('bagformertakes', 1);('approach step', 1);('idea ofbagwise interactions3', 1);('bagformer31 model architecturemodel architecture bagformer', 1);('integrates imageencoder', 1);('12layer visual transformer', 1);('vitb16 dosovitskiy', 1);('touvron', 1);('text encoder basedon 6layer transformer', 1);('vaswani', 1);('initialisedwith rst', 1);('bertbase devlin', 1);('model input image text', 1);('respective sequences visual embeddings fvclsv1v ngand', 1);('token embeddings ftclst1t mg embeddingsare', 1);('common multimodal space', 1);('linear transformation', 1);('l2normalisation', 1);('token embeddings aggregatedto form bag embeddings', 1);('layer bagwise similarity', 1);('late interaction thevisual embeddings bag embeddings32', 1);('pretraining objectivesthe', 1);('imagetext contrastive learning', 1);('itc', 1);('bwcimagetext contrastive learning', 1);('aims align theglobal representations image text', 1);('clip radfordet', 1);('token image patches text tokensare', 1);('dot product', 1);('morespecically', 1);('global similarity image thetext', 1);('followssit sti gvvclstgttcls 1wheregvvclsdenotes', 1);('token ofthe image gvvclsdenotes', 1);('text gvis visual projection head gtis thetextual projection headfor image text calculate imagetotext andtexttoimage contrastive loss asli2t\x001bslogexpsit', 1);('pbsn1expsit', 1);('pbsn1expsti', 1);('learnable temperature parameter bsis thebatch size total imagetext contrastive loss', 1);('training batch', 1);('followslitc12lt2ili2t 4bagwise', 1);('contrastive learning bagwise contrastivelearning', 1);('bagwise similarity', 1);('interaction image patchesand text bags text bag', 1);('embeddings text tokens bag', 1);('layer transforms lastlayer', 1);('token embeddings ftclst1t mgintoa sequence bag embeddings fbclsb1b kg visualtokengvvicomputes similarities', 1);('maximum value thesesimilarities activation visual', 1);('weaverage activation visual tokens bagwiseimagetotext similaritysitbag1nnxi1maxgvvitgtb1bk 5wherenis sequence length image patches kisthe sequence length text bags bagwise texttoimagesimilarity', 1);('bagging layerfigure', 1);('layerthe purpose', 1);('token granularity', 1);('tokens bag canbe word entity phrase time', 1);('priori knowledge fromthe vocabulary model', 1);('alignment text andimages vocabulary', 1);('useful priori knowledgethat', 1);('model enhance', 1);('autophrase shang', 1);('3steps rst step train', 1);('helper willstore index', 1);('wordentityphrase secondstep', 1);('word segmentation algorithm inputtoken index', 1);('step index bag', 1);('intoembeddingbag module', 1);('embeddingbag', 1);('module highefcient', 1);('bags embeddingswithout', 1);('intermediate embeddings', 1);('finallywe', 1);('sequence bag', 1);('layers output34', 1);('architecturerighttwo', 1);('asshown figure', 1);('text tokens', 1);('architecture tokens', 1);('throughthe text encoder', 1);('according', 1);('architecture outperforms', 1);('architecture whichwe', 1);('section35 implementation', 1);('detailstext', 1);('encoder 6layer', 1);('bert', 1);('model 583m parametersand image encoder 12layer visual transformer', 1);('vitb16with', 1);('858m parameters', 1);('following radford', 1);('wetokenize text', 1);('byte pair', 1);('bpe sennrich', 1);('experiments41 experimental setuppretraining dataset', 1);('dataset consists108m imagetext pairs', 1);('averagelength', 1);('details', 1);('pretrain model 15epochs', 1);('batch size', 1);('nvidia v100 gpusadamw loshchilov hutter', 1);('witha weight decay', 1);('following', 1);('cosine schedule', 1);('1e\x004in rst', 1);('images 256x', 1);('randaugment cubuk', 1);('wekeep image resolution', 1);('inferencewe resize images', 1);('entities bagginglayer42', 1);('modal granularity mismatchour', 1);('discrepancy performance texttoimage recall imagetotext recallin crossmodal retrieval', 1);('seethat imagetotext retrieval performance', 1);('token modelwo', 1);('late interaction tokenwise interaction modelwo', 1);('theirtexttoimage retrieval performance', 1);('imagetotext retrieval performance', 1);('control groupmodel wo', 1);('late interaction model wo', 1);('layer conclude thatthe', 1);('model mainlydue', 1);('imagetotext retrieval taskour ndings', 1);('poor performance', 1);('late interaction tokenwise interaction model', 1);('due agranularity mismatch image text', 1);('true languages', 1);('chinese tokengranularity sufcient', 1);('complete semanticsbagformer attempts', 1);('token granularity bags words entities', 1);('enable betteralignment text images success ofbagformer', 1);('ability alleviate themodal granularity mismatch43', 1);('imagetext retrievalin', 1);('section test models', 1);('subtasks imagetotext retrieval texttoimage retrieval imagetotext retrieval model retrieves target text', 1);('image query vice versa texttoimage retrieval', 1);('retrieval benchmark datasets', 1);('flickr30kcna xieetal', 1);('muge linet', 1);('wukong50k guetal', 1);('dueto', 1);('lack training', 1);('wukong50k', 1);('zeroshot settingour', 1);('settings dataset accordance commonpractices', 1);('recallk', 1);('recall top', 1);('imagetotext retrieval andtexttoimage retrieval', 1);('datasets nal comparison', 1);('mr recallk', 1);('resultsare', 1);('thereare test', 1);('available case report results fromthe', 1);('summarize results zeroshotand', 1);('strong benchmark singletower model hasdataset', 1);('study zeroshot imagetext retrieval', 1);('dataset result', 1);('comparable performance stateoftheartmodel', 1);('benchmark model', 1);('wukong vitb', 1);('different datasets eitherzeroshot', 1);('settings comparison', 1);('albefour', 1);('dual tower', 1);('comparable performance44', 1);('ablation studyadditionally', 1);('ablation studies', 1);('late interaction tokenwise model', 1);('yaoet', 1);('late interaction loss whichis', 1);('ablation studies improvements', 1);('novel designs', 1);('late interactionwe', 1);('layer plays key role', 1);('retrieval performance', 1);('main improvement comesfrom', 1);('imagetotext', 1);('retrieval task alleviate modalgranularity mismatch45', 1);('efciency analysisthe', 1);('nvidiat416g gpu latency', 1);('throughput model', 1);('setting query pairedwith top', 1);('theresults', 1);('bagformerhas', 1);('shorter latency', 1);('times shorter andhigher throughput', 1);('encoder architecture use', 1);('extractor 6layer transformer fuse multimodal', 1);('thedual encoder architecture', 1);('thefeature extractor', 1);('token similarity employedfor', 1);('recall metrics46', 1);('architectures testedon', 1);('linet', 1);('shows thatlate', 1);('architecture crossmodal retrieval tasks zeroshot results', 1);('helpthe model', 1);('textimage alignment', 1);('compared', 1);('architecture reason', 1);('information loss', 1);('external knowledge47', 1);('visualization', 1);('crossmodal alignmentthe', 1);('section examines', 1);('crossmodal alignment', 1);('method imagetotext retrieval texttoimage retrieval mrr1 r5 r10 r1 r5 r10zeroshotbagformer', 1);('4636bagformer bagwise', 1);('6607bagformer bagwise', 1);('wordpatch', 1);('visualizations bagwise similarity mapsmethodlatencymsthroughputqueriessalltoall interaction', 1);('2930bagwise interaction', 1);('efciency', 1);('analysiswordpatch alignment capability visualization', 1);('clip', 1);('images wordbag', 1);('thevisualization', 1);('bagwise similaritybetween image patches textual bags', 1);('specically', 1);('wecalculate bagwise similarity image patches andword bag', 1);('heat map shows word bagsactivationas', 1);('promising localizationabilities', 1);('teaware exampleof', 1);('aligns key partof target object examples', 1);('conclusionin', 1);('paper introduce', 1);('dual encoder modelwith novel bagwise interaction mechanism proposedbagformer leverage bagwise interaction mechanism whichintroduce', 1);('appropriate granularity text', 1);('introduce entity knowledge empirical evaluation onthe', 1);('muge flickr30kcna wukong50k', 1);('datasets wedemonstrate', 1);('comparable single tower model', 1);('statementthere', 1);('ethical issuesreferencesanderson', 1);('peter anderson xiaodong chrisbuehler damien teney mark johnson stephen gouldand lei zhang bottomup', 1);('topdown attention image', 1);('visual question', 1);('proceedings ieee', 1);('conference computer vision pattern recognition pages', 1);('jon louis bentley multidimensional', 1);('binarysearch trees', 1);('communications acm', 1);('hui chen guiguang ding xudong liuzijia lin ji liu jungong han imram iterativematching', 1);('recurrent attention memory crossmodalimagetext retrieval', 1);('conference computer vision pattern recognition pages1265512663 2020cheng', 1);('mengjun cheng yipeng sunlongchao wang xiongwei zhu kun yao jie chenguoli', 1);('junyu han jingtuo liu errui ding', 1);('scene text aggregation crossmodalretrieval', 1);('proceedings ieeecvf conferenceon computer vision pattern recognition', 1);('pages51845193 2022cubuk', 1);('ekin cubuk barret zoph jonathonshlens quoc v', 1);('randaugment practical', 1);('data augmentation', 1);('search space', 1);('inproceedings ieeecvf', 1);('conference computer vision pattern recognition workshops pages 7027032020datar', 1);('mayur datar nicole immorlica piotrindyk vahab mirrokni localitysensitive', 1);('pstable distributions', 1);('ofthe twentieth', 1);('annual symposium', 1);('computational', 1);('geometry pages', 1);('jacob devlin mingwei chang kenton lee kristina toutanova bert pretraining', 1);('ofdeep bidirectional transformers language understanding arxiv preprint arxiv181004805 2018dosovitskiy', 1);('alexey dosovitskiy lucas beyeralexander kolesnikov dirk weissenborn xiaohua zhaithomas unterthiner mostafa dehghani matthias minderer georg heigold sylvain gelly', 1);('image isworth', 1);('transformers', 1);('image recognitionat scale arxiv preprint arxiv201011929 2020faghri', 1);('fartash faghri david j fleetjamie ryan kiros sanja fidler vse improving', 1);('visualsemantic embeddings', 1);('hard negativesarxiv preprint arxiv170705612 2017guet', 1);('jiaxi gu xiaojun meng guansong lulu hou minzhe niu hang xu xiaodan liang weizhang xin jiang chunjing xu wukong', 1);('millionlargescale chinese crossmodal', 1);('dataset afoundation framework arxiv preprint arxiv220206767 2022jiaet', 1);('chao jia yinfei yang ye xia yitingchen zarana parekh hieu pham quoc', 1);('yunhsuansung zhen li tom duerig scaling', 1);('visual andvisionlanguage representation learning noisy text supervision', 1);('zaharia', 1);('omar khattab matei zaharia colbert efcient', 1);('effective passage search', 1);('late interaction bert', 1);('ofthe 43rd', 1);('acm sigir', 1);('conference researchand development', 1);('information retrieval', 1);('pages 39482020kim', 1);('wonjae kim bokyung', 1);('ildookim vilt visionandlanguage', 1);('convolution region supervision', 1);('pmlr2021leeet', 1);('kuanghuei lee xi chen gang huahoudong hu xiaodong stacked', 1);('cross attentionfor imagetext', 1);('proceedings europeanconference', 1);('computer vision', 1);('eccv', 1);('pages 2012162018liet', 1);('liunian harold li mark yatskar da yinchojui hsieh kaiwei chang visualbert', 1);('simpleand performant baseline vision language arxivpreprint arxiv190803557 2019liet', 1);('gen li nan duan yuejian fang minggong daxin jiang unicodervl', 1);('universal encoderfor vision language crossmodal', 1);('inproceedings aaai', 1);('articial intelligence', 1);('junnan li ramprasaath selvarajuakhilesh gotmare shaq joty caiming xiong', 1);('chu hong hoi align', 1);('andlanguage representation learning momentum distillation', 1);('junyang lin rui men yang changzhou ming ding yichang zhang peng wang angwang', 1);('jiang xianyan jia', 1);('m6', 1);('chinese multimodal pretrainer arxiv preprint arxiv210300823 2021liuet', 1);('yinhan liu myle ott naman goyaljingfei', 1);('mandar joshi danqi chen omer levy mikelewis luke zettlemoyer veselin stoyanov robertaa', 1);('approach arxivpreprint arxiv190711692 2019liuet', 1);('chunxiao liu zhendong mao tianzhuzhang hongtao xie bin wang yongdong zhanggraph', 1);('network imagetext', 1);('conference computer visionand pattern recognition pages', 1);('hutter', 1);('ilya loshchilov frankhutter decoupled', 1);('weight decay regularization arxivpreprint arxiv171105101 2017luet', 1);('jiasen lu dhruv batra devi parikh', 1);('lee vilbert pretraining', 1);('taskagnostic visiolinguistic representations visionandlanguage tasks', 1);('neural information processing systems 322019malkov', 1);('yashunin', 1);('yu malkov dmitry ayashunin efcient', 1);('robust approximate nearestneighbor search', 1);('navigable small worldgraphs', 1);('ieee', 1);('transactions pattern analysis machine intelligence', 1);('alec radford jong wook kim chrishallacy aditya ramesh gabriel goh sandhini agarwal girish sastry amanda askell pamela mishkin jackclark', 1);('transferable visual models', 1);('natural language supervision', 1);('international conference onmachine', 1);('keshav santhanam omar khattabjon saadfalcon christopher potts matei zahariacolbertv2 effective', 1);('efcient retrieval', 1);('lightweightlate interaction arxiv preprint arxiv211201488 2021sennrich', 1);('rico sennrich barry haddow', 1);('birch neural', 1);('machine translation', 1);('rare wordswith subword units arxiv preprint arxiv150807909 2015shang', 1);('jingbo shang jialu liu meng jiangxiang ren clare r v', 1);('jiawei han automatedphrase', 1);('massive text corpora', 1);('ieee transactions knowledge data engineering', 1);('hugo touvron matthieu cordmatthijs douze francisco massa alexandre sablayrolles herv', 1);('jegou training', 1);('dataefcient imagetransformers distillation attention', 1);('ashish vaswani noam shazeer nikiparmar jakob uszkoreit llion jones aidan n gomezukasz kaiser illia polosukhin attention', 1);('yujing wang yingyan hou haonanwang ziming miao shibin wu hao sun qi chenyuqing xia chengmin chi guoshuai zhao', 1);('neural corpus indexer document retrieval arxiv preprintarxiv220602743 2022xieet', 1);('chunyu xie heng cai jianfei songjincheng li fanjing kong xiaoyu wu henrique morimitsu lin yao dexin wang dawei leng', 1);('zeroand', 1);('r2d2 largescale chinese crossmodal benchmark visionlanguage framework arxiv preprintarxiv220503860 2022yaoet', 1);('lewei yao runhui huang lu hou guansong lu minzhe niu hang xu xiaodan liang zhenguo li xin jiang chunjing xu filip finegrainedinteractive', 1);('arxiv preprintarxiv211107783 2021zeng', 1);('donghuo zeng yi yu keizooyama deep', 1);('triplet neural networks clusterccafor audiovisual crossmodal retrieval', 1);('acm transactionson multimedia computing communications applications tomm', 1);