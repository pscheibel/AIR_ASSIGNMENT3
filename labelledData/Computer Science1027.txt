('mae', 18);('neurips', 9);('imagenet1k', 7);('vitb', 6);('icml', 5);('curran associates inc', 5);('beit', 4);('msggan', 4);('lsgan', 4);('ae', 4);('in1k', 4);('msgganp in1k', 4);('styleganv2adap in1k', 4);('pmlr', 4);('cvpr', 4);('figure', 3);('imagenet', 3);('l1', 3);('vitb vitl', 3);('ade20k', 3);('dino', 3);('mse', 3);('entropy in1k', 3);('iclr', 3);('jul', 3);('research pages', 3);('incvpr', 3);('eccv', 3);('learning objective', 2);('data distribution', 2);('msgmae', 2);('invisible content', 2);('nlp', 2);('compared', 2);('vision transformers', 2);('perceptual', 2);('peak', 2);('vgg', 2);('gans', 2);('original formulation', 2);('examples', 2);('vqv ae', 2);('image decoder', 2);('perceptual loss term', 2);('gan', 2);('styleganv2ada', 2);('adam', 2);('mscoco', 2);('imagenet1k in1k', 2);('fid', 2);('learnt approach', 2);('moco', 2);('infonce', 2);('negative log likelihood in1kdalle', 2);('mse in1k', 2);('msssim l1 in1k', 2);('lsganp in1k', 2);('in1k dalle', 2);('vitl', 2);('hal daum', 2);('proceedings machine learning', 2);('arxiv', 2);('iccv', 2);('springer', 2);('ieee transactions image processing', 2);('improving visual representation learning perceptual understandingsamyakh tukra frederick hoffman ken', 1);('aifsamyakhtukrafrederickhoffmanken', 1);('maewhich', 1);('improves representations learnt modelby', 1);('encouraging learning', 1);('scenelevelfeatures introduction perceptualsimilarity term', 1);('real images ii', 1);('techniques adversarial training literature', 1);('multiscale training adaptivediscriminator augmentation combination results', 1);('pixel reconstruction', 1);('higherlevel details', 1);('show howour method', 1);('perceptual mae', 1);('781top1 accuracy linear probingon', 1);('withsimilar results', 1);('models data1', 1);('introductionselfsupervision', 1);('powerful framework', 1);('deep neural networks', 1);('explicitsupervision labels learning proceeds predictingone part input data', 1);('approaches', 1);('input maskedand', 1);('nlp bert', 1);('similar techniques', 1);('learningvisual representations images', 1);('image reconstruction pretext task onthe basis learning', 1);('patches maskedimage', 1);('useful representations learnt downstreamtasks', 1);('data label efciency avariety', 1);('standard benchmark datasets', 1);('emergesthough representations learnt way', 1);('whole words', 1);('images base unit', 1);('individual pixels', 1);('wordsare', 1);('semantic meaning design whilst pixels images', 1);('natural signals', 1);('highfrequency variations', 1);('heavy spatial redundancy', 1);('early approaches', 1);('trivial solutions reconstruction basedon local textures patterns', 1);('successfulrecent methods', 1);('problem focus learning onhigherlevel image', 1);('proportion patches \x1875 force decoder', 1);('howto reconstruct', 1);('entire objects', 1);('context ii', 1);('beituses', 1);('visual tokenizer drawing higherlevel semantics learnt', 1);('large languagevision modelin paper', 1);('rst approach', 1);('andfocus building', 1);('learnt system iewithout', 1);('additional data', 1);('models explore', 1);('incorporate learning higherlevel', 1);('ideas generative', 1);('literature perceptual similarity', 1);('andii adversarial training 15by', 1);('perceptual loss term ties', 1);('maps learnt decoder network charge', 1);('image patches adversarial discriminator', 1);('original images', 1);('imagelevel supervision training nd results learnt representationswhich', 1);('details scene layout objectboundaries', 1);('explicit supervision orthe use', 1);('inductive biases', 1);('previous work', 1);('network deneperceptual similarity', 1);('concept perceptualsimilarity', 1);('adversarial training losswe', 1);('explore developments loss theuse multiscale gradients', 1);('adaptive discriminator augmentation', 1);('lead qualitative improvement objectcentricness learnt representations hypothesise issues methods1arxiv221214504v1 cscv', 1);('dec', 1);('mode collapse duringadversarial training', 1);('incomplete learning', 1);('overttingon lowlevel image', 1);('literaturethe methods', 1);('accurate reconstruction', 1);('image patches', 1);('arange perceptual metrics', 1);('psnr ssim inception scoreis', 1);('frechet inception distance fid', 1);('moreconsequentially', 1);('consistentboost performance', 1);('previous methods rangeof', 1);('modelsor dataa summary contributions', 1);('novel loss function', 1);('dynamic learning perceptual similarity', 1);('models data', 1);('generative adversarial losses andintroduce multiscale variant', 1);('increases delity', 1);('improves objectcentricness learnt representations validate', 1);('improves performance', 1);('tasks setting', 1);('new stateoftheart', 1);('object detection', 1);('ms coco', 1);('andsemantic segmentation', 1);('ade20k2 related work21 masked image modellingselfsupervised', 1);('learning systems thatdont', 1);('raw data', 1);('supervisory signal training results models', 1);('selfsupervised', 1);('learning hasshown', 1);('considerable success', 1);('language processing nlp', 1);('random parts input textare', 1);('defacto method', 1);('directpredictionapproach rst performant approaches selfsupervisedvisual representation learning', 1);('discriminative tasks', 1);('distortions input image', 1);('agrayscale image input', 1);('contrastive learning', 1);('transformer', 1);('mim', 1);('returns theidea directprediction', 1);('pixels aninput image', 1);('earlywork', 1);('unknown pixel values autoregressive manner', 1);('recent', 1);('full resolution patches autoencoder conguration', 1);('capacity learning highfrequencydetails spatial redundancy', 1);('present naturalimages', 1);('anadditional generative model dvae', 1);('alarge corpus images 250m pretext task topredict', 1);('simpler approach demonstratingthat', 1);('direct pixel prediction', 1);('meansquared error', 1);('effective large proportionof image', 1);('recent methods', 1);('strong performance', 1);('discriminative selfsupervision', 1);('performantin linear', 1);('right level abstraction remainsa challenge', 1);('address ourwork22', 1);('perceptual similaritythe', 1);('aim perceptual similarity', 1);('mimic humanvisual perception', 1);('humans', 1);('capable understandingimages abstract level', 1);('high level conceptsand semantic cues dene', 1);('different entities frame', 1);('similarity aims mimic humanlike judgement deningmetrics encode perceptual distance beinghigher image representations', 1);('visual semantic conceptsstructural', 1);('similarity index ssim', 1);('early form perceptual loss attempts', 1);('properties image thatwhen', 1);('images', 1);('luminance iepixel intensity ii contrast iii structure', 1);('compute similarity', 1);('multiple scales', 1);('similar metrics', 1);('noise', 1);('psnr', 1);('feature similarity index fsim', 1);('andhdrvdp2 33an', 1);('alternative approach', 1);('perceptual similarity', 1);('differences pixels insteadcompute differences intermediary featureslearnt neural network', 1);('manner ona', 1);('large dataset basis', 1);('accurate classication approach', 1);('computer vision', 1);('approach perceptual similarity', 1);('learning perceptual similarity dynamically23', 1);('generative', 1);('modellingif perceptual similarity tries', 1);('semanticstructure images generative models aim', 1);('distribution image data example isgenerative', 1);('adversarial networks gans', 1);('thesamples', 1);('generator model', 1);('discriminator model', 1);('parallel generator', 1);('adversarial loss function', 1);('highdelity images', 1);('training instability mode collapse thenetwork', 1);('subset variancepresent data distribution', 1);('subsequent work', 1);('progan', 1);('ideaof generation', 1);('multiple scales stabilise', 1);('stylegan', 1);('family papers', 1);('improvements learning discriminator', 1);('path length regularisation', 1);('small changes input latent code work theinput decoder lead changes', 1);('similar magnitudein', 1);('maps discriminator', 1);('goodnormalisation input codes', 1);('adaptive discriminatoraugmentation ada', 1);('heavy augmentation training discriminator', 1);('volumes training data', 1);('augmentations effect output thegenerator', 1);('space tobe', 1);('stable small changes lowlevel image statistics work explore additions', 1);('withmultiscale learning', 1);('autoencoder architecturecan', 1);('highlevel representations', 1);('adversarial training', 1);('explicit generative models aim capturethe', 1);('methodsavoid issues mode collapse sufferedby', 1);('need model fulldistribution', 1);('sensitive volume ofdata', 1);('variational autoencoders v ae', 1);('flowbased', 1);('anddiffusion models', 1);('v ae', 1);('learning discrete latent space', 1);('creation codebook', 1);('recentlythis', 1);('rich latent representations learnt', 1);('vqv aemodel', 1);('large data', 1);('prediction target work', 1);('model case', 1);('perceptual similarity loss3', 1);('methodologythe', 1);('learning framework', 1);('introduce perceptual loss term section 32we describe variants adversarial loss withwhich perceptual loss term', 1);('section 33we describe modify', 1);('architecture ensuremaximal learning encoder stage', 1);('multiscale gradients31', 1);('mae perceptual lossthe mse', 1);('loss term', 1);('perceptual loss termlgjjgim\x00ijj1lgperceptual 1wheregdenes', 1);('iis', 1);('original imageandimis', 1);('original image', 1);('maskedmsssim baseline perceptual loss', 1);('onstructural similarity index', 1);('specically', 1);('utilise multiscale structural similarity index variant', 1);('msssim', 1);('48the multiscale component aids', 1);('edges output', 1);('imagei0 perceptual loss term thuslgssim1nxij 1\x00ssim', 1);('gimijiij22whereijare', 1);('pixel indexes', 1);('nis', 1);('total number scales', 1);('3\x023block lter eachscale', 1);('error weightedby inverse 1\x00', 1);('feature', 1);('based', 1);('style reconstruction losses', 1);('perceptual loss relies', 1);('separate loss network decoder', 1);('layer loss network', 1);('toavoid', 1);('dependency external', 1);('label bias', 1);('introduce additionaldiscriminator network', 1);('dwhich', 1);('act loss network', 1);('adversarial setup distinguish', 1);('gand', 1);('theoriginal image', 1);('intuition thefeatures learnt task', 1);('higherorderperceptual cues', 1);('training thedecoderin addition', 1);('reconstruction loss nd', 1);('differences correlation featureactivations', 1);('style reconstructionloss ties', 1);('overall color texture furtherstabilises training perceptual loss becomeslgfeat\x0efjxj11njjj jgim\x00 jijj1\x0esjxj11njjj jgim\x00 jijj13wherejis index layer', 1);('njdenotes', 1);('number elements layer', 1);('gram', 1);('matrix function', 1);('adversarial loss', 1);('lg anyadversarial', 1);('loss function', 1);('baseline experiments', 1);('stable optimisation', 1);('original minmaxclassication loss', 1);('generatordiscriminatorloss pairldadv12di\x0012', 1);('dgim2', 1);('4lgadv12dgim\x0012 5the', 1);('full loss function decoder becomeslgjjgim\x00ijj1lgfeatlgadv 6beyond', 1);('learnt perceptual loss', 1);('adversarial trainingdv', 1);('perceptual learningbaseline', 1);('network comparison experiment', 1);('loss discrete variational autoencoderdv', 1);('equation', 1);('encoder model component', 1);('loss network', 1);('thisthen', 1);('full loss functionfor decoderlgjjgim\x00ijj1lgfeat 7the dv', 1);('image tokenization thedalle dataset', 1);('rich features', 1);('stronghigherorder perceptual cues decoder training32', 1);('adversarial training variantsfor', 1);('perceptual learning adversarial loss function', 1);('baseline model experimentedwith', 1);('address issues', 1);('formulation training instability mode collapse 22we hypothesize', 1);('distributions learnt thesemethods', 1);('cues perceptual learningmsggan stabilise training generatormsggan', 1);('ow gradients thediscriminator generator', 1);('multiple scales isdone', 1);('connections intermediate layersof generator intermediate layers discriminatorthe loss function training', 1);('dandgremains', 1);('modications madeto discriminator', 1);('perceptual path regularisation decoder input discriminator', 1);('adaptive', 1);('discriminator augmentation', 1);('appliedto samples training loss function trainingdandgremains unchanged33', 1);('model architectureone', 1);('issue multiscale', 1);('formulation usedfor', 1);('andstyleganv2ada methods thatthe multiscale learning occurs', 1);('connections discriminator', 1);('dand', 1);('meansthat decoder benets multiscale gradient penalty training', 1);('encoder adapting', 1);('tasksto ensure encoder benets multiscale gradients penalty redesign', 1);('unet', 1);('architecture whichwe term', 1);('maps intermediate encoder layers', 1);('respective decoder layers', 1);('theforward', 1);('ontothe decoder', 1);('direct gradients calculatedwith respect intermediate encoder layer', 1);('encoder decoder4 implementation', 1);('detailspretraining', 1);('multiscale gradient mae msgmae', 1);('dotted', 1);('imagenet1kin1k', 1);('case input patch sizeis', 1);('input patches training', 1);('decoder architecture', 1);('consistent model dimensions hyperparameters data augmentation strategies', 1);('train batchsize', 1);('weighteddecay learning rate', 1);('weight decay is005 cosine strategy', 1);('warmup epochs', 1);('themomentum parameters 1and 2are', 1);('095in experiments', 1);('lgfeatwhere', 1);('factor \x0efof', 1);('thelgssim', 1);('cases theresult focus learning perceptual term thesmaller\x0esvalue', 1);('relative magnitude', 1);('lgfeattermthe', 1);('parameter choice', 1);('works literature', 1);('time discriminator', 1);('new features withwhich compute perceptual similarity training schedule', 1);('lgis', 1);('discriminator ensures', 1);('pretrainedmae encoder model', 1);('decoder architecturewith taskspecic head', 1);('random weightssimilar', 1);('image classication', 1);('vit', 1);('model classication head 29for object detection segmentation', 1);('30we use', 1);('maskrcnn', 1);('decoder model', 1);('semantic segmentation', 1);('upernetmodel', 1);('thelearning', 1);('weight decay', 1);('cosine strategy warmup epochs', 1);('momentum parameters 1and 2are', 1);('experimentsin', 1);('rst explore', 1);('main properties thelearnt representations section', 1);('terms delity', 1);('output ii qualitative attentionmaps', 1);('model iii linear', 1);('following', 1);('performance models', 1);('coco', 1);('forobject detection', 1);('main propertiesimage reconstruction', 1);('reconstruction quality decoder stage modelsover', 1);('quantitative measures', 1);('noise rationpsnr structural similarity index ssim', 1);('inceptionscore', 1);('fr', 1);('echet inception distance', 1);('differences', 1);('reconstruction quality model variants samples', 1);('key areas offocus', 1);('columns ab', 1);('show ground truth image', 1);('cg', 1);('image', 1);('reconstruction quality evaluation', 1);('imagenet1k vitb', 1);('red headers', 1);('columns green headershigher value', 1);('function l1 psnr ssim fidmse', 1);('103these experiments', 1);('perceptual lossesfor methods observe gradual increasein delity', 1);('patches pixellevel measures', 1);('l1 psnr ssim', 1);('consistent boost', 1);('similar pattern', 1);('foris methods', 1);('higherlevelnotion perceptual similarity', 1);('intermediaryfeature maps network', 1);('images suggests thatthrough introduction perceptual loss term decoder learning', 1);('generalisable notion perceptualsimilarity', 1);('infigure 2selfattention maps', 1);('thehighlevel semantics image lowlevel detailswe visualise attention maps nal layer ournetwork', 1);('originalmae formulation combination perceptual adversarial loss', 1);('sharper focus object frame', 1);('training addition multiscale gradients', 1);('adaptive discriminator augmentation perceptual path length regularisation', 1);('bringsfurther improvementin', 1);('similarqualitative results', 1);('contrastive approach learning requirescareful', 1);('image cropswithin batches', 1);('useful semantic information', 1);('common approach freezethe backbone', 1);('encoder model train asimple linear classier top report results ourmodels', 1);('scuh approach', 1);('modelbeit contrastive learning approach', 1);('v3our baseline model variant', 1);('msssimachieves', 1);('712accuracy 3higher', 1);('maetrained', 1);('model variantstyleganv2adap attains', 1);('signicant increase suggests perceptual loss term', 1);('necessary comparison', 1);('perceptual loss', 1);('supervision accuracy improves', 1);('thisintroduces dependency external network training data', 1);('in1k52 downstream learning resultsimage', 1);('classication netune models', 1);('in1kwith', 1);('aconsistent boost performance', 1);('board addinga perceptual loss term', 1);('accuracy 862withour', 1);('styleganv2adap', 1);('classication', 1);('trainingof linear', 1);('finetuningmethod loss function pretraining data vitb vitb vitligpt', 1);('lsgan in1k', 1);('msggan in1k', 1);('862mae dvaep', 1);('object', 1);('detection semantic segmentation performance', 1);('ms coco ade20k', 1);('coco ade20kmethod loss function pretraining data', 1);('map box map', 1);('mask', 1);('441moco v3', 1);('491mae dvaep', 1);('previous methods training onin1k data', 1);('comparable accuracy', 1);('vith', 1);('448architecture 86m parameters vs 632m parameters input image size', 1);('224if use', 1);('network dv', 1);('aep', 1);('obtaina boost', 1);('accuracy 886object detection semantic segmentation object detection netune', 1);('mask rcnn', 1);('architecture outperforms', 1);('attention', 1);('maps models', 1);('labels visualise selfattention', 1);('cls', 1);('token thelast layer sample images', 1);('column', 1);('original input image', 1);('bf', 1);('different losses', 1);('similarly', 1);('semantic segmentationwe netune', 1);('upernet', 1);('504miou 12higher', 1);('maeimpact', 1);('perceptual loss term training abaseline adversarial loss', 1);('perceptual lossterm', 1);('unable train model performs betterthan baseline', 1);('clear stability issues training', 1);('msgganloss', 1);('adversarial reconstruction loss', 1);('11boostover baseline', 1);('loss image classication', 1);('17boost perceptualcomponent', 1);('06vs13boost suggeststhe perceptual loss term plays', 1);('important role', 1);('large driver performanceimpact multiscale', 1);('mae training', 1);('results drop performance 2forimage classication', 1);('similar dropalso', 1);('object detection semantic segmentation', 1);('conclusionwe', 1);('learning ofhigherlevel', 1);('aperceptual loss term adversarial training showedhow representations learnt', 1);('performance downstreamtasks image classication object detection semantic segmentation', 1);('particular performance boostis', 1);('linearprobe setting contrastive methods historicallydone', 1);('rich supervision pixel reconstruction task focusedhigherlevel learning signal', 1);('autoencoder approachthis work', 1);('betweenimages text images image patches haveinherent semantic meaning', 1);('right level abstraction', 1);('image data', 1);('perceptual understanding', 1);('learning semantic', 1);('hangbo bao li dong songhao piao furu wei beitbert', 1);('image transformers', 1);('april2022', 1);('tom brown benjamin mann nick ryder', 1);('subbiah language', 1);('models fewshot learners', 1);('hlarochelle ranzato r hadsell mf balcan hlin', 1);('curranassociates inc', 1);('mathilde caron hugo touvron ishan misra herv', 1);('jegoujulien mairal piotr bojanowski armand joulin emerging', 1);('iniccv', 1);('mark chen alec radford rewon child jeffrey wu heewoo jun david luan ilya sutskever generative', 1);('iii aarti singh', 1);('proceedings machine learningresearch', 1);('ting chen simon kornblith mohammad norouzi geoffrey hinton', 1);('simple framework contrastive learning visual representations', 1);('iii aartisingh', 1);('xinlei chen saining xie kaiming', 1);('empiricalstudy training', 1);('vision transformers arxivpreprint arxiv210402057', 1);('jia deng wei dong richard socher lijia li kai liand li feifei imagenet', 1);('largescale hierarchical imagedatabase', 1);('jacob devlin mingwei chang kenton lee kristina ntoutanova bert pretraining', 1);('deep bidirectional transformers language understanding', 1);('prafulla dhariwal alexander nichol diffusion', 1);('modelsbeat gans image synthesis', 1);('ranzato beygelzimer dauphin ps liang j wortman vaughan', 1);('laurent dinh jascha sohldickstein samy bengiodensity', 1);('nvp iclr openreviewnet', 1);('carl doersch abhinav gupta alexei efros unsupervised', 1);('visual representation learning context predictioniniccv pages', 1);('alexey dosovitskiy jost tobias springenberg martin riedmiller thomas brox discriminative', 1);('learning convolutional neural networks', 1);('zghahramani welling', 1);('cortes n lawrence kqweinberger', 1);('leon gatys alexander ecker matthias bethgeimage', 1);('convolutional neural networks', 1);('spyros gidaris praveer singh nikos komodakis unsupervised', 1);('representation learning', 1);('image rotations', 1);('ian goodfellow jean pougetabadie mehdi mirza bingxu david wardefarley sherjil ozair aaron courville', 1);('bengio generative', 1);('adversarial nets', 1);('z ghahramani welling', 1);('cortes n lawrence kq weinberger', 1);('curran associates inc2014', 1);('kaiming xinlei chen saining xie yanghao li piotrdollar ross girshick masked', 1);('autoencoders scalablevision learners arxiv211106377', 1);('kaiming georgia gkioxari piotr doll', 1);('ross girshick mask', 1);('martin heusel hubert ramsauer thomas unterthinerbernhard nessler sepp hochreiter gans', 1);('atwo timescale update rule converge local nash equilibrium', 1);('nips17', 1);('hook ny usa2017 curran associates inc', 1);('irina higgins loic matthey arka pal christopher burgessxavier glorot matthew botvinick shakir mohamed', 1);('lerchner', 1);('ae learning', 1);('basic visual concepts', 1);('variational framework', 1);('alain hor', 1);('djemel ziou image', 1);('quality metrics', 1);('psnrvs', 1);('icpr', 1);('justin johnson alexandre alahi li feifei perceptuallosses', 1);('realtime style', 1);('ineccv', 1);('animesh karnewar oliver wang raghu sesha iyengarmsggan multiscale', 1);('gradient gan', 1);('stable image synthesisarxiv preprint arxiv190306048', 1);('tero karras timo aila samuli laine jaakko lehtinenprogressive', 1);('quality stabilityand variation', 1);('international conference', 1);('learning representations', 1);('tero karras miika aittala janne hellsten samuli lainejaakko lehtinen timo aila training', 1);('generative adversarial networks', 1);('tero karras samuli laine timo aila', 1);('stylebasedgenerator architecture generative adversarial networks', 1);('tero karras samuli laine miika aittala janne hellstenjaakko lehtinen timo aila analyzing', 1);('improvingthe image quality stylegan', 1);('durk p kingma prafulla dhariwal glow generativeow', 1);('bengio h wallach h larochelle k grauman n cesabianchi rgarnett', 1);('curran associatesinc', 1);('diederik p kingma max welling autoencoding variational bayes iclr', 1);('alexander kolesnikov alexey dosovitskiy dirk weissenborn georg heigold jakob uszkoreit lucas beyermatthias minderer mostafa dehghani neil houlsby sylvain gelly thomas unterthiner xiaohua zhai', 1);('transformers', 1);('image recognition scale', 1);('tsungyi lin michael maire serge belongie james hayspietro perona deva ramanan piotr doll', 1);('ar c', 1);('lawrencezitnick microsoft', 1);('common objects context', 1);('ineccv zurich', 1);('oral', 1);('guilin liu fitsum reda kevin j shih tingchun wangandrew tao bryan catanzaro image', 1);('irregular holes', 1);('partial convolutions', 1);('yinhan liu myle ott naman goyal jingfei', 1);('mandarjoshi danqi chen omer levy mike lewis luke zettlemoyer veselin stoyanov roberta', 1);('cite arxiv190711692', 1);('rafa mantiuk kil joong kim allan g rempel wolfgang heidrich hdrvdp2', 1);('visual metric forvisibility quality predictions luminance conditionsacm', 1);('trans graph', 1);('xudong mao qing li haoran xie raymond k lauzhen wang stephen paul smolley least', 1);('squares generative adversarial networks', 1);('alexander quinn nichol prafulla dhariwal aditya rameshpranav shyam pamela mishkin bob mcgrew ilyasutskever mark chen glide towards', 1);('photorealistic image generation editing', 1);('diffusion models', 1);('kamalika chaudhuri stefanie jegelka lesong csaba szepesvari gang niu sivan sabato', 1);('mehdi noroozi paolo favaro unsupervised', 1);('learning ofvisual representations', 1);('jigsaw puzzles', 1);('bastian leibe jiri matas nicu sebe max welling', 1);('cham', 1);('aditya ramesh mikhail pavlov gabriel goh scott graychelsea v', 1);('alec radford mark chen ilya sutskeverzeroshot', 1);('texttoimage generation', 1);('marina meila', 1);('zhang', 1);('proceedings', 1);('learning', 1);('ronneberger pfischer brox unet convolutional', 1);('networks biomedical image segmentation', 1);('miccai', 1);('lncs', 1);('2015available arxiv150504597 cscv', 1);('tim salimans ian goodfellow wojciech zaremba vickicheung alec radford xi chen xi chen improvedtechniques', 1);('training gans', 1);('lee sugiyama uluxburg guyon r garnett', 1);('samyakh tukra hani j marcus stamatia giannarouseethrough', 1);('scene occlusion reconstruction', 1);('ieee transactions pattern analysis', 1);('intelligence', 1);('aron van den', 1);('oord yazhe li oriol vinyals representation', 1);('learning contrastive predictive', 1);('aaron', 1);('van den', 1);('oord oriol vinyals', 1);('koray kavukcuogluneural discrete representation learning', 1);('guyon u v', 1);('bengio h wallach r fergus vishwanathan r garnett', 1);('ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomez', 1);('kaiser illia polosukhin attention', 1);('guyonu v luxburg bengio h wallach r fergus vishwanathan r garnett', 1);('p vincent h larochelle bengio pa manzagolextracting', 1);('tingchun wang mingyu liu junyan zhu andrew taojan kautz bryan catanzaro highresolution', 1);('image synthesis semantic manipulation conditional gans', 1);('xintao wang ke yu shixiang wu jinjin gu yihao liuchao dong yu qiao chen', 1);('loy esrgan enhanced', 1);('superresolution generative adversarial networks', 1);('ineccvw september', 1);('zhou wang alan', 1);('bovik hamid r sheikh eero psimoncelli image', 1);('quality assessment error visibilityto structural similarity', 1);('z wang ep simoncelli ac bovik multiscale', 1);('structural similarity image quality assessment', 1);('thrityseventh', 1);('signals systems computers', 1);('tete xiao yingcheng liu bolei zhou yuning jiang', 1);('sun unied', 1);('scene understanding', 1);('eccv springer', 1);('zhenda xie zheng zhang yue cao yutong lin jianminbao zhuliang yao qi dai han hu simmim', 1);('june', 1);('lin zhang lei zhang xuanqin mou david zhangfsim', 1);('similarity index image quality assessment', 1);('richard zhang phillip isola alexei efros colorfulimage', 1);('richard zhang phillip isola alexei efros eli shechtmanand oliver wang', 1);('unreasonable effectiveness deepfeatures perceptual metric', 1);('bolei zhou hang zhao xavier puig tete xiao sanja fidler adela barriuso antonio torralba semantic', 1);('understanding scenes ade20k dataset', 1);('internationaljournal computer vision', 1);