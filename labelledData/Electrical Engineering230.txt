('catl', 36);('catlnet', 35);('stl', 15);('ieee', 13);('mas', 12);('fig', 10);('alg', 9);('commgate', 8);('lstm', 7);('hence', 6);('liu', 5);('mpc', 4);('sec', 4);('initial state', 4);('nn', 4);('ieee transactions robotics', 3);('team', 3);('control policy', 3);('pb', 3);('team trajectory', 3);('delivery', 3);('rl', 3);('ltl', 3);('decision', 2);('robotics', 2);('systems', 2);('advances', 2);('springer', 2);('cdc', 2);('dfars', 2);('engineering', 2);('secretary defense research', 2);('communication', 2);('tasks \x16tkithat', 2);('kiafter repair ie', 2);('returns result suc', 2);('ftkitkikito', 2);('minitial', 2);('outnet', 2);('communication channel', 2);('capnet', 2);('catlnetfigure', 2);('overall architecture', 2);('ground', 2);('catlthe', 2);('inner logic', 2);('interagent collision', 2);('uj', 2);('denote', 2);('consider', 2);('team agents', 2);('liu belta', 2);('sahin', 2);('control policies', 2);('belta', 2);('synthesis', 2);('ctde', 2);('nns', 2);('distribution', 2);('public release', 2);('catl liu', 2);('temporal logics', 2);('simulation results', 2);('capability temporal logic', 2);('pmlr', 1);('control conference pages', 1);('learning dynamics', 1);('reinforcement learningwith', 1);('zhang wenliang liu calin belta distributed', 1);('acm transactions embedded computing systems tecs', 1);('feedforward neural network controllers lagrange multipliers approach', 1);('satisfaction stl specications', 1);('yaghoubi georgios fainekos worstcase', 1);('ieee robotics automation', 1);('motion planning signaltemporal logic specications', 1);('ieee2020dawei sun jingkai chen sayan mitra chuchu fan multiagent', 1);('acc', 1);('american control conference', 1);('multiagentreinforcement learning', 1);('sun xiao li calin belta automata', 1);('neural information processing systems', 1);('multiagent communication backpropagation', 1);('learning', 1);('sukhbaatar rob fergus', 1);('task allocationand planning temporal logic goals heterogeneous multirobot systems internationaljournal robotics research', 1);('dimos v dimarogonas simultaneous', 1);('b urger', 1);('schillinger mathias', 1);('coordination countingtemporal logics', 1);('emre sahin petter nilsson necmiye ozay multirobot', 1);('internationalconference cyberphysical systems iccps', 1);('acmieee', 1);('temporal logic constraints', 1);('large collections agents', 1);('emre sahin petter nilsson necmiye ozay provablycorrect', 1);('computing allerton', 1);('allerton', 1);('temporal logic model predictive control', 1);('sadraddini calin belta robust', 1);('control pages', 1);('predictive control signal temporal logic specications 53rd', 1);('mehdi maasoumy richard murray alberto sangiovannivincentelli sanjit seshia model', 1);('raman alexandre donz', 1);('ieee 1977vasumathi', 1);('ofcomputer science sfcs', 1);('annual symposium foundations', 1);('temporal logic programs', 1);('catlamir pnueli', 1);('games arxiv preprint arxiv170310069 201713learning', 1);('humanlevel coordination learningto play starcraft', 1);('emergence', 1);('jun wangmultiagent', 1);('peng ying wen yaodong yang quan yuan zhenkun tang haitao', 1);('ccta', 1);('conference control technology andapplications', 1);('smooth robustness temporal logic', 1);('operator control usingthe', 1);('vardhan pant houssam abbas rahul mangharam smooth', 1);('in2018 ieee', 1);('signal temporallogic specications multiagent adversarial environments', 1);('muniraj kyriakos g vamvoudakis mazen farhood enforcing', 1);('pages 152166springer 2004devaprakash', 1);('formal techniques modelling analysis timed faulttolerant systems', 1);('continuous signals', 1);('temporal properties', 1);('maler dejan nickovic monitoring', 1);('advances neural information processing systems', 1);('multivariate recurrent neural networks', 1);('signal temporal logic', 1);('ji gao lu feng john stankovic stlnet', 1);('abstractionfree method multirobot temporal logic optimal control synthesis', 1);('luo yiannis kantaros michael zavlanos', 1);('multiagent coordination fromcatl specications arxiv preprint arxiv221001732 2022xusheng', 1);('liu kevin leahy zachary serlin calin belta robust', 1);('neural network controllers signaltemporal logic specications subject safety constraints', 1);('liu noushin mehdipour calin belta recurrent', 1);('recurrent neural networks arxiv preprint arxiv210315938 2021wenliang', 1);('safe policy search signal temporal logic specications', 1);('liu calin belta modelbased', 1);('437eaay6276 2019wenliang', 1);('formal methods approach interpretablereinforcement learning robotic planning science', 1);('li zachary serlin guang yang calin belta', 1);('workshopon algorithmic foundations robotics', 1);('logical structure', 1);('infusing', 1);('signal temporal logicspecications', 1);('marco pavone backpropagation', 1);('leung nikos ar', 1);('trajectoryfeedback controller synthesis signal temporal logic specications arxiv preprint arxiv220201997 2022karen', 1);('leung marco pavone semisupervised', 1);('coordination highlevelspecications scratches', 1);('scalable robust algorithms', 1);('leahy zachary serlin cristianioan vasile andrew schoer austin jones roberto tronand calin belta', 1);('method stochastic optimization arxiv preprintarxiv14126980 2014kevin', 1);('catldiederik p kingma jimmy ba adam', 1);('international journal', 1);('temporal logic optimal control synthesisalgorithm largescale multirobot systems', 1);('kantaros michael zavlanos stylus', 1);('attentional communication multiagent cooperationadvances neural information processing systems', 1);('jiang zongqing lu learning', 1);('reinforcement learning temporal logic specications arxiv preprint arxiv210200582 2021jiechuan', 1);('hammond alessandro abate julian gutierrez michael wooldridge multiagent', 1);('smooth robustness measure signal temporal logic forsymbolic control', 1);('gilpin vince kurtz hai lin', 1);('multiagent reinforcement learning', 1);('foerster ioannis alexandros assael nando de freitas shimon whiteson learningto', 1);('conference decision controland european control conference pages', 1);('global ltl specications', 1);('control communicationschemes', 1);('chen xu chu ding calin belta synthesis', 1);('ieeerobotics automation', 1);('continuous motion planning temporal logic', 1);('deep reinforcement learning', 1);('cai mohammadhosein hasanbeig shaoping xiao alessandro abate zhen kanmodular', 1);('ieee roboticsand automation', 1);('heterogeneous multiagent systems signal temporal logic specications integral predicates', 1);('tevk buyukkocak derya aksaray yasin yazco', 1);('methods discretetime dynamicalsystems volume', 1);('belta boyan yordanov ebru aydin gol formal', 1);('decisionand', 1);('55th conference', 1);('robustsatisfaction signal temporal logic specications', 1);('aksaray austin jones zhaodan kong mac schwager calin belta qlearning', 1);('governmentmay', 1);('copyright noticeus government rights work', 1);('notwithstanding', 1);('feb', 1);('dfars part', 1);('unlimited', 1);('us government', 1);('delivered', 1);('institute technology', 1);('massachusetts', 1);('material authors necessarilyreect', 1);('opinions ndings conclusionsor recommendations', 1);('contract fa870215d0001', 1);('air force', 1);('thismaterial', 1);('catldistribution statement approved', 1);('densetime behaviors11learning', 1);('satisfying specication plan incorporate lowerlevel controller', 1);('success rate', 1);('repair algorithm trainingcatlnet', 1);('workwe', 1);('conclusion', 1);('initial states success rate', 1);('enable dothis test nal', 1);('stage task communication', 1);('senseas agents needs behave', 1);('reduces total number communications andthe communication', 1);('corresponding communication time shownin', 1);('bythe nal', 1);('retrain policy networks trajectory', 1);('trajectoriesnext train', 1);('randominitial states nal dataset contains', 1);('satisfying team trajectories', 1);('full communication generate', 1);('dataset repeat process results ina', 1);('3c positiverobustness', 1);('3b results', 1);('repair trajectory', 1);('edge bridge local optimum zerorobustness use', 1);('time theagents', 1);('groundvehicle bridge', 1);('due \x085 ie', 1);('3b trajectory violates', 1);('white squares indicatethat agent communicatein', 1);('agent communicates atthat time', 1);('greensquares', 1);('time step', 1);('trajectoryafter repair', 1);('trajectory repair c', 1);('example trajectories b', 1);('environment', 1);('b c dfigure', 1);('catla', 1);('full communication repair shown10learning', 1);('rst training', 1);('\x00112j 1234uj \x0012122j', 1);('contains history information agent', 1);('dimension communicationvector', 1);('ex', 1);('case studiesconsider', 1);('satisfying rate execution', 1);('repair scheme guidancefor training', 1);('specication execution isnot', 1);('training phase', 1);('global information states agents', 1);('solution existsremark', 1);('specication exists thealgorithm nd words', 1);('complete completenessmeans solution team trajectory satises', 1);('proposition', 1);('ensures soundness', 1);('thedisjunction satisedremark', 1);('positive robustness', 1);('clauses aggedagents', 1);('repairin conclusion tasks \x16tkiare satised8i2f1ikg lemma', 1);('satisfaction tasks', 1);('mkiafter repair agentwe assignkitomkiagents', 1);('ifnxckikitki', 1);('hencenxckikitkidecreases', 1);('agent time', 1);('mkiagents repair ie nxckikitkimki', 1);('x0j\x16tki3', 1);('fj', 1);('similar agents matter', 1);('mkiagents repair ie nxckikitki mkithey', 1);('x0j\x16tki2', 1);('ki sum mkiagents', 1);('repair xjtki6jkiandfj 1xjwill', 1);('sincei2rjxjtkijkiequivalent xj0jftkitkiki', 1);('unchanged xjtkijkiandfj 1xjwill', 1);('original xjtkijkiandfj 0xjwill', 1);('mkiagents agents', 1);('team trajectory ie nxckikitkimki', 1);('steps1 tasks \x16tkithat', 1);('x0j\x16tki8i2f1ikg', 1);('team trjactory', 1);('agents result sucin step', 1);('positive robustnessfor', 1);('control synthesis returns', 1);('rstprove lemma', 1);('tasks \x16tkishould', 1);('x0j', 1);('xsatises catl', 1);('catlproposition', 1);('xu1\x01\x01\x01ujjjresult', 1);('positive robustness thenresult suc break13return', 1);('redo assignment', 1);('rjfig', 1);('trajectory9 forfi21ikjnxckikitki mkigdo10 forj2jckido11 ifxjtkijithenrj', 1);('agents8 xjuj synvi2rjftkitkiki', 1);('mkiagents break7 forfj2jjfj 1gdo', 1);('flag agents need repair', 1);('task ito agent j\x035 ifxj\x03tki6jkithenfj\x03', 1);('rj\x03 rj\x03fig', 1);('\x16tki3 forj\x03insortf\x1axjkitkijj2jckigdo agents cki4', 1);('0result fail1forkinsort\x00\x11xvjikji1tki0kk1\x01do clauses2 forfi21ikjnxckikitki\x14mkigdo', 1);('wkk1viki1\x16tkir1\x01\x01\x01rjjjf1\x01\x01\x01fjjj', 1);('trajectory repairinput', 1);('algorithm terminates return failalgorithm', 1);('clauseviki1\x16tkiif clauses', 1);('redo steps', 1);('otherwise', 1);('positive robustness algorithmterminates return success step', 1);('repeat', 1);('thetrajectory nd tasks', 1);('conjunction formulas step', 1);('control synthesis algorithm tomake agents trajectory', 1);('agent needs repair', 1);('stlformulas', 1);('agent time thosetasks', 1);('capabilities ckisteps', 1);('enoughmki agents', 1);('nd tasks \x16tkihkickimkiitkithat', 1);('robustness tothe', 1);('wecalculate', 1);('andthe system model', 1);('dnf\x08 wkk1viki1\x16tki', 1);('formula negationfree', 1);('xu syn rst rewrite', 1);('formula solutionexists', 1);('individual trajectorywe nd control sequence agent steers', 1);('control synthesisalgorithm', 1);('repair output', 1);('indexsort\x11ini1 i1i2in st\x11i1\x15\x11i2\x15\x15\x11in 9next', 1);('tasksletsort\x01reorder sequence scalars', 1);('rid negations', 1);('jjcj\x00magents withcapabilitycviolate', 1);('words nomore thanm\x001agents capability csatisfy', 1);('xt0jhcjjcj\x00mit', 1);('xt0jhcmitis', 1);('negative taskswe', 1);('form negations', 1);('catlformula dnf', 1);('algorithm', 1);('outer logic', 1);('catlproof sketch', 1);('number conjunctions kthdisjunction8learning', 1);('ikis', 1);('dnfwkk1viki1\x16tkiwhere', 1);('equivalent tohcmit0proposition', 1);('original task hcmiis', 1);('task \x16thcmitis', 1);('task as\x16thcmit suchthatxt0j\x16tiffxt0tjhcmi', 1);('dene', 1);('disjunction conjunctionsto', 1);('disjunctive normal form dnf', 1);('training phase rst step rewrite outerlogic', 1);('describe repair algorithm', 1);('catlnet53 repair catlnetnow', 1);('catlnet commgate', 1);('finallywe', 1);('standard classier minimize cross entropy lossmin\x12gxdg\x00yilog\x10\x1b\x00ghjit\x12g\x011\x11\x001\x00yi log\x10\x1b\x00ghjit\x12g\x012\x118where\x1br2r2is softmax function \x1b1and\x1b2denote 1st', 1);('dgas', 1);('train thecommgate', 1);('ghjt\x12g2r2be', 1);('data pairs hjityithatcovers agents time points', 1);('dgconsist', 1);('initial states form dataset', 1);('agent need communicationrepeat', 1);('label hjitwithyi', 1);('agent shouldcommunicate', 1);('threshold label', 1);('deactivation deactivation', 1);('time wecompare robustness values', 1);('agent jwill use communication', 1);('thechosen', 1);('time point tat time', 1);('agent jat', 1);('butdisable communication channel connection', 1);('full communication', 1);('likely cannotsatisfy specication generate trajectories', 1);('agent needs communicate rst use objective7 nal dataset train', 1);('raining comm gateto', 1);('full communication522', 1);('dandretrain catlnet', 1);('identical agents team minimize k\x16xit\x00\x16xidtk2in', 1);('fjxijtuijt xij0 xijd0 1n\x16uit \x16\x19\x16 xi0t\x12cap\x12l\x12b\x12o\x12fullg 0h\x0017where 201balances', 1);('l\x12cap\x12l\x12b\x12o\x12fullg\x00 nxi1t\x001xt0k\x16xit\x00\x16xidtk2stxijt', 1);('maximize objectivemax\x12cap\x12l\x12b\x12o1\x00', 1);('l\x12cap\x12l\x12b\x12o\x12g', 1);('dfxidji', 1);('team trajectories form dataset', 1);('initial states', 1);('nteam', 1);('policywe use', 1);('specication use therepair algorithm', 1);('whichcan x team trajectory', 1);('repair algorithm', 1);('catlinspired', 1);('coach shows learner solution isan adaptation learners behavior', 1);('hard alearner', 1);('unfamiliar demonstrations', 1);('facing', 1);('learner objectiveand demonstrations', 1);('unseen conditions', 1);('objective imitate mightfail', 1);('suboptimal solution hand ifoptimal demonstrations', 1);('objective human learner', 1);('givenan', 1);('training reliability', 1);('local optima thatviolates specication', 1);('complex policy', 1);('leung', 1);('states optimization step', 1);('toupdate\x12cap\x12l\x12b\x12o resample', 1);('kingma ba', 1);('stochastic optimizer', 1);('adam', 1);('optimization problem use', 1);('substitute constraints objective function', 1);('average approximatethe expectation', 1);('fjxjtujt 0h\x0016in practice', 1);('parameters \x12cap\x12l\x12b\x12othat maximizes objectivemax\x12cap\x12l\x12b\x12oepxj0\x02\x11x\x080\x00 \x01max\x00\x11x\x0800\x01\x01xj2jcuj\x03st \x16ut \x16\x19\x16 x0t\x12cap\x12l\x12b\x12o\x12fullgxjt', 1);('nd optimal', 1);('theteam trajectory', 1);('multiagent system fajjj2jg', 1);('different initial states rst objective', 1);('wewant generalize', 1);('agents communicate', 1);('network training', 1);('commgate521 raining policy networkswe', 1);('policy networks includingcapnet', 1);('training catlnetfollowing ctde', 1);('agents behave differently52', 1);('capabilitiesfed', 1);('trainable parameters increase number agents increases', 1);('parameters \x12cap\x12l\x12g\x12o thenumber', 1);('\x16ut \x16\x19\x16 x0t\x12cap\x12l\x12b\x12o\x12gnote framework agents', 1);('yaghoubi fainekos2019', 1);('constraint uj2ujas', 1);('parameters \x12o outputs control ujt hyperbolic tangent functionis', 1);('nncalled outnet', 1);('hjtis sentback agent jand', 1);('hjtthat guides agentsto generate', 1);('communicate time output', 1);('agents thoughtswho', 1);('parameters \x12b communication channel', 1);('parameters \x12g', 1);('agent communicatesthe', 1);('ie thethoughthjtis', 1);('parameters \x12capand use output as6learning', 1);('b1b2\x01\x01\x01bjcapjbi 1ifci2capjbi 0ifci62capj inputcapvjto', 1);('capvj', 1);('vectorizedrepresentation agent js capability', 1);('capvjbe', 1);('contains information history states', 1);('parameters \x12lfig 2above', 1);('short term memory lstm nn', 1);('thestate agent jat', 1);('extract vector', 1);('pj5 catlnet51 architecture catlnetthe', 1);('initial distribution', 1);('initial states xj0with', 1);('catlnetcan', 1);('beginning section training', 1);('agent observe state connectedto communication channel', 1);('training execution', 1);('state information', 1);('toimplement policies', 1);('nnbased', 1);('real time', 1);('control policy agentthat compute control', 1);('agent needs communicate time tand communication vectors hjtandhjtare', 1);('nds communication strategy ie', 1);('thealgorithm', 1);('limits communication storage realtime computation requirementin paper', 1);('approach intractablein practice', 1);('hence mpc', 1);('secondary objective', 1);('channel time steps whichis', 1);('problem time step', 1);('moreoversince', 1);('large communication vector', 1);('agent thecommunication channel ie hjtxj0t results', 1);('large storage space hjtxjt', 1);('central node', 1);('controller time information needs', 1);('entire team history information allagents', 1);('objective function', 1);('system ateach time', 1);('iecompute sequence', 1);('model predictive', 1);('2021a straightforward method', 1);('agents control time history states agent neededdue temporal requirements', 1);('priority constraint ensures objectivefunction', 1);('bottomsince satisfaction \x08is', 1);('catlfigure', 1);('energy cost communication5learning', 1);('secondary objective minimize total number times agents accessthe communication channel', 1);('satisfying \x15supujt2ujpj2jph\x001t0cujtin addition', 1);('h\x15hrz\x08is', 1);('cost function', 1);('c\x01is', 1);('fjxjt\x19jxj0thjthjt\x19jxj0thjthjt2uj 0h\x0015where\x11x\x080is', 1);('nd control policyujt \x19jxj0thjthjtand communication vectors hjtandhjtthat maximize objectivemax\x19jhjthjtj2j\x11x\x080\x00 \x01max\x00\x11x\x0800\x01\x01xj2jh\x001xt0c\x00\x19jxj0thjthjt\x01stxjt', 1);('initial statesfxj02x 0jjj2jg distributedaspjand', 1);('jwith', 1);('multiagent system', 1);('bandwidth channel formulate thejoint control communication synthesis problem asproblem', 1);('vector hjt2rncfrom channel dimension thecommunication vectors', 1);('agents haveaccess communication channel times time agent broadcast vectorhjt2rncto channel', 1);('agent observe state xjtat time', 1);('weassume', 1);('specication \x08', 1);('jthat', 1);('r4 problem formulation approachconsider', 1);('ground vehicle', 1);('cwhile', 1);('asubgure \x081is satisedbecause 6agents', 1);('example team trajectory', 1);('v6i1\x08i', 1);('region overall specication system \x08', 1);('\x086g025hx2mdelivery 6i6agents capability', 1);('times 1agent capability', 1);('5\x085g025hx2bground 2isince load bridge', 1);('\x084g025hx2rground 4i agents capabilityground', 1);('5time units', 1);('inspection', 1);('2agents capability', 1);('\x083hx2bground 1iu05hx2binspection 2i agentwith capability', 1);('v1andv2within', 1);('8time units2\x082hf025x2v1delivery 3ihf025x2v2delivery 3i3agents withcapability', 1);('cwithin', 1);('supplies region', 1);('\x081hf08x2cdelivery 6i6agents capability', 1);('capjfdelivery inspection', 1);('initaand', 1);('aerial vehicles', 1);('capjfdelivery ground', 1);('initgand', 1);('area ground vehicles', 1);('rin', 1);('jf123456ga', 1);('3a 4ground vehicles j2f1234gand2aerial vehicles j2f56g', 1);('x\x1ar2is', 1);('comparison use earthquake emergency response scenario denedin', 1);('satisfaction \x08example', 1);('future timepoint', 1);('formula \x08', 1);('time horizon', 1);('xtj', 1);('sound ie \x11x\x08t\x150if', 1);('denition \x11can', 1);('xat', 1);('formula \x08with respect team trajectory', 1);('exponential robustness', 1);('denotethe', 1);('robustness ie', 1);('xsatises', 1);('nxct \x15mcatl qualitative semantics ie', 1);('xtjt', 1);('xsatisestat', 1);('4whereiis indicator function ie', 1);('xj2jci\x00xjtj\x01', 1);('function nxct', 1);('formally', 1);('mindividual trajectories agents withcapabilitycsatisfyat timet', 1);('time tif', 1);('positive integer operators onesin', 1);('inner logic formulac2cap capability mis', 1);('thcmiis', 1);('3where \x08\x081and\x082are', 1);('truejtj\x08j\x081\x082j\x081\x082j\x081uab\x082', 1);('predicates \x16are', 1);('similar syntax', 1);('overteam trajectories', 1);('slight abuse terminology', 1);('xtjthe outer logic', 1);('trajectory xsatises', 1);('anindividual', 1);('true time points ab', 1);('becomestrue time point ab andgabstates stays', 1);('fabandalways gabaredened fabtrueuabandgabfab fabstates', 1);('true abare integer timepoints aandb temporal operators', 1);('true time point aband1must stay', 1);('temporal operator where1uab2means 2mustbecome', 1);('uabis', 1);('notconjunction anddisjunction', 1);('boolean', 1);('differentiable function', 1);('weassumefx ris', 1);('inner logic formulas \x16is apredicate form fxt\x150', 1);('syntaxtruej\x16jj12j12j1uab2 2where1and2are', 1);('individual trajectories', 1);('innerlogic outer logic', 1);('twolayer logic', 1);('catl syntax semanticscapability temporal logic', 1);('sun', 1);('individual trajectory waypoints withingiven time window', 1);('wecan nd local controller agent tracks', 1);('control constraint', 1);('long agents', 1);('generate sequence waypoints truedensetime dynamics agents heterogeneous', 1);('nominal dynamics', 1);('high level', 1);('parameters fact dynamicscan', 1);('integrator 1such agentscan', 1);('simplify agents dynamics', 1);('xj0txj0xjtand\x16 x0t \x16x0 \x16xtremark', 1);('agent j\x16xt xjtjjjj1and\x16ut ujtjjjj1be joint state andcontrol', 1);('ujuj0ujh\x001bethe sequence', 1);('agent indices capability c', 1);('jc3learning catlfjjc2capjgbe', 1);('capabilities teamtrajectory dene semantics', 1);('corresponding capabilities', 1);('captures theindividual trajectories', 1);('xfxjcapjgj2j', 1);('individual trajectory sequence xjxj0xjhthen team trajectory', 1);('thatj2jcapjcapthe trajectory agent j', 1);('capj\x12cap', 1);('teamj agenthas', 1);('cap', 1);('initial state xj0', 1);('probability densityfunction', 1);('xj0\x1ax letpjxj0rbe', 1);('mission specication agent', 1);('xjt ujt 01h\x001 1wherexjt2x andujt2uj\x1arnuare state control time tujis control spaceof agentj andhis nite time horizon', 1);('remark', 1);('discrete timedynamics relaxation', 1);('x\x12rnxand', 1);('state space', 1);('wherej2j denotesan agents index', 1);('x consider', 1);('jxjis thecardinality', 1);('bold calligraphic symbols', 1);('modelwe', 1);('preliminaries31', 1);('catlspecications', 1);('heterogeneous teams', 1);('atoc', 1);('reward function communication architecture', 1);('atocwhich', 1);('atoc jiang lu', 1);('bicnetpeng', 1);('commnet sukhbaatar', 1);('dial foerster', 1);('control communication policies', 1);('cooperative tasksmany', 1);('importance communication', 1);('networksin communication', 1);('context multiagent', 1);('stlnet', 1);('x controller', 1);('control systems', 1);('howeverstlnet', 1);('project sequence', 1);('method calledstlnet', 1);('stl mas catlimproving', 1);('agent system', 1);('data paper', 1);('work model', 1);('thoughnot', 1);('system model', 1);('infeasible inpractice paper', 1);('large number trials', 1);('howevermodelfree rl', 1);('stl muniraj', 1);('zhang', 1);('mas ltl sun', 1);('modelfree rl', 1);('agent systems temporallogic specications', 1);('synthesize control policies', 1);('aksaray', 1);('cai', 1);('li', 1);('reinforcement learning rl', 1);('realtime executions methods', 1);('online computation ofine', 1);('shot compute control online', 1);('aboveeither synthesize control', 1);('methods methods', 1);('differentiable robustness controlsynthesis', 1);('catlcatl', 1);('control synthesis', 1);('mip', 1);('buyukkocak', 1);('integral predicates', 1);('capabilitytemporal logic catl leahy', 1);('logics', 1);('methods tosynthesize', 1);('luo', 1);('kantaros zavlanos', 1);('schillingeret', 1);('chen', 1);('bothsolution', 1);('gilpin', 1);('pant', 1);('mixed integer programming mip raman', 1);('optimization problems', 1);('forltl fragments', 1);('roughly', 1);('signicant attention recentyears', 1);('synthesis temporal logic specications', 1);('related workcontroller', 1);('show controland communication policies', 1);('training improves performance', 1);('control policy communication strategygiven', 1);('main contributions paper twofold', 1);('satisfying trajectories toguide training', 1);('satises thecatl specication use repair algorithm generate dataset', 1);('design repair scheme x team trajectory', 1);('hencewe', 1);('dataset expert demonstrations', 1);('expert demonstrations helpthe optimizer converge', 1);('leung pavone', 1);('literature eg', 1);('complex hasbeen', 1);('policy scratch difcult', 1);('additional parameters', 1);('neural networks', 1);('catlnetwhich', 1);('control policy communication strategy', 1);('boththe', 1);('useful information', 1);('necessary transmit', 1);('control policy communicationstrategy agents communicate', 1);('learns communication strategy ie agent needs tocommunicate', 1);('challenging problem framework paper', 1);('utilize resources', 1);('necessary practice communication resources', 1);('multiple agents communication', 1);('observe state', 1);('specication training policyoffline agent compute feedback control realtime', 1);('control policy foreach agent', 1);('framework train', 1);('vulnerable disturbancesin paper', 1);('openloop controller', 1);('shot results openloop controller', 1);('specication formulatedas optimization problem robustness objective function', 1);('continuous real number measures', 1);('catlness', 1);('nov', 1);('unlimitedarxiv221211792v1 cslg', 1);('distribution statement approved', 1);('quantitative semantics', 1);('qualitative semantics whetherrequirements', 1);('different capabilities', 1);('mas theagents', 1);('concrete temporal constraints heterogeneous', 1);('rich task requirements', 1);('2021in paper focus', 1);('leahy', 1);('mas sahin', 1);('work focusedon', 1);('specication languages control systems', 1);('temporal logic stl maler nickovic', 1);('linear temporal logicltl pnueli', 1);('natural languages temporal logics', 1);('theirexpressivity similarity', 1);('coordination solutions difcult compute realtime', 1);('methods focus paper', 1);('true cases agentsare', 1);('complex need efcient way dene thesetasks', 1);('collective tasks', 1);('masas', 1);('multiagent', 1);('coordination heterogeneous', 1);('realworld missions', 1);('introductionmany', 1);('reinforcement learning distributedcontrol communication1', 1);('specication high success ratekeywords multiagent systems temporal logic', 1);('system online', 1);('catlnetthe catlnet', 1);('training efciency overall performance', 1);('guidecatlnets training', 1);('plan repair algorithm', 1);('large teams easilycatlnet', 1);('maximize wherenetwork parameters', 1);('robustness measure', 1);('catlnet takingadvantage', 1);('novel neural network model', 1);('specications policiesare', 1);('complexmission requirements', 1);('control policies heterogeneous multiagent system', 1);('massachusetts usaeditors r firoozi n mehr e yel r antonova j bohg schwager kochenderferabstractin', 1);('massachusetts usakevin leahy kevin leahy llmitedumit lincoln laboratory lexington usazachary serlin zachary serlin llmitedumit lincoln laboratory lexington usacalin belta cbelta bueduboston', 1);('bueduboston', 1);('specicationswenliang liu wliu', 1);('learning dynamics controlcatlnet learning communication coordination', 1);('annual', 1);('xx114', 1);('research vol', 1);('proceedings machine learning', 1);