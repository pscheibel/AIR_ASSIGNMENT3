('cpg', 17);('cpgs', 7);('lstm', 7);('international conference', 7);('drl', 6);('equation', 6);('mlp', 6);('robotics', 6);('ieeersj', 6);('mpc', 4);('figure', 4);('hz', 4);('weight', 4);('velocity', 4);('ieee', 4);('ieee robotics automation', 4);('letters vol', 4);('central patterngenerators', 3);('visual cpgrl', 3);('rhythmic behavior', 2);('navigation tasks', 2);('comparedwith', 2);('recent works', 2);('depth cameras', 2);('gpu', 2);('rough terrain', 2);('mit', 2);('energy consumption', 2);('mlps', 2);('iv', 2);('ris', 2);('cartesian', 2);('pd', 2);('ii', 2);('performance v\x03bx 035ms awide corridor', 2);('amplitude xdirection', 2);('weights wijin', 2);('international journal', 2);('intelligentrobots systems', 2);('challenging terrain', 2);('robotics automation icra ieee', 2);('systems', 2);('wellhausen v koltun hutterlearning', 2);('quadrupedal locomotion', 2);('robot learning', 2);('z xie x da', 2);('panne', 2);('annualconference robot learning', 2);('iros ieee', 2);('g bellegarda q nguyen robust', 2);('visual cpgrl learning', 1);('pattern generatorsfor visuallyguided quadruped navigationguillaume bellegarda auke ijspeertabstract', 1);('present framework', 1);('ie systems', 1);('oscillators thedeep reinforcement learning', 1);('framework bothexteroceptive proprioceptive', 1);('agent learnsto modulate intrinsic oscillator setpoints amplitude andfrequency', 1);('differentoscillators track velocity commands', 1);('collisionswith environment', 1);('different neural networkarchitectures ie memoryfree', 1);('implicit interoscillator couplings', 1);('varyingthe strength', 1);('weights oscillatordynamics equations train policies simulation andperform simtoreal', 1);('unitree go1', 1);('quadrupedwhere observe robust navigation variety scenariosour results', 1);('policy representations', 1);('explicit interoscillator couplings benecial fora', 1);('successful simtoreal', 1);('videoresults', 1);('ntroductionlegged', 1);('variable terrainlocomotion', 1);('sorts dynamiccapabilities animals order hope', 1);('unknown environments exteroceptive', 1);('isnecessary planning control purposes', 1);('exteroceptive measurementsare', 1);('dimensional meaning systems', 1);('hand animals process highdimensional information', 1);('control spinal cord andhigher control centers eg motor cortex', 1);('concept motor commands', 1);('fromhigher control centers ie biological parallel currentoptimal control methods', 1);('inthis', 1);('central pattern generatorknown', 1);('animals spinal cords modulateits parameters feedback exteroceptive andproprioceptive', 1);('robust navigation policiesa', 1);('related work1 biologyinspired', 1);('pattern generatorsare', 1);('neural circuits', 1);('spinal cords vertebrateanimals', 1);('patternsof highdimensional rhythmic output signals evidencefrom nature', 1);('various robotthis research', 1);('swiss national science', 1);('foundationsnsf', 1);('part project', 1);('no197237', 1);('authors thebiorobotics', 1);('laboratory ecole polytechnique federale', 1);('lausanneepfl', 1);('guillaumebellegarda aukeijspeertepflchfig', 1);('unitree go1hardware', 1);('quadrupedal robots', 1);('usedas tool replicate', 1);('locomotion fromseveral points', 1);('role sensory inputreexes', 1);('mechanical design', 1);('quadruped', 1);('evidence gaitgeneration transitions', 1);('simple forcefeedback', 1);('feedback touch sensors', 1);('oraccelerate transitions swingstance phases', 1);('otherworks', 1);('virtual modelcontrol', 1);('robustness 79sensory feedback', 1);('proprioceptiveinformation example camera gyroscope usedas feedback', 1);('external sensory information', 1);('sudden obstacle appearances', 1);('modelbased', 1);('conventional', 1);('impressive performance realworld robot locomotion', 1);('online optimization problems', 1);('modelpredictive', 1);('signicant domain knowledgeand', 1);('new environments', 1);('development ie uneven slippery terrainvision', 1);('capabilities blindpolicies', 1);('perceptiondata constraints optimization process', 1);('elevation map environmentarxiv221214400v1 csro', 1);('dec', 1);('grid map', 1);('plane segmentation', 1);('software uses', 1);('methods havealso', 1);('accuracy map', 1);('learningbased', 1);('deep', 1);('reinforcement learningdrl', 1);('attractive solution train controlpolicies robust external disturbances unseenenvironments simtoreal', 1);('similarly', 1);('successful results trainingblind control policies proprioceptive', 1);('joint commands quadrupedal robotssuch approaches', 1);('successful locomotioncontrollers', 1);('blind', 1);('imitatinganimal motions', 1);('different gaitsthrough', 1);('input recentworks', 1);('similarly mpc', 1);('occupancy maps', 1);('obstacle avoidance endtoend training', 1);('rough terrain use', 1);('height maps', 1);('footstep planning processes controlpolicy', 1);('mpcto', 1);('track footstep plan', 1);('learning', 1);('state representationof environment depth images', 1);('control policy alsoallows', 1);('additionalworks', 1);('gap crossing', 1);('fullight phases', 1);('simtoreal transfer directly', 1);('joint space commands challengingproblem', 1);('deep networks millions trainingsamples addition complexity', 1);('craftingreward functions', 1);('height difculties simtoreal', 1);('dynamics actuatorsthere', 1);('robustness ofpolicies', 1);('simulation domain randomization46', 1);('dynamics randomization', 1);('additionto sufcient simulation environmental noise accuratedynamics', 1);('policy representation terms neuralnetwork architecture', 1);('important role simtoreal', 1);('previous', 1);('network ie', 1);('feedforward networks', 1);('mlps5', 1);('action space', 1);('phase drl', 1);('action space choicehas', 1);('large effect simtorealperformance', 1);('local optima', 1);('joint positionsrecent', 1);('task space foot positions 5456or', 1);('time component phase frameworksuch', 1);('modulating trajectory generators pmtgfor minitaur', 1);('anymal', 1);('additionallyincorporating', 1);('phase encodings facilitates learning differentgaits', 1);('thefeedback terms', 1);('different slopes', 1);('toupdate parameters', 1);('cpgzmp', 1);('engine outputjoint target residuals adapt commands differentterrains', 1);('shi', 1);('parameters foot trajectory generator', 1);('joint targetresiduals locomote variety environments includingstairs slopes', 1);('previous work proposedcpgrl', 1);('oscillator intrinsicamplitude frequency oscillator togetherforms', 1);('central pattern generator', 1);('cpgnetwork', 1);('explicitcouplings oscillators', 1);('work ofowaki', 1);('proprioceptive sensingb', 1);('contributionin', 1);('previous work includeterrainawareness feedback policy network whichenables navigation', 1);('terrain test differentneural network architectures', 1);('networkslstms nd', 1);('networks aremore robust simtoreal', 1);('agent canlearn', 1);('implicit couplings oscillators policynetwork experience', 1);('test varyingexplicit couplings oscillators dynamicsequations couplings oscillators', 1);('toexist biological', 1);('recent work', 1);('andthat sensory feedback', 1);('modulation mightplay', 1);('important role interoscillator synchronizationfor simtoreal', 1);('explicit couplingimproves policy robustness', 1);('concatenatinghighdimensional noisy exteroceptive inputs withlowerdimensional proprioceptive', 1);('summary thiswork addresses', 1);('visionand learning', 1);('useful forbetter simtoreal performance', 1);('gaits bestbe', 1);('andor interoscillatorcouplings', 1);('cpgthe', 1);('rest paper', 1);('iiprovides', 1);('background details', 1);('reinforcement learningand', 1);('pattern generators', 1);('iii', 1);('ourdesign choices integration', 1);('pattern generatorsand', 1);('showsresults analysis learning controller simtoreal', 1);('neural network architectures', 1);('interoscillator couplings', 1);('brief conclusion isgiven section', 1);('vii', 1);('ackgrounda reinforcement learningin', 1);('reinforcement learning framework', 1);('agentinteracts environment', 1);('markov decisionprocess mdp mdp', 1);('saprwheresis', 1);('ais', 1);('actions availableto agentps\x02a\x02s', 1);('transition functionwherepst1jstatgives probability statest', 1);('state st1 andrs\x02a\x02s', 1);('reward function', 1);('rstatst1gives', 1);('reward state st', 1);('state st1 agent goal', 1);('apolicy\x19that maximizes', 1);('pattern generatorswhile', 1);('number neural oscillators proposedto', 1);('circuits focus', 1);('phase oscillators', 1);('behaviors salamander robot\x7fria\x10a4\x16i\x00ri\x00ri\x111\x12iixjrjwijsin\x12j\x00\x12i\x00 ij 2whereriis', 1);('current amplitude oscillator \x12iis thephase oscillator \x16iandiare intrinsic amplitudeand frequency ais', 1);('theconvergence factor', 1);('couplings', 1);('weights wijand phase biases ijfor', 1);('robot single', 1);('matrix \x08representinga trot gait', 1);('as\x0826640\x19 \x19 0\x00\x190 0\x00\x19\x00\x190 0\x00\x190\x19 \x19 037753where rowcolumn order', 1);('front left fl frontright fr hind left hl hind right hr', 1);('parameters awij\x16iieither hand', 1);('evolutionary algorithms ascmaes', 1);('possible map oscillator states totask space foot trajectories track joint levelwith inverse kinematics', 1);('resultsin specic', 1);('openloop gait', 1);('robustto external disturbancesiii l', 1);('earning centralpattern generators visual navigationin', 1);('section describe', 1);('cpgintegrated', 1);('deepreinforcement learning framework design decisions', 1);('visual navigation controllers', 1);('robotsat high level agent', 1);('input exteroceptive andproprioceptive', 1);('cpgstate', 1);('learns modulate', 1);('parameters legwith', 1);('reinforcement learning track velocity commandswhile', 1);('collisions type learning representsan approximation motor learning animals namelyhow', 1);('brain centers motor cortex thecerebellum', 1);('modulation signals', 1);('circuitsin spinal cord control diagram method isshown', 1);('components belowa action', 1);('spacewe', 1);('equations', 1);('leg i2f1234g', 1);('outputwe map foot trajectories', 1);('space similarto', 1);('dynamic omnidirectionalmovements dene', 1);('variable representamplitude ydirection', 1);('leg frame seefigure', 1);('bothamplitudes omnidirectional locomotion updatethe', 1);('reect xandycomponents', 1);('foreach limb dene', 1);('oscillator\x7frxiax\x10ax4\x16xi\x00rxi\x00rxi\x114\x7fryiay\x10ay4\x16yi\x00ryi\x00ryi\x115\x12ii12xjrxjryjwijsin\x12j\x00\x12i\x00 ij 6our action space', 1);('modulate intrinsicoscillator amplitudes phases learning modulate\x16xi\x16yi andifor leg', 1);('agent adapteach states online realtime', 1);('thusfor', 1);('omnidirectional navigation task action space canbe', 1);('\x16x\x16y2r12 agent selectsthese parameters', 1);('limitsfor input training \x16x\x16y2122045hzandaxay50 map oscillator states joint commands werst compute', 1);('foot positions thencalculate', 1);('joint positions inverse kinematicsthis approximation', 1);('layer andone pattern formation layer', 1);('foot positioncoordinates', 1);('followsxifoot\x00dstepfrxicos\x12i 7yifootdstepfryicos\x12i 8zifoot\x00hgcsin\x12iifsin\x12i0\x00hgpsin\x12iotherwise9wheredstep', 1);('maximum step length robotheightgcis max ground clearance swinggpis max ground penetration stance andfr 2r\x00\x16min\x16max\x00\x16min\x001', 1);('\x16min 1and\x16max', 1);('foot varywithin\x06dstepin bothxandydirections leg framepolicyimu base orientationvelocity motor anglesvelocities foot contact booleansstateestimationik', 1);('pd controlcommandhrhlflfrheight measurementsfig', 1);('control architecture learning', 1);('central pattern generators', 1);('velocity commandsterrain height measurements proprioceptive measurements', 1);('states policy network', 1);('parameters \x16x\x16yandforeach legifront', 1);('left fl front right fr hind left hl hind right hr cpg', 1);('foot positions pd arethen', 1);('joint angles inverse kinematics', 1);('torques control policy selectsactions', 1);('khzz m12fig', 1);('mapping cpg', 1);('foot positions leftin', 1);('xzplane', 1);('ground clearance gc ground penetration gp maxstep length dstep design parameters whereas', 1);('states rxand\x12control amplitude phase', 1);('xyplane', 1);('coordinatingomnidirectional motion leg frame arrow shows', 1);('phase motionwith', 1);('points \x16x 2\x16y', 1);('thefulldstep and12dstep respectivelya sample visualization foot trajectory aset parameters', 1);('theseparameters', 1);('possible specify behaviors arein general difcult', 1);('learning jointcommands example', 1);('track history statesand exasperates temporal credit assignment problem ofreinforcement learning framework randomlysamplehgc', 1);('training ie agent noexplicit observation parameters', 1);('user specify robotheight', 1);('foot ground clearance deploymentb', 1);('observation spaceour', 1);('observation space', 1);('velocity commandsand measurements', 1);('available exteroceptive andproprioceptive', 1);('exteroceptive measurementsconsist', 1);('terrain height map', 1);('maround robot base', 1);('insimulation', 1);('ground truth terrain height data knownand hardware grid', 1);('elevation map', 1);('grid map 23the proprioceptive', 1);('body stateorientation linear angular velocities joint statepositions velocities foot contact booleans', 1);('thelast', 1);('policy network', 1);('exteroceptiveand proprioceptive measurements', 1);('compared', 1);('theexteroceptive proprioceptive', 1);('subjectto measurement noise onboard sensors', 1);('source ofstability method eases simtoreal transfertable', 1);('ppo hyperparametersparameter valuebatch', 1);('4096x24minibach size', 1);('4096x6number epochs 5clip range 02entropy coefcient 001discount factor 099gae discount factor', 1);('kldivergence', 1);('rate adaptivec', 1);('reward functionwe', 1);('design reward function track', 1);('bodyvelocity commands body frame xandydirectionsas', 1);('yaw rate \x03bz', 1);('termsto minimize', 1);('body velocities', 1);('aspenalize work', 1);('thereward function summation', 1);('terms\x0flinear velocity', 1);('body xdirectionfv\x03bx\x00vbx\x0flinear velocity', 1);('body ydirectionfv\x03by\x00vby\x0fangular velocity', 1);('body yaw ratef\x03bz\x00bz\x0flinear velocity penalty body zdirection\x00v2bz\x0fangular velocity penalty body roll pitch rates\x00jjbxyjj2\x0fwork\x00j \x01qt\x00qt\x001jwhere \x01\x03represents', 1);('command andfx exp \x00jjxjj2025 terms', 1);('with3dt075dt05dt2dt005dt0001dt wheredt 001is control policy time step', 1);('notably', 1);('iiia', 1);('additional termson foot', 1);('base motion', 1);('variable heightterrain training environment', 1);('notpossible track velocity commands times ie ifthere obstacles way', 1);('weight theforward velocity reward term policy learns preferdeviations velocity commandspenalties ie toturn', 1);('obstacle headond', 1);('neural network architectureswe', 1);('different neural network architecturesto map', 1);('observation actions', 1);('intrinsicoscillator amplitudes phases rst purelytable', 1);('ii randomized', 1);('parameters training rangesparameter', 1);('lower bound upper bound unitsv\x03bx06', 1);('gainkp', 1);('joint gainkd', 1);('mass', 1);('body link', 1);('added', 1);('base mass', 1);('kgcoefcient friction', 1);('feedforward network multilayer perceptron', 1);('mlpconsisting', 1);('architecture memoryenablednetwork', 1);('shortterm memory lstmlayer', 1);('units memoryenablednetwork', 1);('biological parallel ie humans', 1);('full refresh exteroceptive', 1);('andcan walk', 1);('terrain alsoanticipate', 1);('robustness simtoreal', 1);('event noisy measurements latencye', 1);('training detailswe', 1);('isaac gym', 1);('physx', 1);('physicsengine training environment', 1);('unitree go1quadruped', 1);('high throughputwhere simulate', 1);('go1s', 1);('parallel singlenvidia', 1);('rtx', 1);('ppo', 1);('train thepolicy relevant hyperparameters', 1);('iwith', 1);('learncontrol policies', 1);('maximum episode length', 1);('seconds theenvironment resets agent base thigh comesin contact terrain ie', 1);('box groundwe employ terrain curriculum', 1);('terrainto random boxes', 1);('reset sample', 1);('new parametershandgcfor', 1);('oscillator states jointcommands agent', 1);('locomote varyingbody heights step heights', 1);('new velocity commandsfv\x03bxv\x03by\x03bzgare', 1);('applydomain randomization', 1);('physical mass properties andcoefcient friction', 1);('random direction tothe base', 1);('seconds noise', 1);('theproprioceptive measurements', 1);('gaussian', 1);('noise theexteroceptive measurements', 1);('standard deviation 01the control frequency policy', 1);('andthe torques', 1);('joint positions', 1);('khz equations oscillatorsequations', 1);('duringtraining', 1);('resample joint', 1);('controller gains eachenvironment reset', 1);('duringdeployment use', 1);('kp100 kd2iv e xperimental results discussionin', 1);('section report results learning visualnavigation locomotion controllers', 1);('cpgrl snapshotsof', 1);('supplementary video forclear visualizations', 1);('questions1 policy network architecture', 1);('thesimtoreal transfer2 role neural oscillator', 1);('thesimtoreal transfer3 agent', 1);('turning betweendifferent oscillators amplitudesa', 1);('simtoreal transferas', 1);('intel realsense', 1);('t265 unitree go1', 1);('thed435i', 1);('point cloudsto elevation', 1);('construct amap area', 1);('t265', 1);('provideshigh accuracy localization run policy query thismap 17\x0211points', 1);('training concatenate proprioceptive sensingmeasurements', 1);('unitree', 1);('previous actionsb', 1);('role policy architecture interoscillator couplingwe', 1);('train policies neural network architecturesmlp', 1);('iiid foreach', 1);('architecture train', 1);('separate policies', 1);('strong interoscillator', 1);('weights namelywijf00204060810gin', 1);('total of6', 1);('iewij0 policies', 1);('approximate trot', 1);('identical returns insimulation regardless architecture oscillator couplingthis shows', 1);('anegative effect ability policy adapt sensoryfeedback', 1);('omnidirectional locomotion1', 1);('corridor test', 1);('rst test policies', 1);('mwidecorridor command', 1);('velocity v\x03bx035msfor', 1);('seconds test', 1);('successful simtoreal transfers', 1);('results from10 rollouts policy', 1);('iii lstm', 1);('success rate', 1);('mlpand lstm', 1);('strong weak couplinghowever', 1);('transportfor', 1);('amplitudes andfrequencies', 1);('policies locomote', 1);('step length', 1);('thelstm', 1);('velocity slightlymore', 1);('overshoot command', 1);('slower2 navigation', 1);('test', 1);('test policies navigation environment', 1);('obstacles dene failure robot', 1);('velocity v\x03bx 035ms', 1);('seconds andmean results', 1);('rollouts policy summarizedtable', 1);('iii simtoreal', 1);('034mean \x12hz', 1);('iv simtoreal', 1);('041mean \x12hz', 1);('tables v vi', 1);('obstacles agentis', 1);('velocity commandsforv\x03byand\x03bz tests', 1);('mlp lstmpolicies', 1);('benecial successfulnavigation terrain', 1);('success rates architectures', 1);('theexplicit', 1);('reject noise latency associatedwith highdimensional', 1);('relative proprioceptiveexteroceptive measurements', 1);('proveto overall robust', 1);('wall orif angle nonsymmetrical height map measurements agent', 1);('able turn', 1);('angle andthen', 1);('thewall agent', 1);('modulation omnidirectional locomotionwe', 1);('agent modulates', 1);('states toproduce omnidirectional locomotion terrain', 1);('laterallyin body ydirectionsv\x03by\x0604ms turnin place directions \x03bz\x0607rads videoshows gait', 1);('smooth consistent entiretyof motion', 1);('frequency defaultgo1 controller lateral motions', 1);('directions coordination canbe', 1);('xandyamplitudes turning inplace approximate trot gait', 1);('throughoutall commands turning', 1);('example hind rightfoot', 1);('right thebody frame', 1);('thereverse', 1);('true turning', 1);('foot hasthe', 1);('body framev c', 1);('onclusionin', 1);('framework learning', 1);('central pattern generators exteroceptive', 1);('v simtoreal', 1);('performance v\x03bx 035ms atest navigation environment', 1);('mlppolicies', 1);('031mean \x12hz', 1);('vi simtoreal', 1);('performance v\x03bx035ms testnavigation environment', 1);('lstmpolicies', 1);('040mean \x12hz', 1);('states omnidirectional commands v\x03by 04msfrom', 1);('s\x03bz 07rads from1823 and\x03bz\x0007rads', 1);('theyamplitudesryproduce', 1);('locomotion system lateral commands turningin place observe coordination xandyamplitudesdeep reinforcement learning framework agent learnsto modulate intrinsic oscillator amplitudes frequencies', 1);('limbs trackomnidirectional velocity commands', 1);('learning todeviate commands order', 1);('collisions withobstacles results', 1);('lstms', 1);('robustness feedforwardnetworks', 1);('highdimensional inputs noise latency', 1);('dynamics equationsis benecial simtoreal navigation task doesnot', 1);('agents ability', 1);('robust adaptive andefcient policies', 1);('work focus', 1);('ascompare jointspace', 1);('understanding biological parallels learning', 1);('tifanny pereira portela', 1);('initialtests elevation', 1);('thankfranc ois', 1);('longchamp', 1);('camera mount andalessandro', 1);('crespi', 1);('hardware setupreferences1', 1);('j ijspeert', 1);('central pattern generators locomotion control inanimals robots review', 1);('neural networks', 1);('neuroscience2 fukuoka h kimura h cohen adaptive', 1);('robot irregular terrain', 1);('research vol 22no', 1);('spr', 1);('tuleu vespignani ajallooeian e badriand j ijspeert towards', 1);('dynamic trot gait locomotion', 1);('designcontrol', 1);('experiments cheetahcub compliant quadrupedrobot', 1);('research vol 32no', 1);('owaki kano k nagasawa tero ishiguro simplerobot', 1);('physical interlimb communication', 1);('royal society', 1);('interface', 1);('vol 10no', 1);('owaki ishiguro', 1);('spontaneousgait transitions', 1);('scienticreports', 1);('righetti j ijspeert pattern', 1);('generators sensory feedback control', 1);('ieee internationalconference robotics automation', 1);('ajallooeian pouya sproewitz j ijspeert centralpattern', 1);('virtual model control quadrupedrough terrain locomotion', 1);('conferenceon robotics automation', 1);('ajallooeian gay tuleu spr', 1);('j ijspeertmodular', 1);('control limit cycle locomotion', 1);('v barasuol j buchli', 1);('semini frigerio e r de pieri', 1);('g caldwell', 1);('reactive controller framework quadrupedallocomotion', 1);('ieee internationalconference robotics automation ieee', 1);('gay j santosvictor ijspeert learning', 1);('robot gait', 1);('neural networks sensory feedback function', 1);('saputra n takesue k wada j ijspeert n kubotaaquro', 1);('catlike adaptive', 1);('robot novel bioinspiredcapabilities', 1);('frontiers robotics ai', 1);('saputra j botzheim j ijspeert n kubota combiningreexes', 1);('external sensory information neuromusculoskeletalmodel control', 1);('ieee transactions', 1);('j di carlo p wensing', 1);('katz g bledt kim dynamiclocomotion', 1);('mit cheetah', 1);('convex modelpredictivecontrol', 1);('intelligentrobots systems iros', 1);('kim j di carlo', 1);('katz g bledt kim highly', 1);('wholebody impulse control modelpredictive control arxiv preprint arxiv190906586', 1);('sombolestan chen q nguyen adaptive', 1);('conferenceon intelligent robots systems iros', 1);('bellicoso', 1);('jenelten', 1);('gehring hutter dynamiclocomotion', 1);('online nonlinear motion optimization forquadrupedal robots', 1);('letters vol 3no', 1);('kim carballo j di carlo', 1);('katz g bledt', 1);('lim', 1);('kim vision', 1);('dynamic exploration', 1);('terrainwith smallscale', 1);('ieee internationalconference robotics automation icra ieee', 1);('r grandia', 1);('jenelten yang', 1);('farshidian hutterperceptive', 1);('locomotion nonlinear model predictive controlarxiv preprint arxiv220808373', 1);('jenelten r grandia', 1);('farshidian hutter tamolsterrainaware', 1);('motion optimization', 1);('ieeetransactions robotics', 1);('agrawal chen rai k sreenath visionaided', 1);('dynamicquadrupedal locomotion discrete terrain', 1);('motion libraries in2022', 1);('p fankhauser bloesch hutter probabilistic', 1);('mobile robots', 1);('uncertain localization', 1);('ieee roboticsand automation', 1);('ral', 1);('p fankhauser bloesch', 1);('gehring hutter r siegwartrobotcentric', 1);('uncertainty estimatesininternational conference', 1);('climbing walking robotsclawar', 1);('p fankhauser hutter universal grid', 1);('libraryimplementation', 1);('case rough terrain', 1);('navigation inrobot', 1);('ros complete reference volume1 koubaa ed springer', 1);('miki', 1);('wellhausen r grandia', 1);('jenelten homberger', 1);('hutter elevation', 1);('locomotion navigation usinggpu arxiv preprint arxiv220412876', 1);('hoeller n rudin', 1);('choy anandkumar hutter neural', 1);('scene representation locomotion', 1);('ieeerobotics automation', 1);('j tan zhang e coumans iscen bai hafner bohezand v vanhoucke simtoreal learning', 1);('agile locomotion', 1);('j hwangbo j lee dosovitskiy bellicoso v tsounisv koltun hutter learning', 1);('dynamic motor skillsfor', 1);('robots science', 1);('kumar z fu pathak j malik rma rapid', 1);('robots arxiv preprint arxiv210704034', 1);('j lee j hwangbo', 1);('sciencerobotics', 1);('g ji j mun h kim j hwangbo concurrent', 1);('training acontrol policy state estimator', 1);('dynamic robust leggedlocomotion', 1);('margolis g yang k paigwar chen p agrawalrapid', 1);('reinforcement learning arxiv preprintarxiv220502824', 1);('peng e coumans zhang tw lee j tan levinelearning', 1);('agile robotic locomotion skills', 1);('z fu kumar j malik pathak minimizing', 1);('emergence gaits', 1);('robots 5thannual conference', 1);('z fu kumar agarwal h qi j malik pathakcoupling', 1);('vision proprioception navigation', 1);('ieeecvf', 1);('computer vision', 1);('recognition', 1);('r yang zhang n hansen h xu x wang learningvisionguided', 1);('quadrupedal locomotion endtoend crossmodaltransformers arxiv preprint arxiv210703996', 1);('imai zhang zhang kierebinski r yang qin', 1);('wang visionguided', 1);('wild withmultimodal delay randomization arxiv preprint arxiv210914549', 1);('miki j lee j hwangbo', 1);('robust perceptive locomotion quadrupedal robots thewild science', 1);('n rudin hoeller p reist hutter learning', 1);('reinforcement learning 5thannual conference', 1);('v tsounis alge j lee', 1);('farshidian hutter deepgaitplanning', 1);('control quadrupedal gaits', 1);('gangapurwala geisert r orsolino fallon havoutisrloc terrainaware', 1);('reinforcement learningand optimal control', 1);('ieee transactions robotics', 1);('hoeller', 1);('wellhausen', 1);('farshidian hutter learninga', 1);('state representation navigation', 1);('yu jain escontrela iscen p xu e coumans haj tan zhang visuallocomotion learning', 1);('oncomplex terrains vision 5th', 1);('annual', 1);('robotlearning', 1);('kh lee nachum zhang guadarrama j tan', 1);('yu piars accelerating', 1);('visuallocomotionwith predictive information representations arxiv preprintarxiv220713224', 1);('babich garg', 1);('glidegeneralizable quadrupedal locomotion diverse environments witha centroidal model arxiv preprint arxiv210409771', 1);('margolis chen k paigwar x fu kim', 1);('kimand p agrawal learning', 1);('pixels 5th', 1);('j tobin r fong ray j schneider', 1);('zaremba p abbeeldomain', 1);('deep neural networks fromsimulation', 1);('real world', 1);('intelligent robots systems', 1);('exarchos jiang', 1);('yu', 1);('k liu policy', 1);('viakinematic domain randomization adaptation', 1);('ieeeinternational', 1);('peng andrychowicz', 1);('zaremba p abbeel simtoreal', 1);('robotic control dynamics randomizationin2018', 1);('international conference robotics automationicra', 1);('mordatch k lowrey e todorov ensemblecio fullbodydynamic', 1);('motion planning transfers', 1);('physical humanoids in2015', 1);('intelligent robots', 1);('babich garg dynamicsrandomization', 1);('case study quadrupedal locomotionin2021', 1);('robotics automationicra ieee', 1);('j siekmann k', 1);('j warila fern j hurst blindbipedal', 1);('stair traversal', 1);('simtoreal reinforcement learning arxivpreprint arxiv210508328', 1);('j siekmann valluri j dao', 1);('bermillo h duan fern', 1);('hurst learning memorybased', 1);('humanscale bipedallocomotion robotics', 1);('chen', 1);('zhang', 1);('mueller rai k sreenathlearning', 1);('torque control quadrupedal locomotion arxiv preprintarxiv220305194', 1);('g bellegarda k byl training', 1);('task space speed upand', 1);('reinforcement learning', 1);('ieeersj internationalconference intelligent robots systems', 1);('deepreinforcement learning arxiv preprint arxiv201107089', 1);('deep reinforcement learning arxiv preprintarxiv210306484', 1);('iscen k caluwaerts j tan zhang e coumans v sindhwaniand v vanhoucke', 1);('trajectory generators inconference', 1);('robot learning pmlr', 1);('shao jin x liu', 1);('h wang', 1);('yang learningfree', 1);('gait transition', 1);('controllerarxiv preprint arxiv220100206', 1);('yang zhang e coumans j tan', 1);('boots fast', 1);('andefcient locomotion', 1);('gait transitions 5th', 1);('li r lowe ziemke humanoids', 1);('learning walk', 1);('anatural', 1);('cpgactorcritic architecture', 1);('frontiers neurorobotics', 1);('kasaei abreu n lau pereira', 1);('p reis acpgbased', 1);('versatile locomotion framework', 1);('proximalsymmetry loss arxiv preprint arxiv210300928', 1);('h shi', 1);('zhou h zeng', 1);('wang dong j li k wangh tian qh meng reinforcement', 1);('learning withevolutionary trajectory generator general approach quadrupedallocomotion arxiv preprint arxiv210906409', 1);('g bellegarda ijspeert cpgrl learning', 1);('ieee robotics automationletters', 1);('r thandiackal k melo', 1);('paez j herault kano k akiyamaf boyer ryczko ishiguro j ijspeert emergenceof', 1);('localhydrodynamic force', 1);('r sutton g barto reinforcement', 1);('learning introduction ser', 1);('adaptive', 1);('computation machine learning', 1);('j ijspeert crespi ryczko jm cabelguen fromswimming', 1);('salamander robot', 1);('spinalcord model science vol', 1);('n hansen', 1);('cma evolution strategy tutorial arxiv preprintarxiv160400772', 1);('mccrea rybak', 1);('organization mammalianlocomotor rhythm pattern generation brain research reviews vol', 1);('v makoviychuk', 1);('wawrzyniak guo lu k storeym macklin hoeller n rudin allshire handa', 1);('isaac', 1);('high performance', 1);('physics simulation forrobot learning arxiv preprint arxiv210810470', 1);('unitree robotics go1', 1);('j schulman', 1);('wolski p dhariwal radford', 1);('klimov proximal', 1);('policy optimization algorithms', 1);('corr', 1);('vol abs170706347', 1);