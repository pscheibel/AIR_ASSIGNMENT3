('resgrad', 39);('tts', 39);('fastspeech', 19);('ddpms', 12);('iclr', 7);('figure', 7);('gaussian', 6);('ren', 6);('sample quality', 6);('diffusion models', 6);('ddpm', 6);('resgrad4', 5);('liu', 5);('chen', 5);('step', 4);('prodiff', 4);('diffspeech', 4);('residual', 4);('rtf', 4);('diffusion probabilistic models', 4);('kong', 4);('neurips', 3);('icml', 3);('inneurips', 3);('resunet', 3);('mos', 3);('batch size', 3);('hz', 3);('fft', 3);('gradtts', 3);('gradtts popov', 3);('speech quality', 3);('inference speed', 3);('compared', 3);('huang', 3);('popov', 3);('number inference steps', 3);('slight', 2);('sounds', 2);('high quality acoustics', 2);('inicml', 2);('interspeech', 2);('cmos', 2);('diffgantts', 2);('iteration steps', 2);('ddpmbased', 2);('gt', 2);('prodiff huang', 2);('adam', 2);('gpu', 2);('nvidia v100 gpus', 2);('transformer', 2);('groundtruth melspectrogram', 2);('vctk', 2);('points 80hz', 2);('english', 2);('kim', 2);('lj', 2);('introduce formulation', 2);('previous works', 2);('kingma', 2);('ljspeech libritts vctk', 2);('small realtime factor', 2);('model groundtruth melspectrogram', 2);('slow inference speed', 2);('lam', 2);('ho', 2);('libritts', 2);('ljspeech', 2);('realtime factor', 2);('ddpmbased tts', 2);('audiobooks voice13', 1);('present audio samples', 1);('realistic tonal changes noise', 1);('realistic audio', 1);('high frequency artefact', 1);('realistic changes pitch', 1);('lacks', 1);('articulation highlevel crackle recordingsgtmel articulation good', 1);('good robotic voice abit', 1);('background noise human voice', 1);('sound realisticprodiff', 1);('changes pitch naturalbreaks words', 1);('realistic', 1);('quiet hiss inmost recordings', 1);('good acoustic quality audible', 1);('meaning thespeech articulation robotic', 1);('good articulation audible buzz corrupts speechgradtts50', 1);('similar model', 1);('similar comments', 1);('qualitylower volume drop sometimesfastspeech', 1);('pitchseems', 1);('low noticeable hiss levels recordings recordings buzzy', 1);('words distinguish', 1);('noise presentin samples', 1);('acoustics hiss level', 1);('words', 1);('long wordsresgrad50', 1);('articulation speech verylow audible hiss recordings pauses', 1);('synthesis taskresgrad4 model', 1);('englishspeakers', 1);('different models', 1);('list comments perceptual quality', 1);('h uman evaluations commentswe', 1);('diffusion probabilistic models arxiv preprint arxiv220209671 202212a', 1);('zheng pengcheng weizhu chen mingyuan zhou truncated', 1);('librispeech texttospeech', 1);('zen rob clark ron j weiss viet dang ye jia yonghui wu yu zhang zhifeng chenlibritts', 1);('toolkit httpsdatashareedacukhandle102833443 2012heiga', 1);('multispeaker corpus cstr voice', 1);('yamagishi english', 1);('diffusion gans', 1);('generative learning trilemma', 1);('xiao karsten kreis arash vahdat tackling', 1);('cvpr', 1);('stochastic renement', 1);('milanfar deblurring', 1);('whang mauricio delbracio hossein talebi chitwan saharia alexandros g dimakis', 1);('processing', 1);('speech', 1);('ieeeacmtransactions', 1);('robust speech superresolution', 1);('wang deliang wang towards', 1);('vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidan n gomezukasz kaiser illia polosukhin attention', 1);('highdelity speech synthesis', 1);('fast', 1);('cobo florian stimbergnorman casagrande dominik grewe seb noury sander dieleman erich elsen nal kalchbrenner heiga zen alex graves helen king tom walters dan belov demis hassabisparallel', 1);('driessche edward lockhart luis', 1);('van den', 1);('oord yazhe li igor babuschkin karen simonyan oriol vinyals koraykavukcuoglu george', 1);('202111aaron van den', 1);('latent space', 1);('vahdat karsten kreis jan kautz scorebased', 1);('survey neural speech synthesis arxivpreprint arxiv210615561 2021arash', 1);('iclr2021bxu tan tao qin frank soong tieyan liu', 1);('stochastic differential equations', 1);('poole scorebased', 1);('jascha sohldickstein diederik p kingma abhishek kumar stefano ermon', 1);('iclr2021ayang', 1);('implicit models', 1);('chenlin meng stefano ermon denoising', 1);('iniclr', 1);('salimans jonathan ho progressive', 1);('springer', 1);('sciencepp', 1);('lecture notes', 1);('miccai', 1);('networks biomedical image segmentation', 1);('ronneberger philipp fischer thomas brox unet convolutional', 1);('jimenez rezende shakir mohamed variational', 1);('2fast highquality endtoend text speech', 1);('ren chenxu hu xu tan tao qin sheng zhao zhou zhao tieyan liu fastspeech', 1);('textconditional image generation clip latents arxiv preprint arxiv220406125 2022yi', 1);('ramesh prafulla dhariwal alex nichol casey chu mark chen hierarchical', 1);('diffusion probabilistic model texttospeech', 1);('vladimir gogoryan tasnima sadekova mikhail kudinov gradtts', 1);('popov ivan v', 1);('neural texttospeech', 1);('kexin zhao nonautoregressive', 1);('peng wei ping zhao', 1);('g2pe httpsgithubcomkyubyongg2p 2019kainan', 1);('jongseok kim', 1);('generative model forraw audio arxiv preprint arxiv160903499 2016kyubyong park', 1);('oord sander dieleman heiga zen karen simonyan oriol vinyals alex gravesnal kalchbrenner andrew senior koray kavukcuoglu wavenet', 1);('2017aaron van den', 1);('unconditional endtoend neural audio generation model', 1);('courville yoshua bengio samplernn', 1);('mehri kundan kumar ishaan gulrajani rithesh kumar shubham jain jose soteloaaron', 1);('diffusion gans arxiv preprint arxiv220111972 2022csoroush', 1);('efcient texttospeech', 1);('liu dan su dong yu diffgantts highdelity', 1);('aaai', 1);('voice synthesisvia shallow diffusion mechanism', 1);('liu chengxi li yi ren feiyang chen zhou zhao diffsinger singing', 1);('need speech superresolution', 1);('liu woosung choi xubo liu qiuqiang kong qiao tian deliang wang neuralvocoder', 1);('corrabs210913731', 1);('general speech restoration neural vocoder', 1);('toward', 1);('wang v', 1);('liu qiuqiang kong qiao tian yan zhao deliang wang chuanzeng huang', 1);('universalneural vocoder largescale training arxiv preprint arxiv220604658 2022bhaohe', 1);('lee wei ping boris ginsburg bryan catanzaro sungroh yoon bigvgan', 1);('diffusion modelswith datadriven adaptive', 1);('iclr202210sanggil lee heeseung kim chaehun shin xu tan chang liu qi meng tao qin wei chensungroh yoon tieyan liu priorgrad improving', 1);('lam jun wang dan su dong yu bilateral', 1);('2019max w', 1);('adversarialnetworks conditional waveform synthesis', 1);('courville melgan generative', 1);('yoshua bengio aaron', 1);('br', 1);('boissiere lucas gestin wei zhen teoh jose soteloalexandre', 1);('kumar rithesh kumar thibault', 1);('versatilediffusion model audio synthesis', 1);('kong wei ping jiaji huang kexin zhao bryan catanzaro diffwave', 1);('pp 3423492021azhifeng', 1);('ismir', 1);('resunet music source separation', 1);('magnitudeand phase estimation', 1);('kong yin cao haohe liu keunwoo choi yuxuan wang decoupling', 1);('adversarial networks forefcient high delity speech synthesis', 1);('kong jaehyeon kim jaekyoung bae higan generative', 1);('arxiv preprintarxiv220316749 2022jungil', 1);('neural vocoder adaptive noise spectral', 1);('probabilistic model', 1);('koizumi heiga zen kohei yatabe nanxin chen michiel bacchiani specgrad diffusion', 1);('p kingma tim salimans ben poole jonathan ho variational', 1);('convolutionsinneurips 2018diederik', 1);('ow invertible', 1);('p kingma prafulla dhariwal glow generative', 1);('information processingsystems', 1);('advances', 1);('monotonic alignment search', 1);('generative owfor texttospeech', 1);('kim sungwon kim jungil kong sungroh yoon glowtts', 1);('audio synthesis', 1);('oord sander dieleman koray kavukcuoglu efcientneural', 1);('aron van den', 1);('kalchbrenner erich elsen karen simonyan seb noury norman casagrande edward lockhart florian stimberg', 1);('ininterspeech', 1);('neural vocoderwith multiresolution spectrogram discriminators highdelity waveform generation', 1);('jang dan lim jaesam yoon bongwan kim juntae kim univnet', 1);('speech dataset httpskeithitocomljspeechdataset 2017won', 1);('ito linda johnson lj', 1);('conference 2022bkeith', 1);('acm multimedia', 1);('diffusion model highquality texttospeech', 1);('huang zhou zhao huadai liu jinglin liu chenye cui yi ren prodiff progressivefast', 1);('ijcai', 1);('conditional diffusion model highquality speech synthesis', 1);('lam jun wang dan su dong yu yi ren zhou zhao fastdiff afast', 1);('neurips2020rongjie huang max', 1);('ho ajay jain pieter abbeel denoising', 1);('gans image synthesis', 1);('dhariwal alexander quinn nichol diffusion', 1);('icassp', 1);('inference training', 1);('diffusion models vocoder', 1);('chen xu tan ke wang shifeng pan danilo p mandic lei sheng zhao infergradimproving', 1);('gradients waveform generation', 1);('chen yu zhang heiga zen ron j weiss mohammad norouzi william chan wavegrad estimating', 1);('high delity speech synthesis adversarialnetworks', 1);('cobo karen simonyan', 1);('binkowski jeff donahue sander dieleman aidan clark erich elsen normancasagrande luis', 1);('model architectures tasks image synthesis9referencesmikolaj', 1);('resgrad tts', 1);('future work', 1);('quality speech baselines realtime factor speed baselines bymore', 1);('able synthesize', 1);('experiments', 1);('low realtime factor', 1);('lightweight model iterative steps synthesize highqualityspeech', 1);('model result', 1);('learns residual space', 1);('thewhole data space speech', 1);('different', 1);('model correspondinggroundtruth', 1);('models residual output', 1);('work accelerate inference speed', 1);('onclusionin', 1);('sample quality6 c', 1);('steps hasbeen', 1);('clean residual samples', 1);('withmore inference steps', 1);('details residual samples', 1);('steps generate theclean residual data', 1);('shows inference process', 1);('quality speechfigure', 1);('synthesis expressive', 1);('thereforeresgrad', 1);('generates melspectrograms', 1);('generate melspectrograms', 1);('models ie', 1);('conduct case study visualize melspectrograms ground', 1);('ase studyas', 1);('slower53 c', 1);('cmoswith resgrad libritts vctk', 1);('comparison results areshown', 1);('resgradl', 1);('gradtts popovet', 1);('large diffusion model ie decoder model', 1);('sensitive modelsize', 1);('size', 1);('vctkmodel cmos rtf resgrad', 1);('librittsmodel cmos size rtf resgrad', 1);('noise b', 1);('effectiveness method8a', 1);('model size', 1);('sample quality withmuch', 1);('resgrad resunet', 1);('theresidual show comparison sample quality model size inference speed', 1);('wang wang', 1);('2022a speech superresolution task', 1);('highfrequency information melspectrogram', 1);('promising results', 1);('residual informationfor comparison', 1);('residual unet resunet', 1);('batch normalization leakyrelu activation linear convolutional operationtherefore employ', 1);('resconvconsists', 1);('decoder series residual convolutions convolutional layer', 1);('bothencoder', 1);('connections encoder decoder blocks level', 1);('encoder anddecoder blocks', 1);('melspectrogram f', 1);('model theresidual', 1);('unet ronneberger', 1);('following liu', 1);('residual information', 1);('prediction', 1);('frequency information moresimilar ground truth melspectrogramresidual', 1);('generates melspectrogram', 1);('suffers oversmoothingproblem', 1);('comparison melspectrogram', 1);('resgradfigure', 1);('ground truth', 1);('comparison resgrad resunetmodel cmos size mresgrad', 1);('cmos resgrad', 1);('pitch informationmodel', 1);('top corresponding predictedresidual sample', 1);('pred', 1);('column shows correspondinggroundtruth residual sample', 1);('residual sample bottom', 1);('gttopand', 1);('column shows groundtruth residual sample', 1);('generated residual samplefigure', 1);('gt residual', 1);('table 27gt', 1);('quality comparison thesetwo settings', 1);('groundtruth data samples', 1);('groundtruth residual samples inference stageit', 1);('topitch information', 1);('residual samplesand', 1);('appendix a52 blation studyresidual calculation', 1);('ratethe comments judges', 1);('obvious challenging datasets multiplespeakers', 1);('iteration step', 1);('diffspeech prodiff', 1);('speechup method', 1);('method eg', 1);('4step iteration', 1);('voice quality verypooras summary quality', 1);('voice quality thethree datasets inference speed', 1);('reduces inference time', 1);('compared prodiff diffspeech resgrad4', 1);('fasterinference speed onpar', 1);('gradtts50 resgrad4 resgrad50', 1);('inference speedand voice quality', 1);('outperforms baseline', 1);('gradtts50 inference', 1);('libritts resgrad4', 1);('gradtts50 ljspeech', 1);('outperforms baselines', 1);('mos gradtts50', 1);('libritts vctk ljspeech resgrad50outperforms', 1);('rate datasets ie', 1);('multispeaker high', 1);('resgrad50', 1);('oice quality', 1);('resgrad4 resgrad50', 1);('opensource datasetsthe', 1);('different methods exclude otherinterference factors reproduce results methods', 1);('experimental settings', 1);('ddpmswe', 1);('different methods accelerate inference speed', 1);('otherbaselines', 1);('0244synthesis highquality speech', 1);('0009\x00 \x00 \x00 \x00diffspeech', 1);('ocoder 428\x06006\x00 45\x06004\x00 461\x06004\x00fastspeech', 1);('491\x06002\x00 44\x06005\x00 475\x06002\x00gt mel', 1);('libritts vctkmodels mos rtf mos rtf mos rtfrecordings', 1);('sample qualityljspeech', 1);('residual part speaker', 1);('challenging comparison', 1);('samples scratch thesynthesis task', 1);('speakers models', 1);('background noise decreases quality', 1);('speechsamples dataset', 1);('firstly', 1);('main reasons', 1);('ljspeech vctk', 1);('mosscores libritts', 1);('notethat gradtts50 resgrad4 resgrad50', 1);('different methods', 1);('mos rtf', 1);('fast diffusionmodel texttospeech', 1);('texttospeech model speed inferenceby shallow diffusion mechanism', 1);('gans5 diffspeech liu', 1);('texttospeech model speeds inference', 1);('diffganttsliu', 1);('fast speed', 1);('quality speech', 1);('model synthesis', 1);('popular nonautoregressive', 1);('hifiganvocoder kong', 1);('groundtruth melspectrogram synthesize waveform', 1);('groundtruth recordings2', 1);('recording', 1);('nvidia v100 gpu5 r esults51 peech quality inference speedwe', 1);('for160k steps convergence', 1);('following renet', 1);('batch size of16', 1);('nvidia v100gpu', 1);('1700k steps', 1);('original melspectrograms', 1);('train model', 1);('gradtts following popov', 1);('v100 gpu', 1);('teacher model', 1);('teacher model train', 1);('diffusion steps', 1);('2022b rst train', 1);('following huang', 1);('teacher model furtherdecreases', 1);('nstep', 1);('fast diffsionmodel highquality texttospeech', 1);('2022b progressive', 1);('train modelsfor 300k steps loss converge', 1);('nvidia v100 gpu', 1);('generator discriminator use', 1);('forboth', 1);('diffgantts t1', 1);('2022c train', 1);('diffgantts following liu', 1);('160k steps convergence2', 1);('main stage trains', 1);('stage trains auxiliary decoder 160k steps', 1);('warmup', 1);('main stage', 1);('stages warmupstage', 1);('different data', 1);('2022b congurationsare', 1);('diffusion model train', 1);('ttsbased', 1);('acoustic model', 1);('detailsof training settings baseline models', 1);('vctk libritts', 1);('multispeaker dataset', 1);('baseline models dataset iethe single speaker dataset', 1);('fair reproducible comparison train', 1);('raining baseline modelsfor', 1);('100gpu device44', 1);('nvidia v', 1);('inference speed use objective measurement realtimefactor', 1);('twodifferent models', 1);('eachcmos', 1);('overall sample quality 5point scale', 1);('speakers judgesto', 1);('tests invite 14native', 1);('comparison mean opinion score', 1);('mos mean opinion score', 1);('human subjective evaluation', 1);('500k training stepsfor evaluation', 1);('strong sample quality improvement', 1);('batch sizeand nd', 1);('max length sample', 1);('batch size isset', 1);('diffusion time steps', 1);('thenumber', 1);('resgrad adam', 1);('100k steps untilmoderate quality speech generatedfor training', 1);('al2017 use', 1);('vaswani', 1);('learning rate plan schedule', 1);('weight delay \x15', 1);('adamw', 1);('model use', 1);('training noniterative', 1);('raining evaluationfor', 1);('generate 48khz waveform opensourcecode5 experiments vocoder', 1);('hifigan', 1);('hifigan kong', 1);('ljspeech libritts', 1);('model parametersfor', 1);('borrows implementation ofcialopensource', 1);('resgrad unet', 1);('dropout rate isset', 1);('inputoutput size layers', 1);('kernel size', 1);('convolution networks nal linearprojection layer convolution layers duration predictor variance adaptor', 1);('fastspeech2ren', 1);('durationpredictor variance adaptor architecture use', 1);('inputoutput size thenumber channels rst', 1);('kernel size 1dconvolution twolayer convolution network', 1);('number head', 1);('sizeof multihead attention', 1);('blocks multihead selfattention 1d convolution bothphoneme encoder melspectrogram decoder feedforward', 1);('model composedof', 1);('odel configurationwe', 1);('groundtruth pitch duration42', 1);('predictedduration pitch', 1);('notethat', 1);('groundtruth pitch calculate residual', 1);('groundtruth samples willincrease burden', 1);('melspecotogramhowever calculate residual', 1);('samples qualityeg clearness naturalness', 1);('highfrequency details', 1);('models way residual', 1);('highfrequency details ingroundtruth melspectrogram difcult', 1);('2a residual', 1);('figure2a figure', 1);('groundtruth melspectrograms pitchwe', 1);('length mismatch', 1);('otherwisethere', 1);('melspectrogram residual calculation', 1);('pitchduration calculate residual durationwe use groundtruth duration', 1);('pitchduration inference need', 1);('utilizesgroundtruth pitchduration training', 1);('calculate residual melspectrogram', 1);('frequencycutoffs hop length 480jang', 1);('points 0hz', 1);('use128band melspectrogram', 1);('higherfrequency cutoffs hop length 300lee', 1);('extract 80band melspectrogram', 1);('librittswe', 1);('frequency cutoffsand hop length 256ren', 1);('extract 80bandmelspectrogram', 1);('specically ljspeech', 1);('common practice', 1);('datasets intomelspectrogram', 1);('raw waveform', 1);('graphmesequence phoneme sequence transform', 1);('opensource tools park', 1);('groundtruth pitch residual calculatedwithout groundtruth pitch ie pitch', 1);('comparison residual', 1);('residual figure', 1);('test dataset', 1);('rate 48khz extract108speakers datasets rst 5recordings speaker 540recordings totalare', 1);('20123is multispeaker dataset', 1);('yamagishi', 1);('training datasetvctk', 1);('recordings test dataset', 1);('speakers theclean subset trainclean100 trainclean360 devclean testclean speaker randomlyselect', 1);('rate 24khz total use', 1);('20192isa multispeaker dataset', 1);('libritts zen', 1);('12577samples model training', 1);('002samples modelevaluation', 1);('following konget', 1);('rate 2205khz contains13100english speech recordings female speaker', 1);('20171is singlespeaker dataset', 1);('ljspeechito johnson', 1);('opensource benchmark datasets', 1);('e xperimental setup41 ataset preprocessingdataset', 1);('models plugandplay way4', 1);('models acts', 1);('plugandplay resgrad', 1);('large room speedingup diffusion models', 1);('wheels leaves', 1);('standson shoulders giants', 1);('model predicts residual iterative way', 1);('leverages prediction', 1);('shoulders giants', 1);('standing', 1);('followingtwo aspects', 1);('residual analyze advantages', 1);('rough sample usingan iterative model', 1);('noniterative model', 1);('full use', 1);('iterative noniterative methodresgrad', 1);('fast inference thesample quality', 1);('sample qualitybut cost', 1);('pros cons', 1);('models egfastspeech', 1);('models eg', 1);('dvantages resgradgenerally', 1);('residual x0andf ytogether nal outputmelref x0f 5wheremelrefis', 1);('melspectrogram f yfrom', 1);('tyt1p\x12xt\x001jxtc', 1);('denoise data sample synthesize residual x0byp\x12x0\x01\x01\x01xt\x001jxtc', 1);('noise pxt\x18n0i', 1);('model f', 1);('3in inference stage rst estimate melspectrogram f yfrom text input ywith', 1);('s\x12xttc \x0fp1\x00\x16 t', 1);('ex0\x0ft', 1);('data logdensity logqxtjx0with respect thedata pointxtsxtt rxtlogqxtjx0 \x00\x0fp1\x00\x16 t training objective', 1);('estimate score3functions\x12which', 1);('previous work', 1);('training objective', 1);('different methods parameterize', 1);('corresponding noise level time step tthere', 1);('t 1\x00 t \x16 tqts1 sdenotes', 1);('tx01\x00\x16 t\x0f 2where', 1);('nxtp\x16', 1);('time stept21t', 1);('t1', 1);('noise schedule', 1);('clean residual', 1);('noise \x0f\x18n 0iinto', 1);('ydenotes text inputin training stage injects', 1);('model egfastspeech', 1);('asxmelgt\x00f 1wheremelgtdenotes groundtruth melspectrogram f', 1);('groundtruth melspectrograms residual', 1);('diffusion probabilistic modelto', 1);('ormulation resgradwe', 1);('melspectrogram summation rst two32 f', 1);('resgradand', 1);('model ie', 1);('melspectrogram thuscan', 1);('residual contains highfrequency details', 1);('residual melspectrogram', 1);('verview resgradas', 1);('advantages method31', 1);('section rst', 1);('ethodin', 1);('new training congurations3', 1);('training models', 1);('generate residual information doesnot', 1);('image quality measuredby objective distances', 1);('adiffusion model residual estimation', 1);('initial image', 1);('ddpms inwhang', 1);('samplingstepsbeyond speech synthesis relevant work speed inference', 1);('comparable sample quality par withthe quality', 1);('enhance sample quality', 1);('residual smallnumber inference steps', 1);('origin data space', 1);('corresponding groundtruth speech residual spaceis', 1);('whole speech scratch generate residual betweenthe output', 1);('degradedin work', 1);('otherwise', 1);('speech sufcient number', 1);('howeverto', 1);('different perspectives', 1);('process generatorthe methods', 1);('models framework', 1);('ganbased', 1);('2022c utilizes', 1);('diffgantts liu', 1);('forddpms example', 1);('training techniques', 1);('additional', 1);('number inferencesteps', 1);('noise additionalinput', 1);('latent representation', 1);('the2priornoise distribution', 1);('steps inference stage', 1);('koizumiet', 1);('lee', 1);('condition information', 1);('priornoise distribution', 1);('eld speech synthesis', 1);('salimans ho2022in', 1);('xiao', 1);('zheng', 1);('dhariwal nichol', 1);('process song', 1);('various methods', 1);('large number inference steps', 1);('dhariwal nichol2021 ramesh', 1);('various tasks', 1);('stateoftheart generationresults', 1);('resgrad2 r elated workdenoising', 1);('speech withsimilar speech quality veries effectiveness', 1);('sample quality baselines withthe', 1);('ddpms resgrad', 1);('otherspeedup baselines', 1);('small realtime factor experiments', 1);('highquality speech', 1);('whole speech scratch complexity ofdata space', 1);('speed inference', 1);('novel method', 1);('main contributions work', 1);('plugandplay modelwhich', 1);('complex learning space ie residual space', 1);('qualityresgrad generate high quality speech lightweight model', 1);('originaltts output', 1);('generate residual inference output', 1);('resgradis', 1);('generate speech training', 1);('rst utilize', 1);('specically', 1);('residual lesscomplex', 1);('speech scratch', 1);('corresponding groundtruthmelspectrogram', 1);('diffusion model predicts residual output', 1);('smallrealtime factor inference end', 1);('model way themodel size', 1);('complexity data space', 1);('previous methods minimize number inference steps', 1);('estimatedwith inference steps', 1);('highdimensional data space', 1);('2022c vocoder', 1);('ttshuang', 1);('minimize number inference steps eg 2\x186steps', 1);('residual estimatedmelspectrogram', 1);('rst predicts residual melspectrogram estimatedby', 1);('illustration resgrad resgrad', 1);('textstop gradientadditionttsresgradestimated mel generated residual refined melfigure', 1);('dec', 1);('lei he1arxiv221214518v1', 1);('microsoft corresponding', 1);('technology7university surreyywork', 1);('china6south china', 1);('science technology', 1);('china5universityof', 1);('london2microsoft azure speech3msra4renmin', 1);('steps highdimensional data space address issue\x031imperial college', 1);('steps eg', 1);('large numberof', 1);('al2022aa major disadvantage diffusion models', 1);('2022b vocoders', 1);('surpasses stateoftheart methods acousticmodels', 1);('able toachieve sample quality matches', 1);('mechanism iterative renement', 1);('based', 1);('binkowski', 1);('kumar', 1);('generative adversarial networks', 1);('peng', 1);('variational autoencoders', 1);('kingma dhariwal', 1);('van denoord', 1);('rezende mohamed', 1);('kalchbrenner', 1);('mehriet', 1);('oord', 1);('generative models eg autoregressive models', 1);('great progress withthe development', 1);('tan', 1);('recent years texttospeech', 1);('ntroductionin', 1);('areavailable httpsresgrad1githubio', 1);('audio', 1);('baseline methods', 1);('similar speech quality', 1);('sample quality inference', 1);('comparison speedup methods ofddpms', 1);('vctkexperimental', 1);('multiple speakers', 1);('challenging datasets', 1);('singlespeaker dataset', 1);('weverify resgrad', 1);('model plugandplay way', 1);('inference process', 1);('lightweight model thusa', 1);('generation target groundtruthmelspectrogram residual', 1);('reduces complexity task', 1);('need synthesize speech scratch', 1);('corresponding groundtruth speech', 1);('residual model output', 1);('model eg', 1);('lightweight diffusion model learns rene output spectrogram', 1);('high samplequality', 1);('sample quality work improvethe inference speed', 1);('previous', 1);('slow inference speed restricts application realtime systems', 1);('iterative renement process highdimensionaldata space results', 1);('highdelity samples', 1);('strong capability', 1);('diffusion probabilistic', 1);('resgrad r esidual denoising diffusion probabilistic models text speechzehua chen\x031y yihan wu4 yichong leng5 jiawei chen6 haohe liu7 xu tan3yang cui2 ke wang2 lei he2 sheng zhao2 jiang bian3 danilo mandic1fzehuachen18dmandic', 1);