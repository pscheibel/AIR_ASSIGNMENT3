('rl', 43);('rl-based', 19);('nip', 17);('recommender systems', 16);('acm sigir forum', 14);('vol', 14);('december', 14);('o\x0fine evaluation', 10);('recsys', 9);('reinforcement learning', 8);('de', 8);('evaluation protocol', 7);('sergey levine', 7);('recommender system', 6);('online performance', 6);('o -policy evaluation', 6);('icml', 6);('rijke', 5);('next-item prediction', 5);('url', 5);('dietmar jannach', 5);('aviral kumar', 5);('o\x0fine fashion', 4);('jeunen', 4);('rendle', 4);('retailrocket', 4);('bene ts', 4);('ope', 4);('o\x0fine', 4);('justin fu', 4);('re ect', 3);('potential bene ts', 3);('future research', 3);('sequential recommendation', 3);('jannach', 3);('gomez-uribe', 3);('hunt', 3);('chen', 3);('zhao', 3);('selection bias', 3);('last.fm', 3);('instacart', 3);('rl4rec', 3);('ir', 3);('wsdm', 3);('online evaluation', 3);('ecological validity', 3);('long-term outcomes', 3);('q-value', 3);('hasselt', 3);('value function', 3);('fu', 3);('target policy', 3);('paolo cremonesi', 3);('maarten', 3);('acm trans', 3);('inf', 3);('syst', 3);('george tucker', 3);('o\x0fine reinforcement learning', 3);('netherlands', 2);('next-item prediction protocol', 2);('certain o\x0fine', 2);('mcnee', 2);('quadrana', 2);('reinforcement', 2);('markov', 2);('decision process', 2);('mdp', 2);('whole-sequence optimization', 2);('real-world scenarios', 2);('sound evaluation methodology', 2);('common pitfalls', 2);('previous studies', 2);('next-item prediction evaluation protocol', 2);('garcin', 2);('ji', 2);('sun', 2);('data leakage', 2);('implicit feedback', 2);('ferrari dacrema', 2);('next-item', 2);('hidasi', 2);('content recommendation', 2);('product recommendation', 2);('movielens', 2);('grouplens', 2);('aaai', 2);('cikm', 2);('kdd', 2);('sigir', 2);('www', 2);('e ect', 2);('doing', 2);('evaluating', 2);('bandit algorithms', 2);('lee', 2);('recommendation platforms', 2);('high return', 2);('hussein', 2);('top item', 2);('item recommendation', 2);("optimizer 's curse", 2);('certain cases', 2);('value estimate', 2);('brandfonbrener', 2);('gu', 2);('online', 2);('previous section', 2);('counterfactual', 2);('joachims', 2);('community [', 2);('simulators', 2);('additionally', 2);('huang', 2);('tobin', 2);('openai', 2);('intermediate models', 2);('policy evaluation', 2);('neurips', 2);('q-learning', 2);('o r', 2);('nachum', 2);('mohammad norouzi', 2);('ziyu wang', 2);('alexander novikov', 2);('cosmin paduraru', 2);('tom', 2);('paine', 2);('iclr', 2);('doina precup', 2);('learning', 2);('harrie oosterhuis', 2);('acm comput', 2);('surv', 2);('olivier jeunen', 2);('aixin sun', 2);('jie zhang', 2);('thorsten joachims', 2);('adith swaminathan', 2);('ste', 2);('alex ray', 2);('jonas schneider', 2);('wojciech zaremba', 2);('yang yu', 2);('paper o\x0fine evaluation', 1);('reinforcement learning-based recommendation', 1);('critical', 1);('alternatives romain de', 1);('naver labs europe', 1);('amsterdam france', 1);('romain.deffayet @ naverlabs.comthibaut', 1);('thonet naver labs europe france', 1);('thibaut.thonet @ naverlabs.com', 1);('jean-michel renders naver labs europe france', 1);('jean-michel.renders @ naverlabs.commaarten', 1);('amsterdam', 1);('m.derijke @ uva.nl', 1);('abstract', 1);('se- quential recommender systems', 1);('rec- ommenders', 1);('o\x0fine evaluation practices', 1);('notably', 1);('alternative ways', 1);('recom- mender systems aim', 1);('reliable evaluation protocols', 1);('introduction recommender', 1);('major role', 1);('internet users', 1);('ubiqui- tous presence', 1);('e-commerce platforms', 1);('correct', 1);('careful evaluation', 1);('impacts business metrics', 1);('user satisfaction {', 1);('recommendation accuracy', 1);('relevant items', 1);('main indicator', 1);('recommender systems highlights', 1);('additional criteria', 1);('beyond-accuracy', 1);('fair- ness', 1);('user experience', 1);('general [', 1);('such criteria', 1);('one-shot recommendation', 1);('rec- ommender system', 1);('longer-term experience', 1);('sequential nature', 1);('2022arxiv:2301.00993v1 [ cs.ir ]', 1);('jan', 1);('recommendation engines', 1);('whole sequences', 1);('one-shot predictions [', 1);('select appropriate actions', 1);('item recommendations', 1);('full sequence', 1);('user interactions', 1);('natural t', 1);('recommendation scenarios', 1);('online exploration', 1);('sequence optimization', 1);('ful ll', 1);('beyond-accuracy criteria', 1);('appropriate reward function', 1);('e ective', 1);('entire span', 1);("user 's experience", 1);('auxiliary metrics', 1);("sequence 's cumula- tive reward", 1);('lacks ecological validity [', 1);('andrade', 1);('gener- alize', 1);('certain shortcomings', 1);('current evaluation practices', 1);('namely', 1);('tra- ditional one-shot', 1);('speci cs', 1);('brie', 1);('evaluation practices', 1);('cumulative reward', 1);('important topic', 1);('major issues', 1);('rl-', 1);('related', 1);('recommender systems evaluation', 1);('recom- mendation literature', 1);('firstly', 1);('matrix completion problem', 1);('o\x0fine evaluation obsolete [', 1);('secondly', 1);('recommender system evaluation {', 1);('next-item prediction pro- tocol', 1);('study {', 1);('cremonesi', 1);('multiple issues', 1);('dataset construction fallacies', 1);('counter-intuitive statements', 1);('major source', 1);('inaccuracies [', 1);('krichene', 1);('negative items', 1);('inference time', 1);('drawing incorrect conclusions', 1);('recommendation performance', 1);('studies rea\x0erm', 1);('appropriate baseline selection', 1);('certain claims', 1);('baselines [', 1);('ludewig', 1);('speci c', 1);('additional caveat', 1);('o\x0fine evaluation protocols', 1);('sequential recommendation studies', 1);('o\x0fine evaluation protocol', 1);('sequential item recommendation', 1);('real user feedback', 1);('top items', 1);('past interactions', 1);('model', 1);('ndcg', 1);('evaluation setup', 1);('se- quential recommendation studies', 1);('gru4rec', 1);('encompasses sev- eral variants', 1);('recsys challenge', 1);('ben-shimon', 1);('movie recom- mendation', 1);('recent years', 1);('year1710111214number', 1);('evolution', 1);('recommendation papers', 1);('2022. proceedings', 1);('major information retrieval', 1);('january', 1);('october', 1);('\\reinforcement learning recommendation', 1);('\\reinforcement learning recommender', 1);('dblp1and', 1);('icdm', 1);('ijcai', 1);('figure', 1);('dblp', 1);('address sequential item recommendation', 1);('tasks irrelevant', 1);('conversational recommendation', 1);('explainable recommendations', 1);('ignore papers', 1);('relevant articles', 1);('industrial recommendation platform', 1);('optimize long-term outcomes', 1);('optimize whole-sequences', 1);('individual actions', 1);('costly search', 1);('combinatorial space', 1);('action sequences', 1);('2022rl algorithms', 1);('scalar rewards', 1);('generate novel policies', 1);('inaccurate estimation', 1);('major shortcomings', 1);('myopic evaluation', 1);('short- term rewards', 1);('causal e ect', 1);('important motivation', 1);('full trajectories', 1);('average reward', 1);('convergence guarantees', 1);('optimal policy', 1);('rewards one-shot prediction', 1);('item {', 1);('static nature', 1);('causal impact', 1);('recommendation policy', 1);('subsequent interactions', 1);('myopic agents', 1);('standard recommendation datasets', 1);('immediate satisfaction', 1);('user guidance', 1);('content discovery', 1);('re- wards', 1);('lifetime value', 1);('whole lifetime', 1);('long- term outcomes', 1);('trajectory diverse', 1);('enjoyable recommender systems', 1);('sequential decision-making process', 1);('reward function', 1);("user 's needs", 1);('suboptimal target', 1);('particular treatment', 1);('organic interactions', 1);('implicit e ect', 1);('exogenous factors', 1);('active user feedback', 1);('voluntary movie reviews', 1);('product search', 1);('user choice', 1);('enjoyable experience overall', 1);('binary target', 1);('scalar reward', 1);('evaluation incentivizes researchers', 1);('optimal actions', 1);('novel policies', 1);('exists simpler methods', 1);('imitation learning [', 1);('reward maximization objective', 1);('di erent', 1);('discard performant policies', 1);('high ratings mitigates', 1);('data collection implies', 1);('risky', 1);('previous points', 1);('next-item prediction evaluation', 1);('problematic aspect', 1);('model predictions', 1);('top- kmost', 1);('slate recommenda- tion', 1);('tacit assumption', 1);('metrics correlate', 1);('online results', 1);('previous studies [', 1);('strong assumption', 1);('o\x0fine reward', 1);('actual online reward', 1);('goethals', 1);('practical impact', 1);('particular set', 1);('catastrophic impact', 1);("optimizer's curse", 1);('triad [ van', 1);('sutton', 1);('barto', 1);('2022to update', 1);('previous state', 1);('function approximation', 1);('o -policy fashion', 1);('such conditions', 1);('small overestimations', 1);('out-of-distribution ac- tions', 1);('model predicts', 1);('q-values', 1);('multiple scenarios', 1);('extensive research', 1);('o\x0fine reinforcement learning [ van', 1);('levine', 1);('kostrikov', 1);('harmful phenomenon', 1);('standard next-item prediction evaluation', 1);('out-of-distribution item', 1);('catastrophic failure', 1);('deployment time', 1);('failure tends', 1);('action-space [', 1);('certain recommendation scenarios', 1);('upshot', 1);('proto- col', 1);('online metrics', 1);('potential solutions', 1);('recommender systems di\x0ecult', 1);('partial solutions', 1);('open questions', 1);('obvious counter-measure', 1);('recommender systems online', 1);('actual recommendation platform', 1);('industrial platform', 1);('business rules', 1);('large body', 1);('information retrieval', 1);('inverse propensity', 1);('swaminathan', 1);('propensity weight', 1);('one-shot bandit problem', 1);('studies address', 1);('kiyohara', 1);('kawakami', 1);('unbi- asedness guarantees', 1);('mild assumptions', 1);('cien- cies', 1);('ips', 1);('su ers', 1);('high variance', 1);('inverse propensity weights [', 1);('precup', 1);('non-tabular settings', 1);('state-action pair', 1);('continuous spaces', 1);('generalization capabilities', 1);('propensity [', 1);('hanna', 1);('o\x0fine manner', 1);('o -policy training', 1);('certain methods', 1);('extreme example', 1);('policy-gradient recommender', 1);('propensity weights', 1);('optimal regardless', 1);('true performance', 1);('counterfactual ope', 1);('shortcomings high-', 1);('own shortcomings', 1);('certain practical settings', 1);('simulator-based', 1);('assess progress', 1);('industrial applications [', 1);('gulcehre', 1);('qin', 1);('inter- action', 1);('hardest problems', 1);('apparent stochasticity', 1);('human behavior', 1);('true value', 1);('user behavior', 1);('unobservable metrics', 1);('inner workings', 1);('semi-synthetic simulators', 1);('synthetic part', 1);('item embeddings [', 1);('shi', 1);('unseen data', 1);('missing-not-at-random case [', 1);('wide range', 1);('con gurations', 1);('simulator design', 1);('regardless', 1);('simulator exhibits', 1);('real data', 1);('approaches aim', 1);('domain randomization [', 1);('intermediate', 1);('intermediate evaluation', 1);('building blocks', 1);('nal recommendation model [', 1);('nal model', 1);('human annotations', 1);('item relevance', 1);('top- krecommendation', 1);('cumulative click maximization', 1);('click model', 1);('propensity scores', 1);('state dynamics', 1);('user changes', 1);('likely use', 1);('training distribution', 1);('high uncertainty regions', 1);('proper countermeasure', 1);('uncertainty-aware', 1);('nal performance', 1);('di erent levels', 1);('value overestimation issue', 1);('previous section results', 1);('high uncertainty', 1);('out-of-distribution state-action pairs', 1);('safe policies', 1);('high-return policies', 1);('uncertainty [', 1);('available actions', 1);('accurate estimate', 1);('held-out test', 1);('o\x0fine dataset', 1);('safe policy', 1);('high in-support', 1);('reliable improvement', 1);('unsafe policy', 1);('evaluation needs', 1);('fujimoto', 1);('non-tabular setting', 1);('certain degree', 1);('kumar', 1);('] show', 1);('evaluation focuses', 1);('main open question', 1);('ne distance measures', 1);('conclusion', 1);('traditional approaches', 1);('catastrophic deployment', 1);('myopic protocol', 1);('shortterm accuracy', 1);('suboptimal recommendation target', 1);('satisfactory solution', 1);('o\x0fine metrics', 1);('finding', 1);('appropriate o\x0fine evaluation protocols', 1);('active research area', 1);('sequential recommendation community', 1);('e ort', 1);('recommen- dation scenario', 1);('recommender systems paves', 1);('such uncertainty', 1);('oosterhuis', 1);('safer policy', 1);('di erent context', 1);('counterfactual learning', 1);('ghosh', 1);('reichlin', 1);('adaptive o\x0fine', 1);('uncertain states', 1);('references chittaranjan andrade', 1);('internal', 1);('research design', 1);('indian journal', 1);('psychological medicine', 1);('david ben-shimon', 1);('michael friedmann', 1);('alexander tsikinovsky', 1);('johannes h\x7f', 1);('lior rokach', 1);('bracha shapira', 1);('//recsys.acm.org/recsys15/ challenge/', 1);('david brandfonbrener', 1);('will whitney', 1);('rajesh ranganath', 1);('joan bruna', 1);('hung-hsuan chen', 1);('chu-an chung', 1);('hsin-chien huang', 1);('wen tsui', 1);('acm sigkdd explorations newsletter', 1);(':37 {', 1);('minmin chen', 1);('alex beutel', 1);('paul covington', 1);('sagar jain', 1);('francois belletti', 1);('ed h. chi', 1);('top-k', 1);('o -policy correction', 1);('reinforce recommender system', 1);('recommender systems research', 1);('crisis', 1);('ai magazine', 1);(':43 {', 1);('nov.', 1);('romain de', 1);('jean-michel renders', 1);('click models', 1);('policy distributional', 1);('recent neural recommendation approaches', 1);('matthew soh', 1);('diagnosing', 1);('d4rl', 1);('datasets', 1);('deep data-driven reinforcement learning', 1);('mengjiao yang', 1);('michael r. zhang', 1);('yutian chen', 1);('benchmarks', 1);('deep o -policy evaluation', 1);('scott fujimoto', 1);('david meger', 1);('o -policy', 1);('florent garcin', 1);('boi faltings', 1);('olivier donatsch', 1);('ayar alazzawi', 1);('christophe bruttin', 1);('amr huber', 1);('news recommender systems', 1);('dibya ghosh', 1);('anurag ajay', 1);('pulkit agrawal', 1);('o\x0fine rl', 1);('carlos a. gomez-uribe', 1);('neil hunt', 1);('net ix recommender system', 1);('algorithms', 1);('business value', 1);('manage', 1);('pengjie gu', 1);('mengchen zhao', 1);('chen chen', 1);('dong li', 1);('jianye hao', 1);('bo', 1);('action representations', 1);('caglar gulcehre', 1);('sergio g\x13', 1);('colmenarejo', 1);('konrad zo', 1);('rishabh agarwal', 1);('josh merel', 1);('daniel mankowitz', 1);('gabriel dulac-arnold', 1);('jerry li', 1);('matt ho', 1);('nicolas heess', 1);('nando', 1);('freitas', 1);('josiah hanna', 1);('scott niekum', 1);('peter stone', 1);('importance', 1);('behavior policy', 1);('bal\x13', 1);('alexandros karatzoglou', 1);('linas baltrunas', 1);('domonkos tikk', 1);('session-based', 1);('recurrent neural networks', 1);('jin huang', 1);('herke', 1);('hoof', 1);('keeping', 1);('dataset biases', 1);('inrecsys', 1);('mohamed medhat gaber', 1);('eyad elyan', 1);('chrisina jayne', 1);('imitation', 1);('market basket analysis', 1);('//www.kaggle.com/c/instacart -market-basket-analysis/data', 1);('paul resnick', 1);('alexander tuzhilin', 1);('markus zanker', 1);('recommender', 1);('systems |', 1);('matrix completion', 1);('commun', 1);('acm', 1);(':94 {', 1);('revisiting', 1);('implicit-feedback recommender systems', 1);('rec- sys', 1);('bart goethals', 1);('pessimistic', 1);('reward models', 1);('o -policy learning', 1);('recommen- dation', 1);('luo ji', 1);('qi qin', 1);('bingqing han', 1);('hongxia yang', 1);('optimize lifetime value', 1);('cold-start recommendation', 1);('yitong ji', 1);('chenliang li', 1);('critical study', 1);('recom- mender system o\x0fine evaluation', 1);('tobias schnabel', 1);('unbiased', 1);('haruka kiyohara', 1);('kosuke kawakami', 1);('ofrl', 1);('designing', 1);('policy evaluation platform', 1);('practical perspectives', 1);('conse- quences+reveal', 1);('ilya kostrikov', 1);('ashvin nair', 1);('walid krichene', 1);('anikait singh', 1);('stephen tian', 1);('chelsea finn', 1);('work ow', 1);('o\x0fine model-free robotic reinforcement learning', 1);('corl', 1);('hojoon lee', 1);('dongyoon hwang', 1);('kyushik min', 1);('jaegul choo', 1);('towards', 1);('long-term user feedbacks', 1);('interactive recommendation systems', 1);('tutorial', 1);('open problems', 1);('malte ludewig', 1);('noemi mauro', 1);('sara lati', 1);('performance', 1);('non-neural approaches', 1);('m. mcnee', 1);('john riedl', 1);('joseph a. konstan', 1);('accuracy metrics', 1);('hurt recommender systems', 1);('chi', 1);('robust', 1);('safe query-specializationin counterfactual learning', 1);('marcin andrychowicz', 1);('bowen baker', 1);('maciek chociej', 1);('rafal jozefowicz', 1);('bob mcgrew', 1);('jakub pachocki', 1);('arthur petron', 1);('matthias plappert', 1);('glenn powell', 1);('szymon sidor', 1);('josh tobin', 1);('peter welinder', 1);('lilian weng', 1);('dexterous in-hand manipulation', 1);('international journal', 1);('robotics', 1);(':3 {', 1);('richard s. sutton', 1);('satinder p. singh', 1);('eligibility', 1);('o -policy policy evaluation', 1);('rongjun qin', 1);('songyi gao', 1);('xingyuan zhang', 1);('zhen xu', 1);('shengkai huang', 1);('zewen li', 1);('weinan zhang', 1);('neorl', 1);('near real-world benchmark', 1);('o\x0fine reinforcement learn-', 1);('massimo quadrana', 1);('sequence-aware', 1);('recommender sys- tems', 1);('alfredo reichlin', 1);('giovanni luca marchetti', 1);('hang yin', 1);('ali ghadirzadeh', 1);('danica kragic', 1);('recovering', 1);('out-of-distribution states', 1);('li zhang', 1);('yehuda koren', 1);('recommender system dataset', 1);('//www.kaggle.com /datasets/retailrocket/ecommerce-dataset', 1);('jing-cheng shi', 1);('qing da', 1);('shi-yong chen', 1);('anxiang zeng', 1);('virtual-taobao', 1);('virtualiz-', 1);('real-world online', 1);('retail environment', 1);('counter-intuitive observations', 1);('fresh look', 1);('zhu sun', 1);('di yu', 1);('hui fang', 1);('jie yang', 1);('xinghua qu', 1);('cong geng', 1);('benchmarking', 1);('reproducible evaluation', 1);('fair comparison', 1);('richard sutton', 1);('andrew barto', 1);('introduction', 1);('mit', 1);('batch', 1);('bandit feedback', 1);('counterfactual risk minimization', 1);('machine learning', 1);(':1731 {', 1);('rachel fong', 1);('pieter abbeel', 1);('domain', 1);('deep neural networks', 1);('real world', 1);('in2017 ieee/rsj', 1);('international conference', 1);('intelligent robots', 1);('systems', 1);('iros', 1);('2017. doi', 1);('hado', 1);('yotam doron', 1);('florian strub', 1);('matteo hessel', 1);('nicolas sonnerat', 1);('joseph modayil', 1);('deep', 1);('wayne xin zhao', 1);('zihan lin', 1);('zhichao feng', 1);('pengfei wang', 1);('ji-rong wen', 1);('appropriate o\x0fine evaluation', 1);('top-n recommendation algorithms', 1);