('mirthumb', 16);('aspect ratio', 14);('fcdb', 12);('figure', 11);('aspect ratios', 9);('iou', 8);('proceedings', 8);('proceedings ieee', 8);('lu', 6);('international conference', 6);('vfn', 5);('nvidia', 5);('cnn', 4);('automatic image', 4);('multiple candidates', 4);('roi', 4);('original image', 4);('imagenet', 4);('acm', 4);('multimedia', 4);('corr', 4);('ieee', 4);('aesthetic image', 3);('cropnet', 3);('wideresnet502', 3);('lvrn', 3);('computervision pattern recognition', 3);('multiple crop candidates', 2);('large dataset images', 2);('aspect ratio outputs', 2);('original images', 2);('image aesthetics visual attention regions', 2);('image aesthetics', 2);('different aspect ratios', 2);('cnnbased', 2);('aspect ratios aesthetics', 2);('box prediction', 2);('zhang', 2);('boxes differentaspect ratios', 2);('aspect ratiofigure', 2);('regression head', 2);('adam', 2);('gaic', 2);('vpn', 2);('tilu', 2);('learning', 2);('ieee transactions multimedia', 2);('theieee conference computer vision pattern recognition pages', 2);('computervision', 2);('experiencebased direct generation', 1);('automatic image croppingcasper christensengracenote nielsen companyaneesh vartakavigracenote nielsen companyaneeshvartakavinielsencomabstractautomatic image cropping', 1);('challenging task withmany', 1);('applications task', 1);('important regions', 1);('select appealing candidateprior approaches model', 1);('novel convolutional neural network', 1);('basedmethod crop images', 1);('modelingimage aesthetics', 1);('salient regions model', 1);('critical factor inuences aesthetics', 1);('automatic image croppingdid', 1);('likely dueto lack datasets task', 1);('benchmark method', 1);('public datasets', 1);('tasks rst aesthetic image', 1);('regard aspectratio', 1);('thumbnail generation', 1);('xedaspect ratio outputs aesthetics crucialwe show strategy', 1);('competitive performsbetter', 1);('methods tasks', 1);('furthermore', 1);('onestage model', 1);('twostage endtoend methods inference', 1);('present qualitative evaluation studyand nd model', 1);('able generalize diverse images unseen datasets', 1);('alsond model generate crops', 1);('aesthetics ground truth', 1);('dataset image thumbnail generation ne', 1);('acompetitive image', 1);('introductionwith', 1);('proliferation devices', 1);('smartphones smarttelevisions tablets imagery', 1);('different aspect ratiosis', 1);('necessary user interface', 1);('responsiveweb design standards images', 1);('largenumber images', 1);('automatic image cropping', 1);('great practical signicance', 1);('large catalogs imagesan', 1);('effective aesthetic', 1);('helpfulto industries applications store display largeamounts media', 1);('social networks image sharingplatforms image galleries surveillance systems photography graphic design softwareimage', 1);('highlight visualattention regions', 1);('regions process', 1);('alternatively', 1);('photographers mayuse composition concepts rule thirds thegolden ratio maximize aesthetics', 1);('tocrop images aspect ratio nal', 1);('task affects theaesthetics', 1);('image example', 1);('portrait crop landscape image', 1);('multiple subjects', 1);('subset nalcrop', 1);('faces aesthetic reasons', 1);('advances', 1);('methods couldtherefore', 1);('research visual perception andaestheticsthe detection visual attention regions imageshas', 1);('active area research time', 1);('itby drawing', 1);('images salient regions', 1);('assessment', 1);('activeresearch area', 1);('lowlevel rules featureswhich difcult formulate generalize torecent', 1);('learning approaches', 1);('aspect ratio ofan image', 1);('recent aesthetics assessment approaches35', 1);('requirement1arxiv221214561v1 cscv', 1);('dec', 1);('2022or concern', 1);('techniques output', 1);('image', 1);('typical rst stage thumbnail generation approaches', 1);('representationsof images strategies', 1);('thumbnails xedaspect ratios', 1);('image aesthetics9', 1);('aesthetics visual attention regionsmore', 1);('recent solutions', 1);('incorporate modelingthe', 1);('avisual attention region', 1);('region interest roi', 1);('box maximize aestheticsthis twostage approach disadvantages theimage salient regions', 1);('multiple salient subjects', 1);('need excludedfor aesthetic reasons', 1);('singlestage approach implicitlymodels images aesthetics attention regions canovercome drawbacks', 1);('susceptibleto failure cases', 1);('attention aesthetics', 1);('salient region foundor ground truth aesthetic assessment', 1);('ambiguous due neutral image aesthetics', 1);('learningframework nd', 1);('wideresnet50242', 1);('overall performance dataset aniou', 1);('model lightweight efcientthan twostage approaches simpler train', 1);('withoutany', 1);('model optimization', 1);('model processover600imagessec', 1);('cropssec imageis', 1);('5aspect ratios', 1);('nvidia tesla v100gpu', 1);('knowledge work rstattempt', 1);('problem image', 1);('visual attention aestheticsdue lack', 1);('public datasets support approach train', 1);('large internal dataset images', 1);('important image content', 1);('efcient architecture predicts', 1);('multiple aspect ratios', 1);('approaches image croppingdid', 1);('benchmark task datasets', 1);('regard toaspect ratio', 1);('mirthumb3', 1);('thumbnail generationin', 1);('ourmodel wideresnet502', 1);('generate outputs aspect ratio', 1);('competitive moreefcient', 1);('stateoftheart performanceon', 1);('aesthetics attention regions', 1);('accurateand efcient image', 1);('qualitative evaluation', 1);('generalizationability model', 1);('fcdb mirthumb', 1);('datasetswithout ne', 1);('observe model cangenerate aesthetic crops', 1);('original ground truth', 1);('highlights challengesin objective evaluation image', 1);('systems suchas reliance', 1);('metric whenseveral', 1);('good crops', 1);('existin summary rst work attempt aesthetic image', 1);('visualattention image aesthetics', 1);('necessary builda', 1);('competitive image', 1);('simple architecture bells andwhistles', 1);('recentstateoftheart approaches', 1);('roiawarepooling', 1);('composition patterns', 1);('custom loss functions', 1);('singlestage model efcient ableto output', 1);('multiple candidates isnovel aesthetic', 1);('aware image', 1);('related workprior', 1);('automatic image croppingproblem', 1);('toget nal crop task', 1);('techniques generate largenumber candidates', 1);('windows varyingsizes aspect ratios', 1);('original image ofwhich', 1);('criterion asimage aesthetics attention regions nd bestcandidate', 1);('inefcient search spacespans', 1);('entire image', 1);('strategies mitigate', 1);('local redundancy', 1);('eliminatingcandidates encompass', 1);('entire region of2interest', 1);('efcient solutions', 1);('regard aesthetics', 1);('image generate manycandidates', 1);('position height aspect ratio', 1);('boxes andevaluate nd', 1);('approaches generate', 1);('candidates struggle', 1);('methods aim predicta single crop region', 1);('visual attention region image', 1);('regression network thatpredicts optimal', 1);('thesestrategies', 1);('efcient generate singlecandidate', 1);('approacheshowever methods', 1);('22once candidates', 1);('different wayssaliency', 1);('thebest crop', 1);('salient regions techniques', 1);('salient regions range signal processing', 1);('deep learning methods', 1);('determiningadjusting', 1);('methods nd', 1);('roi37', 1);('ardizzone', 1);('ciocca', 1);('sunand ling', 1);('31aesthetic evaluation methods', 1);('quantify scoreimages crop candidates', 1);('comprehensive review methods', 1);('deng', 1);('aesthetic', 1);('image croppingalgorithms', 1);('composition rules rule thirds visual balance', 1);('datasets v', 1);('deep learning methods 26other', 1);('nishiyama', 1);('7fusion methods', 1);('attention aestheticmethods', 1);('stages harness advantages ofboth approaches', 1);('determiningadjustingstrategy rst', 1);('attention region', 1);('small number candidates', 1);('aesthetic evaluation score', 1);('findinggeneration', 1);('strategies tryto regress', 1);('salient regions image', 1);('fusion approachesinclude', 1);('tu', 1);('guo', 1);('li', 1);('dataset images', 1);('humansprior methods', 1);('strategy design', 1);('sharpness color distancethat', 1);('boxes40 41some image', 1);('thisframework reinforcement learning framework', 1);('evaluation metrics', 1);('direct generation strategy', 1);('direct generation', 1);('input image', 1);('visual attention regions', 1);('candidates methods suffer thesame drawbacks', 1);('approaches aswhen', 1);('absent efcient', 1);('methods model', 1);('extractor efciency', 1);('large internal dataset trainour', 1);('39there use cases efciency', 1);('desiredfor example', 1);('multiple candidates userand', 1);('work focuses applications benet', 1);('candidates efciencyreasonsimage', 1);('thumbnail generationwhich aims', 1);('representative versions theoriginal images', 1);('useful content fromthe', 1);('background contrast image', 1);('aesthetic quality', 1);('salientregions approach', 1);('similar recent thumbnailgeneration approaches', 1);('fastat', 1);('cropnet3', 1);('similar strategy sharedfeature extractor', 1);('dataset annotatedby', 1);('workers contrast largerdataset', 1);('attentionto image aesthetics section', 1);('benchmark approach', 1);('stateoftheart performance', 1);('demonstratethat algorithm', 1);('pleasingimages display examples3', 1);('approach31 datasetprior', 1);('cite lackof', 1);('large datasets', 1);('effective image', 1);('limitation unableto nd', 1);('datasets support experiencebaseddirect generation approach image', 1);('strict aspect ratio requirements', 1);('internaldataset 51000images study', 1);('asiconic imagery tv programs movies', 1);('lead characters', 1);('backgroundthat conveys context relevant program imagewas', 1);('large group', 1);('important image content preservethe aesthetics adhere strict aspect ratio requirementsunlike datasets', 1);('rate discard images', 1);('aesthetics effort mitigate subjective bias', 1);('boxes workers rank annotate', 1);('efciency reasons', 1);('editors crop images', 1);('bias singleeditor', 1);('wepresent', 1);('examples images section', 1);('ofall', 1);('1athe dataset', 1);('diverse aspect ratios', 1);('successful modelwould generalize input images', 1);('weconsider', 1);('common aspect ratios addition', 1);('absolute error image', 1);('similar analysis performedby', 1);('celona', 1);('preprocessing augmentationwe', 1);('resize images', 1);('original image store bounds locations', 1);('coordinates thetop', 1);('horizontal ips color trans21', 1);('ratio02000040000counta distribution', 1);('ratio050001000015000countb distribution', 1);('original images169', 1);('ratio000005010maec mean absolute error mae', 1);('aspect ratio ofthe', 1);('aspect ratio distributionsformations', 1);('brightness saturation', 1);('spatial transformation rotation vertical', 1);('theseaffect composition image', 1);('modelour', 1);('intotwo modules', 1);('extractor thebackbone', 1);('multiple parallel regression heads', 1);('foreach aspect ratio', 1);('thisdesign', 1);('predictor heads', 1);('new aspect ratios', 1);('retrain rest network fromscratch', 1);('time inferenceas', 1);('able generate cropsfor unseen aspect ratios', 1);('leveragingthe predictions', 1);('similar aspect ratios helpfulwhen training data scarce331', 1);('feature extractorthe', 1);('output xedlengthfeature vector input image', 1);('regression heads', 1);('extractor regression head aspect ratio needs4featureextractorfeaturevectorregressionheads169', 1);('poolconvolutioninputimagea model architecture4096x1lrelulrelulrelulrelu512x1128x164x13x1sigmoidcxcywtransform', 1);('aspect ratio enforced regression head', 1);('transform generates', 1);('proposed model frameworkfigure', 1);('nonenforced', 1);('box prediction width wis', 1);('aspect ratio c', 1);('enforced', 1);('boxprediction height', 1);('similar information', 1);('important regions locations image', 1);('architectures backbone', 1);('vgg', 1);('resnet', 1);('densenet', 1);('wideresnet42 mobilenetv2', 1);('computer vision tasks', 1);('previous solutions', 1);('common architectures wideavailability', 1);('network weights', 1);('image classication', 1);('tasks study effect', 1);('networks section', 1);('regression headas', 1);('2b regression head', 1);('neural network', 1);('leaky relu', 1);('activation function intermediate layers sigmoid activation output regression head dedicatedto', 1);('box single aspect ratio', 1);('coordinates topleft xtlytlandthe bottomright corners xbrybr', 1);('representation guaranteethat output', 1);('aspectratiowe use alternate regression head', 1);('regression head landscape square aspectratio', 1);('coordinates center xcycandthe widthw', 1);('heightfor portrait aspect ratio', 1);('center coordinatesxcycand height h', 1);('weillustrate figure', 1);('aspect ratio xedfor', 1);('thetransform operation', 1);('2b run time clip the5prediction', 1);('possible boundingbox', 1);('center coordinates xcyc', 1);('invalid output use', 1);('smoothl1', 1);('boundingbox coordinates', 1);('fast rcnn', 1);('aspect ratio architecturecould', 1);('multiple regression heads peraspect ratio', 1);('useful cases wherefor example closeup version', 1);('versionfor aspect ratio needed4', 1);('experiments ablation studywe', 1);('validation test', 1);('18optimizer default learning rate', 1);('validation setwe use', 1);('boundary displacement error bde', 1);('theintersection union', 1);('previous approaches', 1);('nothave editors rank rate', 1);('different crops', 1);('metrics leverage', 1);('allmetrics', 1);('tables section', 1);('allthe aspect ratios test set41', 1);('evaluation datasetwe', 1);('models baseline method predicts', 1);('center image', 1);('baselines', 1);('box fraction largestpossible', 1);('box aspect ratio', 1);('gaic43', 1);('recent method capableof', 1);('predictor head method moreefcient use', 1);('models code', 1);('bythe authors', 1);('unable netune', 1);('images whichare', 1);('available dataset', 1);('table 1we', 1);('study inuence', 1);('extractor component themodel nd', 1);('signicant performance improvements', 1);('position type objects image use', 1);('subsequent experiments411', 1);('enforced aspect ratio predictionwe', 1);('test method', 1);('box report results', 1);('aspect ratio enforcedprediction method improves model performance', 1);('exact aspect ratio requirement412', 1);('cnn backbone architecturewe', 1);('aspect ratio regression heads', 1);('hyperparameters learning rate', 1);('constant present themetrics', 1);('architecture performs', 1);('overall alsond', 1);('mobilenetv2', 1);('itssmaller size terms number', 1);('trainable parameters42', 1);('evaluation fcdbthe', 1);('impose anyrequirements aspect ratios', 1);('model designedto', 1);('accurate benchmark difcult', 1);('modify model thisexperiment', 1);('boxes aspect', 1);('regressionheads attach single', 1);('regression head tothe', 1);('fcdbtraining', 1);('training validation', 1);('andthen netune', 1);('batch size', 1);('optimizerwith learning rate 1\x0210\x005for', 1);('similar previous experimentswe', 1);('present metrics', 1);('wereport', 1);('ground truth window acandidate view', 1);('post processingstep', 1);('vpnthe', 1);('approach competitivewith models', 1);('model image aestheticsor visual attention regions', 1);('multiple cropcandidates model', 1);('score theendtoend model', 1);('straightforward training approach', 1);('identication visual attention regions', 1);('score evaluates average 1745candidates', 1);('image inefcient', 1);('asmnet32', 1);('score uses inefcienttwostage', 1);('composition patternsfrom', 1);('composition rules', 1);('wang', 1);('authors approaches usethe', 1);('evaluation purposes ableto nd signicant inuence', 1);('pretraining train set enforced iou bdebaseline08', 1);('imagenet gaic43 true', 1);('wideresnet502 imagenet true', 1);('wideresnet502 imagenet false', 1);('true', 1);('model', 1);('evaluation datasetmodel', 1);('size ioubdevgg16', 1);('0025wideresnet502 688m', 1);('0023resnet50 255m', 1);('0025resnext50 250m', 1);('0027densenet121 79m', 1);('0025mobilenetv2 35m', 1);('cnn backbone architecture comparison', 1);('small size', 1);('test images', 1);('wide differences betweenindividual approaches models performance', 1);('subset models netune onfcdb', 1);('study impact', 1);('learning ourdataset', 1);('training model describedabove', 1);('oursimagenet onlyachieves iou', 1);('dataset betterthan', 1);('architecture signicant contributor performance', 1);('pretrainingon datasetprior approaches', 1);('efciency usingthe time crop single image metric', 1);('dependent hardware input image size implementationdetails', 1);('fair comparison difcult', 1);('neverthelesswe', 1);('present number crops', 1);('measure efciency', 1);('amongst', 1);('morerecent', 1);('speed 50fps image', 1);('gpu', 1);('approach bylu', 1);('able crop images', 1);('fps contrastour model', 1);('backbone crop 606input frames', 1);('nvidia tesla v100 gpuin', 1);('over3000 output crops', 1);('time load preprocess images', 1);('images order consistent enablecomparisons', 1);('evaluation mirthumbeven', 1);('goals image', 1);('methods differ thumbnail generation datasets', 1);('similar theyannotate image', 1);('model themirthumb test', 1);('test generalization ability', 1);('wealso', 1);('baseline methods section', 1);('aspect ratios notpresent dataset', 1);('wesynthesize', 1);('model predictions aspect ratios', 1);('aspect ratio inour model generate target aspect ratio', 1);('wereduce height', 1);('center 21prediction model', 1);('theclosest', 1);('keepthe height', 1);('width results areshown', 1);('aspect ratiosthat training', 1);('34these results', 1);('model generalizeswell', 1);('similar datasets tasks44', 1);('qualitative assessmentthe', 1);('perception image aesthetics', 1);('visual examples results algorithm images', 1);('mirthumb fcdband', 1);('dataset rst', 1);('cases ourmodel', 1);('mirthumbtest', 1);('human subjects', 1);('rare training dataset', 1);('mirthumb7model', 1);('tuning avg candidates iou bde fps gpu hardwarevfn', 1);('naa2rl', 1);('nvidia titan xvpn', 1);('nawang', 1);('na', 1);('tioursimagenet', 1);('nvidia tesla v100ours', 1);('nvidia tesla', 1);('evaluation fcdb', 1);('highlight models', 1);('model aesthetics andor attention regions', 1);('fps', 1);('refersto number input frames', 1);('train set test set iou baseline08', 1);('fatclean', 1);('mirthumb mirthumb', 1);('evaluation mirthumbdataset', 1);('model predictions', 1);('iouscore', 1);('inthe objective evaluation image', 1);('systems suchas', 1);('metric reliance single reference annotation', 1);('research areas', 1);('critical order tobuild', 1);('reliable robust image', 1);('nd model predictions appearto', 1);('composition aspects', 1);('aesthetics trainingto', 1);('ruleofthirds grid someimages', 1);('predictions infigure', 1);('behavior consistent', 1);('aspectratios source images target crop', 1);('likely result ourdataset', 1);('source images croppedby editorial experts', 1);('datasets image', 1);('flms', 1);('model predictionsfrom test', 1);('model identify themain subject image', 1);('subject relativelysmall', 1);('camera inanimate', 1);('thelast', 1);('display predictionswhen input', 1);('similar content differentoriginal', 1);('mirthumb predictionfigure', 1);('model generate crops', 1);('original annotations', 1);('withoutnetuningaspect ratios cases model', 1);('regions interest', 1);('similar cropsfor', 1);('output aspect ratioswe', 1);('examples model predictions', 1);('generalization ability model different8original 169h 11s 34vfigure', 1);('illustrating', 1);('models ability', 1);('aestheticand composition properties eg rule thirds', 1);('netuningdataset model', 1);('challengingand diverse images', 1);('images pets day andnight time landscapes abstract patterns inanimate objects observe model', 1);('importantimage content', 1);('difcult cases', 1);('large portion ofthe image', 1);('cropof portrait image', 1);('conclusionswe', 1);('direct generationstrategy image', 1);('image aesthetics visual attentionregions model', 1);('efcient straightforward architecture witha', 1);('different aspect ratios model', 1);('train existingmultistage approaches efcient inference asit', 1);('multiple candidatesdue lack', 1);('public datasets task', 1);('regard aspect ratio andmirthumb image thumbnail generation', 1);('generate outputs', 1);('stateoftheart results', 1);('examples ourmodel generates aesthetic crops ground truthannotations', 1);('able generalizeacross', 1);('multiple datasets', 1);('aesthetic properties source image inthe nal cropsreferences1', 1);('edoardo ardizzone alessandro bruno giuseppe mazzola saliency', 1);('alfredo petrosinoeditor image analysis processing iciap', 1);('berlin heidelberg', 1);('springer berlin heidelberg', 1);('luigi celona gianluigi ciocca paolo napoletano raimondo schettini autocropping', 1);('elisa ricci samuel rota bul cees snoek oswald lanz stefano messelodi nicu sebe', 1);('image analysis processing iciap', 1);('pages 315325cham', 1);('springer', 1);('huarong chen bin wang tianxiang pan liwang zhou', 1);('zeng cropnet realtime', 1);('j chen g bai liang z li automatic', 1);('computational complexity study', 1);('ieeeconference computer vision pattern recognitioncvpr', 1);('qiuyu chen wei zhang ning zhou peng lei yi xu yuzheng jianping fan adaptive', 1);('convolution network image aesthetics assessment', 1);('yiling chen tzuwei huang kaihan chang yuchentsai hwanntzong chen bingyu chen quantitativeanalysis', 1);('algorithms datasetand comparative study', 1);('ieee winter', 1);('conference onapplications', 1);('computer vision wacv', 1);('pages 226234ieee', 1);('yiling chen jan klopp min sun shaoyi chien', 1);('professional photographs web', 1);('gianluigi ciocca claudio cusano francesca gaspariniand raimondo schettini selfadaptive', 1);('forsmall displays', 1);('ieee transactions', 1);('electronics', 1);('yubin deng chen', 1);('loy xiaoou tang imageaesthetic', 1);('experimental survey', 1);('ieee signalprocessing magazine', 1);('seyed esmaeili bharat singh larry davis fastatfast', 1);('automatic thumbnail generation', 1);('deep neural net9original', 1);('images test dataset10original', 1);('ne tuning11works', 1);('chen fang zhe lin radomir mech xiaohui shen automatic', 1);('visual composition boundarysimplicity content preservation models', 1);('proceedingsof', 1);('ross girshick fast', 1);('international conference computer vision pages', 1);('guanjun guo hanzi wang chunhua shen yan yan', 1);('mark liao automatic', 1);('visual aesthetic enhancement', 1);('deep neural networks', 1);('kaiming xiangyu zhang shaoqing ren jian sundeep', 1);('residual learning image recognition', 1);('conference computer vision patternrecognition pages', 1);('gao huang zhuang liu laurens van der maaten kilian q weinberger densely', 1);('convolutional networks', 1);('conference computervision pattern recognition pages', 1);('laurent itti christof koch ernst niebur', 1);('visual attention', 1);('rapid scene analysisieee', 1);('transactions', 1);('pattern analysis machine intelligence', 1);('md baharul islam chen tet khuan muhammad ehsanrana md kabirul islam aaics aestheticsdriven', 1);('conferenceon data mining multimedia image processing', 1);('icdmmipa2016', 1);('diederik p kingma jimmy ba adam', 1);('method forstochastic optimization', 1);('yoshua bengio yann lecuneditors', 1);('learning representations iclr', 1);('san diego ca usa may', 1);('2015conference track', 1);('debang li huikai wu junge zhang kaiqi huang a2rl aesthetics', 1);('aware reinforcement learning image', 1);('nian liu junwei han dingwen zhang shifeng wen', 1);('liu predicting', 1);('eye xations', 1);('convolutionalneural networks', 1);('conference oncomputer', 1);('vision pattern recognition', 1);('peng lu jiahui liu xujun peng xiaojie wang weaklysupervised', 1);('realtime image', 1);('aesthetic distributions', 1);('acm internationalconference multimedia mm', 1);('newyork ny usa', 1);('computing machinery', 1);('peng lu hao zhang xujun peng xiaofu jin anendtoend', 1);('neural network image', 1);('learningcomposition aesthetic photos', 1);('p lu h zhang x peng x jin learning', 1);('objects aesthetic region image', 1);('peng lu hao zhang xujun peng xiang peng aesthetic', 1);('regression network image croppingsignal', 1);('processing image communication', 1);('lu x xing', 1);('cai x xu listwise', 1);('view rankingfor image', 1);('ieee access', 1);('mai hailin jin feng liu compositionpreservingdeep', 1);('photo aesthetics assessment', 1);('naila murray luca marchesotti florent perronninava', 1);('largescale database aesthetic visual analysisin2012', 1);('computer vision patternrecognition', 1);('masashi nishiyama takahiro okabe yoichi sato imarisato sensationbased', 1);('mark sandler andrew howard menglong zhu andrey zhmoginov liangchieh chen mobilenetv2 invertedresiduals', 1);('linear bottlenecks', 1);('karen simonyan andrew zisserman', 1);('deep convolutional networks largescale image recognition', 1);('inyoshua bengio yann lecun', 1);('internationalconference learning representations iclr', 1);('sandiego ca usa may', 1);('conference track', 1);('jin sun haibin ling scale', 1);('international journal computer vision', 1);('yi tu li niu weijie zhao dawei cheng liqing zhangimage', 1);('composition saliency', 1);('aware aesthetic score map', 1);('thirtyfourth aaai conferenceon articial intelligence aaai', 1);('thirtysecond innovative applications articial intelligence conferenceiaai', 1);('tenth aaai symposium educationaladvances articial intelligence eaai', 1);('yorkny usa february', 1);('aaaipress', 1);('shimon ullman amnon shaashua structural', 1);('saliencythe detection', 1);('salient structures', 1);('eleonora vig michael dorr david cox largescaleoptimization', 1);('saliency predictionin', 1);('natural images', 1);('proceedings ieee conferenceon computer vision pattern recognition', 1);('lijie wang xueting wang toshihiko yamasaki kiyoharu aizawa aspectratiopreserving', 1);('multipatch imageaesthetics score prediction', 1);('proceedings ieee con12ference computer vision pattern recognition', 1);('workshops pages', 1);('wenguan wang qiuxia lai huazhu fu jianbing shen', 1);('ling salient', 1);('object detection', 1);('learningera indepth survey', 1);('wenguan wang jianbing shen deep', 1);('attention box prediction aesthetics assessment', 1);('wenguan wang jianbing shen haibin ling', 1);('deepnetwork solution attention aesthetics', 1);('transactions pattern analysis machine intelligence', 1);('zijun wei jianming zhang xiaohui shen zhe linradomir mech minh hoai dimitris samaras goodview', 1);('photo composition', 1);('dense viewpairs', 1);('jianzhou yan stephen lin sing bing kang xiaooutang learning', 1);('automatic image croppinginproceedings', 1);('computer visionand pattern recognition', 1);('jianzhou yan stephen lin sing bing kang xiaooutang changebased', 1);('exclusion andcompositional', 1);('international journal', 1);('sergey zagoruyko nikos komodakis', 1);('residual networks', 1);('hui zeng lida li zisheng cao lei zhang grid', 1);('new benchmark efcientmodel', 1);('h zeng', 1);('li z cao', 1);('reliable efcient image', 1);('grid anchor', 1);('in2019 ieeecvf', 1);('computer vision pattern recognition cvpr', 1);('luming zhang mingli', 1);('qi zhao xiao liu jiajunbu chun chen probabilistic', 1);('ieee transactions image processing', 1);