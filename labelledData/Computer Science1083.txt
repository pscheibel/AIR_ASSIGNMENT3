('dfa', 22);('bp', 18);('fig', 14);('cim', 10);('nkland', 4);('launay', 4);('wgus', 4);('flops', 3);('furthermore', 3);('hence', 3);('adcs', 3);('neurosim', 3);('bp dfa', 3);('feedback alignment', 2);('dnnneurosim', 2);('direct feedbackalignment', 2);('neural networks', 2);('neumann', 2);('rram', 2);('sanz', 2);('dfas', 2);('mnist', 2);('mac', 2);('v10', 2);('synaptic arrays', 2);('atthe', 2);('fashionmnist', 2);('dfarequires', 2);('impact', 2);('dfa bp', 2);('network depth', 2);('proceedings', 2);('biologically plausible learning neuromorphichardware architectureschristopher wolters12 brady taylor2 edward hanson2 xiaoxuan yang2 ulf schlichtmann1and yiran chen21department electrical computer engineering duke', 1);('durham nc2institute electronic', 1);('automation technical', 1);('munich munich germanyemail1fchwolters', 1);('ulfschlichtmann gtumde2fbradygtaylor edwardthanson xiaoxuanyang1 yiranchen gdukeeduabstract', 1);('number parameters', 1);('complex networks', 1);('deep learning', 1);('human performance result datamovement millions model parameters', 1);('memory wall', 1);('neuromorphiccomputing', 1);('analog memories thesoftware side sequential', 1);('backpropagation', 1);('algorithm preventsefcient parallelization', 1);('convergence novel methoddirect', 1);('inherent layer dependenciesby', 1);('error output layerat intersection hardwaresoftware codesign ademand', 1);('tolerable hardwarenonidealities', 1);('work explores interrelationshipof', 1);('bioplausible learning insitu neuromorphichardware', 1);('energy area latency', 1);('impact hardware nonidealities quantization onalgorithm performance', 1);('network topologies andalgorithmlevel design choices scale latency energy areaconsumption chip', 1);('knowledge workis rst', 1);('different learning algorithmson', 1);('computeinmemorybased', 1);('hardware vice versa', 1);('thebest', 1);('backpropagationbasednotably', 1);('hardware imperfections', 1);('signicant speedup dueto parallelization', 1);('training time factor approachingn', 1);('nlayered', 1);('terms computeinmemory', 1);('deep neural network directfeedback alignment hardwaresoftware codesigni', 1);('ntroductionas', 1);('model complexities', 1);('dnnincrease', 1);('machine learning programs', 1);('human performance 5these models place', 1);('heavy demands', 1);('power aproblem', 1);('moores lawas', 1);('limits transistor technology', 1);('millions weights putsenormous demand data movement', 1);('imbalance results strict separation computationand memory von', 1);('expensive', 1);('drastic bottleneck', 1);('orders magnitude moreenergy', 1);('data transfers memory andchip oatingpoint operations', 1);('solution inwhich memory modules data processing units uniedto', 1);('data transportation memory chip', 1);('resistiverandomaccess', 1);('new generation nonvolatile memory systems', 1);('low access time energyconsumption', 1);('macros executehighthroughput dotproducts', 1);('computational densityand energy efciency', 1);('learning neuromorphic hardware emphasis energyarea latencywhile brain', 1);('empirical relation', 1);('learning neuroscience fact', 1);('backpropagation bp', 1);('biological implausibility', 1);('launayet', 1);('global dependence thenetworks layers postsynaptic layers', 1);('known', 1);('prevents network', 1);('learning process', 1);('biological synapses', 1);('symmetrical weight structuresin feedforward feedback directions', 1);('asthe weight transportation problem', 1);('faithful neuralbehavior family', 1);('direct feedback alignment dfawhich', 1);('solves implausibilities achievescompetitive performance', 1);('computational ow 7furthermore need algorithms robustlytolerate nonideal properties neuromorphic hardware', 1);('potential novel', 1);('inthis', 1);('different learning rulesperformance neuromorphic hardware architectures viceversa involves', 1);('inmemory implementations', 1);('particular attention chip area latencyand energy', 1);('softwareside accuracy', 1);('theprimary', 1);('learning hardwaresoftwarecodesign', 1);('absolute learning performancerelative differences', 1);('different technologies', 1);('various metrics section', 1);('ii', 1);('schemesin section', 1);('iii', 1);('approach determiningalgorithm', 1);('hardware viceversa', 1);('willdiscuss results section', 1);('iv', 1);('conclude paper insection', 1);('arxiv221214337v1 csne', 1);('dec', 1);('echnical backgrounda direct feedback alignmentthe', 1);('central question credit assignment neural networksis', 1);('mathematically', 1);('corresponds calculatingthe gradient respect output layer', 1);('denotes elementwise', 1);('hadamard', 1);('wis', 1);('theith layers weight matrix ais activation \x0eanis', 1);('error e8i21n\x001 \x0eailai', 1);('wti1\x0eai1', 1);('f0iai1the nal weight updates', 1);('as8i21n \x0ewi\x00\x0eaihti\x001 2parameter updates', 1);('backward sequentiallythrough network', 1);('blame error', 1);('neuron structure results ina computational ow', 1);('backward passesare', 1);('weights update ofsynaptic weights', 1);('backward process', 1);('bufferrequirements hardware', 1);('neuron needsprecise knowledge neurons', 1);('subsequent layers makingthe gradient calculation', 1);('global contrast brain highlyparallel asymmetric local computations', 1);('howeverbp', 1);('unable parallelize backward pass', 1);('itssequential layer dependencies', 1);('training bottleneckwithin', 1);('networksone potential solution biological implausibilities', 1);('performance limitations', 1);('bp direct feedbackalignment dfa', 1);('general structure', 1);('backward paths', 1);('symmetricweights random matrices', 1);('error projection', 1);('learning occurs network learns makethe teaching signal', 1);('useful mathematical terms', 1);('equation', 1);('3denes error projection', 1);('whereas formulas', 1);('layers error', 1);('same8i21n\x001 \x0eai', 1);('bie', 1);('random matrix', 1);('bi', 1);('corresponding dimensions output features\x02number classes replacesthe', 1);('weight matrix', 1);('wti furthermore', 1);('layer parallel placeof\x0eai1', 1);('layer dependencies', 1);('plausible process 7experiments', 1);('performance par', 1);('image classication stateoftheartmethods', 1);('graph convolutional networks', 1);('dfafails', 1);('convolutional neural networks', 1);('work focuses', 1);('networks onlyb', 1);('computinginmemorydespite', 1);('fundamental differences computational process learning rules', 1);('matrixvector multiplications', 1);('large numbers parallel', 1);('mac multiply accumulate', 1);('equations', 1);('3the number computations', 1);('increases networkdepth', 1);('demand computational power', 1);('hardware systems', 1);('close gap memory computation thevon', 1);('networks weights inmemory analog nature', 1);('physical memory computation', 1);('weight transferfrom memory chip', 1);('high performanceand energy efciency', 1);('similar tothe brain calculations', 1);('computational speedupthe', 1);('analog memory', 1);('input vector voltage signal', 1);('vand', 1);('applyingto memory cells', 1);('matrix weights', 1);('according', 1);('toohms law', 1);('current device product ofvand device conductance currents accumulate downeach column', 1);('kirchhoffs', 1);('current law', 1);('currentsijnxi1vigij 4are', 1);('column gijis conductance ofthe memristor ith row andjth column correspondsto dot product column conductances inputvoltage signal column weights', 1);('separatedot product', 1);('enormous throughput highenergy efciency 12however scheme encounters key', 1);('involvingvarious device circuitlevel nonidealities', 1);('thememory cells dataconversion circuitry', 1);('potential', 1);('issuesarise fabrication', 1);('processes egprocess variations', 1);('programmabilityand analogtodigital converters', 1);('analog outputs memory resultingerrors accumulate matrixvector multiplications degradethe models performance', 1);('critical study impact', 1);('imperfections largescale', 1);('dnnsiii pproachdue', 1);('solutions requiredfor hardware software address tasks', 1);('penget', 1);('circuitlevel macromodel', 1);('architectures performance metrics chip area latency energy supportsa hierarchical organization device level memorytechnology circuit level peripherals chiplevel tiles processing elements subarrays algorithmlevel neural network topologies', 1);('linear relationship', 1);('weight gradients digital circuit modules', 1);('due nonlinear asymmetric model', 1);('linear weight gradients', 1);('devicetodevice cycletocycle variation nonideal weight update lead accuracy degradations insitu training', 1);('c show device retention model', 1);('adc quantization loss partial sums feedforward operations', 1);('shows simulator', 1);('network topology input', 1);('design chip floorplan weightduplication', 1);('maximize memory utilization', 1);('memory total memory', 1);('certain layers network', 1);('convolutional layer', 1);('kernel size', 1);('memory subarray size order speed', 1);('dnn', 1);('e shows python wrapper neural activations', 1);('synaptic weights', 1);('feedforward evaluation', 1);('old synaptic weights weight update', 1);('weight update evaluation backpropagation', 1);('different weight gradients iteration hardware performance', 1);('limit overhead', 1);('time framework default', 1);('real traces neural activation', 1);('new old synaptic weights', 1);('iteration epoch run', 1);('reasonable simulation time', 1);('track hardware performance', 1);('different epochs training', 1);('f shows traces', 1);('different locations chip', 1);('topdown hierarchy', 1);('chip tile processing element', 1);('pe', 1);('synaptic array framework outputs', 1);('training inference accuracy python wrapper hardware metrics chip area latency', 1);('dynamic energy leakage power', 1);('energy efficiency throughput', 1);('core training inference modular circuit component estimation', 1);('spice', 1);('technology nodes 130nm 7nm', 1);('ptm', 1);('iii cim architecture training cim', 1);('accelerators support training', 1);('additional peripheral circuits calculate error weight gradient', 1);('key steps training', 1);('computation error', 1);('computation weight gradient', 1);('weight update', 1);('main hierarchical design', 1);('architecture breakdown details', 1);('different computation steps', 1);('architecture', 1);('simulator top level chip contains tiles', 1);('global buffer neuralfunctional peripheries', 1);('accumulation activations weight gradient computation function', 1);('srambased', 1);('multiple processing elements', 1);('pes pe', 1);('adder trees', 1);('local buffers', 1);('htree', 1);('interconnect support training synaptic arrays', 1);('schematic', 1);('chip oorplan', 1);('hierarchical designcan', 1);('chip tiles', 1);('pes pes', 1);('synaptic arrays manypossible memory typesto model', 1);('different technologies levels abstraction thestructure', 1);('hardware scheme', 1);('1in general', 1);('onchip memory sufcientto store synaptic weights', 1);('entire neural network', 1);('thusthe', 1);('access offchip memory fetch input data andbuffer intermediate values topdown perspective thechip', 1);('multiple tiles weights', 1);('aglobal buffer neural function units', 1);('accumulationand activation units tile', 1);('intoseveral processing elements tile buffer', 1);('activationsaccumulation modules partial sums output buffer', 1);('level processing element', 1);('analog calculations', 1);('weight gradient units wgus', 1);('staticrandomaccess memory', 1);('sram', 1);('8the simulator', 1);('direct consequence additionalbackward matrices', 1);('additional memory requirements', 1);('matrices matrix', 1);('dimensionsas backward matrices', 1);('error dimension thesecond dimension', 1);('number ofoutput', 1);('compute gradients', 1);('nlayers', 1);('nwgus', 1);('contrast oneis', 1);('backpropagationanother', 1);('random matrices errorfeedback', 1);('weight matrices theelimination need', 1);('transposable subarrays supportonchip training', 1);('backward computations transposablereadout scheme realizes', 1);('additional peripheral circuitry', 1);('decoders', 1);('adcsare', 1);('transposable arrays', 1);('peripheral circuitryis', 1);('neededone architectural difference', 1);('different dimensions matrices', 1);('duringthe backward pass error dimension', 1);('matrixmultiplications scale', 1);('totheir dimension', 1);('potential sources differences inour design metrics accuracy area latency energy amultiobjective optimization problem', 1);('different', 1);('functionsfor metrics need', 1);('optimize target value', 1);('impact metricsiv', 1);('iscussionwith', 1);('previous works', 1);('accuracy par', 1);('bpsunder', 1);('constraints focus', 1);('relative hardware comparisons betweenthe algorithms', 1);('learningas estimates', 1);('constant trainingprocess breakdown rst epoch depictedthroughout experiments default network layerswith', 1);('bp dfaachieve', 1);('comparable classication performance', 1);('task topology', 1);('different analysesmight', 1);('adjustments parameters changeswill indicateda', 1);('model performance direct feedback alignmentwhen', 1);('different hardware network hyperparameters', 1);('general performance', 1);('dfacompared bp', 1);('comparable performance theclassication task', 1);('fundamental output measure', 1);('experiments sanz', 1);('xavierinitialization relu', 1);('activation functions', 1);('results training largerbatches', 1);('dfasinherent', 1);('gradient approximation', 1);('thenumber iterations', 1);('models converge toa', 1);('stable training accuracy', 1);('modelperformance learning rule', 1);('accuracy dfa bp', 1);('layersthese results', 1);('epochs convergence asnetwork depth increasesthis', 1);('important insight latency evaluationswithin', 1);('networks network depth increases', 1);('epochs converge', 1);('especially', 1);('rstfew epochs', 1);('stable convergence', 1);('renetti', 1);('9characterize phenomenon memorise', 1);('whererst matrices', 1);('wandbare', 1);('process alignment occurs sequentiallythe effect', 1);('asecond', 1);('alignment phase becomesmore', 1);('apparent different matrix widths ie numberof', 1);('table compares nal testaccuracy learning rules', 1);('epochs trainingover', 1);('different matrix widthstable', 1);('ifinal test accuracy different layer widthswidth dfa bp8', 1);('080the gap', 1);('evidently', 1);('certain degree freedom', 1);('thenumber weights', 1);('align weights stillhave exibility', 1);('imperfections dfabased trainingwith', 1);('ndings mind impacts circuitparameters', 1);('adc precision subarray size network performance', 1);('corresponding nonidealities', 1);('complex data dependencies', 1);('circuitimperfections software side', 1);('signicant graphicsmemory contrast', 1);('itscomputational graph training analyses assumptionscan', 1);('general trends', 1);('onchip training', 1);('memory requirements threelayer networkis', 1);('task analysisfig', 1);('displays training stops 1bit adc precisiondue', 1);('gradients quantization errors 2bit precision', 1);('thresholdin contrast precision levels', 1);('yield signicantimprovement accuracy', 1);('large number epochs', 1);('slow learning process', 1);('adc precision hassignicant impact area energy consumption constitutinga major bottleneck', 1);('scheme tradeoff introducedby subarray size', 1);('overhead peripheral circuitslarger dimension subarrays invoke', 1);('overhead processingmore array data peripheral circuit', 1);('due substantialfig', 1);('adc precision', 1);('subarray size', 1);('dfabased', 1);('3bit adc', 1);('adequate accuracy resultswhile', 1);('subarray size increases errors', 1);('ir', 1);('dropir drop', 1);('noise inthe partial sum accumulationc', 1);('noise induced quantization device imperfectionsunlike', 1);('circuit nonidealities device imperfections', 1);('dfa bp1 quantization precision', 1);('quantizationeffects gradient', 1);('critical forbp', 1);('deep networks', 1);('sensitive errorsare', 1);('stillit', 1);('gradient precision', 1);('difcult align matrices', 1);('wandb', 1);('weight gradient precisions learningfor algorithms', 1);('agradient precision', 1);('bits error quantization', 1);('precisionsalthough 1bit', 1);('forbp', 1);('relative differences', 1);('visible performance steps observedfor', 1);('corresponding precision levels contrast', 1);('dfayields', 1);('accuracy precisions', 1);('quantizes error', 1);('hand error', 1);('layer layer', 1);('initial layers', 1);('low precisionsfig', 1);('effects', 1);('error precision test accuracy', 1);('bpregarding', 1);('hardware metrics', 1);('substantial differences', 1);('learning rule', 1);('error precisiondue errors', 1);('small dimensional sizein addition', 1);('robustness togeneral noise quantization', 1);('precision theactivation values', 1);('competitive performancefor', 1);('bits whereas', 1);('high performance allprecisions', 1);('activation values', 1);('thehardware side', 1);('area energy latency', 1);('thereforethe', 1);('quantization robustness', 1);('measurable advantageover', 1);('device imperfections', 1);('addition precision ofthe models hardware nonidealities', 1);('computational errors', 1);('imprecise results', 1);('experimentally', 1);('work imperfections devicetodevice', 1);('iterative training', 1);('visible difference', 1);('different levels variability', 1);('conductance states result pulsetopulse cycletocycle variation impact modelperformance', 1);('sweeping', 1);('standard deviation', 1);('conductances learningrules yield', 1);('different results', 1);('tocomparable accuracies', 1);('different degrees variabilitywhereas', 1);('moresevere', 1);('testaccuracies drop overall performance cycletocycle variation changes time contrast constantdevicetodevice variations errors', 1);('duringthe iterative training', 1);('dfa furthermore', 1);('variation converge cycletocyclevariation', 1);('weights toalign random weights', 1);('algorithmfrom convergingd', 1);('chip areaas fig', 1);('additional weight matrix', 1);('area consumption', 1);('area terms ofmemory cells', 1);('total chiparea', 1);('peripheral circuits', 1);('majority chiparea', 1);('adcs ics', 1);('circuits accumulationlogic weight gradient units', 1);('wgus bp', 1);('due need transposablecim 05ic116adc527accumulation99other92weightuni00a0gradients161cim 07ic75adc240accumulation49other97weightuni00a0gradients531fig', 1);('breakdown', 1);('chip area', 1);('adccircuitry', 1);('consumes area', 1);('bp wgus', 1);('consume areafor', 1);('dfafig', 1);('hardwarespecic', 1);('area consumption network depth includingadc', 1);('wgu', 1);('right area', 1);('bp dfaweights', 1);('dfachip', 1);('due parallel weightupdates layer', 1);('comparison betweenchip areas', 1);('use ofadcs', 1);('number changeswith', 1);('reveals trends', 1);('adcsin bp wgus dfa', 1);('insimilar trends total chip area', 1);('additional matrix memory requirementsdfa consumes', 1);('numberof layers increases', 1);('sramcells', 1);('costly terms area', 1);('network terms matrix width moresignicant difference', 1);('memory utilization', 1);('thediscrete', 1);('step tiles', 1);('network size', 1);('layers thenumber', 1);('featuresthe tile limit', 1);('memory cells', 1);('thereforea', 1);('tile structure', 1);('structure toaccount weights results', 1);('low utilization asignicant area overhead peripheralse', 1);('energy consumptionprevious', 1);('reduction number ofperipherals', 1);('compute gradientsin', 1);('dfa breaking', 1);('energy consumption different2', 1);('total chip area', 1);('network depthfig', 1);('memory utilization leftand chip area', 1);('tiles limit', 1);('memory cells means 1025hidden', 1);('area reducingmemory utilizationhardware categories', 1);('share allocatedto', 1);('offchip buffers', 1);('activations', 1);('errors gradientshave', 1);('offchip memory', 1);('bottleneck training process', 1);('offchip accesses', 1);('force energy', 1);('matrices sizeand intermediate values', 1);('differences inbuffer accesses', 1);('energy consumptionf', 1);('training latencya', 1);('similar pattern', 1);('training latency 91thereof', 1);('actual computations', 1);('intermediate results', 1);('assumption differentlayers access', 1);('dram', 1);('blocks parallel considerablespeedup', 1);('weight gradientcalculation', 1);('fundamental differences', 1);('9in contrast', 1);('sequential computational owdfa', 1);('scheme networkdepth increases latency', 1);('dfatakes', 1);('training time', 1);('number oflayers layers', 1);('ratio latencies', 1);('todfa approaches', 1);('nfornparallelized', 1);('epochs converge speedup respect toperformance', 1);('parallelization enablessubstantial acceleration', 1);('throughputv c', 1);('onclusionwhile backpropagation', 1);('model performance inmost cases', 1);('noisy environments', 1);('resolves bottleneck sequential dependenciesthus', 1);('environments edge devices', 1);('valuable alternative', 1);('tradeoffs', 1);('area latency', 1);('incorporatingadditional hardware', 1);('whena', 1);('chip design', 1);('degree parallelizationand number', 1);('thispotentially', 1);('increase precision2', 1);('training', 1);('network depth ability ofdfa parallelize weight updates', 1);('considerable reduction latencyof', 1);('values eg activation values', 1);('hence dfa', 1);('precision values chip area', 1);('bpaccuracy', 1);('toovercome imprecise naturefrom biological perspective', 1);('neuromorphic hardware', 1);('local computations', 1);('fundamental implausibilities learning articial neural', 1);('enhancethe idea bioplausibility', 1);('higherenergy efciency noise tolerance', 1);('conventional neural networks', 1);('yoshua bengio donghyun lee jorg bornschein thomas mesnard', 1);('lin towards', 1);('miao hu catherine graves li yunning li ning ge eric montgomery noraica', 1);('hao jiang stan williams jianhua joshua yangqiangfei xia john william strachan memristorbased', 1);('analogcomputation neural network classication dot product', 1);('materials', 1);('julien launay iacopo poli franc', 1);('boniface florent krzakaladirect', 1);('feedback alignment scales', 1);('modern deep learning tasks andarchitectures', 1);('h larochelle ranzato r hadsell mf balcanand h lin', 1);('advances neural information processing systems', 1);('curran associates inc', 1);('julien launay iacopo poli florent krzakala principled', 1);('training ofneural networks', 1);('direct feedback alignment', 1);('yann lecun yoshua bengio geoffrey hinton deep', 1);('may', 1);('yann lecun corinna cortes', 1);('mnist database handwrittendigits', 1);('arild nkland direct', 1);('learning deepneural networks', 1);('xiaochen peng shanshi huang hongwu jiang anni lu shimengyu dnnneurosim', 1);('v20 endtoend', 1);('framework forcomputeinmemory accelerators onchip training', 1);('ieee transactionson computeraided', 1);('integrated circuits systems pp1112', 1);('maria renetti st', 1);('dascoli ruben ohana sebastian goldtalign', 1);('memorise dynamics learning feedback alignmentin', 1);('marina meila tong zhang', 1);('international conference', 1);('machine learning', 1);('learning', 1);('research pages', 1);('pmlr', 1);('jul', 1);('albert jim', 1);('sanz mohamed akrout benchmarking', 1);('accuracyand robustness feedback alignment algorithms', 1);('linghao', 1);('xuehai qian yiran chen pipelayer', 1);('learning pages', 1);('brady taylor qilin zheng ziru li shiyu li yiran chenprocessinginmemory', 1);('technology machine learning', 1);('basic toasic', 1);('ieee transactions circuits systems ii express briefs', 1);('han xiao kashif rasul roland v', 1);('novelimage dataset', 1);('machine learning algorithms', 1);('xiaoxuan yang syrine belakaria biresh kumar joardar huanrui yangjanardhan rao doppa partha pratim pande krishnendu chakrabarty', 1);('helen li multiobjective', 1);('optimization reram crossbars robustdnn', 1);('stochastic noise', 1);('ieeeacm internationalconference computer aided', 1);('iccad', 1);('ieee press2021', 1);