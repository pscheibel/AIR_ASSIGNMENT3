('computer vision', 31);('stt', 30);('proceedings', 30);('edge loss', 26);('pattern recognition', 19);('ieee/cvf', 18);('fig', 15);('edge maps', 15);('content images', 14);('s2wat', 14);('content details', 12);('image style', 12);('stytr2', 12);('style images', 11);('conv pe', 11);('cnn-based', 10);('transformer', 10);('transformer-based', 10);('relu', 10);('laplacian', 9);('international conference', 9);('artflow', 8);('identity losses', 8);('arbitrary style', 7);('pe', 7);('ape', 7);('different', 6);('iest', 6);('cast', 6);('ieee', 6);('weiming dong', 6);('content leak problem', 5);('artistic style', 5);('gatys', 5);('vgg', 5);('ne content details', 5);('perceptual losses', 5);('edge extractor', 5);('ln', 5);('ics', 5);('european conference', 5);('fan tang', 5);('changsheng xu', 5);('arbitrary image style', 4);('style patterns', 4);('methods [', 4);('ours', 4);('figure', 4);('compared', 4);('transformers', 4);('furthermore', 4);('novel edge loss', 4);('msa', 4);('mlp', 4);('content structure', 4);('adain', 4);('sanet', 4);('matthias bethge', 4);('neural information processing systems', 4);('yanghao li', 4);('springer', 4);('proceed-', 4);('chongyang ma', 4);('arbitrary', 4);('advances', 4);('aaai', 4);('articial intelligence', 4);('vision transformers', 4);('vision transformer', 4);('image', 3);('texture synthesis', 3);('neural style', 3);('content leak', 3);('canny', 3);('sobel', 3);('fcand style', 3);('ic', 3);('feature maps', 3);('\x00 l', 3);('identity loss', 3);('wct', 3);('mcc', 3);('style quality', 3);('style', 3);('alexander', 3);('ecker', 3);('leon', 3);('im-', 3);('dmitry ulyanov', 3);('andrea vedaldi', 3);('victor lempitsky', 3);('yijun li', 3);('ming-hsuan yang', 3);('jie', 3);('jiebo luo', 3);('errui ding', 3);('yingying deng', 3);('training', 3);('han zhang', 3);('recent years', 2);('sufcient style patterns', 2);('content image', 2);('main purpose', 2);('nst', 2);('input images', 2);('thanks', 2);('content style', 2);('recently', 2);('deng', 2);('contrastive learning strategy', 2);('vision tasks', 2);('cnn-', 2);('picture clarity', 2);('multiple style', 2);('stylebank', 2);('flow-based', 2);('transformer-based stytr2', 2);('satisfying effects', 2);('style transfer', 2);('li', 2);('lapstyle', 2);('icand', 2);('style image', 2);('content im- ages', 2);('input image', 2);('h\x02w\x023', 2);('default value', 2);('mha', 2);('artistic patterns', 2);('there-', 2);('mask operation', 2);('style differences', 2);('lcontent', 2);('content perceptual loss', 2);('andrelu 51are', 2);('iss', 2);('adam', 2);('reference time', 2);('different image style', 2);('state-of-the-art arbitrary style', 2);('qualitative comparison', 2);('artistic characteristics', 2);('in-', 2);('attention mechanism', 2);('projection ow network', 2);('method [', 2);('cape', 2);('comparison', 2);('edge loss canny sobel laplacian', 2);('william t freeman', 2);('convolutional neural networks', 2);('age style', 2);('acm', 2);('lu yuan', 2);('jing liao', 2);('eccv', 2);('serge belongie', 2);('lu sheng', 2);('xiaogang wang', 2);('xueting li', 2);('jan kautz', 2);('closed-form solution', 2);('universal style', 2);('video style', 2);('inproceedings', 2);('zhizhong wang', 2);('haibo chen', 2);('wei xing', 2);('dongming lu', 2);('wei liu', 2);('real-time', 2);('tianwei lin', 2);('fu li', 2);('dongliang', 2);('xin li', 2);('ieee/cvf con-', 2);('haibin huang', 2);('lei wang', 2);('language understanding', 2);('hugo touvron', 2);('matthijs douze', 2);('francisco massa', 2);('herv', 2);('jegou', 2);('machine learning', 2);('pmlr', 2);('huaxia xia', 2);('haoqi fan', 2);('bo xiong', 2);('jitendra malik', 2);('christoph feichten-', 2);('computer vi-', 2);('ze liu', 2);('yutong lin', 2);('yue cao', 2);('han hu', 2);('yixuan wei', 2);('zheng zhang', 2);('swin', 2);('object detection', 2);('huiwen chang', 2);('lu jiang', 2);('ce liu', 2);('edge enhanced image style transfer', 1);('transformers chiyu zhang1', 1);('jun yang2', 1);('zaiyan dai3', 1);('peng cao4 sichuan normal', 1);('university 1alienzhang19961005 @ gmail.com2jkxy yjun @ sicnu.edu.cn f3daizaiyan,4pcg @ stu.sicnu.edu.cn', 1);('abstract', 1);('ob- jects', 1);('qualitative', 1);('quantitative experiments', 1);('comparable performance', 1);('state-of-the-art image style', 1);('introduction rendering', 1);('interesting topic', 1);('com- puter vision', 1);('long history', 1);('re- searchers [', 1);('] utilize techniques', 1);('pro- cess', 1);('fea- tures', 1);('iterative', 1);('] ren- der', 1);('noise images', 1);('feed-forward networks [', 1);('feed-forward manner', 1);('vivid', 1);('feed-forward methods', 1);('certain number', 1);('inadequate style quality', 1);('encoder-transfer-decoder archi-', 1);('visual', 1);('small ones', 1);('attention mechanism [', 1);('content leak prob- lem', 1);('meth- ods', 1);('repetitive stylization process', 1);('zhang', 1);('previous methods', 1);('] leverage', 1);('visual quality', 1);('previ- ous methods', 1);('cap- ture long-range dependencies', 1);('owing', 1);('self-attention mechanism', 1);('global information', 1);('archi- tecture', 1);('multi-time downsample operations', 1);('1arxiv:2301.00592v1 [ cs.cv ]', 1);('jan', 1);('2023the content leak problem [', 1);('good effect', 1);('im- age style', 1);('high visual quality', 1);('styletransfer', 1);('encode content', 1);('different encoders', 1);('hierarchal structure', 1);('semantic information', 1);('en- hance', 1);('extra restriction', 1);('main contributions', 1);('new image style', 1);('network name', 1);('stylize images', 1);('high quality', 1);('images ob-', 1);('extensive', 1);('outstanding effects', 1);('able results', 1);('related', 1);('image style transfer', 1);('rough classication', 1);('generalization abili- ties', 1);('backbone architecture', 1);('generalization abilities', 1);('style trans- fer encodes', 1);('certain tricks', 1);('con- ditional instance normalization [', 1);('certain module', 1);('arbitrary style trans- fer', 1);('tech- niques', 1);('upstream tasks', 1);('image classication', 1);('im- age generation', 1);('] methods', 1);('flow-', 1);('structure wherethe shape', 1);('adopts hierarchal architecture', 1);('contrastive loss', 1);('adversarial loss', 1);('opti- mization targets', 1);('image style trans- fer methods', 1);('main objects', 1);('vison transformer', 1);('inherited', 1);('long-range dependencies', 1);('natural lan- guage processing', 1);('nlp', 1);('wide variety', 1);('image classication [', 1);('object detection [', 1);('semantic segmentation [', 1);('image generation [', 1);('traditional structure', 1);('hierarchical ar- chitecture', 1);('favorable effect', 1);('convolutional operations', 1);('ful- ll', 1);('parametric positional', 1);('operations [', 1);('utilization', 1);('oper- ators', 1);('contour detection', 1);('devia- tions', 1);('image distortions', 1);('iterative image style', 1);('lapla-', 1);('cian loss', 1);('subsequently', 1);('l- ter', 1);('revision network', 1);('feed-forward image style', 1);('above meth- ods', 1);('transformer-based stt', 1);('colorful artistic features', 1);('method', 1);('architec- ture', 1);('isby', 1);('module name', 1);('isinto', 1);('linear projection', 1);('trans- form', 1);('generated', 1);('partitionlinear projectionconv pe conv pelayer', 1);('1layer 2layer 3layer 1layer 2layer', 1);('transformer encoder transformer decoderdecoder edge extractor edge extractor edge loss lnmsamhalnmlp ln', 1);('k v', 1);('architecture', 1);('transformer decoder layer figure', 1);('net architecture', 1);('images need', 1);('overall architecture', 1);('optimization strategy', 1);('overall architecture encoder', 1);('content-aware po- sitional', 1);('convolutional layers', 1);('activation layer', 1);('main role', 1);('reection layers', 1);('re- sults', 1);('con- volutional layers', 1);('content-aware posi- tional', 1);('independent domain-specic encoders', 1);('normal pic- tures', 1);('patch partition layer', 1);('shape ofhw 8\x028\x02c', 1);('adding', 1);('three- layer', 1);('computation process', 1);('+ ^cl', 1);('multi- head self-attention', 1);('multi- layer perceptron', 1);('layernorm', 1);('shape consistent', 1);('inputconv', 1);('1x1reflectconv 3x3relureflectconv 3x3output', 1);('decoder', 1);('original size', 1);('de- code', 1);('sequence-like shapehw 8\x028\x02c', 1);('module', 1);('decoder layers', 1);('computational process', 1);('q=ln', 1);('y\x01wv ~xl=mha', 1);('+ ^xl xl=mlp', 1);('+ ~xl', 1);('layer l', 1);('style fea- tures', 1);('wq', 1);('wk', 1);('projection matrices', 1);('value vectors', 1);('leveraging', 1);('cross attention', 1);('output images', 1);('edge detection', 1);('contour extraction', 1);('content de- tails', 1);('back- ground', 1);('similar- ity', 1);('optimization target', 1);('main structure', 1);('ex- ist', 1);('corresponding place', 1);('weak responses', 1);('overall computational process', 1);('edg -ic', 1);('laplacianoperator', 1);('old parameter', 1);('above steps', 1);('network optimization', 1);('per- ceptual losses', 1);('content differences', 1);('identity losses [', 1);('whole loss function', 1);('ltotal=\x15clcontent', 1);('+\x15slstyle+ \x15id1lid1+\x15id2lid2+\x15edgledg', 1);('lid1andlid2are', 1);('ledgrepresents', 1);('magnitude differences', 1);('perceptual loss', 1);('vgg19', 1);('41andrelu 51are', 1);('cal- culate', 1);('style perceptual loss', 1);('mean-variance channel-wise nor- malization', 1);('calcu- lation', 1);('=x l2ck l', 1);('lstyle', 1);('=x l2lk\x16', 1);('k2+ k\x1b', 1);('style per- ceptual losses', 1);('thel-th layer', 1);('mean-variance channel-wise normalization', 1);('loss', 1);('following', 1);('style representations', 1);('lid1=kicc\x00ick2+kiss\x00isk2', 1);('lid2=x', 1);('l2lk l', 1);('icc', 1);('k2+k l', 1);('com- mon pair', 1);('specically', 1);('origi- nal content', 1);('original results', 1);('sec-', 1);('op- erator rst', 1);('threshold function', 1);('ledg=kedg-ic\x00edg-icsk2', 1);('experiments', 1);('details datasets', 1);('ms-coco', 1);('content dataset', 1);('wikiart', 1);('style dataset', 1);('shorter side rst', 1);('training information', 1);('pytorch', 1);('im- plement', 1);('batch size', 1);('initial learning rate', 1);('optimizer [', 1);('warmup strategy [', 1);('learning rate', 1);('tesla v100 gpu', 1);('tesla p100 gpu.4.2', 1);('different methods fulll', 1);('different ways', 1);('colorful results', 1);('second-order statistics', 1);('alignment process', 1);('transfers ade- quate style', 1);('overow issue', 1);('linear operations', 1);('generate unde-', 1);('contrastive learning strat- egy', 1);('favorable effects', 1);('plentiful style representa- tions', 1);('methods nd', 1);('balance be- tween content', 1);('en- coder', 1);('style pat- terns', 1);('drops content details', 1);('quantitative comparison', 1);('content differ- ences', 1);('indirect metric', 1);('content quality', 1);('implicit metric', 1);('eval- uate', 1);('auxiliary metrics', 1);('content loss', 1);('transformer-', 1);('obvious advantages', 1);('reversible transformation', 1);('content', 1);('oursfigure', 1);('visual comparison', 1);('prob- lem', 1);('drop grad-', 1);('experimental rounds', 1);('] utilize', 1);('net- work', 1);('reversible trans- formation', 1);('strict reversibility', 1);('long-range depen- dencies', 1);('content leak is-', 1);('20th rounds', 1);('styl- ization', 1);('degree lack', 1);('20th round', 1);('content struc- ture', 1);('content leak problem.4.4', 1);('ablation', 1);('positional', 1);('absolute positional encod-', 1);('functional [', 1);('para- metric [', 1);('] positional', 1);('sinu- soidal', 1);('vertical track artifacts', 1);('large positional deviation', 1);('unsatisfactory per- formance', 1);('convolutional oper- ations', 1);('verti- cal track artifacts', 1);('pat- tern', 1);('edge loss erases', 1);('ours s2wat stytr2 cast iest artflow mcc sanet wct adain content loss', 1);('style loss', 1);('# 0.160.160.16', 1);('quantitative', 1);('loss values', 1);('random samples average', 1);('random samples', 1);('bold font marks', 1);('underline shows', 1);('second-best values', 1);('content content style styleours s2wat stytr2 artflow cast iest mcc sanet wct adainround', 1);('visualization', 1);('pe ape conv pe', 1);('different types', 1);('ex- tract', 1);('important step', 1);('hollow stroke', 1);('ne strokes', 1);('clear- est result', 1);('unpleasant patterns', 1);('vertical/horizontal tracks', 1);('demon- strate', 1);('conclusion', 1);('long-range in- formation', 1);('content-aware positional en-', 1);('convolutional op- erations', 1);('positional information', 1);('im- ages', 1);('new method', 1);('ne con- tent details', 1);('sufcient style', 1);('stylized images content', 1);('edge imagesfigure', 1);('different edge detection operators', 1);('references', 1);('alexei', 1);('efros', 1);('an- nual conference', 1);('computer', 1);('interactive tech- niques', 1);('stefan bruckner', 1);('eduard gr', 1);('func- tions', 1);('illustrative volume', 1);('computer graph-', 1);('forum', 1);('wiley online', 1);('leon gatys', 1);('tex-', 1);('ture synthesis', 1);('ad-', 1);('neural algorithm', 1);('arxiv preprint arxiv:1508.06576', 1);('aaron hertzmann', 1);('eli shechtman', 1);('preserving', 1);('arxiv preprint arxiv:1606.05897', 1);('eric risser', 1);('pierre wilmot', 1);('connelly barnes', 1);('controllable neural texture synthesis', 1);('histogram losses', 1);('arxiv preprint arxiv:1701.08893', 1);('shaohua li', 1);('xinxing xu', 1);('liqiang nie', 1);('tat-seng chua', 1);('laplacian-steered', 1);('multimedia', 1);('naiyan wang', 1);('jiaying liu', 1);('xiaodi hou', 1);('demystifying', 1);('arxiv preprint arxiv:1701.01036', 1);('jiahao lu', 1);('neural texture synthesis', 1);('asia pacic information technol-', 1);('ogy conference', 1);('justin johnson', 1);('alexandre alahi', 1);('li fei-fei', 1);('perceptual', 1);('real-time style', 1);('vadim lebedev', 1);('texture', 1);('feed-forward', 1);('syn- thesis', 1);('arxiv preprint arxiv:1603.03417', 1);('chuan li', 1);('michael wand', 1);('precomputed', 1);('real-time texture synthesis', 1);('markovian generative adversarial networks', 1);('stance normalization', 1);('fast styliza- tion', 1);('arxiv preprint arxiv:1607.08022', 1);('texture networks', 1);('maximizing', 1);('feed-forward stylization', 1);('vincent dumoulin', 1);('jonathon shlens', 1);('manjunath kud-', 1);('arxiv preprint arxiv:1610.07629', 1);('dongdong chen', 1);('nenghai yu', 1);('gang hua', 1);('explicit representation', 1);('neural im- age style', 1);('minxuan lin', 1);('xiao li', 1);('chang-', 1);('xu', 1);('distribution', 1);('multi- modal', 1);('multi-domain image stylization', 1);('acm transac-', 1);('multimedia computing', 1);('communications', 1);('ap-', 1);('tomm', 1);('hang zhang', 1);('kristin dana', 1);('multi-style', 1);('generative net- work', 1);('tian qi chen', 1);('mark schmidt', 1);('fast', 1);('arxiv preprint arxiv:1612.04337', 1);('xun huang', 1);('adaptive instance normalization', 1);('computer vi- sion', 1);('chen fang', 1);('jimei yang', 1);('zhaowen wang', 1);('xin lu', 1);('universal', 1);('neural information processing sys- tems', 1);('ziyi lin', 1);('jing shao', 1);('avatar-', 1);('multi-scale', 1);('zero-shot style', 1);('decora- tion', 1);('shuyang gu', 1);('congliang chen', 1);('ar-', 1);('bitrary style', 1);('ming-yu liu', 1);('photorealistic image stylization', 1);('ming lu', 1);('hao zhao', 1);('anbang yao', 1);('yurong chen', 1);('feng xu', 1);('li zhang', 1);('con-', 1);('sifei liu', 1);('learning', 1);('linear transformations', 1);('fast image', 1);('huan wang', 1);('yuehai wang', 1);('haoji hu', 1);('ming- hsuan yang', 1);('collaborative', 1);('haoyi xiong', 1);('jun huan', 1);('ultrafast', 1);('photorealistic style', 1);('neural architecture search', 1);('articial intel-', 1);('zhijie wu', 1);('chunjin', 1);('yang zhou', 1);('minglun gong', 1);('hui huang', 1);('efanet', 1);('alignment net- work', 1);('jan svoboda', 1);('asha anoosheh', 1);('osendorfer', 1);('jonathan masci', 1);('two-stage', 1);('recom- bination', 1);('xiao-chang liu', 1);('xuan-yi li', 1);('ming-ming cheng', 1);('peter hall', 1);('geometric', 1);('arxiv preprint arxiv:2007.05471', 1);('yongcheng jing', 1);('xiao liu', 1);('yukang ding', 1);('xinchao wang', 1);('mingli', 1);('shilei wen', 1);('dynamic', 1);('instance normalization', 1);('lei zhao', 1);('lihong qiu', 1);('qihang mo', 1);('sihuan lin', 1);('diversied', 1);('pro-', 1);('tao li', 1);('haozhi huang', 1);('li shen', 1);('xuan wang', 1);('yongyi tang', 1);('jinwen ma', 1);('univer- sal style', 1);('high-resolution images', 1);('arxiv preprint arxiv:2006.09029', 1);('zhuoqi ma', 1);('nannan wang', 1);('jie li', 1);('xinbo gao', 1);('drafting', 1);('pyramid network', 1);('fast high-quality', 1);('dae', 1);('young park', 1);('kwang hee lee', 1);('style-attentional networks', 1);('yuan yao', 1);('jianqiang ren', 1);('xuansong xie', 1);('weidong liu', 1);('yong-jin liu', 1);('jun wang', 1);('attention-aware', 1);('multi-stroke style', 1);('wen sun', 1);('feiyue huang', 1);('multi-adaptation network', 1);('songhua liu', 1);('meiling wang', 1);('zhengxing sun', 1);('qian li', 1);('adaattn', 1);('revisit', 1);('arbitrary neural style', 1);('multi-channel correlation', 1);('huiming zhang', 1);('zhiwen zuo', 1);('ailin li', 1);('artistic', 1);('internal-external learning', 1);('contrastive learn-', 1);('siyu huang', 1);('yibing', 1);('dejing dou', 1);('artow', 1);('unbiased', 1);('re- versible neural ows', 1);('xiaolei wu', 1);('zhihao hu', 1);('dong xu', 1);('style-', 1);('parametric style composition', 1);('ieee/cvf interna-', 1);('tional conference', 1);('xingjia pan', 1);('yuxin zhang', 1);('tong-yee lee', 1);('do-', 1);('contrastive learning', 1);('arxiv preprint arxiv:2205.09542', 1);('chiyu zhang', 1);('jun yang', 1);('zaiyan dai', 1);('hierarchical vision transformer', 1);('strips window attention', 1);('arxiv preprint arxiv:2210.12381', 1);('dzmitry bahdanau', 1);('kyunghyun cho', 1);('yoshua bengio', 1);('neural', 1);('machine translation', 1);('arxiv preprint arxiv:1409.0473', 1);('ashish vaswani', 1);('noam shazeer', 1);('niki parmar', 1);('jakob uszko-', 1);('llion jones', 1);('aidan n gomez', 1);('kaiser', 1);('illia polosukhin', 1);('attention', 1);('alec radford', 1);('karthik narasimhan', 1);('tim salimans', 1);('ilya sutskever', 1);('improving', 1);('gen- erative', 1);('jacob devlin', 1);('ming-wei chang', 1);('kenton lee', 1);('kristina toutanova', 1);('bert', 1);('pre-training', 1);('deep bidirectional transformers', 1);('arxiv preprint arxiv:1810.04805', 1);('alexey dosovitskiy', 1);('lucas beyer', 1);('alexander kolesnikov', 1);('dirk weissenborn', 1);('xiaohua zhai', 1);('thomas unterthiner', 1);('mostafa dehghani', 1);('matthias minderer', 1);('georg heigold', 1);('syl-', 1);('gelly', 1);('trans-', 1);('image recognition', 1);('arxiv preprint arxiv:2010.11929', 1);('matthieu cord', 1);('alexandre sablayrolles', 1);('data-efcient image transformers', 1);('at- tention', 1);('li yuan', 1);('yunpeng chen', 1);('tao wang', 1);('weihao yu', 1);('yujun shi', 1);('zi-hang jiang', 1);('francis eh tay', 1);('jiashi feng', 1);('shuicheng yan', 1);('tokens-to-token', 1);('ieee/cvf in-ternational', 1);('xiangxiang chu', 1);('bo zhang', 1);('zhi tian', 1);('xiaolin wei', 1);('explicit position encodings', 1);('arxiv preprint arxiv:2102.10882', 1);('kai han', 1);('xiao', 1);('enhua wu', 1);('jianyuan guo', 1);('chunjing xu', 1);('yunhe wang', 1);('yifan xu', 1);('zhijie zhang', 1);('mengdan zhang', 1);('kekai sheng', 1);('ke li', 1);('liqing zhang', 1);('xing sun', 1);('evo-vit', 1);('slow-fast', 1);('token evolution', 1);('dynamic vision transformer', 1);('aaai confer-', 1);('zhengzhong tu', 1);('hossein talebi', 1);('feng yang', 1);('peyman milanfar', 1);('alan bovik', 1);('yinxiao li', 1);('maxvit', 1);('multi-axis', 1);('arxiv preprint arxiv:2204.01697', 1);('benjamin graham', 1);('alaaeldin el-nouby', 1);('pierre', 1);('armand joulin', 1);('levit', 1);('convnets clothing', 1);('interna- tional conference', 1);('wenhai wang', 1);('enze xie', 1);('xiang li', 1);('deng-ping fan', 1);('kaitao', 1);('ding liang', 1);('tong lu', 1);('ping luo', 1);('ling shao', 1);('pyramid', 1);('versatile backbone', 1);('dense prediction', 1);('karttikeya mangalam', 1);('zhicheng yan', 1);('multiscale', 1);('chao-yuan wu', 1);('karttikeya man-', 1);('improved', 1);('multiscale vision transformers', 1);('classica- tion', 1);('arxiv preprint arxiv:2112.01526', 1);('stephen lin', 1);('baining guo', 1);('hierarchical', 1);('zhuliang yao', 1);('zhenda xie', 1);('jia ning', 1);('li dong', 1);('transformer v2', 1);('scaling', 1);('nicolas carion', 1);('gabriel synnaeve', 1);('nicolas usunier', 1);('alexander kirillov', 1);('sergey zagoruyko', 1);('end-to-', 1);('end object detection', 1);('european confer- ence', 1);('xizhou zhu', 1);('weijie su', 1);('lewei lu', 1);('bin li', 1);('jifeng dai', 1);('deformable detr', 1);('deformable trans- 10formers', 1);('end-to-end object detection', 1);('arxiv preprint arxiv:2010.04159', 1);('zhigang dai', 1);('bolun cai', 1);('yugeng lin', 1);('junying chen', 1);('up-detr', 1);('unsupervised', 1);('josh beal', 1);('eric kim', 1);('eric tzeng', 1);('dong huk', 1);('andrew zhai', 1);('dmitry kislyuk', 1);('toward', 1);('arxiv preprint arxiv:2012.09958', 1);('saining xie', 1);('xinlei chen', 1);('piotr', 1);('kaim-', 1);('ross girshick', 1);('benchmarking', 1);('arxiv preprint arxiv:2111.11429', 1);('yuqing wang', 1);('zhaoliang xu', 1);('xinlong wang', 1);('chunhua shen', 1);('baoshan cheng', 1);('hao shen', 1);('end-to-end', 1);('video instance segmentation', 1);('sixiao zheng', 1);('jiachen lu', 1);('hengshuang zhao', 1);('xiatian zhu', 1);('zekun luo', 1);('yabiao wang', 1);('yanwei fu', 1);('jianfeng feng', 1);('tao xiang', 1);('philip hs torr', 1);('rethinking', 1);('semantic segmen- tation', 1);('sequence-to-sequence perspective', 1);('trans- formers', 1);('yifan jiang', 1);('shiyu chang', 1);('zhangyang wang', 1);('transgan', 1);('strong gan', 1);('arxiv preprint arxiv:2102.07074', 1);('maskgit', 1);('masked', 1);('generative image transformer', 1);('kwonjoon lee', 1);('zhuowen tu', 1);('vitgan', 1);('vi- sion transformers', 1);('arxiv preprint arxiv:2107.04589', 1);('tsung-yi lin', 1);('michael maire', 1);('james hays', 1);('pietro perona', 1);('deva ramanan', 1);('piotr doll', 1);('lawrence zitnick', 1);('microsoft', 1);('common objects', 1);('fred phillips', 1);('brandy mackintosh', 1);('wiki', 1);('art gallery', 1);('issues', 1);('diederik p kingma', 1);('jimmy ba', 1);('stochastic optimization', 1);('arxiv preprint arxiv:1412.6980', 1);('ruibin xiong', 1);('yunchang yang', 1);('di', 1);('kai zheng', 1);('shuxin zheng', 1);('chen xing', 1);('huishuai zhang', 1);('yanyan lan', 1);('liwei wang', 1);('tieyan liu', 1);('layer normalization', 1);