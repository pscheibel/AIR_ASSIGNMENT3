('ieee', 38);('wmm-v', 33);('computer vision', 33);('zsl', 32);('g-zsl', 30);('training instances', 30);('semantic space', 30);('imagenet', 27);('eq', 27);('zero-shot learning', 24);('proceedings', 24);('pattern recognition', 24);('deep wmm-v', 22);('zero-shot', 20);('sae', 20);('source classes', 18);('figure', 18);('cnn', 17);('awa', 16);('eszsl', 14);('target classes', 13);('mm-v', 13);('devise', 12);('fu', 11);('svr', 11);('pattern analysis', 11);('machine intelligence', 11);('ieee transactions', 11);('deep-svr', 10);('] w', 10);('top-1', 10);('learning', 9);('international conference', 9);('neural information processing systems', 9);('t. xiang', 9);('fudan', 8);('china', 8);('open vocabulary', 8);('machine learning', 8);('supervised', 8);('upervised', 8);('ausuc', 8);('advances', 8);('s. gong', 8);('specically', 7);('conse', 7);('amp', 7);('cnn vgg19', 7);('b. schiele', 7);('springer', 7);('computer', 6);('wmm-voc', 6);('l-bfgs', 6);('weibull', 6);('table', 6);('wmm-voc deep wmm-voc deep-svr sae', 6);('f-', 6);('> s', 6);('s-', 6);('> f', 6);('top-5', 6);('deep wmm- v', 6);('acm', 6);('european conference', 6);('deep wmm-voc', 5);('data term', 5);('particularly', 5);('open set recognition', 5);('unseen classes', 5);('xian', 5);('vgg-19', 5);('svm', 5);('svr-map', 5);('z ero-shot', 5);('source training instances', 5);('-like setting', 5);('z. akata', 5);('l. sigal', 5);('t. m. hospedales', 5);('data', 4);('email', 4);('jiang', 4);('class name', 4);('training data', 4);('zero-shot recognition', 4);('wt', 4);('ilsvrc', 4);('different settings', 4);('training instance number020406080100top1 accuracy', 4);('open-set setting', 4);('deep svr', 4);('s. bengio', 4);('joint', 4);('f. shen', 4);('hanze dong', 3);('yu-gang jiang', 3);('xiangyang xue', 3);('generalized', 3);('open-set', 3);('zero- shot learning', 3);('shanghai', 3);('hefei', 3);('columbia', 3);('semantic embeddings', 3);('open set image recognition', 3);('class prototypes', 3);('semantic', 3);('large number', 3);('critically', 3);('wsabie', 3);('ale', 3);('sje', 3);('open-set recognition', 3);('unseen instances', 3);('one-shot learning', 3);('large amount', 3);('open set vocabulary', 3);('learning setting', 3);('notably', 3);('recognition', 3);('rp', 3);('+\x15kwk2 f', 3);('conference version [', 3);('singer', 3);('hubness problem', 3);('margin distribution', 3);('minimal values', 3);('class zi', 3);('prototype uzi', 3);('signicant level', 3);('deep network', 3);('experimental', 3);('test instances', 3);('sgd', 3);('a+w cnn overfeat', 3);('cnn inception-v2', 3);('dap', 3);('eszslfig', 3);('learning task', 3);('different number', 3);('discriminative information', 3);('source domain', 3);('top-', 3);('aux', 3);('@ k', 3);('tag', 3);('pseudo', 3);('feature extractor', 3);('machine', 3);('towards', 3);('s. changpinyo', 3);('w.-l. chao', 3);('f. sha', 3);('a. frome', 3);('li', 3);('r. socher', 3);('l. fei-fei', 3);('r. fergus', 3);('object categories', 3);('g. s. corrado', 3);('dean', 3);('t. mikolov', 3);('transductive', 3);('neural networks', 3);('knowledge', 3);('l. liu', 3);('m. rohrbach', 3);('w. j. scheirer', 3);('t. e. boult', 3);('a. torralba', 3);('w. t. freeman', 3);('large', 3);('ph.d.', 3);('phd', 3);('star award', 3);('xiaomei wang', 2);('meng wang', 2);('object categorization', 2);('recent years', 2);('object classes', 2);('vice versa', 2);('zero- shot', 2);('vocabulary atoms', 2);('attributes', 2);('typically', 2);('wang', 2);('shanghai key lab', 2);('intelligent information processing', 2);('yanwei fu', 2);('information', 2);('source dataset', 2);('target dataset', 2);('continuous semantic space', 2);('fig', 2);('illustration', 2);('support vector regression', 2);('t-sne visualization', 2);('motor vehicles', 2);('open set', 2);('image recognition settings', 2);('semantic words', 2);('incorrect ones', 2);('training samples', 2);('voc', 2);('conference paper [', 2);('one-shot learning [', 2);('semantic attributes [', 2);('siamese', 2);('class labels', 2);('large open set vocabulary', 2);('different label', 2);('previous work', 2);('novel classes', 2);('large-scale dataset', 2);('recently', 2);('semantic word vectors', 2);('word vectors', 2);('word2vec [', 2);('glovec', 2);('recognition step', 2);('comparing', 2);('competitive performance', 2);('semantic entities', 2);('class label', 2);('additional distractor classes', 2);('test time', 2);('learning embedding', 2);('rd', 2);('word vector', 2);('w=', 2);('loss function', 2);('instance x', 2);('nn', 2);('rocchio', 2);('mm-voc', 2);('ds', 2);('training class', 2);('minimization problem', 2);('triplet term', 2);('formally', 2);('c+1', 2);('\x001 2d', 2);('\x152 +', 2);('ms', 2);('wis', 2);('source training classes', 2);('margin distance', 2);('available training instances', 2);('algorithm', 2);('extreme', 2);('prototypes', 2);('instances g', 2);('positive instances', 2);('few-shot learning setting', 2);('learning process', 2);('/2010 dataset', 2);('source/auxiliary classes', 2);('resnet101', 2);('target data', 2);('target splits', 2);('recognition vocabulary', 2);('chance performance', 2);('additionally', 2);('hence', 2);('source instances', 2);('classication', 2);('evaluation setting', 2);('pen- set', 2);('test data', 2);('source/auxiliary domain', 2);('target domain', 2);('-like settings', 2);('mimic s', 2);('test', 2);('prediction candidates', 2);('acc', 2);('oc methods', 2);('hybrid', 2);('3billion words', 2);('recognition accuracy', 2);('a+w cnn', 2);('sse', 2);('cnn googlenet', 2);('uvds', 2);('dem', 2);('relation', 2);('cnn overfeat', 2);('100-d word vector', 2);('1000-d word vector', 2);('classication accuracy', 2);('state-of-art methods', 2);('oc outperforms', 2);('varying', 2);('seen-unseen', 2);('curve', 2);('large-scale', 2);('wlearned', 2);('deep version', 2);('z ero shot', 2);('k >', 2);('open-set310k', 2);('supervised-like', 2);('accuracy', 2);('zero shot-like', 2);('learning framework', 2);('3k 5k 10k 20k 50k', 2);('knn', 2);('embed', 2);('good performance', 2);('image classication', 2);('s. ullman', 2);('cvpr05', 2);('a. bendale', 2);('t. boult', 2);('b. gong', 2);('object recognition', 2);('a. vedaldi', 2);('a. zisserman', 2);('delving', 2);('4.3.1 [', 2);('machine learning research', 2);('j. deng', 2);('g. dinu', 2);('a. lazaridou', 2);('m. baroni', 2);('s. j. hwang', 2);('x. xue', 2);('p. perona', 2);('j. shlens', 2);('z. fu', 2);('attribute', 2);('e. kodirov', 2);('k. grauman', 2);('4.2.1 [', 2);('s. kotz', 2);('i. sutskever', 2);('g. e. hinton', 2);('data engineering', 2);('t.', 2);('x. xu', 2);('multimedia', 2);('yang', 2);('l. shao', 2);('c. manning', 2);('introduction', 2);('m. stark', 2);('cvpr', 2);('society conference', 2);('l. p. jain', 2);('knowledge discovery', 2);('databases', 2);('l. zhang', 2);('k. p. murphy', 2);('k. verma', 2);('p. rai', 2);('articial intelligence', 2);('learning systems', 2);('t. zhang', 2);('z.-h. zhou', 2);('disney', 2);('professor', 2);('research interests', 2);('acm sigmm rising', 2);('brown', 2);('leonids', 2);('vocabulary-informed zero-shot', 1);('open-set learning y', 1);('leonid sigal abstract', 1);('signicant progress', 1);('class vocabularies', 1);('address problems', 1);('incorporates distance constraints', 1);('distance', 1);('constraints ensure', 1);('model shows improvements', 1);('large open set recognition', 1);('310k class vocabulary', 1);('animal', 1);('index terms vocabulary-informed', 1);('ntroduction object', 1);('unprecedented advances', 1);('convolutional neural networks', 1);('cnns', 1);('successful recognition models', 1);('learning problems', 1);('concept class [', 1);('exuberant need', 1);('recognition models', 1);('humans', 1);('000basic level categories [', 1);('object category classes', 1);('internet', 1);('research areas', 1);('fmri images [', 1);('character recognition [', 1);('verication [', 1);('object recognition [', 1);('video understanding [', 1);('zero-shot learning approaches aim', 1);('recog- nize instances', 1);('target \x0fyanwei', 1);('{ yanweifu', 1);('hzdong15 } @ fudan.edu.cn', 1);('xyxue } @ fudan.edu.cn', 1);('corresponding author', 1);('aitrics', 1);('eric.wangmeng @ gmail.com', 1);('sigal', 1);('bc', 1);('canada', 1);('lsigal @ cs.ubc.ca.categories', 1);('intermediate- level semantic representations', 1);('visual instances', 1);('training time', 1);('general experimental setting', 1);('important drawbacks', 1);('target label', 1);('unknown labels [', 1);('000entry level categories', 1);('large amounts', 1);('world [', 1);('vast open set vocabulary', 1);('corresponding semantic knowledge', 1);('source class recognition', 1);('class-incremental learning [', 1);('appropriate model', 1);('recent study [', 1);('] argues', 1);('own brains', 1);('smoothlyarxiv:2301.00998v1 [ cs.cv ]', 1);('jan', 1);('4source/auxiliary classes', 1);('decision', 1);('source/target classes', 1);('external vocabulary atoms', 1);('truck andcarorunicycle andtricycle', 1);('cortical surface', 1);('image instances', 1);('zero-shot class truck', 1);('large overlap', 1);('mini- vans', 1);('such objects', 1);('basic knowledge', 1);('recognition criterion stricter', 1);('encoding', 1);('model results', 1);('generic recognition', 1);('vocab- ulary/semantic dictionary', 1);('textual sources', 1);('statistical semantic relations', 1);('semantic dictionary', 1);('weighted maximum margin v', 1);('embedding', 1);('training visual instances', 1);('particular class', 1);('semantic word vector prototype', 1);('correct class word vector prototype', 1);('nearby classes', 1);('appropriate margins', 1);('training sample', 1);('word vector prototype', 1);('extreme values theory', 1);('main contribution', 1);('novel paradigm', 1);('end-to-end network', 1);('nearest-neighbor distance', 1);('images project', 1);('correct class prototypes', 1);('experimentally', 1);('open set image recognition performance', 1);('vocabulary entities', 1);('effective learning', 1);('r elated work', 1);('learning approaches [', 1);('key idea', 1);('new categories', 1);('zero-shot learning [', 1);('vast open set vocabulary [', 1);('contextual information [', 1);('visual-semantic', 1);('such models', 1);('different forms', 1);('examples', 1);('networks [', 1);('class-incremental learning', 1);('identify classes', 1);('experimental settings', 1);('similarly', 1);('target labels', 1);('conceptually', 1);('open-vocabulary object retrieval [', 1);('natural language open- vocabulary queries', 1);('object recognition algorithms', 1);('] aims', 1);('object classiers', 1);('enable one-shot learning', 1);('contextual infor- mation [', 1);('object classiers.2.3', 1);('zero-shot learning zero-shot learning', 1);('semantic representations [', 1);('attribute vector prototypes', 1);('human annotation effort', 1);('alternative semantic representation [', 1);('large-scale text corpus', 1);('language models', 1);('semantic representations', 1);('notable exception', 1);('21k zero-shot classes', 1);('modest vocabulary', 1);('1k source classes', 1);('explore vocabularies', 1);('problem setup', 1);('conventional zero-shot learning', 1);('chao', 1);('zero-shot learning algorithms', 1);('evaluation settings', 1);('visual-semantic embedding mapping', 1);('support vector regressors', 1);('neural network [', 1);('common new space', 1);('cca', 1);('model trains', 1);('training in- stances', 1);('open set vocabulary items', 1);('word vector representation', 1);('incorporates constraints', 1);('vocabulary prototypes', 1);('v ocabulary', 1);('problem', 1);('assume', 1);('ds=fxi', 1);('zigns i=1ofns samples', 1);('english', 1);('phrases w', 1);('ws\\wt=', 1);('jwtj > > jwsj', 1);('new test image', 1);('vector x\x03the goal', 1);('function z\x03=f', 1);('available information', 1);('class label z\x03', 1);('problem changes', 1);('\x0fzero-shot learning', 1);('wtg', 1);('open set setting', 1);('target datasets', 1);('denition', 1);('vocabulary-informed learning', 1);('complete vocabulary data', 1);('oc utilizes', 1);('additional annotations', 1);('semantic knowledge', 1);('semantic embed-', 1);('large- scale corpus', 1);('vocabulary entity w2w', 1);('semantic vector u2rd', 1);('semantics', 1);('image recognition', 1);('such semantic', 1);('semantic knowledge base', 1);('neighbor distance', 1);('=carif g', 1);('class j', 1);('essentially', 1);('semantic word vector', 1);('class prototype [', 1);('core question', 1);('samples xiproject', 1);('corresponding class prototypes uzithan', 1);('prototype uiin', 1);('open set vocabulary i2wnzi', 1);('function f', 1);('eachimage sample xiis', 1);('corresponding class prototype uziby', 1);('arg min', 1);('wnsx', 1);('rdis', 1);('frobenius norm', 1);('form solution', 1);('matrix w', 1);('neighbor classier', 1);('= arg min i', 1);('wtx', 1);('simple variant', 1);('z\x03= arg min ikwtx\x03\x00', 1);('nearest', 1);('classier measures distance', 1);('semantic vectors', 1);('pro- totypes', 1);('employ semantic vector prototype', 1);('positive prototype', 1);('pigs andhog', 1);('likely prototype', 1);('infor- mation retrieval', 1);('relevance feedback', 1);('relevant instances', 1);('vector space', 1);('chap', 1);('sophisticated algorithms [', 1);('maximum margin voc embedding', 1);('semantic word space', 1);('wsuch', 1);('easiest way', 1);('above objective', 1);('euclidian', 1);('sample projections', 1);('generalizing', 1);('kernel version', 1);('] .5', 1);('appropriate prototypes', 1);('wtxi\x00uzi', 1);('compatibility function [', 1);('strategy \x0f\x00insensitive', 1);('=1tj\x18j2 \x0f', 1);('\x15is regularization coefcient', 1);('j= maxn', 1);('j \x00wzi\x01\x0fo', 1);('j-th value', 1);('corresponding vector', 1);('jis thej-th column', 1);('class ziand', 1);('equal weight wziis', 1);('compute wziin section', 1);('conventional \x0f\x00svr', 1);('convex quadratic', 1);('differentiable everywhere', 1);('minimization problem directly2', 1);('samples project', 1);('data constraints', 1);('uziis asymptomatic', 1);('minor error', 1);('discriminative constraints', 1);('mv', 1);('=1 2avx a=1\x14', 1);('a2wnw s', 1);('cis', 1);('margin gap', 1);('[ \x01 ]', 1);('smooth hinge loss [', 1);('tentative experiments shows', 1);('similar results', 1);('variance.is convex', 1);('speedup computation', 1);('avtarget', 1);('source/auxiliary prototype uziin', 1);('similar constraints', 1);('source prototype pairs', 1);('=1 2bsx b=1\x14', 1);('wsis', 1);('source/auxiliary dataset vocabulary', 1);('term enforces', 1);('bsprototypes', 1);('prototype uziin', 1);('crammer', 1);('loss [', 1);('slight variants', 1);('vs.', 1);('complete triplet', 1);('rank hinge loss', 1);('considers loss', 1);('source/auxiliary data', 1);('maximum margin vocabulary-informed embedding', 1);('wntx', 1);('l\x0f', 1);('controls contribution', 1);('practical advantage', 1);('objective function', 1);('weighted maximum margin voc embedding', 1);('previous method', 1);('num- ber', 1);('data samples span', 1);('large radius [', 1);('hubness [', 1);('adding', 1);('subsection introduces', 1);('novel class', 1);('investigation [', 1);('] .6', 1);('pairwise distance', 1);('negative instance', 1);('positive instance', 1);('fundamen- tal', 1);('svms', 1);('intuitive interpretation', 1);('such classiers', 1);('reproducing kernel hilbert', 1);('previous', 1);('classiers [', 1);('] aim', 1);('recent studies [', 1);('generalization performance', 1);('semantic space g', 1);('many4 samplesg', 1);('class distributions5', 1);('distance dij=kg', 1);('instance i', 1);('di=', 1);('minimal values \x16di', 1);('= mindi', 1);('based', 1);('= exp\x12 \x00\x12kg', 1);('k \x15i\x13\x14i\x13', 1);('scale parameters', 1);('diusing maximum likelihood estimate', 1);('mle', 1);('alg', 1);('equation', 1);('specic class', 1);('cauchy', 1);('6. codes', 1);('extreme value theorem', 1);('evt', 1);('input', 1);('values x1', 1);('output', 1);('estimated', 1);('parameters ^\x14', 1);('ifn==', 1);('else', 1);('sortx1', 1);('xnto getx [', 1);('] \x15\x01\x01\x01\x15x [ n ]', 1);('wherex [ i ]', 1);('maximum', 1);('likelihood estimator', 1);('np\x10 x\x14 [ i ] logx [ i ] \x00x\x14 [ n ] logx [ n ] \x11', 1);('p\x10', 1);('x\x14 [ i ] \x00x\x14 [ n ] \x11 =x logx [ i ]', 1);('solve eq', 1);('estimate ^\x14', 1);('fzero function', 1);('matlab', 1);('compute', 1);('^\x15=\x10p\x10 x^\x14 [ i ] \x00x^\x14 [ n ] \x11 =n\x111=^\x14', 1);('consider', 1);('samples g', 1);('class distributions', 1);('vast open vocabulary uzj', 1);('duzi=f', 1);('gzj2\x08 g', 1);('uzj gfor', 1);('bound- ary', 1);('= exp \x00 kgzi\x00uzik \x15uzi', 1);('above equation models', 1);('minimum value', 1);('boundary density', 1);('boundary distribution', 1);('esti- mate', 1);('minimal value \x16duzi', 1);('exp\x12 \x00\x12\x16d', 1);('\x15uzi\x13\x14uzi\x13 =', 1);('=\x15uzi\x01log1=\x14uzi\x121 0:05\x13', 1);('coverage distribution', 1);('class g', 1);('instance g', 1);('cuzi=\x08', 1);('orange circle', 1);('distance \x16cuzi', 1);('= maxcuziwill', 1);('probability distribution', 1);('= 1\x00exp0 b @ \x00 kg', 1);('\x00uzik \x150uzi', 1);('\x140 uzi1', 1);('ca', 1);('where\x140 iand\x150 iare reverse', 1);('scale pa- rameters', 1);('cuzi', 1);('coverage distribution uzi', 1);('maximum values \x16c', 1);('=\x150 uzi\x01log1=\x140 uzi\x121 1\x000:05\x13', 1);('weight wzifor classziin', 1);('wzi/\x10 \x16d', 1);('+ \x16c', 1);('^\x15=x1in one-shot setting', 1);('w.', 1);('weights wziare', 1);('important role', 1);('training iterations', 1);('weight wzistarts', 1);('deep weighted maximum margin voc embedding', 1);('extract xifrom', 1);('raw images', 1);('convolutional layers', 1);('corresponding network', 1);('stochastic gradient descendent', 1);('e xperiments', 1);('animals', 1);('target/test classes', 1);('model [', 1);('wsas', 1);('few-shot recognition sce- narios', 1);('training examples', 1);('wsvocabulary', 1);('wtas', 1);('general', 1);('-zero -shot recognition', 1);('uses source classes', 1);('targetwtor originalwsrecognition vocabulary', 1);('entire open vocabulary', 1);('jwj\x19 310katoms', 1);('test images', 1);('oc variants', 1);('competitors', 1);('source data', 1);('shot', 1);('open-set recognition settings', 1);('wand', 1);('semantic manifold', 1);('neural network', 1);('linear layer', 1);('entire network', 1);('semantic encoder-decoder paradigm', 1);('projects visual', 1);('original visual', 1);('representation [', 1);('rst learns', 1);('classes [', 1);('state-of-the-art large-scale zero-shot learning approaches', 1);('multi- class logistic regression classier', 1);('class probabilities', 1);('author webpage [', 1);('metrics', 1);('eval- uation metrics', 1);('evaluation metrics', 1);('main evaluation metric', 1);('tandu', 1);('h=', 1);('setting', 1);('parameters', 1);('recognition tasks', 1);('various number', 1);('relevant baselines', 1);('method variants', 1);('codes', 1);('x \x15to0:01and = 0:6with', 1);('learning rate', 1);('2every 10epochs.avandbsare', 1);('5in order', 1);('balance performance', 1);('computational cost', 1);('pairwise constraints', 1);('stochastic gradient descent', 1);('great progress ini-', 1);('steady convergence', 1);('full objective', 1);('good initialization', 1);('leverage benets', 1);('hybrid method', 1);('large-scale datasets', 1);('approx- imate', 1);('friedlander', 1);('hybrid optimization methods', 1);('hybrid algorithm', 1);('% training time', 1);('google', 1);('large text corpus', 1);('7billion words', 1);('umbc webbase', 1);('wikipedia', 1);('web documents', 1);('1billion words', 1);('low frequency', 1);('high frequency', 1);('frequency <', 1);('> 10million times', 1);('310k words/phrases', 1);('openness = 1\x00p', 1);('dataset 4.2.1', 1);('learning classiers', 1);('few source training instances', 1);('mimic human performance', 1);('resnet100', 1);('methods s. sp features acc', 1);('akata', 1);('a+w cnn googlenet', 1);('tmv-blp', 1);('sr+se', 1);('pst', 1);('latem', 1);('cmt', 1);('taste', 1);('klda+krr', 1);('cln+krr', 1);('w/a cnn overfeat', 1);('sync', 1);('w/a cnn', 1);('net [', 1);('gfzsl', 1);('se-gzsl', 1);('clswgan', 1);('f-clswgan [', 1);('ptmca', 1);('jayaraman', 1);('yuet', 1);('iap', 1);('hex', 1);('cnn decaf', 1);('ahle', 1);('different semantic spaces', 1);('s. sp', 1);('dimension word2vec dictionary', 1);('chance-level', 1);('different', 1);('different methods', 1);('eszsl zsl', 1);('previous methods [', 1);('100/1000-dimensional word2vec representation', 1);('key novelty', 1);('wmm- v', 1);('source train-', 1);('oc validate', 1);('zero-shot learning accuracy', 1);('deep models', 1);('conduct experiments', 1);('dimensional word vectors', 1);('instances from10', 1);('dimension svr-map deep-svr sae eszsl mm-voc wmm-voc deep wmm-voc supervised100-dim', 1);('51.4/- 71.59/91.98 70.22/92.60 74.86/94.85 58.01/87.88 75.57/94.31 76.23/94.85 1000-dim 57.1/- 76.32/95.22 75.32/94.17 75.08/94.27 59.1/77.73', 1);('/96.01 76.55/', 1);('zero-shot100-dim', 1);('52.1/- 53.12/84.24 67.96/95.08 73.69/95.83 61.10/96.02 82.78/98.92 84.87/98.87 1000-dim 58.0/- 64.29/88.71 71.42/97.18 74.17/97.12 83.84/96.74 89.09/', 1);('g-zsl100-dim', 1);('5.65/54.45 2.15/52.7 2.88/68.37 19.74/85.79 28.92/88.01 33.04/89.11 1000-dim', 1);('0/39.84 0/35.91 0/33.09 8.54/59.79 27.98/90.47 34.77/90.76', 1);('general zero', 1);('1000-dim word2vec representation', 1);('method shows signicant improvements', 1);('few-shot setting', 1);('visual semantic', 1);('information learning', 1);('% and90:65 % accuracy', 1);('previous methods', 1);('additional attribute representations', 1);('competitor methods', 1);('own method', 1);('general zero-shot learning', 1);('general zero-shot learning results', 1);('general zero-shot setting', 1);('overall', 1);('handausuc', 1);('eszsl supervised', 1);('learning results', 1);('pen-set310ksetting', 1);('large vocabulary', 1);('310k entities', 1);('100-dim word vector representations', 1);('maximum margins', 1);('training class name', 1);('source training data', 1);('corresponding non-', 1);('open-set recognition accuracy', 1);('no.of tr', 1);('ins', 1);('unavailable results', 1);('metrics eszsl sae deep-svr wmm-v', 1);('2.88/0 2.15/0 5.65/0 28.92/27.98 33.04/', 1);('75.76/76.08 70.13/75.32 71.22/', 1);('70.20/74.20 71.16/69.48', 1);('5.55/0 4.17/0 10.47/0 40.96/40.64 45.13/', 1);('0.4231/0.4344 0.3885/0.4556 0.3048/0.3939 0.4840/', 1);('0.19/0 0.78/0 5.34/0.02 25.57/25.68 27.59/', 1);('78.02/83.41 78.92/81.46 74.23/77.33 75.53/77.19', 1);('0.38/0 1.54/0 10.00/0.04 38.04/38.56 40.42/', 1);('0.4409/0.4710 0.3870/0.4483 0.3452/0.4400 0.4764/', 1);('0.71/0 0.87/0 4.69/0 24.63/27.22', 1);('/32.86 s', 1);('/86.24 81.08/85.48 83.30/86.02 74.99/77.67 78.96/78.64', 1);('1.41/0 1.72/0 8.88/0 37.08/40.31', 1);('0.4507/0.5139 0.4190/0.4740 0.3776/0.4780 0.5016/0.5572 0.5554/', 1);('0.37/0 0.44/0 5.19/0 27.80/30.53', 1);('/28.19 s', 1);('89.98/91.16 88.18/', 1);('85.37/85.64 77.36/78.34 80.64/78.32', 1);('0.74/0 0.88/0 9.79/0 40.90/43.94', 1);('0.5096/0.5294 0.4493/0.5120 0.3353/0.4397 0.5144/0.5319', 1);('0.83/0 0.37/0 5.39/0 27.15/29.42', 1);('/31.78 s', 1);('notable advantage', 1);('method tends', 1);('source label', 1);('humpback whale', 1);('blue whale', 1);('false positive rate', 1);('nundenes', 1);('unseeen instances', 1);('experiments', 1);('100- dim word vector prototypes', 1);('false positive rates', 1);('1000-dimensional word2vec representation', 1);('awa.testing classes awa', 1);('targ', 1);('svr-map mm-voc deep-svr deep wmm-voc wmm-voc fig', 1);('openset', 1);('settings svr-map deep-svr eszsl sae mm-voc wmm-voc deep wmm-voc supervised', 1);('25.6/ 31.26/50.51 38.26/64.38 32.95/54.44 37.1/62.35 35.95/62.77 38.92/65.35', 1);('4.1/ 5.29/13.32 5.86/13.71 5.11/12.62 8.90/14.90 8.50/20.73 9.26/21.99', 1);('fair comparison', 1);('g eneral zero-shot', 1);('source training', 1);('standard few-shot learning assumes disjoint instance', 1);('target domains', 1);('sec', 1);('ablation study', 1);('standard few-shot learning assumption', 1);('-few-shot learning', 1);('vgg-', 1);('dataset [', 1);('pseudo-', 1);('training classiers', 1);('additional ablation study', 1);('few-shot-like task', 1);('few-shot source training instance', 1);('mimic human capability', 1);('penalty term', 1);('outper- forms', 1);('supervised learning', 1);('training instance number0204060top1 accuracy', 1);('eszsl zero-shot learning', 1);('training instance number0246810top1 accuracy', 1);('zero-shot learning results', 1);('oc result', 1);('mm- v', 1);('oc outperform', 1);('full set', 1);('few-shot target training', 1);('introduce few-shot learning experiments', 1);('target instances', 1);('target class', 1);('general denition [', 1);('obvious advantage', 1);('1- shot target setting', 1);('deep', 1);('d-svr', 1);('w-v', 1);('d-w-v', 1);('wwm-voc', 1);('deep wwm-voc', 1);('metrics eszsl sae d-svr w-v d-w-v3000u', 1);('few-shot target training instances', 1);('method', 1);('1-instance 3-instance', 1);('3-shot setting', 1);('few-shot learning task', 1);('free vocabulary', 1);('low-level image', 1);('additional constraints', 1);('zero- shot learning setting', 1);('methods s. sp t-1 t-5 deep wmm-voc', 1);('w 9.26/10.29 21.99/23.12', 1);('w 8.5/8.76 20.30/21.36', 1);('w 8.9/9.5 14.9/16.8', 1);('w 5.11/9.32 12.26/21.04', 1);('w 5.86/8.3 13.71/18.2', 1);('w 5.29/5.7 13.32/14.12', 1);('] w /11.00 /25.70', 1);('] w 5.5/7.8 13.1/15.5', 1);('] w 3.7/5.2 11.8/12.8', 1);('] w 3.5/6.1 10.5/13.1', 1);('chance', 1);('signicant improvements', 1);('max-margin constraints', 1);('> 3per class', 1);('sev- eral state-of-the-art large-scale zero-shot recognition models', 1);('deep- svr', 1);('t-1', 1);('t-5', 1);('poor', 1);('inefcient learning', 1);('similar poor performance', 1);('oc obtains', 1);('word vector representations', 1);('class names', 1);('additional textual descriptions', 1);('open set image recognition results14', 1);('testing classes imagenet data aux', 1);('@ k 0123456accuracy', 1);('mm-voc deep-svr deep wmm-voc wmm-voc fig', 1);('recognition results', 1);('openness=', 1);('chance=', 1);('synony- mous', 1);('ground truth names', 1);('similar open set recognition accuracy', 1);('linear mappingg', 1);('visual space', 1);('ne-tune low-level', 1);('qualitative', 1);('oc model', 1);('ima-', 1);('genet2012/2010 dataset', 1);('target/zero-shot classes', 1);('open-set max-margin constraints', 1);('neighbor- hood', 1);('spider monkey', 1);('killer_whale chihuahua_dog dalmatian_dog buffalo grizzly_bear collie spider_monkeyword prototype', 1);('golden_retrievercolliesfox_terriersheepdogshetland_ponyjack_russell_terriercattle_dogwellarddrover collie killer_whaletilikumorcasbrancheauorcaseaworldbottlenose_dolphinsea_lionwhaleseaworld_orlando spider_monkeycapybaragiant_anteatermarmosettamarinmacawhowler_monkeyssquirrel_monkeysmacaquemacaws grizzly_beargrizzlypolar_bearelkgrizzly_bearscoyotecariboumountain_lionmountain_goatsbighorn_sheep buffalominneapolisdetroitchicagokansas_citypittsburgherieduluthminnesotagrand_rapids chihuahua_dogciudad_ju_rezsonorasinaloacoahuiladurangojaliscomichoac_nzacatecasnuevo_leon dalmatian_dogistriaragusadalmatian_coastkor_ulagradiscasardinianzadarcroatianistrianfig', 1);('visualization', 1);('training image', 1);('onclusion and future work', 1);('paper introduces', 1);('learning paradigm', 1);('open set semantic vocabulary', 1);('extensive', 1);('ex- perimental results', 1);('such learning paradigm', 1);('strikingly', 1);('000class labels', 1);('acknowledgments', 1);('nsfc project', 1);('stcsm project', 1);('scholar', 1);('tp2017006', 1);('shanghai municipal', 1);('technol-', 1);('ogy major', 1);('project', 1);('zjlab', 1);('references', 1);('4.3.3 [', 1);('f. perronnin', 1);('z. harchaoui', 1);('c. schmid', 1);('label-embedding', 1);('s. reed', 1);('d. walter', 1);('h. lee', 1);('evaluation', 1);('output embeddings', 1);('amit', 1);('m. fink', 1);('n. srebro', 1);('uncovering', 1);('multiclass classication', 1);('e. bart', 1);('cross-generalization', 1);('ieee com-', 1);('puter society conference', 1);('open world recognition', 1);('i. biederman', 1);('recognition-by-components', 1);('human image understanding', 1);('psychological', 1);('synthesized', 1);('predicting', 1);('visual exemplars', 1);('empirical study', 1);('k. chateld', 1);('k. simonyan', 1);('return', 1);('convolutional nets', 1);('arxiv preprint arxiv:1405.3531', 1);('k. crammer', 1);('algorithmic implementation', 1);('vector machines', 1);('dec', 1);('n. ding', 1);('jia', 1);('k. murphy', 1);('h. neven', 1);('h. adam', 1);('object classication', 1);('label relation graphs', 1);('w. dong', 1);('l.-j', 1);('k. li', 1);('large-scale hierarchical image database', 1);('improving', 1);('arxiv preprint arxiv:1412.6568', 1);('h. dong', 1);('separate domains', 1);('probabilistic perspective', 1);('arxiv preprint arxiv:1810.07368', 1);('a. farhadi', 1);('i. endres', 1);('d. hoiem', 1);('d. forsyth', 1);('describing', 1);('bayesian approach', 1);('one-shot', 1);('ieee trans', 1);('pattern anal', 1);('mach', 1);('intell', 1);('apr', 1);('4.3.2 [', 1);('r. felix', 1);('b. vijay kumar', 1);('i. reid', 1);('g. carneiro', 1);('multi-modal', 1);('f. fleuret', 1);('g. blanchard', 1);('pattern', 1);('m. p. friedlander', 1);('m. schmidt', 1);('deterministic-stochastic methods', 1);('siam', 1);('scientic computing', 1);('a1380a1405', 1);('deep visual-semantic', 1);('social activity', 1);('multimodal latent attributes', 1);('multi- view zero-shot learning', 1);('semi-supervised', 1);('recent', 1);('toward', 1);('data-efcient understanding', 1);('visual content', 1);('processing magazine', 1);('semantic manifold distance', 1);('s. guadarrama', 1);('e. rodner', 1);('k. saenko', 1);('n. zhang', 1);('r. farrell', 1);('j. donahue', 1);('t. darrell', 1);('open-vocabulary', 1);('object retrieval', 1);('robotics', 1);('t. hertz', 1);('b. hillel', 1);('d. weinshall', 1);('kernel function', 1);('small training samples', 1);('a. g. huth', 1);('s. nishimoto', 1);('a. t. vu', 1);('j. l. gallant', 1);('action categories', 1);('human brain', 1);('neuron', 1);('relating', 1);('tax- onomies', 1);('d. jayaraman', 1);('unreliable attributes', 1);('g. koch', 1);('r. zemel', 1);('r. salakhutdinov', 1);('one-shot image recognition', 1);('icml', 1);('deep learning workshop', 1);('n. balakrishnan', 1);('n. l. johnson', 1);('continuous', 1);('multivariate distributions', 1);('john wiley', 1);('s. nadarajah', 1);('value distributions', 1);('scientic', 1);('a. krizhevsky', 1);('deep convolutional neural networks', 1);('n. kumar', 1);('a. c. berg', 1);('p. n. belhumeur', 1);('s. k. nayar', 1);('simile classiers', 1);('c. h. lampert', 1);('h. nickisch', 1);('s. harmeling', 1);('attribute-based', 1);('classi- cation', 1);('zero-shot visual object categorization', 1);('h. larochelle', 1);('d. erhan', 1);('bengio', 1);('zero-data', 1);('new tasks', 1);('aaai', 1);('hubness', 1);('annual meeting', 1);('computational linguistics', 1);('language pro-', 1);('papers', 1);('lee', 1);('w.-f. hsieh', 1);('c.-m. huang', 1);('smooth support vector machine', 1);('epsilon-insensitive regression', 1);('h. t. shen', 1);('acm multimedia', 1);('n. xie', 1);('discriminative representation extraction', 1);('g. ding', 1);('j. han', 1);('unseen', 1);('visual data synthesis', 1);('x. li', 1);('unseen visual data', 1);('diffusion regularisation', 1);('ieee trans-', 1);('p. raghavan', 1);('h. schtze', 1);('information retrieval', 1);('language engineering', 1);('k. chen', 1);('dis-', 1);('inadvances', 1);('m. norouzi', 1);('convex combination', 1);('arxiv preprint arxiv:1312.5650', 1);('m. palatucci', 1);('d. pomerleau', 1);('t. m. mitchell', 1);('semantic output codes', 1);('s. j. pan', 1);('q. yang', 1);('knowledge engineering', 1);('d. parikh', 1);('relative', 1);('j. pennington', 1);('glove', 1);('global', 1);('word representation', 1);('empirical methods', 1);('natural language processing', 1);('emnlp', 1);('s. ebert', 1);('transfer', 1);('trans- ductive setting', 1);('evaluating', 1);('large-scale setting', 1);('g. szarvas', 1);('i. gurevych', 1);('semantic relatedness', 1);('in2010 ieee computer', 1);('b. romera-paredes', 1);('p. torr', 1);('simple approach', 1);('e. m. rudd', 1);('extreme value machine', 1);('h. sattar', 1);('s. muller', 1);('m. fritz', 1);('a. bulling', 1);('prediction', 1);('search targets', 1);('open-world settings', 1);('r. e. schapire', 1);('freund', 1);('p. bartlett', 1);('w. s. lee', 1);('boosting', 1);('new explanation', 1);('probability', 1);('a. rocha', 1);('a. sapkota', 1);('shigeto', 1);('i. suzuki', 1);('k. hara', 1);('m. shimbo', 1);('matsumoto', 1);('ridge regression', 1);('con-', 1);('m. ganjoo', 1);('c. d. manning', 1);('a. ng', 1);('f. sung', 1);('p. h. torr', 1);('few-shot learning', 1);('s. thrun', 1);('t. tommasi', 1);('b. caputo', 1);('technical', 1);('tiny images', 1);('large data', 1);('nonparametric object', 1);('scene recognition', 1);('sharing', 1);('multiview object detection', 1);('visual object detection', 1);('communications', 1);('i. tsochantaridis', 1);('t. joachims', 1);('t. hofmann', 1);('altun', 1);('interdependent output variables', 1);('sep', 1);('efcient', 1);('additive kernels', 1);('g. arora', 1);('a. mishra', 1);('proc', 1);('ieee conf', 1);('comput', 1);('vis', 1);('pattern recognit', 1);('simple exponential family framework', 1);('r. vilalta', 1);('drissi', 1);('perspective view', 1);('articial', 1);('intelligence review', 1);('j. weston', 1);('n. usunier', 1);('scaling', 1);('large vocabulary image annotation', 1);('twenty-second', 1);('l. wolf', 1);('i. martin', 1);('robust', 1);('in2005 ieee computer', 1);('z. wu', 1);('harnessing', 1);('scene semantics', 1);('large-scale video understanding', 1);('g. sharma', 1);('q. nguyen', 1);('m. hein', 1);('latent', 1);('zero-shot classication', 1);('t. lorenz', 1);('feature', 1);('learning-the good', 1);('f. x. yu', 1);('l. cao', 1);('r. s. feris', 1);('j. r. smith', 1);('s.-f. chang', 1);('design-', 1);('category-level attributes', 1);('discriminative visual recognition', 1);('yu', 1);('z. ji', 1);('j. guo', 1);('pang', 1);('adaptive structural', 1);('solving', 1);('large scale linear prediction problems', 1);('stochastic gradient descent algorithms', 1);('twenty-rst interna- tional conference', 1);('distribution machine', 1);('acm sigkdd', 1);('z. zhang', 1);('saligrama', 1);('semantic similarity', 1);('distribution learning', 1);('iapr', 1);('articial neural networks', 1);('mary', 1);('london', 1);('m.eng', 1);('com-', 1);('puter science', 1);('nanjing univer-', 1);('post-doctoral po- sition', 1);('pittsburgh', 1);('pa', 1);('usa', 1);('video understanding', 1);('life-long learning.17', 1);('master degree', 1);('information system', 1);('bachelor degree', 1);('electronic infor- mation engineering', 1);('shandong', 1);('reaseach interests in- clude zero-shot/few-shot learning', 1);('visual question', 1);('undergraduate student ma-', 1);('data science track', 1);('professor y', 1);('current research interests', 1);('machine learning theory', 1);('computer sci-', 1);('fudan- jilian joint', 1);('research center', 1);('intelligent video', 1);('high-level informa- tion', 1);('big video data', 1);('video event recognition', 1);('object/scene recognition', 1);('large- scale visual search', 1);('acm china ris-', 1);('research award', 1);('young researchers', 1);('nsf china', 1);('as- sociate editor', 1);('acm tomm', 1);('machine vision', 1);('applications', 1);('mva', 1);('neurocomputing', 1);('city university', 1);('hong kong', 1);('hefei univer-', 1);('b.e', 1);('special class', 1);('gifted y', 1);('electronic engineering', 1);('ustc', 1);('current research interests in- clude multimedia content analysis', 1);('computer vi- sion', 1);('book chapters', 1);('con- ference papers', 1);('associate editor', 1);('ieee tkde', 1);('circuits', 1);('systems', 1);('video', 1);('ieee tcsvt', 1);('ieee tmm', 1);('ieee tnnls', 1);('bs', 1);('communication engineering', 1);('xi-', 1);('dian university', 1);('computer science', 1);('shang-', 1);('com- puter vision', 1);('multimedia information processing', 1);('leonid sigal', 1);('associate professor', 1);('univer-', 1);('faculty member', 1);('vector', 1);('canada cifar ai chair', 1);('nserc canada', 1);('chair', 1);('crc', 1);('senior', 1);('scientist', 1);('m.a', 1);('boston', 1);('m.sc', 1);('research interests lie', 1);('computer graphics', 1);('research emphasis', 1);('statistical approaches', 1);('visual recognition', 1);('tpami', 1);('ijcv', 1);('iccv', 1);('neurips', 1);