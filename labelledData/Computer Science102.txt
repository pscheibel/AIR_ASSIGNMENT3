('english', 14);('awe', 12);('mcpc', 10);('xlsr-53', 10);('ieee', 10);('abx', 9);('awes', 8);('arabic', 8);('error rates', 8);('dtw', 7);('chung', 7);('holzenberger', 6);('interspeech', 6);('speech recognition', 5);('acoustic', 5);('target languages', 5);('unsupervised', 5);('variable-length segments', 4);('asr', 4);('mfccs', 4);('cpc', 4);('xlsr', 4);('wav2vec2', 4);('mfcc', 4);('alexei baevski', 4);('michael auli', 4);('proc', 4);('herman kamper', 4);('icassp', 4);('low-resource settings', 3);('embeddings', 3);('baevski', 3);('speech represen- tations', 3);('word pairs', 3);('van den', 3);('oord', 3);('ieee spoken language', 3);('technology workshop', 3);('slt', 3);('word embeddings', 3);('emmanuel dupoux', 3);('speech', 3);('input signal', 2);('self-supervised', 2);('large amounts', 2);('variable-length speech segments', 2);('peng', 2);('zero-shot cross-lingual trans- fer', 2);('zero-shot cross-lingual', 2);('low-resource languages', 2);('staden', 2);('riviere', 2);('fea- tures', 2);('target lan- guages', 2);('ger-', 2);('force alignment', 2);('lstm', 2);('target sequence', 2);('appendix', 2);('speech representations', 2);('mod- els', 2);('librispeech', 2);('es ar', 2);('self-supervised awes', 2);('supervised awes', 2);('english mfcc', 2);('learning setting', 2);('automatic speech recognition', 2);('speech communication', 2);('james', 2);('alexis conneau', 2);('frame- work', 2);('abdelrahman mohamed', 2);('advances', 2);('neural information processing systems', 2);('ronan collobert', 2);('yevgen matusevych', 2);('international conference', 2);('acoustics', 2);('aaron', 2);('aren jansen', 2);('karen livescu', 2);('montreal', 2);('encoder parameters', 2);('wav2vec', 2);('supervised acoustic embeddings', 1);('transferability across languages sreepratha ram uae', 1);('university sree_ram @ uaeu.ac.aehanan', 1);('aldarmaki mbzuai', 1);('hanan.aldarmaki @ mbzuai.ac.ae', 1);('abstract', 1);('phonetic content', 1);('irrelevant factors', 1);('speaker variations', 1);('pre- training', 1);('frame-level fea- ture representations', 1);('em-', 1);('perfect separation', 1);('linguistic con- tent', 1);('indirect ob- jectives', 1);('dif- ferent', 1);('keywords unsupervised asr', 1);('transfer learn-', 1);('introduction', 1);('speech recognition systems get-', 1);('avail- ability', 1);('com- putational power', 1);('gulati', 1);('low- resource languages', 1);('training data', 1);('aldarmaki', 1);('un-', 1);('multiple languages', 1);('low-resource lan- guages', 1);('kawakami', 1);('conneau', 1);('word-level segmental', 1);('asrwhere', 1);('xed-dimensional vectors', 1);('relative success', 1);('abdel-hamid', 1);('fosler-lussier', 1);('similar vein', 1);('kamper', 1);('con- tain speaker', 1);('phonetic variability', 1);('latent space with-', 1);('possible approaches', 1);('non- linguistic variations', 1);('models versus su-', 1);('different types', 1);('perfor- mance', 1);('small amount', 1);('different language', 1);('different languages', 1);('effective approach', 1);('low-resource speech models', 1);('train- ing1', 1);('background', 1);('related', 1);('spoken', 1);('xed-length frames', 1);('ms duration', 1);('python training', 1);('evaluation scripts', 1);('//github.com/h- aldarmaki/acoustic_embeddingsarxiv:2301.01020v1 [ cs.cl ]', 1);('jan', 1);('variable-length word segments', 1);('dynamic', 1);('warping', 1);('early technique', 1);('variable- length segments', 1);('optimal frame-wise alignment', 1);('mo- tivates', 1);('efcient metrics', 1);('euclidean', 1);('levin', 1);('different', 1);('auto-encoder network', 1);('reconstruction loss', 1);('compared', 1);('direct comparison', 1);('supe- rior performance', 1);('alternative training strategy', 1);('cor- respondence auto-encoders', 1);('term dis- covery', 1);('contrastive learning', 1);('multi-lingual adap- tation', 1);('jacobs', 1);('above models', 1);('static acoustic', 1);('kam-', 1);('pre-', 1);('yang', 1);('egnlish', 1);('phone classication accuracy', 1);('multi-lingual training', 1);('xlsr-', 1);('lan- guages', 1);('con-', 1);('objectives', 1);('methodology', 1);('effec- tiveness', 1);('acoustic word em-beddings', 1);('target languages ver- sus zero-shot cross-lingual', 1);('different source language', 1);('stan- dard acoustic', 1);('furthermore', 1);('previous works', 1);('simple architecture', 1);('prelimi- nary validation results', 1);('awes2', 1);('source language', 1);('zero- shot', 1);('word boundaries', 1);('eval- uate', 1);('phonetic discriminability', 1);('speaker invariance', 1);('different occurrences', 1);('words end', 1);('experimental settings', 1);('model architecture', 1);('multi-layer bidirec- tional', 1);('se- quence', 1);('tacoustic', 1);('spo- ken word', 1);('backward states', 1);('decoder generates', 1);('previous time step', 1);('sen- sitive', 1);('input sequence', 1);('mse', 1);('input word', 1);('nega- tive log-likelihood', 1);('2-layer networks', 1);('feature extraction', 1);('s3prl toolkit3', 1);('s3prl upstream models', 1);('wav2wec2', 1);('cho- sen', 1);('dtw-based abx', 1);('en-', 1);('glish data', 1);('bartelds', 1);('aver-', 1);('reasonable results', 1);('s3prl implementation', 1);('dynamic delta', 1);('delta-delta coefcients', 1);('data', 1);('panayotov', 1);('multilingual librispeech', 1);('pratap', 1);('word bound- aries', 1);('ara-', 1);('mgb2', 1);('//github.com/s3prl/s3prl 4we', 1);('apc', 1);('vq- apc', 1);('vq-wav2vec', 1);('inferior perfor- mance', 1);('ali', 1);('di- alects', 1);('various noise conditions', 1);('word alignment process', 1);('evaluation scheme', 1);('minimal-pair abx', 1);('schatz', 1);('phoneme discrimination', 1);('zero-resource settings', 1);('minimal con- trast', 1);('phoneme difference', 1);('distance measure', 1);('different speaker', 1);('levenshtein', 1);('edit distance', 1);('speaker ids', 1);('different speakers', 1);('sound recordings', 1);('word alignment quality', 1);('automatic process', 1);('invalid segments', 1);('reliable test', 1);('valid- ity', 1);('complementary eval- uation', 1);('k- means', 1);('unique words', 1);('cluster label', 1);('word id', 1);('distance metric', 1);('automatic word alignments', 1);('ve characters.en fr', 1);('dtw mfcc', 1);('k-means clustering accuracy', 1);('cosine', 1);('set- tings', 1);('conrming', 1);('previous results', 1);('acoustic fea- tures', 1);('modied cpc', 1);('cross-speaker eval- uation', 1);('unsurprisingly', 1);('scores overall', 1);('signicant re- duction', 1);('errors rates', 1);('test lan- guages', 1);('error rate', 1);('ac- curacy results', 1);('conclusions', 1);('superior effectiveness', 1);('acoustic word em- beddings', 1);('use- ful', 1);('speaker variability', 1);('re- duction', 1);('fur- ther investigations', 1);('noise robustness', 1);('similar man- ner', 1);('acknowledgement', 1);('arab emirates', 1);('uaeu-zu joint', 1);('grant g00003715', 1);('emirates', 1);('mobility', 1);('references ossama abdel-hamid', 1);('li deng', 1);('dong yu', 1);('hui jiang', 1);('deep', 1);('segmental neural networks', 1);('hanan aldarmaki', 1);('asad ullah', 1);('sreepratha ram', 1);('nazar zaki', 1);('ahmed ali', 1);('peter bell', 1);('yacine messaoui', 1);('hamdy mubarak', 1);('steve renals', 1);('yifan zhang', 1);('mgb-2 challenge', 1);('multi-dialect broadcast media recognition', 1);('wei-ning hsu', 1);('speech recogni- tion', 1);('arxiv preprint arxiv:2105.11084', 1);('henry zhou', 1);('abdel', 1);('mohamed', 1);('arxiv', 1);('yuhao zhou', 1);('martijn bartelds', 1);('wietse', 1);('vries', 1);('faraz sanal', 1);('caitlin richter', 1);('mark liberman', 1);('martijn wieling', 1);('neural', 1);('phonetics', 1);('mathieu bernard', 1);('hadrien titeux', 1);('phonem-', 1);('text', 1);('phones transcription', 1);('multiple lan- guages', 1);('source software', 1);('speech2vec', 1);('sequence-to-sequence framework', 1);('yu-an chung', 1);('chao-chung wu', 1);('chia-hao shen', 1);('hung-yi lee', 1);('lin-shan lee', 1);('audio', 1);('audio segment representations', 1);('sequence-to-sequence autoen- coder', 1);('cross-lingual representation learn-', 1);('arxiv preprint arxiv:2006.13979', 1);('anmol gulati', 1);('james qin', 1);('chung-cheng chiu', 1);('niki parmar', 1);('yu zhang', 1);('jiahui yu', 1);('wei han', 1);('shibo wang', 1);('zhengdong zhang', 1);('yonghui wu', 1);('conformer', 1);('convolution-augmented', 1);('yanzhang', 1);('eric fosler-lussier', 1);('segmen-', 1);('tal conditional random elds', 1);('deep neural net-', 1);('acoustic models', 1);('rst-pass word recog- nition', 1);('sixteenth annual', 1);('inter-', 1);('nils holzenberger', 1);('mingxing', 1);('julien karadayi', 1);('rachid riad', 1);('learn-', 1);('xed-size representations', 1);('christiaan jacobs', 1);('zero-resource languages', 1);('con- trastive learning', 1);('multilingual adaptation', 1);('sharon goldwater', 1);('multilingual', 1);('acoustic word em-', 1);('processing zero-resource lan- guages', 1);('pro-', 1);('kazuya kawakami', 1);('luyu wang', 1);('chris dyer', 1);('phil blun-', 1);('learning', 1);('multilingual speech representations', 1);('findings', 1);('computational lin-', 1);('emnlp', 1);('keith levin', 1);('katharine henry', 1);('fixed-dimensional', 1);('acoustic embed- dings', 1);('understanding', 1);('ieee.michael mcauliffe', 1);('michaela socolof', 1);('sarah mi-', 1);('michael wagner', 1);('morgan sonderegger', 1);('trainable text- speech alignment', 1);('vassil panayotov', 1);('guoguo chen', 1);('daniel povey', 1);('sanjeev khudanpur', 1);('asr cor- pus', 1);('public domain audio books', 1);('signal processing', 1);('puyuan peng', 1);('correspondence variational autoencoder', 1);('acoustic word embeddings', 1);('vineel pratap', 1);('qiantong xu', 1);('anuroop sriram', 1);('gabriel synnaeve', 1);('mls', 1);('large-scale multilingual dataset', 1);('speech research', 1);('morgane riviere', 1);('armand joulin', 1);('pierre-emmanuel mazar', 1);('unsuper-', 1);('inicassp', 1);('confer-', 1);('processing', 1);('thomas schatz', 1);('vijayaditya peddinti', 1);('francis bach', 1);('hynek hermansky', 1);('evaluating', 1);('minimal-pair abx task', 1);('analysis', 1);('classi- cal mfc/plp pipeline', 1);('annual', 1);('speech com-', 1);('munication association', 1);('yazhe li', 1);('oriol vinyals', 1);('representation', 1);('contrastive pre- dictive', 1);('arxiv e-prints', 1);('pages arxiv1807', 1);('lisa', 1);('compar- ison', 1);('acoustic word embed- dings', 1);('shu-wen yang', 1);('po-han chi', 1);('yung-sung chuang', 1);('cheng-i jeff lai', 1);('kushal lakhotia', 1);('yist y lin', 1);('andy t liu', 1);('jiatong shi', 1);('xuankai chang', 1);('guan- ting lin', 1);('superb', 1);('universal performance benchmark', 1);('arxiv preprint arxiv:2105.01051', 1);('appendix a.1 dataset details a.2 model architecture', 1);('hyper-parameters', 1);('acoustic word', 1);('slight variationsdataset test dev', 1);('total number', 1);('particular congura- tion', 1);('different acoustic', 1);('grus', 1);('lstms', 1);('positional encodings', 1);('previous outputs', 1);('infe- rior performance', 1);('previous output', 1);('decoder hurt', 1);('stable training', 1);('layer network', 1);('embed- dings sizes', 1);('computational efciency', 1);('low- resource settings', 1);('validation data', 1);('a.3 training details', 1);('nll', 1);('phonemizer', 1);('bernard', 1);('titeux', 1);('sen- sible', 1);('pytorch', 1);('//github.com/bootphon/phonemizermodel input', 1);('no.of parameters', 1);('self-supervised mfcc', 1);('supervised mfcc', 1);('input', 1);('layer size', 1);('nvidia k80 gpu', 1);('aws', 1);('p2.xlarge instances', 1);('adam optimizer', 1);('sgd', 1);('step learn-', 1);('rate schedule', 1);('word alignments', 1);('montreal forced aligner7', 1);('mcauliffe', 1);('aligner uses', 1);('accu- rate', 1);('aeneas toolkit8', 1);('tts', 1);('actual audio segments', 1);('amazon polly tts', 1);('low quality', 1);('high variability', 1);('accurate boundaries', 1);('high level', 1);('noise conditions', 1);('background mu- sic', 1);('forced-aligner', 1);