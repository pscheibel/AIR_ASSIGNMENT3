('ieee', 10);('speech', 9);('icassp', 8);('gslm', 6);('discrete units', 6);('timit', 6);('yossi adi', 5);('abx', 5);('cpc', 5);('v-measure', 5);('cr', 5);('k-means', 5);('international conference', 5);('ssl', 4);('language model', 4);('hubert', 4);('librispeech', 4);('units resynthesis', 4);('key', 4);('speech representations', 3);('high correlation', 3);('units context', 3);('discrete representation', 3);('continuous representation', 3);('formally', 3);('circular resynthesis', 3);('hubert50', 3);('self-supervised', 3);('processing', 3);('felix kreuk', 3);('following', 2);('discrete unit', 2);('speech signal', 2);('stu', 2);('t0', 2);('waveglow', 2);('hifi-gan', 2);('evaluation metric', 2);('spatial structure', 2);('corresponding phonemes', 2);('t-sne', 2);('figure', 2);('intuitively', 2);('strong correlation', 2);('uts', 2);('notice', 2);('units interpretation', 2);('mfcc50', 2);('local-single', 2);('local-full', 2);('context-single', 2);('ued', 2);('rst k-means step', 2);('hierarchical clustering', 2);('weighed hierarchical clustering', 2);('units redundancies', 2);('speaker information', 2);('wei-ning hsu', 2);('benjamin bolte', 2);('kushal lakhotia', 2);('language processing', 2);('alexei baevski', 2);('acoustics', 2);('joseph keshet', 2);('eugene kharitonov', 2);('adam polyak', 2);('jade copet', 2);('analysing discrete self supervised speech representation for spoken language modeling amitay sicherman', 1);('engineering', 1);('computer', 1);('hebrew', 1);('jerusalem', 1);('israel abstract', 1);('analyzes discrete', 1);('generative spoken lan-', 1);('modeling', 1);('practical improvements', 1);('analysis nds', 1);('speech units', 1);('phoneme families', 1);('addition-', 1);('unit redundancies', 1);('new methods', 1);('show signicant improvement', 1);('zero-resource speech metrics', 1);('code', 1);('analysis tools', 1);('index terms', 1);('generative spo- ken language', 1);('nlp', 1);('lm', 1);('introduction recently self-supervised learning', 1);('great success', 1);('downs stream tasks [', 1);('automatic speech recognition', 1);('speaker diarization [', 1);('phone segmentation [', 1);('remarkable results', 1);('specically', 1);('recent success', 1);('generative spoken language modeling', 1);('such representation', 1);('time domain signal', 1);('neural vocoder [', 1);('inference time', 1);('mean- ingful', 1);('coherent speech utterances', 1);('discrete representations', 1);('theauthors', 1);('phonetics ele- ments', 1);('linguistic properties', 1);('different articulatory classes', 1);('release portions', 1);('phone classes', 1);('language information', 1);('bilingual models', 1);('dis- crete representations', 1);('phoneme classes', 1);('speaker identity', 1);('identify redundancies', 1);('addition', 1);('redun- dancies', 1);('signicant improvement', 1);('background', 1);('main mod- ules', 1);('speech-to-unit', 1);('unit language model', 1);('unit-to-speech', 1);('unit-to-speech module [', 1);('module encodes', 1);('raw speech signal', 1);('model rst encodes', 1);('discrete units [', 1);('audio samples', 1);('raw signal', 1);('samples x=', 1);('consider', 1);('encoder network', 1);('speech utterance', 1);('spectral representations', 1);('low frequency', 1);('encoder network f.', 1);('such models', 1);('k-means algorithm isarxiv:2301.00591v1 [ cs.cl ]', 1);('jan', 1);('units', 1);('visualization process', 1);('models outputs', 1);('generate discrete units', 1);('element ziinzis', 1);('pos- itive integer', 1);('kgfor1\x14i\x14t0', 1);('kis', 1);('units repetitions', 1);('common approach', 1);('collapse repetitions', 1);('units duration', 1);('sequence 12,12,25,31,31,31', 1);('corresponding durations 2,1,3', 1);('ulm', 1);('generate speech', 1);('module converts', 1);('discrete speech repre- sentation', 1);('raw waveform', 1);('tacotron2.0', 1);('] vocoder', 1);('method', 1);('analyze representations', 1);('huebrt', 1);('] models', 1);('various number', 1);('analysis code', 1);('visualization tools', 1);('analysis units interpretation', 1);('mutual in- formation', 1);('different speech properties', 1);('speaker id', 1);('score [', 1);('units-to-phonemes alignment', 1);('corpus [', 1);('dataset contains pairs', 1);('gender analysis', 1);('fig', 1);('units visualization', 1);('additional point', 1);('units meaning', 1);('2d spatial view', 1);('contains information regard-', 1);('speci-', 1);('high-dimensional speech representation', 1);('t- sne', 1);('] algorithm', 1);('nonlinear dimensionality re- duction', 1);('non-linear distance re- lations', 1);('low dimensions', 1);('oronoi diagram [', 1);('scat- ter plot', 1);('area plot', 1);('2d space', 1);('units-phonemes alignment', 1);('previous paragraph', 1);('re- place', 1);('unit id', 1);('area base', 1);('phoneme family', 1);('visual description', 1);('units information', 1);('opposite direction', 1);('speech resyn- thesis', 1);('look-up- table', 1);('corresponding 20ms speech segments', 1);('transcription error', 1);('character error rate', 1);('sound pieces', 1);('neural vocoder', 1);('input audio x.', 1);('arbitrary length', 1);('lookup v', 1);('ocoder denes', 1);('lv', 1);('model manages', 1);('hide information', 1);('model size', 1);('gender phoneme cpc50', 1);('tis', 1);('rst appearance', 1);('maps unit', 1);('different types', 1);('context- full-key', 1);('full resynthesis procedure', 1);('ad- ditional resynthesis stage', 1);('unit-edit-distance', 1);('evalu- ate robustness', 1);('discrete speech representation', 1);('signal variations', 1);('datasets transcriptions', 1);('robust clustering equipped', 1);('simple meth- ods', 1);('standard k-means', 1);('target number', 1);('rst method', 1);('additional k-means', 1);('cluster cen- torids', 1);('cluster centorids', 1);('cer', 1);('concatenate methods', 1);('table contains results', 1);('different lookup key types', 1);('l-s', 1);('l-f', 1);('c-s', 1);('context-full', 1);('c-f', 1);('model size hi-genkey type c-f c-s l-f l-s cpc50', 1);('euclidean distance', 1);('distance metric', 1);('swap', 1);('ithand jthcluster', 1);('continuous centroids', 1);('ithand jthdiscrete unit', 1);('results', 1);('datasets', 1);('] corpus', 1);('look-up vocoder', 1);('additionally', 1);('dif- ferent attributes', 1);('v-', 1);('gender scores', 1);('low correlation', 1);('gen- der', 1);('units lead', 1);('phoneme score', 1);('max point', 1);('units visualization figure', 1);('consistent structure- rst', 1);('units thatfig', 1);('2d view', 1);('units centers', 1);('units phoneme', 1);('oronoi diagram', 1);('units areas', 1);('comparing', 1);('speaker information.for', 1);('better.the methods', 1);('regular', 1);('k-k', 1);('k-h', 1);('k-', 1);('k-wh', 1);('model sizeabx', 1);('k k-k k-h k-wh k k-k k-h k-wh k k-k k-h k-wh cpc50', 1);('frica- tives', 1);('etc', 1);('different phonemes families', 1);('mfcc', 1);('space uses', 1);('no-', 1);('such gures', 1);('dif- ference', 1);('look-up scores-', 1);('units express', 1);('units length', 1);('different context', 1);('different units.4.5', 1);('robust clustering', 1);('different axes', 1);('phonetic measure', 1);('speaker results', 1);('furthermore', 1);('abx-across', 1);('cr-', 1);('conclusion', 1);('complementary points', 1);('references', 1);('shu-wen yang', 1);('superb', 1);('universal performance benchmark', 1);('arxiv preprint arxiv:2105.01051', 1);('yao-hung hubert tsai', 1);('ruslan salakhutdinov', 1);('abdelrah-', 1);('mohamed', 1);('speech rep- resentation learning', 1);('ieee/acm transactions', 1);('audio', 1);('ad-', 1);('neural information processing systems', 1);('morgane riviere', 1);('unsupervised', 1);('trans- fers', 1);('sig-', 1);('yehoshua dissen', 1);('speaker diarization', 1);('arxiv preprint arxiv:2204.04166', 1);('contrastive learning', 1);('phoneme segmentation', 1);('arxiv preprint arxiv:2007.13465', 1);('tu-anh nguyen', 1);('abdelrahman mo-', 1);('language model-', 1);('raw audio', 1);('transactions', 1);('computational linguistics', 1);('tu anh nguyen', 1);('generative', 1);('dialogue language', 1);('arxiv preprint arxiv:2203.16502', 1);('zal', 1);('borsos', 1);('rapha', 1);('marinier', 1);('damien vincent', 1);('eu-', 1);('kharitonov', 1);('olivier pietquin', 1);('matt shari', 1);('olivier teboul', 1);('david grangier', 1);('marco tagliasacchi', 1);('neil zeghidour', 1);('audiolm', 1);('audio generation', 1);('arxiv preprint arxiv:2209.03143', 1);('arxiv preprint arxiv:2104.00355', 1);('dan wells', 1);('hao tang', 1);('korin richmond', 1);('pho-', 1);('netic analysis', 1);('en- glish speech', 1);('proc', 1);('interspeech', 1);('maureen', 1);('seyssel', 1);('marvin lavechin', 1);('em-', 1);('dupoux', 1);('guillaume wisniewski', 1);('prob-', 1);('arxiv preprint arxiv:2203.16193', 1);('arxiv preprint arxiv:2202.07359', 1);('itai gat', 1);('ann lee', 1);('gabriel synnaeve', 1);('emmanuel dupoux', 1);('arxiv preprint arxiv:2209.15483', 1);('jonathan shen', 1);('natural tts synthesis', 1);('mel spectrogram predictions', 1);('signal processing', 1);('ryan prenger', 1);('gen- erative network', 1);('speech synthesis', 1);('acous-', 1);('andrew rosenberg', 1);('julia hirschberg', 1);('external cluster evaluation measure', 1);('proceedings', 1);('joint conference', 1);('empirical methods', 1);('natural language processing', 1);('natural language learning', 1);('emnlp- conll', 1);('john', 1);('garofolo', 1);('acoustic phonetic continu- ous speech corpus', 1);('linguistic data consortium', 1);('laurens', 1);('van der', 1);('maaten', 1);('geoffrey hinton', 1);('visu-', 1);('machine learning', 1);('franz aurenhammer', 1);('oronoi diagramsa survey', 1);('fundamental geometric data structure', 1);('acm comput-', 1);('csur', 1);('vassil panayotov', 1);('asr corpus', 1);('public domain audio books', 1);('sig- nal processing', 1);('jacob kahn', 1);('libri-light', 1);