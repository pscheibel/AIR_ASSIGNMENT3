('isokann', 40);('koopman', 33);('figure', 10);('sec', 8);('kt', 7);('montecarlo', 7);('sde', 5);('standard deviation', 5);('theorem', 4);('girsanov', 3);('dominant eigenfunctions', 3);('s\x001', 3);('linear map', 3);('sin', 3);('sn', 3);('mtraining', 3);('eq', 3);('optimal', 3);('koopmanoperator', 2);('arnoldilike', 2);('furthermore', 2);('feedback loop', 2);('algorithm', 2);('proposition', 2);('nitesimal generator', 2);('tand', 2);('sk', 2);('kon', 2);('snkt', 2);('sne', 2);('arnoldi', 2);('eigenfunctions vi', 2);('iterative nature', 2);('adam', 2);('eulermaruyama', 2);('empirical extrema', 2);('whereas', 2);('training data', 2);('sgd', 2);('radonnikodym', 2);('original dynamics', 2);('ex0xexp', 2);('corollary', 2);('kand', 2);('optimal control', 2);('control b controlfigure', 2);('monte carlo', 2);('learning koopman', 1);('eigenfunctions stochastic di usions withoptimal importance', 1);('isokannalexander sikorski enric ribera borrell marcus weberzuse', 1);('berlinjanuary', 1);('2023abstractfor stochastic di usion processes dominant eigenfunctions', 1);('important information slowscale dynamics locationand frequency', 1);('rare events article reformulate eigenproblem terms functionsin', 1);('optimal control importance', 1);('new formulation', 1);('algorithm allowingfor proof convergence incorporate optimal control result', 1);('adaptive iterativealgorithm', 1);('function approximation demonstratethe usage', 1);('method experiments', 1);('approximation accuracy severalorders magnitude1', 1);('introductionmany', 1);('realworld stochastic processes', 1);('rare events example', 1);('events inmolecular systems analysis frequency mechanism events', 1);('process dominant invariant subspaces', 1);('usuallythis', 1);('type analysis', 1);('kind chicken egg problem order compute dominantinvariant subspace', 1);('operator process', 1);('sample thoseevents', 1);('generate bias processfor', 1);('need information dominant invariant subspace thekoopman operatorthe key idea article', 1);('iterative algorithm approximates dominanteigenfunctions operator use intermediate approximations', 1);('optimal bias observe relevant events algorithm approximatingeigenfunctions', 1);('isokann111', 1);('theory optimal', 1);('path measures 4brie y', 1);('neural networks asfunction representations', 1);('subspace projections transformation', 1);('suitable application neural networks compute eigenfunctions', 1);('functions span invariant subspace', 1);('reconstructthe eigenfunctions', 1);('interpretation reaction coordinates', 1);('rare events reaction paths', 1);('interpretation functions', 1);('previous iterations', 1);('adaptthe sample locations iterations eg strati', 1);('global coverage', 1);('exploration theory optimal importance', 1);('theother hand', 1);('variance samples requiredto approximate action', 1);('mathematical physics', 1);('linkcorresponding', 1);('author sikorskizibde1an acronym', 1);('invariant', 1);('operators arti cial neural networks1arxiv230100065v1 mathds', 1);('dec', 1);('potential', 1);('uof', 1);('double wellwith', 1);('metastable regions', 1);('potential barrierfigure', 1);('dominant eigenfunctions v1v2of', 1);('operator double', 1);('local global information', 1);('functions neural networks', 1);('even complex highdimensional systems', 1);('general ideas', 1);('article willtry construct', 1);('basic building blocks way', 1);('amenable future analysisin', 1);('basic knowledge eigenfunctions', 1);('abstract formulation', 1);('problem terms functionssec', 1);('invariant subspaces', 1);('operator abstract formulation', 1);('adequate transformation', 1);('explicit choice', 1);('isokannalgorithm', 1);('convergence 1disokann show reconstruct eigenfunctionsof', 1);('operator functions section', 1);('conclude section', 1);('providingan algorithmic description form', 1);('starts introduction theory optimal importance samplingof', 1);('classical random variables', 1);('result optimal', 1);('path observables di usion processes', 1);('applythis result', 1);('zero variance sampler evaluation', 1);('applythe1disokann algorithm onedimensional doublewell potential observe improvement ofthe accuracy', 1);('uncontrolled case2isokann', 1);('theorybefore', 1);('key idea', 1);('chapter chapter recall basics', 1);('theory summarize', 1);('new resultsin', 1);('new dimensionagnostic formulation', 1);('classical 1disokann', 1);('aspecial case formulation', 1);('convergence algorithm function', 1);('reconstruct dominant eigenfunctions', 1);('1we conclude section discussion', 1);('actual implementation', 1);('operatoralthough approach', 1);('nonreversible stochastic processes', 1);('focusfrom eigenfunctions invariant subspaces simplicity', 1);('explanations reversible case', 1);('potentialdriven di usion processes', 1);('x xtt\x150of', 1);('values state space', 1);('xrnwith', 1);('constant di usion term \x1b2rn\x02nand force eld bxrngiven gradient', 1);('smooth potential b\x00ruuxr2bis andimensional', 1);('brownianmotionthe koopman', 1);('tktl1xl1x', 1);('function f2l1x isde', 1);('pointwise evaluation via\x00ktf\x01x', 1);('efxtjx0x', 1);('2ie expectation value', 1);('fat timetwhen', 1);('x0x recall', 1);('theprocess timehomogeneous', 1);('time t\x150efxttjxtx \x00ktf\x01xthe eigenfunctions vi2l1x ofktsatisfy', 1);('t\x150ktvi\x15itvi', 1);('3\x15it exptqi', 1);('q1q2\x15 4with timedependent eigenvalues \x15it exponential time rates qiwhich', 1);('v1vdastheddominant eigenfunctions callv1\x111', 1);('trivial eigenfunction', 1);('clear context orof importance omit', 1);('kthe', 1);('particular interest decay slowest', 1);('long time behavior system number dof eigenfunctions interest', 1);('timescales system', 1);('spectral gapthere', 1);('di erent approaches', 1);('discretizationof statespace cells', 1);('matrix representation', 1);('classical method startingtrajectories cell', 1);('certain cell sampledrivenmethod', 1);('ulamgalerkin', 1);('indicator functions ofthe cells', 1);('kare', 1);('dense matrixapproximation', 1);('high dimensions number cells', 1);('grid increases exponentiallyone', 1);('squarerootapproximation', 1);('sqra', 1);('2it approximates', 1);('operator nite volume approximationwhere volumes', 1);('voronoi', 1);('evaluations potential', 1);('uat', 1);('sparse matrix representation', 1);('computation ofthe eigenfunctionsall', 1);('classical approaches', 1);('alternative summarize', 1);('recent matrixfree approach learning linearcombination eigenfunctions neural networks22', 1);('isokann computing', 1);('dominant eigenspacethe', 1);('uses nonparametric representation form neural network inorder', 1);('dominant invariant subspace', 1);('power iteration theapproximation', 1);('simulationsto end', 1);('useful reformulate eigenproblem terms', 1);('function idi1xrdwith 0\x14 i\x141pi i', 1);('satisfying equation', 1);('srdrd', 1);('section coreidea components iof span invariant subspace', 1);('theyconsists linear combinations eigenfunctions', 1);('k furthermore', 1);('nition functions', 1);('reconstructthe eigendecomposition', 1);('kproposition', 1);('interpretation macrostates the2we', 1);('bto gradient eld process', 1);('xtto', 1);('real eigendecompositionour principal results', 1);('terms invariant subspaces', 1);('eigenfunctionshowever sake simplicity', 1);('reversible systems only3figure', 1);('components twodimensional function linear combinations theeigenfunctions', 1);('case application ofk general linear corresponds shiftscale', 1);('section 24figure', 1);('scatter', 1);('v1againstv2and 1against 2on uniform grid', 1);('xpccaconstructs', 1);('smappingvonto', 1);('theunitsimplex form fuzzy memberships toddi erent', 1);('direct characterization', 1);('rare transitionsin form', 1);('times reaction rates exit paths etc', 1);('approximates function', 1);('dominant eigenspace aniterative sequence approximations', 1);('equation n1x', 1);('nxtjx0x 6withsnsnkt n linear map', 1);('previous iteration', 1);('arnoldiiteration', 1);('iterative application', 1);('decayof eigenfunctions exponential eigenvalue', 1);('howto construct', 1);('snas', 1);('compensate decay dominant components prevail whilstthe nondominant ones vanish limit nspans dominant subspace', 1);('1spanf n1 ndgn1spanfv1vdg', 1);('linear action', 1);('konthat', 1);('n andsns 8let', 1);('note presentation', 1);('di ers', 1);('original variant', 1);('iterationin form', 1);('general ddimensional', 1);('equivalent original variant', 1);('slight abuse notation', 1);('illustrative', 1);('sde1', 1);('potentialux x2\x0012 9the double', 1);('dominant eigenfunctions aregiven', 1);('functions linear combination ofthe eigenfunctions', 1);('slow timescale dynamics', 1);('membership functions', 1);('wells potential exit pathsare', 1);('gradients \x00r', 1);('probabilties exit rates computedfrom', 1);('previous description', 1);('linear transformation', 1);('sora', 1);('splays isokann', 1);('way determiningsuitables4in principle map', 1);('scan', 1);('useful result', 1);('iterations converge', 1);('corresponding choice', 1);('snwe', 1);('requiresome speci c propertiesin order', 1);('slet', 1);('method nd thedominant eigenfunctions matrix principle', 1);('wherethe application', 1);('sncorresponds gramschmidt', 1);('orthonormalization orthogonalizationensures', 1);('subsequent ones followingnormalization step ensures eigenvectors decay', 1);('multiple iterationsnote', 1);('gramschmidt', 1);('orthonormalization nonlinear procedurethe', 1);('input vectors', 1);('linear map ie theorthonormalization procedure input matrix kwe nd linear map k', 1);('ksuch thatk kk 10it', 1);('sas', 1);('data ineq 6forisokann wantsto ful ll role goal linear transformation', 1);('snis', 1);('tocounteract decay dominant eigenfunction components', 1);('nafter application thekoopman operator', 1);('khowever', 1);('linear combinations eigenfunctions', 1);('continuous space', 1);('neural network setting orthonormalization', 1);('hard problem', 1);('whole state space3on hand orthonormality', 1);('strong assumption', 1);('ssuch', 1);('ampli es rst deigenfunctions', 1);('awayfrom zero', 1);('representation dominant subspace sequence', 1);('thereconstruction eigenfunctions cf section 25we motivate heuristic approach', 1);('pccaalgorithm', 1);('construct transformationsand', 1);('convergence 1dsettinglet', 1);('summarize idea', 1);('pccamethodology', 1);('metastable systemsthe statespace regions', 1);('individual eigenfunctions', 1);('extremal representative therespective metastabilities system practice', 1);('state space', 1);('xover', 1);('respectiveeigenfunction components vithe', 1);('pccacan', 1);('asa method identify simplex structure construct linear transformation space ofeigenfunction components', 1);('big possible speci', 1);('optimization problemwe', 1);('picture functions su\x0ecient time propagation orpower iterations functions', 1);('plotting xover', 1);('xovervplot', 1);('modulo linear transformationachange basis', 1);('pccaonto', 1);('nin order nd transformationsuch', 1);('n1 lls unitsimplex inhibits exponential decay nontrivial eigenfunctions', 1);('independent components', 1);('dominanteigenfunctions decay', 1);('nondominant ones', 1);('behavior andprevail forn1', 1);('preliminary results', 1);('pccawith', 1);('minor modi cations4 constructsin', 1);('dimensions works ne focus paper optimal control willreserve', 1);('future work', 1);('proof simpler case singletimescale', 1);('section24 1disokann', 1);('pccain', 1);('rst nontrivial eigenfunction v2', 1);('pccasolutioncan', 1);('s3one', 1);('functions nite number', 1);('points orthonormalize wrt resultingvectors', 1);('work ne', 1);('points eigenfunction di er', 1);('ie theindividual metastabilites', 1);('priori notlend adaptive scheme', 1);('does4in order work', 1);('pccahas', 1);('stable respect permutations ie', 1);('sndonot', 1);('xr2is', 1);('rstcomponent \x16 1xralone \x12\x16 1\x00\x16 \x13 11this representation', 1);('series scalar neural networks \x16 nxr scalar representation isthe approach', 1);('pccasolution recall', 1);('v1\x111 note v2x minv2maxv2', 1);('xforms', 1);('line segment ie 1dimensional simplex thev1v2plane', 1);('pccathen', 1);('unique map', 1);('swhich', 1);('maps simplex', 1);('unit simplexfxyjxy 1x 0y 0gsee', 1);('4to end', 1);('introduce map \x16sfor', 1);('continuous functions \x142cx\x16s\x14 \x14\x00min\x14max\x14\x00min\x1412such \x16s\x14', 1);('x\x1001', 1);('unit interval', 1);('ashift scale a\x0enelinear argument', 1);('linear map 1d subspacesf1\x14j\x142cxg similarlyf\x141\x00\x14j\x142cxgand', 1);('pccasolutionon', 1);('component ie exists matrix', 1);('s2r2\x022such', 1);('satis ess\x01\x12\x141\x00\x14\x13\x12\x16s\x141\x00\x16s1\x00\x14\x13', 1);('pccais', 1);('input k thecase orthonormalization procedure', 1);('action rst component equivalentlygiven a\x0enelinear map', 1);('rst component function formulate followingexplicit iterative 1disokann procedure', 1);('eqs', 1);('to13 generic \x16 0xr', 1);('components v1andv2 1disokann iteration\x16 n1\x16sk\x16 n 14converges function\x16 limn1\x16 n v1 v2 15for', 1);('sk\x16', 1);('shiftscale ie a\x0ene linear', 1);('k11one', 1);('eigendecomposition \x16 0p1i1aivi havekn\x16 01xi1ai\x15nivia111xi2ai\x15nivi 18for largen contribution', 1);('thecontribution v1v2', 1);('hence', 1);('slow eigenfunctions', 1);('wehave 2r\x16 limn1\x00\x16s\x0ek\x01n\x16', 1);('v1 v2 19which proves', 1);('kacts', 1);('\x16sk\x16 \x16', 1);('implicit construction', 1);('sfrom\x16sin eq', 1);('shows xedpoint result 16to summarize', 1);('scalar problemreproduces', 1);('classical 1disokann procedure', 1);('role linear map', 1);('sdetermined', 1);('a\x0enelinear \x16s simpler representation', 1);('toshow convergence function', 1);('abuse notation justi', 1);('trivial solution \x111625', 1);('restoring', 1);('compute eigenfunctions', 1);('k whereas', 1);('corresponding invariant subspace show restore eigenfunctions fromthe solution', 1);('equivalent tok', 1);('means basistransformation making use', 1);('moorepenrose', 1);('idi1be column vector icomponent functions', 1);('sbe', 1);('full rankmatrix thatsk 21ifx\x03is eigendecomposition', 1);('q s\x001', 1);('ieqxx\x03 22thene', 1);('xare', 1);('kwith', 1);('eigenvalues \x03proof assumption', 1);('k s\x001 inserting', 1);('id', 1);('x x\x03', 1);('computational', 1);('procedurewith theoretical considerations', 1);('algorithm practice', 1);('neural networks function approximators', 1);('monte carlo mc', 1);('koopmanevaluationsto', 1);('main formula iterative update', 1);('nxtjx0xm 24here', 1);('learning commonmean', 1);('error loss', 1);('random training points xmm 1m aprocedural description', 1);('iterative scheme consistof representation functions nand b evaluation', 1);('hand side ie thecomputation', 1);('snand', 1);('operatorfor representation n', 1);('neural networks', 1);('good approximationproperties', 1);('dimensions di erentiability', 1);('optimal controlpart general feedforward architecture', 1);('suitable whilst convolutional networks couldbe', 1);('due spatial structure state space', 1);('con neourselves', 1);('architecture simplicity case update step n1consistsof', 1);('datadnfxmsmg smsnk nxm', 1);('current n nare', 1);('lot betweenthe iterations', 1);('sense initialize n1with weights nas', 1);('learnedstructure speed learning', 1);('whilst talk di erent networks nfor eachiterationnto', 1);('practice update single instance thenetworkin view learning procedure', 1);('batch learning thewhole data batch', 1);('dnis', 1);('current representation n', 1);('theupdate', 1);('stochastic optimizer', 1);('classical stochastic gradientdescent', 1);('minimize empirical', 1);('l2errormin', 1);('n1xxmsm2dn n1xm\x00sm2', 1);('b evaluation', 1);('hand side', 1);('approximation thekoopman operator', 1);('training point xm use representation expectation value andapproximate action', 1);('sum simulation', 1);('ansde integrator', 1);('end pointsykmk 1k action', 1);('operator xmis', 1);('empiricalaverage\x14mk nxm', 1);('nxtjx0xm\x191kkxk1 nykm 27to summarize xmwe average evaluation', 1);('sdesimulationswhat', 1);('application shiftscale', 1);('case 1disokann action', 1);('snisdetermined', 1);('shiftscale \x16sfrom', 1);('global extrema input functionk practice', 1);('data f\x14mgto', 1);('dimensions compute matrix', 1);('snusingpccato', 1);('nd transformation maps columns matrix', 1);('\x141\x14m unitsimplex', 1);('training points', 1);('coverthe areas', 1);('points xm principle', 1);('ndthe functions system', 1);('thesde integration', 1);('useful synthetic data regimewhere trajectories', 1);('adapting training points xm willsee trajectory simulations information', 1);('reaction coordinates', 1);('samplingof thexm ie xm', 1);('end points', 1);('previous simulationspn mxn\x001m0mkyn\x001km1a 28we', 1);('mstrati', 1);('uniform samples ui201', 1);('mequallysized', 1);('partitions interval', 1);('npi closestto', 1);('ui furthermore', 1);('samples extremal nto facilitate goodapproximation extrema', 1);('samples xmwhich uniform', 1);('good coverageor bridges', 1);('transition region', 1);('e\x0ecient ow information thepoweriteration process', 1);('variation ie harderto', 1);('bene cial training neuralnetwork itselflast', 1);('systems ergodic dynamics willtherefore approximate stationary distribution', 1);('toevade curse dimensionality', 1);('meaningful samples', 1);('thereaction pathsto summarize strati', 1);('sample uniform', 1);('stationary conditionedon', 1);('additional cost', 1);('learning processthe', 1);('npower', 1);('main ingredients', 1);('power iteration learning dominant subspace2 neural network approximation', 1);('evaluationin outermost loop', 1);('power iteration nto n1', 1);('theory haveconvergence n1', 1);('number iterations', 1);('classical convergence criteria', 1);('relative absolute tolerances', 1);('rateof convergence', 1);('number power iterates', 1);('ndepends', 1);('eigenvalues the8koopman operator', 1);('spectral gap implies', 1);('decay nondominant spectrum andhence', 1);('convergencewhen training neural network', 1);('loop batch', 1);('mtrainingpointsxmwhich', 1);('kindividual', 1);('trajectory simulations number trainingpointsmas', 1);('kdepend', 1);('step sizes', 1);('neural networkoptimizer', 1);('practice evaluation', 1);('tothe neural network update', 1);('multiple update steps batch ofdata', 1);('iterationnote variance training data', 1);('k\x001', 1);('high metastablesystems', 1);('due impact', 1);('rare transitions', 1);('xspace', 1);('address problem variance inthe', 1);('techniques optimal control importance samplingalgorithm', 1);('isokanninputnthe', 1);('number power iterationsmthe number xsampleskthe number', 1);('koopman montecarlo', 1);('samples 0initial neural networkoutput', 1);('napproximates', 1);('function cf', 1);('ton\x001do2 form', 1);('tomdo3xm samplex0 sample training points4 fork 1tokdo5 yk samplextxm simulate trajectories6\x14m 1kpk nyk', 1);('s\x14', 1);('target data8 \x01 r\x12npm nxm\x00sm2compute loss gradient9 n1 optim n\x01 train neural network10return', 1);('nsubroutines', 1);('samplex0 subroutine', 1);('points xm', 1);('uniform strati', 1);('section 26samplext', 1);('solver eg', 1);('section 34s empirical shiftscale', 1);('pccasection', 1);('23optim gradient', 1);('optimization neural network eg', 1);('eigenfunctions functionsin chapter rst recall importance', 1);('bettersample eigenfunctions', 1);('functions conclude chapterwith numerical example31', 1);('importance sampling', 1);('random variablesimportance', 1);('express expectation value', 1);('observable f', 1);('respect tosome distribution pby expectation value respect distribution qwithp q bythe formulazepf', 1);('eq\x14fdpdq\x15', 1);('observable fis', 1);('bychoosingq\x03such thatdpdq\x03zfieq\x03fzp havezeq\x03\x14fzf\x15eq\x03z 309now', 1);('zis', 1);('fsample q\x03', 1);('wetherefore', 1);('importance sampler', 1);('distribution q\x03aszerovariancesampler oroptimalimportancesampler', 1);('unknown result', 1);('zinorder', 1);('ne optimal', 1);('distribution q\x0332', 1);('optimal importance sampling di', 1);('processessince', 1);('di usion processes importance', 1);('themeasures path measures', 1);('probability density function', 1);('importance samplingcan', 1);('stochastic processes', 1);('di usion process', 1);('ingeneral', 1);('expectation pathdependent quantities', 1);('ne thework', 1);('cost fand terminal cost gaswttxzttfxssdsgxt 31one', 1);('expectation values form xtextxexp \x00wttx', 1);('extxexp', 1);('\x00zttfxssds\x00gxt 32girsanovs theorem builds', 1);('di usion processes allowingto sample', 1);('di usion processes', 1);('ofmeasure terms', 1);('derivative end', 1);('xutt\x150dxut', 1);('bxut \x1buxuttdt\x1bdbt 33with admissible control term', 1);('thatwith zero control u', 1);('xxu0 letpdenote', 1);('xandqdenote', 1);('xu according girsanovs', 1);('theorem changeof measure fromqtopanalogous todpdqabove', 1);('xuis', 1);('bygttxudpdq ttxu exp \x00zttuxuss\x01dbs\x0012zttjuxussj2ds34which', 1);('estimator terms', 1);('process x0', 1);('\x00w0txug0txu 35note', 1);('value estimator control uits variancewill', 1);('analogous', 1);('case exists optimal measure', 1);('corresponding optimalcontrolu\x03for', 1);('estimator exhibits zero variance', 1);('optimal control u\x03is', 1);('byu\x03xt \x1brxlog xt 36and', 1);('zero variance estimator x0', 1);('ex0xexp\x00w0txasg0txu\x03', 1);('operatorwe show optimal control theorem', 1);('leth2l1xbe', 1);('function single realization', 1);('xustartinginxu0xwith', 1);('controluxt \x1brxlogkt\x00thx 38then', 1);('kthat', 1);('point xkthxasg0txuhxut 3910proof', 1);('withfx', 1);('andgx \x00loghx', 1);('extxhxt ex0xhxt\x00t kt\x00thx', 1);('resultthis result shows', 1);('order compute optimal control', 1);('khwe', 1);('need tohave access derivatives', 1);('kh', 1);('conundrum line general optimal importanceresult', 1);('forisokann convergence nprovides', 1);('approximate description useto compute controllet', 1);('observable interest eigenfunction', 1);('iehviwith eigenvalue \x15it case', 1);('operator itseigenvalue', 1);('cancels application rlog results timeindependent controlu\x03xt \x1brxlogkt\x00tvix \x1brxlog\x15it\x00tvix \x1brxvixvix 41this', 1);('simple example', 1);('good point', 1);('feeling optimal importance samplingworks', 1);('control pushes system direction', 1);('relative maximal ascent', 1);('ifthe', 1);('evaluation increases path', 1);('weight increments', 1);('commensuraterelative scale expectation value', 1);('relative current value rvvwhereas', 1);('integral whichmay', 1);('nite product timepoints', 1);('increase observableis', 1);('matter path', 1);('obtains zerovariance', 1);('singular whenever vix', 1);('according perronfrobenius', 1);('nontrivial eigenfunction', 1);('ie crosses', 1);('point wehave nd way', 1);('problem alleviate problem', 1);('theform \x16sin', 1);('42due linearity', 1);('obtainkt x', 1);('vix \x15itvix 43and', 1);('control terms isu\x03xt \x1brxlogkt\x00t x \x1br x x \x15it\x00t\x00 44in case', 1);('control time', 1);('relative contributions ofthe dominant eigenfunctions expectation value', 1);('time \x15it\x14\x15i0', 1);('canconclude u\x03\x01t \x1br', 1);('ie controlis', 1);('pure eigenfunction case', 1);('full magnitude ttnote requirement functions', 1);('\x14 \x141', 1);('bytheir interpretation macrostates', 1);('importance sampling34', 1);('application isokannin', 1);('previous section', 1);('zerovariance sampler', 1);('operatorin terms gradient solution', 1);('general observables hor', 1);('case solution', 1);('priori compute control arguehow', 1);('main idea', 1);('optimal importance', 1);('intermediate results nandsnto compute pseudooptimal control', 1);('approximation optimal control', 1);('variance reductionwhereas', 1);('proof statement', 1);('objective associatedoptimal control problem', 1);('convex control', 1);('conjecture thevariance', 1);('approximate optimal', 1);('wellnote importance sampler', 1);('converge albeit', 1);('long variance becomeunbounded6', 1);('usual conditions stochastic gradient descent convergence ie', 1);('recall equation control 38uxt \x1brxlogkt\x00thx 45in order compute di erential', 1);('kt\x00tat', 1);('su\x0ecient convergence', 1);('n\x19 n\x001 nsn\x001kt n\x001 46to approximate action', 1);('ktby sn\x001\x001sn\x001\x001', 1);('nkt n\x001\x19kt n', 1);('semigroup property', 1);('matrix logarithm', 1);('matrix approximation ekt\x00tkt\x00t n\x19ekt\x00t n exp\x12t\x00ttlog\x00sn\x001\x001\x01\x13 n 48note general ddimensional case expectation values', 1);('nare vector', 1);('works scalar case', 1);('wehave compute', 1);('individual control', 1);('matrix approximation', 1);('cancompute pseudooptimal control ith component', 1);('nexplicitlyu\x03ixt \x1brxlog0xjekt\x00tij jx1a\x1bpjekt\x00tijrx jxpjekt\x00tij jx49in case 1disokann action', 1);('operator nconverges shiftscale in43', 1);('estimate parameters and\x152from extrema', 1);('n\x001as applythe', 1);('explicit control', 1);('eigenfunction 44now', 1);('compute control modify algorithm line', 1);('samplingthe trajectories', 1);('order compute', 1);('trajectory noise', 1);('y addition', 1);('component withg exp\x00gt dgt12uxutt2dtuxutt\x01dbtdg0', 1);('koopman monte carlo', 1);('approximation line', 1);('average evaluations theendpoints', 1);('kindependent', 1);('respective weights', 1);('gmk', 1);('nxm\x191kxk nxutmgm 51in way assumption', 1);('approximation ofthe functions results', 1);('approximation action', 1);('approximationof optimal control pseudooptimal control', 1);('variance whichfacilitates', 1);('approximation power iterates ie functionas proof concept', 1);('reduction variance hand classicdoublewell potential6which', 1);('term turnalso overall', 1);('variance7in conjunction strati', 1);('multiple search directions', 1);('respective metastabilties', 1);('interplay search directions', 1);('balance betweenexploration exploitation12a', 1);('training', 1);('power iterations batches', 1);('steps blueline shows training loss', 1);('red line shows', 1);('samplesin training data35', 1);('example controlled', 1);('1disokann double welllet', 1);('doublewell potential', 1);('metastable behavior', 1);('challenging sample variance ourexperiments', 1);('training performance', 1);('thecontrol 44we', 1);('network 0rrwith sigmoidal activationfunctions', 1);('layers size', 1);('ie layer sizes', 1);('\x025\x025\x021 network generationn compute', 1);('interval \x0022', 1);('position simulate', 1);('strong order', 1);('stepsize \x01', 1);('generation n', 1);('points l', 1);('stochastic gradient descent steps', 1);('adamoptimizer', 1);('learning rate \x11', 1);('procedure correspondingto single power iteration total', 1);('iterationsfor experiment monitor root training loss', 1);('ie root', 1);('errorrmse s1mxm nxm\x00sm2 52and', 1);('mc', 1);('estimator 27mstd 1mxms1kxk nykm\x00\x16m2where\x16m1kxk nykm 53over training phase', 1);('iterations l', 1);('training steps eachlet', 1);('shows square rootof training loss', 1);('casesof study', 1);('5a observe', 1);('uncontrolled system', 1);('iterations approaches itsplateau error 10\x001but afterwards training loss', 1);('thiscomes', 1);('training data exhibits noise magnitude', 1);('expectthe average loss', 1);('noise data', 1);('loss itselfseems', 1);('whilst', 1);('theempirical loss', 1);('level noise solution', 1);('experiment observe', 1);('5b loss behaves', 1);('experiment rst', 1);('theloss decreases', 1);('power iterations', 1);('plateaunotice training noise', 1);('strong contrast', 1);('uncontrolled case decreases', 1);('training furthermore', 1);('training loss', 1);('followingthe noise level', 1);('high importance13a', 1);('blue line shows', 1);('function end training', 1);('red dots', 1);('traintarget ie', 1);('evaluations xm', 1);('standard deviation error', 1);('performance plots furthermore identify', 1);('individual trainingbatches', 1);('mstd', 1);('itsstandard deviation', 1);('inbetween neural network training loops', 1);('whereas rmseplateaus', 1);('batch observe jumps', 1);('beginning ofeach', 1);('new batch jumps', 1);('previous batch plateau withoutgeneralization', 1);('batch ank8let', 1);('shows di erent', 1);('functions application oftheisokann algorithm', 1);('n\x001xm themrandom locations xmthe error', 1);('estimators ie noisein training data', 1);('theuncontrolled', 1);('boundaries understoodas result noise', 1);('subsequent noisy estimation empirical shiftscale', 1);('conclusionin', 1);('new theoretical results', 1);('strengths ofisokann', 1);('convergence proof', 1);('thm', 1);('prop', 1);('new adaptive', 1);('samplingwhich complements', 1);('formulating isokann', 1);('terms ofthe transformation', 1);('s6', 1);('higherdimensional functions', 1);('theoriginal 1disokann', 1);('pccafor', 1);('sford1', 1);('study proof convergence case', 1);('open future workthe', 1);('main contribution article introduction importance', 1);('isokann whereas', 1);('varianceshould explode proof convexity variance control', 1);('proof ofthe convergence control', 1);('furthermore concept optimalimportance', 1);('useful iterative solution', 1);('general cfcor 21an', 1);('actual molecular dynamics', 1);('mdsystem', 1);('techniques fare complexities', 1);('real world problemsthis', 1);('way run', 1);('trajectories di erent', 1);('locations lowoverhead aswell', 1);('md', 1);('simulations hope interfaces', 1);('enhance research molecular systems8to increase e\x0eciency algorithm', 1);('plateau ank indication interruptthe', 1);('current training generate', 1);('new training batch14acknowledgementwe', 1);('luca donati luzie helfmann', 1);('insightful discussionsthis research', 1);('deutsche forschungsgemeinschaft dfg', 1);('crc', 1);('cascades complex systems project number', 1);('project a05 probing', 1);('systems optimal nonequilibrium forcingcode availabilitythe code', 1);('numerical examples', 1);('julia', 1);('github', 1);('athttpsgithubcomaxskoptimpsamplingjl tag jmp9references1', 1);('bovier', 1);('metastability', 1);('reversible di usion processes', 1);('sharp', 1);('asymptotics capacitiesand exit times', 1);('j eur math soc jems', 1);('luca donati marcus weber bettina g keller markov', 1);('models square root approximation', 1);('fokkerplanck', 1);('griddependent ux journal ofphysics', 1);('condensed matter', 1);('n ernst', 1);('computation', 1);('temperaturedependent dissociation rates', 1);('metastable proteinligand complexes', 1);('molecular simulation', 1);('hartmann', 1);('importance', 1);('path space di usion processes slowfastvariables', 1);('probab theory relat', 1);('carsten hartmann', 1);('variational characterization free energy theory algorithmsinentropy', 1);('nov', 1);('wilhelm huisinga metastability markovian systems', 1);('approach inapplication molecular dynamics', 1);('phd', 1);('fachbereich mathematik', 1);('informatik fuberlin', 1);('stefan klus p\x13', 1);('koltai christof sch\x7f', 1);('utte numerical approximation', 1);('perronfrobenius koopman', 1);('operator journal', 1);('computational dynamics', 1);('sept', 1);('pp 5179doi103934jcd2016003', 1);('han cheng lie convexity', 1);('stochastic control', 1);('odi usions', 1);('doi1048550arxiv160305900 urlhttpsarxivorgabs160305900', 1);('adam nielsen monte carlo', 1);('computation error transition probabilities', 1);('statistics probability', 1);('nikolas n\x7f', 1);('lorenz richter solving', 1);('hamiltonjacobibellman pdesusing', 1);('neural networks perspectives theory', 1);('di usions measures pathspace', 1);('partial di', 1);('equations applications', 1);('robert julian rabben sourav ray marcus weber isokann invariant', 1);('neural network journal', 1);('physics', 1);('susanna r\x7f', 1);('marcus weber fuzzy', 1);('pcca', 1);('markovstate', 1);('models data classi cation', 1);('advances data analysis classi', 1);('christof sch\x7f', 1);('stefan klus carsten hartmann overcoming timescale barrier molecular dynamics transfer operators variational principles machine learning tech', 1);('takustr', 1);('berlin zib', 1);('benjamin j zhang tuhin sahai youssef marzouk koopman framework rareevent simulation stochastic di', 1);('equations j comput phys', 1);('456c 20229in order reproduce experiments plots paper runjulia', 1);('pkgaddhttpsgithubcomaxskoptimpsamplingjljmpjulia', 1);('optimpsampling optimpsamplingpaperplots15', 1);