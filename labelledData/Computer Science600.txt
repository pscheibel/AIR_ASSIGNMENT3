('original baseline', 10);('cvpr', 8);('gaussian', 6);('cnn', 5);('pretext task', 5);('equation', 4);('typeaware', 4);('nips', 4);('fashion compatibilityprediction', 3);('specically', 3);('id', 3);('csanet', 3);('score', 3);('eccv', 3);('general pretext task', 2);('rst generate', 2);('image distortion', 2);('pretext tasks', 2);('jigsaw puzzles', 2);('fashion outt', 2);('igray', 2);('experimental', 2);('polyvore outts polyvoreouttsd', 2);('scenet', 2);('different 1\x004is', 2);('color distortion task', 2);('figure', 2);('score056', 2);('083scenet 28wo', 2);('083csanet 17wo', 2);('082ocmcf 27wo', 2);('acm mm', 2);('incvpr', 2);('ieee transactions multimedia', 2);('iccv', 2);('iclr', 2);('z zhou z su r wang attributeaware', 2);('heterogeneousgraph network fashion compatibility prediction', 2);('neurocomputing', 2);('semisupervised', 1);('compatibility predictionby color distortion predictionling xiao toshihiko yamasakidepartment information communication engineeringgraduate', 1);('information', 1);('technologythe', 1);('tokyo tokyo japanabstractsupervised', 1);('learning methods', 1);('fromthe fact largescale', 1);('dataset mandatorywhich difcult', 1);('signicantissue fashion compatibility prediction compatibility aims', 1);('peoples perception aestheticswhich sparse', 1);('due fast fashion', 1);('moreoverlabeling', 1);('expert knowledgeat', 1);('good sense aesthetics', 1);('learning techniques eld paper', 1);('generalcolor distortion prediction task', 1);('lowlevel image information', 1);('discriminative representation fashion compatibility', 1);('distort image', 1);('image color balance contrast sharpness andbrightness', 1);('convolutionalneural network', 1);('probability distribution', 1);('possible distortions', 1);('stateoftheart methods fashioncompatibility shows effectiveness', 1);('thesemethods ability', 1);('pretext task baseline', 1);('original baseline1', 1);('introductionfashion', 1);('compatibility prediction', 1);('lot research attention', 1);('challenging task', 1);('dataset ensurehigh accuracy', 1);('main difculties', 1);('restrictthe development', 1);('sense ofcompatibility', 1);('labeling', 1);('needsome expert knowledge', 1);('goodsense aesthetics', 1);('particular fashion compatibility', 1);('subjective evaluation', 1);('labels notalways', 1);('obvious consistent', 1);('learning methods havebeen', 1);('computer vision tasks', 1);('fashion compatibility predictionproblem', 1);('different conventional object classication recognition example dress becompatible necklace', 1);('differentshapes colors texture', 1);('reasoning items compatibilityfrom', 1);('multiple perspectives color texture patternand style', 1);('complementary compatibility', 1);('different similarityin work', 1);('baselines fashion compatibility predictionthe core intuition', 1);('work lowlevel image', 1);('key roles peoples aesthetic evaluationsif model cant', 1);('difference lowlevel information', 1);('impossible model extracthighlevel compatibility information image', 1);('concretely', 1);('images adjustingthe image color balance contrast sharpness brightness', 1);('agaussian noise', 1);('backbonefor probability distribution', 1);('possible distortionsthe', 1);('stateoftheartmodels effectiveness', 1);('main contributions', 1);('below1 paper', 1);('general color distortion prediction task force baseline', 1);('lowlevel image', 1);('extract discriminative representations fashion compatibility prediction2 rst', 1);('gausarxiv221214680v1', 1);('dec', 1);('2022sian noise', 1);('effective color distortionprediction task fashion compatibility prediction3', 1);('stateoftheart baselines fashion compatibility eldand shows effectiveness', 1);('performance inspiration', 1);('future workin', 1);('learning fashion compatibility fashion recommendation fashionrelatedtasks2', 1);('related', 1);('selfsupervised', 1);('popularityacross variety modalities ability avoidthe cost', 1);('largescale datasets', 1);('text 6and graphs', 1);('multiple pretext tasks', 1);('pseudo labels', 1);('data models learngood representations', 1);('multiple computer vision', 1);('greyscale images', 1);('useful features object recognition anddetection tasks', 1);('wu', 1);('instance discrimination id', 1);('pretext task contrastive loss 9id treats image instance distinct class ownand trains classier distinguish', 1);('individual instance classes', 1);('effective learning', 1);('strong visual representations', 1);('texture colors object harmful objection recognitionin', 1);('strong data augmentation techniquessuch color distortion eg color', 1);('recognition detection performance', 1);('color texture invariant', 1);('wang', 1);('thatthe batchwise crossview comparisons', 1);('improvethe positivenegative sample ratio', 1);('invariant mappinghowever', 1);('learning fashion eld isnot', 1);('kim', 1);('learning fashioncompatibility', 1);('color histograms', 1);('discriminating shapeless local patches', 1);('discriminating textures instance', 1);('revanur', 1);('random transformations image batch shapeand appearance measure discrepancy betweenthe representations', 1);('imageshowever researches', 1);('fashioneld high need', 1);('learning totackle problems', 1);('nature offashion paper aim', 1);('baselines thefashion compatibility eld22 fashion compatibility', 1);('work fashion compatibility prediction canbe', 1);('supervised', 1);('ofeither conditional similarity networks', 1);('graphneural networks', 1);('long short term memorylstm', 1);('dataset difcult', 1);('expert knowledge notionofcompatibility', 1);('research needs', 1);('solvethe problems', 1);('nature fashion paper aim', 1);('fashion compatibility eld paper', 1);('design pretext task', 1);('accuracy fashion compatibility prediction3', 1);('methodswith', 1);('knowledge color contrast sharpness andbrightness', 1);('key factors', 1);('peoples aesthetic evaluation cloth image', 1);('theoretically', 1);('lowlevel information', 1);('fashion compatibility prediction', 1);('extractor theyare', 1);('classication detection tasks', 1);('thetwo', 1);('tasks focus highlevel general', 1);('aspecic class', 1);('problem paper', 1);('aprediction task force baselines focus onlowlevel informationfirst generate', 1);('imagesficoloricontrastisharpnessibrightnessg compatible appearance contains', 1);('kinds complementaryappearance', 1);('similar appearance force featureextractor', 1);('complementary information addgaussian noise', 1);('moredistortions force', 1);('similarity information dene hyperparameter controlthe distortion', 1);('shows details', 1);('color distortionprediction task', 1);('distortionsadjust image color balanceadjust image contrastadjust image sharpnessadd', 1);('fcclassification', 1);('loss05 04cnnadjust image brightnessfigure', 1);('overview', 1);('color distortion prediction task', 1);('numbersdfd\x01jyg4y1 whered\x01jyis distortion appliesto imageiand yields', 1);('iygijywith', 1);('f\x01gets', 1);('imageiy\x03as input label y\x03is', 1);('unknown modelf\x01 yields probability distribution possibledistortionsfiy\x03j\x12 ffyiy\x03j\x12g4y1 1wherefiy\x03j\x12is', 1);('probability distortion label and\x12are', 1);('parameters modelf\x01therefore', 1);('ntraining', 1);('dfiigni0', 1);('objective model learns', 1);('ismin\x121nnxi0lossii\x12 2where loss function loss\x01is', 1);('aslossii\x12 \x00144xy1logfygiijyj\x12 3we', 1);('image distortion designs andhow', 1);('image belowadjust image color balance', 1);('image color balance rst transform', 1);('ifrom rgbspace', 1);('gray space', 1);('mixigray andiwith hypeparameter', 1);('g\x020587 b\x020114icolor10\x00', 1);('1igray 1i4adjust image contrast', 1);('image contrast werst calculate', 1);('value image andimean', 1);('imean', 1);('andiwith hypeparameter', 1);('g\x020587 b\x020114imean', 1);('05icontrast 10\x00 2imean 2i5adjust image sharpness', 1);('image sharpnesswe rst', 1);('smooth image andismooth', 1);('ismooth', 1);('andiwith ahypeparameter', 1);('i\x03filterisharpness', 1);('10\x00 3ismooth 3i6adjust image brightness', 1);('image brightness rst', 1);('empty image', 1);('i0', 1);('i0andiwith', 1);('7i0zeroiibrightness 10\x00', 1);('normal distributionnwith', 1);('n01', 1);('control noise distortion degree', 1);('i0colori0contrast i0sharpness', 1);('icolor ni0contrast icontrast ni0sharpness isharpness ni0brightness ibrightness n84', 1);('pretext task stateoftheartbaselines experiments', 1);('fillintheblank fitb', 1);('outt compatibility tasks', 1);('theeffectiveness pretext task epoch number', 1);('\x16 minibatch size', 1);('ground truth', 1);('negative images outt', 1);('ofnegative images category positiveimage', 1);('ofcial codes', 1);('previous works', 1);('part ofthe codes', 1);('ocmcf', 1);('different theoriginal papers', 1);('fair comparison42 image', 1);('experimental results', 1);('image colorbalance contrast sharpness brightness generate', 1);('original image experiments', 1);('tothe baseline numbers bold', 1);('equal betterthan', 1);('image distortion task', 1);('random numbers', 1);('1\x004to show strategy', 1);('effective people canassign numbers', 1);('tasks43 combination image distortion andgaussian', 1);('experimental results imagedistortion', 1);('color distortion task combination image distortion', 1);('effective pretext task', 1);('numbers results', 1);('image distortion task numbers bold', 1);('color distortion task baseline canoutperform', 1);('notethat', 1);('random values', 1);('effective people', 1);('numbers dealwith tasks44', 1);('visualizationfigures', 1);('visualization results', 1);('fromfigure', 1);('similar color', 1);('accurate recommendations theoriginal baseline', 1);('score compatibleoutts', 1);('score incompatible ones comparedwith', 1);('ability baselinewhen reasoning fashion items compatibility theimagewe', 1);('different methods wecan', 1);('space forfashion compatibility prediction demonstratesthe effectiveness', 1);('discussionsthe', 1);('simple formulation pretext task severaladvantages', 1);('available python packagesthat', 1);('lines code cando', 1);('experimental sectionof paper pretext task', 1);('big margin5', 1);('conclusionsin', 1);('pretext tasksfor fashion compatibility prediction', 1);('based', 1);('knowledge lowlevel information plays', 1);('important rolewhen', 1);('fashion item outt', 1);('general color distortion prediction task improvethe baselines ability reasoning compatibility amongfashion items', 1);('image colorbalance contrast sharpness brightness respectivelythen increase difference', 1);('typeawarequestion scequestion csaocmcfquestionwithoutwithwithoutwithwithoutwithfigure', 1);('visualization', 1);('incomplete outt row', 1);('shows answers recommendation generatedby', 1);('original baseline row shows answers recommendation', 1);('color distortion task item', 1);('black red boxes ground truth', 1);('false recommendation respectivelynote', 1);('accurate recommendation answers', 1);('similar colors', 1);('original baselinefailstypeaware', 1);('score065', 1);('score055', 1);('score044056csa score061', 1);('score064', 1);('score067', 1);('score034', 1);('059score044 074figure', 1);('example', 1);('results compatibility task', 1);('black red boxes', 1);('compatibleand incompatible outts', 1);('score outt', 1);('compatible vice versa improvedbaseline', 1);('score compatible outts', 1);('score forincompatible ones', 1);('original baselinebefore', 1);('stateoftheart methods fashion compatibility eld', 1);('effectiveness ourmethod', 1);('experiments', 1);('polyvore outts polyvore outtsddatasets', 1);('pretext task adoptedthe baseline', 1);('proposedpretext tasks', 1);('models fashioneld', 1);('high potential', 1);('learning ofother computer vision', 1);('image distortion task baseline', 1);('image distortion task outperforms', 1);('original baseline casesmethods', 1);('pretexttask', 1);('outts polyvore outtsdfitb acc compat acc fitb acc compat acctypeaware', 1);('different pretext tasks baseline', 1);('color distortion task outperforms', 1);('image distortion task casesmethods', 1);('pretexttask polyvore outts polyvore outtsdfitb acc compat acc fitb acc compat acctypeaware', 1);('csa', 1);('pretext tasktypeaware', 1);('pretext taskfigure', 1);('tsne visualization compatibility', 1);('different methods', 1);('takenas examples', 1);('box area', 1);('color distortion tasklearns', 1);('space fashion compatibility', 1);('original baselinereferences1', 1);('baevski zhou mohamed auli', 1);('wav2vec20 framework', 1);('learning speech representations', 1);('caron misra j mairal p goyal p bojanowski', 1);('joulin unsupervised', 1);('learning visual', 1);('cluster assignments', 1);('chen kornblith norouzi g hinton', 1);('simpleframework contrastive learning visual representationsinicml pages', 1);('chen kornblith k swersky norouzi', 1);('hinton', 1);('x chen h fan r girshick k improved', 1);('baselines momentum contrastive learning arxiv preprintarxiv200304297', 1);('j devlin mw chang k lee k toutanova bertpretraining', 1);('deep bidirectional transformers', 1);('arxiv preprint arxiv181004805', 1);('jb grill', 1);('strub', 1);('altch', 1);('e c', 1);('tallec p richemond ebuchatskaya', 1);('doersch', 1);('avila pires z guo gheshlaghi azar', 1);('piot bootstrap', 1);('new approach', 1);('guan h wen x', 1);('c wang ch yeh x changand', 1);('nie partially', 1);('compatibility modelingieee', 1);('trans image process', 1);('r hadsell chopra lecun dimensionality', 1);('reduction learning invariant', 1);('volume 2pages', 1);('x han z wu g jiang ls davis learning', 1);('fashioncompatibility bidirectional lstms', 1);('k h fan wu xie r girshick momentumcontrast', 1);('visual representation learning', 1);('p jing ye', 1);('nie j liu su lowrank', 1);('multirepresentation learning fashion compatibilityprediction', 1);('p jing j zhang', 1);('nie ye j liu su tripartitegraph', 1);('latent lowrank representation fashioncompatibility prediction', 1);('kim k saito mishra sclaroff k saenko', 1);('plummer selfsupervised', 1);('visual attribute learning forfashion compatibility', 1);('n komodakis gidaris unsupervised', 1);('image rotations', 1);('n lee j lee', 1);('c park', 1);('augmentationfree', 1);('learning graphs', 1);('aaai', 1);('lin tran ls davis', 1);('complementary item retrieval', 1);('x liu sun z liu lin learning', 1);('diverse fashioncollocation neural graph', 1);('ieee transactions', 1);('x liu', 1);('zhang z hou', 1);('mian z wang j zhang jtang selfsupervised', 1);('generative', 1);('transactions knowledge data engineering', 1);('misra lv maaten selfsupervised', 1);('learning ofpretextinvariant representations', 1);('nakamura r goto outt', 1);('generation style extraction', 1);('bidirectional lstm autoencoder arxiv preprintarxiv180703133', 1);('noroozi p favaro unsupervised', 1);('learning visualrepresentations', 1);('r qian meng', 1);('gong mh yang h wang belongie cui spatiotemporal', 1);('contrastive video representation learning', 1);('cj reed x yue nrusimha ebrahimi v vijaykumar r mao', 1);('li zhang guillory metzgerand k keutzer selfsupervised', 1);('wacv', 1);('revanur v kumar sharma semisupervisedvisual', 1);('representation learning fashion compatibility', 1);('inacm', 1);('recommender systems', 1);('r sarkar n bodla vasileva', 1);('lin beniwal alu g medioni outttransformer outt', 1);('representations fashion recommendation', 1);('su x', 1);('n zheng', 1);('guan li', 1);('nie complementary', 1);('outt compatibility', 1);('r tan mi vasileva k saenko ba plummer learning', 1);('similarity conditions', 1);('explicit supervision', 1);('iniccv', 1);('mi vasileva ba plummer k dusad rajpal r kumar forsyth learning', 1);('typeaware embeddings forfashion compatibility', 1);('p velickovic', 1);('fedus wl hamilton p li bengioand rd hjelm deep', 1);('graph infomax', 1);('x wang z liu sx yu unsupervised', 1);('learning crosslevel instancegroup discrimination', 1);('z wu xiong sx yu lin unsupervised', 1);('nonparametric instance discrimination', 1);('xiao yamasaki sat selfadaptive', 1);('training forfashion compatibility prediction', 1);('icip', 1);('xu j xiao z zhao j shao xie zhuangselfsupervised', 1);('spatiotemporal learning', 1);('video clip orderprediction', 1);('x zhai oliver kolesnikov', 1);('beyer s4l selfsupervised', 1);('h zhang x yang j tan ch wu j wang ccjkuo learning', 1);('color compatibility fashion outts arxivpreprint arxiv200702388', 1);('r zhang p isola aa efros', 1);('colorful image colorization', 1);('ziegler asano selfsupervised', 1);('learning object parts semantic segmentation', 1);