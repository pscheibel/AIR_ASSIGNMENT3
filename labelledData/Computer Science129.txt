('panoptic-partformer', 46);('partpq', 45);('panoptic-partformer++', 38);('pps', 35);('panoptic segmentation', 32);('cvpr', 32);('part segmentation', 31);('fig', 26);('cpp', 25);('resnet50', 25);('pwq', 24);('tab', 23);('sec', 21);('ppp', 20);('eccv', 18);('vol', 15);('no', 15);('mask2former', 15);('pq', 13);('cross attention', 13);('x. li', 13);('panoptic- partformer++', 13);('xi', 13);('gflops', 12);('part query', 12);('works [', 12);('transactions on pattern anal ysis and machine intelligence', 11);('table', 10);('ablation', 10);('object queries', 9);('y. tong', 9);('coco', 9);('qi\x001', 9);('attention', 9);('compared', 8);('transformer', 8);('part masks', 8);('effect', 8);('resnet101', 7);('vits', 7);('semantic segmentation', 7);('fp', 7);('iou', 7);('part', 7);('mask predictions', 7);('mi\x001', 7);('eq', 7);('dataset [', 7);('a. kirillov', 7);('k.', 7);('x. wang', 7);('l.-c. chen', 7);('d. tao', 6);('panoptic', 6);('part queries', 6);('previous works [', 6);('mapillary', 6);('deeplabv3+', 6);('doll', 6);('iccv', 6);('learning', 6);('y. yang', 6);('y. zhu', 6);('h. adam', 6);('g. cheng', 6);('w. wang', 6);('firstly', 5);('mask prediction', 5);('secondly', 5);('new metric', 5);('cityscapes pps', 5);('new state-of-the-art results', 5);('different types', 5);('k-net', 5);('scene segmentation', 5);('following', 5);('fpn', 5);('joint reasoning', 5);('gmc', 5);('dd', 5);('r. girshick', 5);('h. zhao', 5);('y. li', 5);('sun', 5);('deep', 5);('ieee transactions on pattern anal ysis and machine intelligence', 4);('previous', 4);('vision transformer', 4);('computer vision', 4);('background context', 4);('ps', 4);('s. xu', 4);('beijing', 4);('backbone [', 4);('query learning', 4);('thing query', 4);('recent works [', 4);('instance segmentation', 4);('mask transformers', 4);('design [', 4);('scene segments', 4);('mlp', 4);('part segments', 4);('ssq', 4);('psq', 4);('stuff', 4);('decoupled decoder', 4);('nth+nst+npt', 4);('fs', 4);('mhsa', 4);('qi', 4);('panoptic- partformer', 4);('global masked', 4);('part masked', 4);('different', 4);('bsanet', 4);('sa', 4);('bdd', 4);('c. xu', 4);('x. qi', 4);('j. li', 4);('fully', 4);('y. chen', 4);('y. wu', 4);('a. yuille', 4);('end-to-end', 4);('neurips', 4);('z. zhang', 4);('l. zhang', 4);('pmlr', 4);('panopticpartformer++', 3);('unied', 3);('decoupled', 3);('part-whole quality', 3);('thirdly', 3);('pascal context pps', 3);('part-whole modeling', 3);('panoptic part segmentation', 3);('z. lin', 3);('china', 3);('recently', 3);('detr', 3);('mask classication', 3);('ne details', 3);('corresponding query', 3);('dot product', 3);('masked', 3);('cityscapes', 3);('work [', 3);('panopticpartformer', 3);('dynamic convolution', 3);('multiple times', 3);('ground truth', 3);('part annotations', 3);('gt', 3);('corresponding features', 3);('green arrows', 3);('previous stage', 3);('red arrows', 3);('joint learning', 3);('scene masks', 3);('meta-architecture', 3);('global-part masked', 3);('pmc', 3);('training', 3);('part classes', 3);('panoptic-deeplab', 3);('coco-pretraining', 3);('generalization ability', 3);('experiment', 3);('upsnet', 3);('condininst', 3);('segformer-b5', 3);('swin-base', 3);('convnext-base', 3);('re-', 3);('aligned', 3);('pe', 3);('boundary supervision', 3);('global rst', 3);('visualization', 3);('x. liang', 3);('s. liu', 3);('l. lin', 3);('d.', 3);('j. jia', 3);('z. li', 3);('b. cheng', 3);('h. wang', 3);('object detection', 3);('t. kong', 3);('l. li', 3);('luo', 3);('z. liu', 3);('x. chen', 3);('unsupervised', 3);('proceedings', 3);('t. darrell', 3);('icml', 3);('x. zhang', 3);('y. wang', 3);('t.-y', 3);('lin', 3);('j. dai', 3);('j. wang', 3);('part predictions', 2);('task association', 2);('multiple levels', 2);('computer', 2);('wuhan', 2);('part-', 2);('panoptic segmentation results', 2);('inferior results', 2);('entire pipeline', 2);('joint', 2);('part segmentation results', 2);('motivated', 2);('part mask prediction', 2);('part decoder', 2);('dynamic convolution [', 2);('pixel-level computation', 2);('swin transformer', 2);('baseline method', 2);('baseline [', 2);('part segmen- tation', 2);('stuff query', 2);('extra semantic segmentation loss', 2);('part query learning', 2);('experiment part', 2);('datasets [', 2);('previous baselines', 2);('pixel level', 2);('extensive experiments', 2);('mask-transformer', 2);('panop- tic segmentation', 2);('semantic part segmentation', 2);('] focus', 2);('multiple objects', 2);('methods [', 2);('part-level semantics', 2);('deep learning era', 2);('part discovery', 2);('] explore', 2);('baseline methods', 2);('representation learning', 2);('feature extractor', 2);('object query', 2);('recent work [', 2);('part- whole quality', 2);('part class', 2);('stuff queries', 2);('tp', 2);('intersection', 2);('merged', 2);('pixel-level evaluation', 2);('previous analysis', 2);('hpq', 2);('meta architecture', 2);('mask', 2);('mask transformer', 2);('scene', 2);('cross reasoning', 2);('part mask predictions', 2);('generate things', 2);('stuff masks', 2);('generate part masks', 2);('decoder aligned decoder', 2);('initial heads thing/stuff mask prediction part mask prediction inner product convolution decoupled decoderfeature extractor', 2);('stuff predictions', 2);('precise location', 2);('fsandfp', 2);('state-of-the-art results', 2);('nal panoptic part segmentation', 2);('initial mask prediction', 2);('different queries', 2);('qth', 2);('qst', 2);('full correlation', 2);('car parts', 2);('otherwise', 2);('previous work [', 2);('dynamicconv', 2);('corresponding queries', 2);('transformers', 2);('meta architecture design', 2);('furthermore', 2);('dice loss [', 2);('scene-level semantic classes', 2);('cityscapes panoptic parts', 2);('pascal panoptic parts', 2);('validation images', 2);('fair comparison', 2);('cityscapes panoptic segmentation', 2);('resnet', 2);('batch size', 2);('single-scale inference', 2);('previous work', 2);('hrnet', 2);('new pro-', 2);('recent state-of-the-art backbones', 2);('various backbones', 2);('convnext', 2);('extra gain', 2);('mask r-cnn', 2);('segformer-b1', 2);('efcientps', 2);('efcientnet', 2);('polytransform', 2);('detectors', 2);('panoptic partformer++', 2);('swin', 2);('cityscapes panoptic', 2);('core design', 2);('effectiveness', 2);('dc', 2);('x x', 2);('separate reasoning', 2);('sequential reasoning', 2);('dense prediction', 2);('dp', 2);('aspp', 2);('dp-based', 2);('method pq partpq', 2);('sognet', 2);('seamless', 2);('unifying', 2);('signicant drop', 2);('part segmentation needs', 2);('joint query', 2);('will', 2);('dph', 2);('removing', 2);('part segmentation quality', 2);('part cross attention', 2);('comparison', 2);('maskformer meta-architecture', 2);('resnet-50', 2);('coco-', 2);('visualization examples', 2);('bottom', 2);('red boxes', 2);('s. yan', 2);('h. zhang', 2);('pattern analysis', 2);('machine intelligence', 2);('c. lu', 2);('j. shi', 2);('y. zhao', 2);('y. zhang', 2);('y. xiong', 2);('r. hu', 2);('pyramid networks', 2);('l. wang', 2);('convolutional networks', 2);('j. feng', 2);('a. raventos', 2);('a. bhargava', 2);('a. gaidon', 2);('kontschieder', 2);('h. li', 2);('j. wu', 2);('f. massa', 2);('a. g. schwing', 2);('w. zhang', 2);('j. pang', 2);('k. chen', 2);('c. c. loy', 2);('image segmentation', 2);('r. zhang', 2);('y. jiang', 2);('c. wang', 2);('h. hu', 2);('y. wei', 2);('s. lin', 2);('z. zhu', 2);('l. xie', 2);('s. qi', 2);('j. shen', 2);('neural networks', 2);('q. li', 2);('h. torr', 2);('l. yang', 2);('z. wang', 2);('m. yang', 2);('l. van gool', 2);('g. papandreou', 2);('f. schroff', 2);('s. qiao', 2);('e. xie', 2);('z. yu', 2);('a. anandkumar', 2);('j. m. alvarez', 2);('t. lu', 2);('j. zhang', 2);('springer', 2);('r. b. girshick', 2);('object', 2);('ieee', 2);('perona', 2);('efcient', 2);('image recognition', 2);('y. liu', 2);('y. qiao', 2);('s. xie', 2);('x. zhu', 2);('segment-', 2);('p ami', 2);('c. feichtenhofer', 2);('c. shen', 2);('f. milletari', 2);('n. navab', 2);('v-net', 2);('convolu- tional neural networks', 2);('medical image segmenta- tion', 2);('m. tan', 2);('panoptic part segmentation xiangtai li', 1);('shilin xu', 1);('yibo y', 1);('haobo yuan', 1);('guangliang cheng', 1);('yunhai tongy', 1);('zhouchen lin', 1);('fellow ieee', 1);('dacheng tao', 1);('fellow ieee abstract panoptic part segmentation', 1);('unies panoptic segmentation', 1);('works utilize', 1);('architectural level', 1);('rst end-to-end', 1);('previous metric', 1);('decouples part', 1);('model things', 1);('classication problem', 1);('such task', 1);('part-whole perspectives', 1);('new part-whole cross attention scheme', 1);('part segmentation qualities', 1);('new part-whole interaction method', 1);('extensive ablation studies', 1);('signicant cost drop', 1);('strong baseline', 1);('future research', 1);('code', 1);('index terms scene understanding', 1);('ntroduction oneessential', 1);('under- stand', 1);('visual entity', 1);('representative direction', 1);('class label', 1);('in- stance', 1);('id', 1);('foreground objects', 1);('wide range', 1);('animal parts', 1);('car parts [', 1);('vision systems', 1);('robot navigation [', 1);('li', 1);('electronics engineering', 1);('peking univeristy', 1);('key', 1);('program', 1);('no.2020yfb2103402', 1);('s-lab', 1);('nanyang technological', 1);('phd', 1);('peking univseristy', 1);('authors contribute', 1);('yang', 1);('jd explore', 1);('yuan', 1);('cheng', 1);('sensetime', 1);('y. yang panoptic segmentation panoptic part segmentation', 1);('output', 1);('part segmentationimage', 1);('input', 1);('panopitc part segmentation illustrationfig', 1);('part seg-', 1);('multi-level concept understanding', 1);('output per-pixel scene- level classication', 1);('background stuff', 1);('segment things', 1);('individual instances', 1);('specic parts', 1);('hybrid approaches [', 1);('different individual model predictions', 1);('panoptic segmentation methods', 1);('part segmentation methods', 1);('part segmen- tation results', 1);('entire process', 1);('arxiv:2301.00954v1 [ cs.cv ]', 1);('jan', 1);('huge engineering efforts', 1);('extra head', 1);('such design', 1);('studies [', 1);('tasks [', 1);('sequential tasks', 1);('components [', 1);('mutual effect', 1);('detection transformer', 1);('sev- eral', 1);('stuff learning', 1);('strong results', 1);('complex components', 1);('nms', 1);('box detection heads', 1);('such design considers', 1);('full scene understand-', 1);('full scene information renders part representation', 1);('dis- criminative information', 1);('global context', 1);('effective frame- work', 1);('panopic-partformer', 1);('part predic- tion', 1);('decode things', 1);('decoder contains', 1);('scene decoder', 1);('pixel-level self-attention', 1);('recent work', 1);('performs self- attention', 1);('instance level', 1);('corresponding mask', 1);('multi-head self-attention layers [', 1);('poses instance-wise information', 1);('inner reasoning', 1);('entire procedure', 1);('vi- sion', 1);('decoder [', 1);('extensive', 1);('sec.4.3', 1);('re- sults', 1);('previous design', 1);('bench- marks', 1);('encoderpanoptic segmentation encoderpart segmentationpanoptic part segmentation panoptic segmentation encoder part segmentationpanoptic part segmentation encoderpanoptic- partformerpanoptic part segmentation', 1);('model baseline', 1);('shared encoder', 1);('unified solutionthing query part query stuff queryfig', 1);('panoptic-fpn-like', 1);('current panoptic segmentation frameworks', 1);('performs joint learning', 1);('signicant contributions', 1);('metric highlights', 1);('inspired', 1);('pixel-wise segmentation quality', 1);('region- wise segmentation quality', 1);('hierarchical view', 1);('considers part', 1);('scene results', 1);('new metric decouples', 1);('part segmentation errors', 1);('scene segmentation errors', 1);('pixel- wise segmentation', 1);('region-wise segmentation', 1);('pixel-region level', 1);('part-whole level evaluation', 1);('origi- nal', 1);('query-level reasoning', 1);('part objects', 1);('global rst strategy', 1);('previous step', 1);('2.we presentieee', 1);('part fea- tures learning', 1);('deformable encoder', 1);('extract multiscale', 1);('following mask2former', 1);('different architectural designs', 1);('output thing', 1);('part segmenta- tion predictions', 1);('nms-free', 1);('panop- tic segmentation predictions', 1);('previous conference version', 1);('% improvement', 1);('% improve- ment', 1);('important aspects', 1);('new metric names', 1);('part whole quality', 1);('scene segmenta- tion', 1);('region level', 1);('new state-of-the-are results', 1);('present additional analytical results', 1);('comprehensive ablation studies', 1);('\x0fwe re-write', 1);('r elated work', 1);('different aspects', 1);('current', 1);('previous approaches', 1);('human analysis [', 1);('multiple parts', 1);('representative works [', 1);('] design specic methods', 1);('per-pixel classication', 1);('methods focus', 1);('model global-part context', 1);('human instance part segmentation', 1);('pipelines [', 1);('bottom-up pipelines [', 1);('top-down', 1);('two-stage detectors [', 1);('semantic part seg- mentation', 1);('bottom-up', 1);('methods rst segment', 1);('hu- man', 1);('task-specic part segmentation', 1);('car part segmen- tation [', 1);('settings needs', 1);('specic design', 1);('contains part segmentation', 1);('] performs seg- mentation', 1);('networks [', 1);('panoptic segmentation result', 1);('computation cost', 1);('stuff segmentation', 1);('thing segmentation', 1);('different task heads', 1);('detection-based', 1);('box prediction', 1);('bottom-up models [', 1);('pixel-level afnity', 1);('center heat maps', 1);('semantic segmentation results', 1);('effective task association method', 1);('complex process', 1);('performance drop', 1);('complex scenarios', 1);('panoptic segmentation masks', 1);('box supervision', 1);('hierarchical information', 1);('scene understanding', 1);('long history', 1);('object de- tection', 1);('ap- proaches', 1);('important cues', 1);('classication [', 1);('generative adversarial networks', 1);('few-shot part segmentation', 1);('part motion information', 1);('dynamic video inputs', 1);('full scene', 1);('instance-wise part segmentation [', 1);('task [', 1);('work annotates', 1);('cityscape pps', 1);('eval- uation', 1);('nal results', 1);('panoptic segmentation result.ieee', 1);('panoptic segmentation algorithms', 1);('part semantic segmentation', 1);('multi-level recognition', 1);('things segmenta- tion', 1);('complex scene understanding task', 1);('multiple instances', 1);('vit', 1);('dif- ferent directions', 1);('rst aspect', 1);('global-range relation', 1);('image patch', 1);('cnn', 1);('mask image', 1);('] explore large-scale text-image pairs', 1);('vision language', 1);('vlms', 1);('zero shot', 1);('vocabulary settings [', 1);('task pipeline', 1);('object detection task', 1);('set prediction problem', 1);('learnable queries', 1);('learning process', 1);('query-based', 1);('instance segmentation [', 1);('video object detection [', 1);('video segmentation [', 1);('ethod overview', 1);('rst review', 1);('potential issues', 1);('briey describe', 1);('meta- architecture', 1);('inference procedure', 1);('preliminary problem denition', 1);('input image', 1);('i2rh\x02w\x023', 1);('masksfyigg i=1=f', 1);('gg i=1wherecidenotes', 1);('ground truth class label', 1);('mask miandgis', 1);('number ofmasks', 1);('input scene', 1);('ci2l =fcst', 1);('thing masks', 1);('unique triple tuple', 1);('semantic id', 1);('instance id', 1);('part id', 1);('task reduces', 1);('specic case', 1);('term thing', 1);('stuff segments', 1);('individual outputs', 1);('natural part-whole relationship', 1);('recent', 1);('segmentation use', 1);('detr-like', 1);('max- deeplab', 1);('thing queries', 1);('high- resolution', 1);('depending', 1);('different reasoning methods', 1);('different meth- ods', 1);('different designs', 1);('following detr', 1);('corresponding masks', 1);('intermediate outputs', 1);('mask labels', 1);('part-whole quality metric partpq metric', 1);('original paper', 1);('2tpiou p', 1);('jtpj+1 2jfpj+1 2jfnj', 1);('true positive segment', 1);('false positive seg- ment', 1);('false negative segment', 1);('segment pand', 1);('ground-truth segmentgfor', 1);('class l', 1);('wherel2 l', 1);('ground-truth segment', 1);('anfp', 1);('fn', 1);('ground- truth segment', 1);('segment contains', 1);('parts annotations', 1);('issues', 1);('such metric', 1);('different models', 1);('panoptic-parformer', 1);('baseline contains', 1);('panoptic segmentation model [', 1);('] andieee', 1);('upper bound analysis', 1);('merge', 1);('resnet-50 backbone', 1);('setting panoptic-gt part-gt partpq p pwq merged', 1);('pps metric analysis', 1);('important properties', 1);('metric properties', 1);('pq partpq hpq pwq pixel-level evaluation x', 1);('x region-level evaluation', 1);('x x x x part-whole evaluation', 1);('x x x decouple errors', 1);('x balance part', 1);('separate part segmentation model [', 1);('huge gain', 1);('panoptic segmentationt', 1);('decou- ple', 1);('lacks interpretability', 1);('model performance', 1);('sum- mary', 1);('proposed part-whole quality', 1);('scene segmentation outputs', 1);('miou th', 1);('st+miou part\x01partpq p', 1);('panoptic quality', 1);('miou calculates', 1);('scene segment quality', 1);('=miou th', 1);('part segment quality', 1);('=miou part\x01partpq p.', 1);('ve properties', 1);('region- level evaluation', 1);('part-whole evaluation', 1);('er- rors', 1);('part-scene segments', 1);('notice', 1);('hierarchical panoptic quality', 1);('different depths', 1);('backbonescene initial heads joint query reasoning decoder part initial headsthing query part query stuff query backbonetransformer decoderjoint query reasoning decoder', 1);('-transformer -like', 1);('default designfig', 1);('default general', 1);('learning part', 1);('cross reasoning stages', 1);('meta architecture extending', 1);('sim- ple way', 1);('global scopes', 1);('good solution', 1);('panoptic-partformer meta-architecture', 1);('core in- sights', 1);('cross at- tention', 1);('meta-architecture overview', 1);('overall illustration', 1);('encoder backbone', 1);('extract fea- tures', 1);('transformer decoder', 1);('back- bone', 1);('joint query reasoning backbonescene', 1);('thing query stuff query part querydynamic conv final prediction fig', 1);('red', 1);('generate scene', 1);('initial prediction heads', 1);('initial mask predictions', 1);('yellow', 1);('green area', 1);('current stage output', 1);('stage outputs', 1);('nal output [', 1);('design details', 1);('encoder', 1);('rst extract image', 1);('backbone network', 1);('convolution network', 1);('feature pyramid network', 1);('decoder networks', 1);('scene fea- ture', 1);('part prediction', 1);('different properties', 1);('mask proposal level prediction', 1);('inner parts', 1);('mask proposal', 1);('experimental section', 1);('top-down manner', 1);('fea- tures', 1);('naive bilinear', 1);('ow [', 1);('low resolution', 1);('high resolution', 1);('locational information', 1);('decoder outputs', 1);('scene featuresfsand part', 1);('panoptic-partformer thing', 1);('queries', 1);('initial head predic-', 1);('] show', 1);('single mask classication', 1);('model treats thing', 1);('input queries', 1);('initial weights', 1);('rst stage weights', 1);('ini- tial', 1);('decoder prediction', 1);('1\x021convolution layers', 1);('initial outputs', 1);('ground truth masks', 1);('such initial heads', 1);('encoder layers', 1);('qptand mth', 1);('mst', 1);('mptwith', 1);('nth\x02d', 1);('nst\x02d', 1);('npt\x02dand', 1);('nst\x02h\x02w', 1);('npt\x02h\x02w.d', 1);('channel number', 1);('fpandfs', 1);('nth', 1);('nst', 1);('nptare', 1);('part classication', 1);('joint thing', 1);('part query reasoning', 1);('previous mask predic- tions', 1);('previous object queries', 1);('key insights', 1);('scene noisy cases', 1);('human body', 1);('human parts', 1);('nd joint learning', 1);('u andmi\x001 u', 1);('qpt', 1);('\x02d andmi\x001 u =concat', 1);('stage index', 1);('trans-', 1);('initial heads', 1);('rst dimension', 1);('xivia', 1);('previous mask predictions', 1);('xi=wx', 1);('uhx vmi\x001', 1);('qu', 1);('mi\x001is', 1);('per-instance mask', 1);('previous stage i\x001', 1);('decoder head', 1);('spatial location', 1);('iis layer number', 1);('center part', 1);('scene mask prediction', 1);('ptand scene query', 1);('th andxi st.', 1);('rene input queries', 1);('^qi\x001 u=dynamicconv', 1);('dynamic convolution uses', 1);('generate parameters', 1);('weight input queries', 1);('uses input query', 1);('uto generate', 1);('original query input', 1);('dy- namic convolution introduces', 1);('instance-wise information', 1);('gener- alization', 1);('complementary effects', 1);('operation absorbs', 1);('query look', 1);('^qi\x001 u=gate x', 1);('u+gate q', 1);('fc', 1);('layernorm', 1);('ln', 1);('sigmoid layer', 1);('different gate functions', 1);('gate xand gate q', 1);('self-attention layer', 1);('layers [', 1);('^qi\x001 u', 1);('+^qi\x001 u', 1);('multi head self attention', 1);('ffn', 1);('feed forward network', 1);('current vision', 1);('feed-forward layers onqi uand', 1);('class scores', 1);('feed-forward layers', 1);('inner product', 1);('fsfp', 1);('generate scene masks', 1);('stage input', 1);('iteration number', 1);('inter-mask predictions', 1);('mask supervision', 1);('panopticformer++ motivation', 1);('scene level', 1);('part level segment outputs', 1);('current state-of-the- art', 1);('baseline model', 1);('cross reasoning de-', 1);('likewise', 1);('joint query reasoning part', 1);('new design', 1);('global- part masked', 1);('global scene', 1);('enhanced feature extractor', 1);('default de-', 1);('feature pyramid networks', 1);('decoder design un-', 1);('experiment results', 1);('part supervision', 1);('minor effect', 1);('joint query reasoning design', 1);('ql=', 1);('ml\x001+ mlp', 1);('ql', 1);('kt', 1);('vl+ql\x001', 1);('joint query reasoning backbonething', 1);('thing query stuff query part queryglobal masked', 1);('attention final prediction part masked', 1);('joint query reasoning rst', 1);('performs cross attention', 1);('local part', 1);('object masks', 1);('fsas', 1);('fpas', 1);('rene part queries', 1);('whereml\x001is 2d attention mask', 1);('previous stage l.', 1);('ml\x0012rn\x02h\x02wis', 1);('multilayer perceptron', 1);('qlwithqi\x001', 1);('ml\x001withmi\x001', 1);('mlps', 1);('scene featurefs', 1);('contains multiscale fea- tures', 1);('notation brevity', 1);('high- est mask resolution', 1);('fsfor', 1);('formulation purposes', 1);('output queries', 1);('thing/stuff mask predictions', 1);('inner production', 1);('thing/stuff masks', 1);('part queriesqi\x001 pt0from', 1);('attention outputs', 1);('qlandml\x001in eq', 1);('7.kl andklare', 1);('fp.qi\x001', 1);('global context information', 1);('local ne', 1);('nal part queries', 1);('inner production withfp', 1);('different resolution', 1);('extra dense prediction head', 1);('part structure', 1);('attentions', 1);('discussion', 1);('core contribution', 1);('ourmain', 1);('challenging task', 1);('part learning benets', 1);('global relations rst', 1);('good design', 1);('experiment section', 1);('classication results', 1);('cross-entropy loss', 1);('lpart', 1);('lthing', 1);('lstuff', 1);('such settings', 1);('stage ican', 1);('li=\x15part\x01lpart+\x15thing\x01lthing', 1);('+\x15stuff\x01lstuff +\x15cls\x01lcls', 1);('lfinal', 1);('=pn ili', 1);('total stages', 1);('frame- work', 1);('inference', 1);('output masks', 1);('panoptic segmetnation results', 1);('panoptic segmen- tation results', 1);('panoptic-fpn', 1);('panoptic mask', 1);('nal panoptic part segmentation results', 1);('pixels cor-', 1);('part prediction contains', 1);('scene- level class', 1);('void label', 1);('e xperiment', 1);('experiment setup datasets', 1);('scene understanding datasets', 1);('pascal voc', 1);('part-level semantic classes', 1);('vehicle high-level categories', 1);('pas- cal voc', 1);('benchmark [', 1);('scene- level semantics', 1);('previous settings [', 1);('scene- level classes', 1);('] results', 1);('sub-task comparison', 1);('details', 1);('vision trans-', 1);('backbone networks', 1);('xavier', 1);('initialization [', 1);('adamw', 1);('weight decay', 1);('gpus', 1);('rst pretrain', 1);('previous baselines [', 1);('multiscale training [', 1);('input images', 1);('random crop augmentations', 1);('random rectangular patch', 1);('similar setting', 1);('scale range', 1);('whole image', 1);('large models', 1);('evaluation metric', 1);('main metrics', 1);('panopticpart-former', 1);('panopticpart-former++', 1);('cityscape panoptic part dataset', 1);('previous baselines.all', 1);('scale inference', 1);('test time augmentation', 1);('resne50', 1);('complex pipelines [', 1);('method results', 1);('previous baseline', 1);('large model comparison', 1);('swin-transformer', 1);('previous works', 1);('individual models [', 1);('1.3-1.6 %', 1);('recent method', 1);('vision transformers [', 1);('simpler pipeline', 1);('new baseline', 1);('parameter comparison', 1);('parameters', 1);('baseline model [', 1);('model obtains', 1);('% parameter drop', 1);('parameter cost', 1);('signicant improvements', 1);('pascal panoptic part dataset', 1);('com- pare', 1);('pascal panoptic part', 1);('different settings', 1);('signicant gain', 1);('% gains', 1);('backbones [', 1);('large model', 1);('scaling up panoptic-partformer++', 1);('potential performance', 1);('rst explore', 1);('series [', 1);('beit-v2', 1);('different metrics', 1);('key factor', 1);('different backbones', 1);('state-of-the- art methods', 1);('metrics', 1);('pand npare', 1);('scene-level classes', 1);('pq partpq pwq panoptic', 1);('p np', 1);('p np settings', 1);('xception-', 1);('hrnet-ocr', 1);('hrnetv2-w48', 1);('part based segformer-b5', 1);('new state-of-the- art results', 1);('end-to-end design', 1);('pq partpq pwq settings', 1);('dlv3-resnest269', 1);('unied approach panoptic partformer', 1);('panoptic partformer', 1);('performance', 1);('\x02800 in-', 1);('method pq partpq param', 1);('gflops upsnet', 1);('ocr', 1);('+polytransform +', 1);('scaling up', 1);('effec- tiveness', 1);('dataset backbone pq partpq pwq cpp swin-base', 1);('cpp convnext-base', 1);('cpp convnext-large', 1);('cpp beit-v2', 1);('ppp swin-base', 1);('ppp convnext-base', 1);('ppp convnext-large', 1);('opposite conclusion', 1);('convenext', 1);('recent works', 1);('results com-', 1);('analysis', 1);('present ablation study', 1);('model designs', 1);('mask-transformer-like', 1);('base- lines', 1);('original design', 1);('% drop', 1);('removing dynamic convolution', 1);('self attention', 1);('large drop', 1);('decoupled de-', 1);('self atten-', 1);('interaction', 1);('dd dc sa i=1 i=3 pq partpq xxx', 1);('-x -x', 1);('x x x x', 1);('query reasoning', 1);('setting pq partpq joint reasoning', 1);('query prediction', 1);('atrous spatial pyramid pooling', 1);('method pq partpq joint query', 1);('aligned decoder', 1);('settings pq partpq p np', 1);('features', 1);('position encoding', 1);('method pq', 1);('w/o part anno', 1);('w part anno', 1);('boundary loss', 1);('b- loss', 1);('+ b-loss', 1);('val- idation set.\x03indicates', 1);('dcn', 1);('original papers', 1);('method backbone pq pq', 1);('panoptic fcn\x03', 1);('panoptic fcn++', 1);('swin-large', 1);('panoptic-partformer resnet50', 1);('panoptic-partformer++ resnet50', 1);('panoptic-partformer swin-base', 1);('panoptic-partformer++ convnext-base', 1);('decreasing', 1);('stage number', 1);('performing', 1);('interaction results', 1);('whether', 1);('part information', 1);('different query interaction methods', 1);('query pairs', 1);('thing-part query', 1);('thing-part query rst', 1);('query sec- ond', 1);('default setting', 1);('whole scene context', 1);('choose', 1);('following panopticfpn', 1);('settings [', 1);('dense pre-', 1);('previous dense prediction', 1);('version [', 1);('joint learning benets part segmentation', 1);('part decoder results', 1);('adding', 1);('necessity', 1);('positional encoding', 1);('xpandxu.in tab', 1);('po- sition information [', 1);('binary cross entropy loss', 1);('boundary su- pervision', 1);('good cue', 1);('part segmentation [', 1);('joint training', 1);('joint learning benets', 1);('panoptic seg- mentation baseline', 1);('stuff prediction', 1);('dense prediction head', 1);('component dd gmc pmc partpq pwq ssq psq x x x', 1);('query reasoning de-', 1);('setting partpq pwq joint reasoning', 1);('global', 1);('pps fusion', 1);('merge method partpq pwq', 1);('component', 1);('key component', 1);('removing part masked', 1);('extra part query attention', 1);('scene segmentation results', 1);('part attention', 1);('decoder design', 1);('query interaction design', 1);('different attention methods', 1);('part-rst rea-', 1);('attention contains', 1);('global scene query learning', 1);('extra part dense prediction', 1);('extra semantic part segmenta- tion head', 1);('such supervision', 1);('decouple design', 1);('task-specic loss', 1);('final pps', 1);('extra dense semantic segmentation prediction head', 1);('dense prediction results', 1);('method pq partpq pwq gflops k-net', 1);('90k training', 1);('method coco-pretrain pq partpq pwq panoptic-partformer', 1);('panoptic-partformer x', 1);('panoptic-partformer++ x', 1);('baseline methods compared', 1);('signicant results', 1);('previous separate baselines [', 1);('simple exten- sion', 1);('maskformer', 1);('data-efcient learner', 1);('visualization analysis visualization', 1);('generalization', 1);('image prediction ground truth', 1);('mapillary fig', 1);('top', 1);('image prediction ground truth image prediction ground truth fig', 1);('pascal context panoptic part', 1);('stuff classes', 1);('rst row', 1);('considerable results', 1);('human scene', 1);('outdoor scene', 1);('row shows', 1);('small objects cases', 1);('failure cases', 1);('tiny objects', 1);('visual improvements', 1);('fur- ther show', 1);('part segmentation qual- ity', 1);('semantic consistency', 1);('onclusion', 1);('left', 1);('right', 1);('shown', 1);('pro- pose', 1);('per- form scene', 1);('state-of-the- art results', 1);('new strong baseline', 1);('benet multiple-level concept scene understanding', 1);('idea development', 1);('references', 1);('c. rother', 1);('x. shen', 1);('j. yang', 1);('j. tang', 1);('convolutional neu- ral network', 1);('q. geng', 1);('f. lu', 1);('x. huang', 1);('s. wang', 1);('z. zhou', 1);('r. yang', 1);('part-level', 1);('street view images', 1);('ieee transactions', 1);('m. cordts', 1);('m. omran', 1);('s. ramos', 1);('t. rehfeld', 1);('m. enzweiler', 1);('r. benenson', 1);('u. franke', 1);('s. roth', 1);('b. schiele', 1);('cityscapes dataset', 1);('urban scene understanding', 1);('geus', 1);('meletis', 1);('x. wen', 1);('g. dubbelman', 1);('aware panoptic segmentation', 1);('g. gkioxari', 1);('pyramid', 1);('y. tian', 1);('multi-class part parsing', 1);('joint boundary-semantic awareness', 1);('s. k. jagadeesh', 1);('r. schuster', 1);('d. stricker', 1);('multi-task', 1);('efcient panoptic-part segmentation', 1);('icpram', 1);('r. liao', 1);('m. bai', 1);('e. yumer', 1);('r. urtasun', 1);('panoptic segmentation network', 1);('g. lin', 1);('s. li', 1);('o. bourahla', 1);('f. wang', 1);('m. xu', 1);('banet', 1);('bidirectional', 1);('aggregation network', 1);('t. tagawa', 1);('fuse things', 1);('l. porzi', 1);('s. r. bulo', 1);('a. colovic', 1);('q. zhao', 1);('overlap graph network', 1);('aaai', 1);('g. zhang', 1);('h. xu', 1);('auto-panoptic', 1);('cooperative', 1);('multi-component architecture search', 1);('nips', 1);('m. d. collins', 1);('t. liu', 1);('t. s. huang', 1);('fast baseline', 1);('bottom-up panoptic segmentation', 1);('axial-deeplab', 1);('stand-alone', 1);('n. carion', 1);('g. synnaeve', 1);('n. usunier', 1);('s. zagoruyko', 1);('max-', 1);('mask trans- formers', 1);('per-pixel', 1);('towards', 1);('i. misra', 1);('r. girdhar', 1);('masked-attention', 1);('universal image seg- mentation', 1);('w. zhan', 1);('m. tomizuka', 1);('z. yuan', 1);('sparser-cnn', 1);('learnable proposals', 1);('a. vaswani', 1);('n. shazeer', 1);('n. parmar', 1);('j. uszkoreit', 1);('l. jones', 1);('a. n. gomez', 1);('l. kaiser', 1);('i. polosukhin', 1);('arxiv preprint arxiv:1706.03762', 1);('y. lin', 1);('y. cao', 1);('b. guo', 1);('hierarchical', 1);('g. huang', 1);('attention-guided', 1);('panoptic-', 1);('panoptic part segmen- tation', 1);('b. jia', 1);('s.-c. zhu', 1);('human- object interactions', 1);('x. yang', 1);('h. su', 1);('j. zhu', 1);('s. choudhury', 1);('i. laina', 1);('c. rupprecht', 1);('a. vedaldi', 1);('unsuper-', 1);('contrastive reconstruction', 1);('advances', 1);('neural information processing systems', 1);('h.-s. fang', 1);('g. lu', 1);('x. fang', 1);('j. xie', 1);('y.-w. tai', 1);('weakly', 1);('human body part', 1);('y. pang', 1);('l. shao', 1);('compositional neural information fusion', 1);('a. arnab', 1);('holistic', 1);('instance-level human', 1);('arxiv preprint arxiv:1709.03612', 1);('m. jiang', 1);('parsing r-cnn', 1);('instance-level human analysis', 1);('r. ji', 1);('l. wen', 1);('c. zhao', 1);('f. huang', 1);('s. lyu', 1);('semantic neural tree', 1);('k. gong', 1);('instance-', 1);('level human', 1);('j. zhao', 1);('y. cheng', 1);('t. sim', 1);('understand-', 1);('adversarial learning', 1);('new benchmark', 1);('mm', 1);('t. zhou', 1);('dif-', 1);('ferentiable multi-granularity human representation learning', 1);('instance-aware human semantic', 1);('u. michieli', 1);('e. borsato', 1);('l. rossi', 1);('zanuttigh', 1);('gmnet', 1);('graph', 1);('network', 1);('large scale part semantic segmen-', 1);('encoder-decoder', 1);('separable convolution', 1);('seman- tic image segmentation', 1);('detecting', 1);('switchable atrous convolu- tion', 1);('r. hou', 1);('guizilini', 1);('c. fang', 1);('j. lynch', 1);('real-time', 1);('dense detections', 1);('delving', 1);('h. yuan', 1);('polyphonicformer', 1);('aware video panoptic segmentation', 1);('q. yu', 1);('m. collins', 1);('k-means mask transformer', 1);('f. felzenszwalb', 1);('d. mcallester', 1);('d. ra-', 1);('r. fergus', 1);('a. zisserman', 1);('class recognition', 1);('scale-invariant learning', 1);('ieee computer', 1);('society conference', 1);('pattern recognition', 1);('iiii', 1);('n. zhang', 1);('r. farrell', 1);('f. iandola', 1);('deformable part descriptors', 1);('attribute prediction', 1);('n. tritrong', 1);('rewatbowornwong', 1);('s. suwajanakorn', 1);('one-shot semantic part segmentation', 1);('h. ling', 1);('j. gao', 1);('k. yin', 1);('j.-f. laeche', 1);('a. barriuso', 1);('a. torralba', 1);('s. fidler', 1);('datasetgan', 1);('data factory', 1);('minimal human effort', 1);('s. sabour', 1);('a. tagliasacchi', 1);('s. yazdani', 1);('g. hinton', 1);('d. j', 1);('fleet', 1);('part representation', 1);('ow capsules', 1);('z. xu', 1);('c. sun', 1);('k. murphy', 1);('w. t. freeman', 1);('b. tenenbaum', 1);('arxiv preprint arxiv:1903.05136', 1);('m. hu', 1);('c. liu', 1);('x. xin', 1);('w. jia', 1);('renovating', 1);('r-cnn', 1);('accurate multiple human', 1);('m. everingham', 1);('c. k. williams', 1);('j. winn', 1);('a. zis-', 1);('pascal visual object classes', 1);('voc', 1);('challenge', 1);('ijcv', 1);('c. tang', 1);('x. hu', 1);('q. tian', 1);('visual', 1);('arxiv preprint arxiv:2207.14227', 1);('a. dosovitskiy', 1);('l. beyer', 1);('a. kolesnikov', 1);('d. weissenborn', 1);('x. zhai', 1);('t. unterthiner', 1);('m. dehghani', 1);('m. minderer', 1);('g. heigold', 1);('s. gelly', 1);('arxiv preprint arxiv:2010.11929', 1);('h. touvron', 1);('m. cord', 1);('m. douze', 1);('a. sablayrolles', 1);('h. jegou', 1);('data-efcient image transformers', 1);('distilla- tion', 1);('eatformer', 1);('evolution- ary algorithm', 1);('arxiv preprint arxiv:2206.09325', 1);('k. li', 1);('gao', 1);('g.', 1);('uniformer', 1);('efcient spatiotemporal rep- resentation learning', 1);('arxiv preprint arxiv:2201.04676', 1);('j. guo', 1);('k. han', 1);('h. wu', 1);('y. tang', 1);('cmt', 1);('convolutional', 1);('vision transformers', 1);('scalable vision learners', 1);('a. radford', 1);('j. w. kim', 1);('c. hallacy', 1);('a. ramesh', 1);('g. goh', 1);('s. agar-', 1);('g. sastry', 1);('a. askell', 1);('mishkin', 1);('j. clark', 1);('transferable visual models', 1);('natural language supervision', 1);('g. ghiasi', 1);('x. gu', 1);('y. cui', 1);('scaling', 1);('open- vocabulary image segmentation', 1);('image-level labels', 1);('z. chen', 1);('y. duan', 1);('vision', 1);('transformer adapter', 1);('dense predictions', 1);('arxiv preprint arxiv:2205.08534', 1);('w. su', 1);('l. lu', 1);('b. li', 1);('deformable detr', 1);('deformable transformers', 1);('end-to-end object detection', 1);('iclr', 1);('b. dong', 1);('f. zeng', 1);('t. wang', 1);('solq', 1);('arxiv preprint arxiv:2106.02351', 1);('fash-', 1);('human fashion segmentation', 1);('q. zhou', 1);('l.', 1);('l. ma', 1);('transvod', 1);('video object detection', 1);('spatial-temporal transformers', 1);('t. meinhardt', 1);('l. leal-taixe', 1);('trackformer', 1);('multi-object', 1);('arxiv preprint arxiv:2101.02702', 1);('video', 1);('video segmentation', 1);('s. ren', 1);('residual learning', 1);('b. hariharan', 1);('s. j. belongie', 1);('feature', 1);('k. yang', 1);('semantic', 1);('accurate scene', 1);('solo', 1);('solov2', 1);('dynamic', 1);('fast instance segmentation', 1);('m. maire', 1);('s. belongie', 1);('j. hays', 1);('d. ramanan', 1);('c. l. zitnick', 1);('microsoft', 1);('common objects', 1);('s. ahmadi', 1);('h. bao', 1);('l. dong', 1);('f. wei', 1);('beit', 1);('bert', 1);('image transformers', 1);('arxiv preprint arxiv:2106.08254', 1);('x. glorot', 1);('y. bengio', 1);('understanding', 1);('feedforward neural networks', 1);('thir- teenth', 1);('international conference', 1);('articial intelligence', 1);('jmlr', 1);('i. loshchilov', 1);('f. hutter', 1);('weight decay regulariza- tion', 1);('segformer', 1);('simple', 1);('efcient design', 1);('r. mohan', 1);('a. valada', 1);('panoptic segmen- tation', 1);('international journal', 1);('rethinking', 1);('convolutional neural networks', 1);('y. yuan', 1);('object-contextual', 1);('k. sun', 1);('t. cheng', 1);('b. jiang', 1);('c. deng', 1);('d. liu', 1);('y. mu', 1);('high-resolution representa- tion learning', 1);('visual recognition', 1);('j. liang', 1);('n. homayounfar', 1);('w.-c. ma', 1);('r. ur-', 1);('polygon transformer', 1);('c. wu', 1);('h. lin', 1);('t.', 1);('j. mueller', 1);('r. manmatha', 1);('resnest', 1);('split-attention', 1);('arxiv preprint arxiv:2004.08955', 1);('f. chollet', 1);('xception', 1);('separable convolutions', 1);('g. neuhold', 1);('t. ollmann', 1);('s. rota bulo', 1);('mapillary vistas dataset', 1);('semantic understanding', 1);('street scenes', 1);('h. mao', 1);('c.-y', 1);('wu', 1);('atrous convolution', 1);('semantic image segmentation', 1);('deformable convnets v2', 1);('l. qi', 1);('arxiv preprint arxiv:2108.07682', 1);('s.-a', 1);('ahmadi', 1);('s. tan', 1);('improving', 1);('edge supervision', 1);('pointrend', 1);('f. yu', 1);('h. chen', 1);('w. xian', 1);('f. liu', 1);('madhavan', 1);('bdd100k', 1);('heteroge- neous multitask learning', 1);