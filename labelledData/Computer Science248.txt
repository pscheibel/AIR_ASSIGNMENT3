('reid', 50);('gcl', 20);('cvpr', 20);('fig', 15);('ganbased', 12);('eccv', 11);('gan', 9);('mixup', 9);('dgnet', 8);('cvpr21', 8);('eq', 7);('jvtc', 7);('z zhong', 7);('person reidentication', 7);('neurips', 7);('dmixup', 6);('positive pairs', 6);('market1501', 6);('eccv20', 6);('iccv', 6);('identity encoder', 5);('mixup contrast', 5);('r1 r5 r10', 5);('3d mesh', 4);('uda', 4);('dbscan', 4);('rotation contrast', 4);('dukemtmcreid', 4);('buc', 4);('mmcl', 4);('gcljvtc', 4);('iclr', 4);('aaai', 4);('compared', 3);('representation learning', 3);('lagadec', 3);('previous work', 3);('video person', 3);('uda reid', 3);('domain adaptive', 3);('supplementary materials', 3);('generative module', 3);('eid', 3);('structure encoder', 3);('mesh', 3);('knegative', 3);('pki1exp', 3);('act', 3);('hyperparameter', 3);('equation', 3);('cvpr20', 3);('iccv19', 3);('oneex', 3);('representation similarity', 2);('traditional data augmentation', 2);('ganbased reid', 2);('new stateoftheart unsupervisedperson', 2);('towards', 2);('contrastive', 2);('systems integration', 2);('source domain', 2);('idunrelated', 2);('orange clothes', 2);('mixup fmixup', 2);('mars dukemtmcvideoreid', 2);('data', 2);('crgan', 2);('isgan', 2);('concrete guidance', 2);('cail', 2);('pseudo labels', 2);('pseudo', 2);('decodergand discriminator', 2);('data augmentation', 2);('person image', 2);('augmentation decoder', 2);('eidand', 2);('real images', 2);('accurate images', 2);('beta', 2);('contrastive module', 2);('mars', 2);('dukemtmcvideoreid', 2);('msmt17', 2);('forthe', 2);('sgd', 2);('market duke', 2);('duke market', 2);('based', 2);('multi', 2);('rotation', 2);('r1 r5 r10wo ganbaseline', 2);('ganx', 2);('information nmi', 2);('proposedgcl stateoftheart', 2);('softsim', 2);('metacam', 2);('market1501 dukemtmcreid msmt17', 2);('datasets test', 2);('names parenthesesmethod', 2);('tssl', 2);('aaai20', 2);('pda crgan dgnet', 2);('images guidance', 2);('eug', 2);('dal', 2);('taudl', 2);('utal', 2);('oim', 2);('gans', 2);('comparison', 2);('fdgan', 2);('fdgan isgan dgnet', 2);('front side', 2);('universit', 2);('cotedazur', 2);('ieee tpami', 2);('bmvc', 2);('video person reidentication', 2);('wang', 2);('bs', 2);('ms', 2);('phd', 2);('invariance generated variancefor unsupervised', 1);('reidenticationhao chen', 1);('wang benoit lagadec antitza dantcheva francois bremondabstract', 1);('work focuses', 1);('representation learning person reidentication', 1);('reid recent', 1);('selfsupervisedcontrastive learning methods', 1);('views sameimage', 1);('undesirable distortions identity', 1);('alwaysfavorable idsensitive', 1);('tasks paper', 1);('traditional data augmentation generative adversarialnetwork', 1);('views contrastive learning 3d mesh', 1);('person image generator', 1);('disentangle person image', 1);('deviating', 1);('methodsthat work', 1);('space pose camera style conduct', 1);('specic contrastive losses', 1);('training generative contrastive modules method', 1);('performance mainstream largescale benchmarksindex', 1);('terms', 1);('person reidentication image synthesis representation disentanglement data augmentation contrastive learningf1', 1);('ntroductiongiven', 1);('image target person person reidentication', 1);('aims matchingimages person', 1);('impressive resultshowever', 1);('strong domain gaps betweendifferent domains illumination condition cameraproperty scenario variation', 1);('specic domainis', 1);('hard generalize domains', 1);('straightforwardsolution annotate retrain', 1);('model newdomain cumbersome', 1);('realworld deployments', 1);('automatic adaptive', 1);('increasingattention research community', 1);('scalabilityin realworld deploymentsrecent', 1);('contrastive learning studies', 1);('promising performance', 1);('different views', 1);('versionsof image contrastive methods', 1);('representationsthat invariant', 1);('different conditions context dataaugmentation plays', 1);('crucial role', 1);('realworldcondition variance', 1);('learning methods ableto', 1);('robust representations', 1);('previous', 1);('traditional data augmentation techniques\x0fh', 1);('chen wang dantcheva', 1);('bremond inriaand universit', 1);('e c ote dazur', 1);('route des', 1);('lucioles', 1);('valbonne france email', 1);('fhaochen yaohuiwang antitzadantcheva francoisbremondginriafr\x0fb', 1);('avenue du', 1);('campon', 1);('cannet france email', 1);('benoitlagadecesifranceneteg random', 1);('random augmentation techniques', 1);('undesirable distortion', 1);('crucial identityinformation', 1);('adversarial network gan', 1);('augmentation substitute', 1);('able disentangle representationinto', 1);('moreaccurate', 1);('acertain factor', 1);('domain adaptation task attempts adapta model', 1);('target domain setting intuitive touse', 1);('generate sourcedomain images style target domain modelcan', 1);('images target domainstyle source domain labels', 1);('unsuperviseddomain adaptation performance', 1);('relies onquality scale source domain', 1);('differently', 1);('contrastive representation learningtask source domain', 1);('mandatory endwe', 1);('generative module contrastive moduleinto joint learning frameworkfor generative module', 1);('3d mesh basedgenerator', 1);('conventional', 1);('use2d pose', 1);('body shapeinformation 3d mesh recovery', 1);('estimates bodyshape', 1);('3d pose conserves identityinformation', 1);('3d meshesto', 1);('images newposes', 1);('views contrastivemodulefor contrastive module use', 1);('algorithm generate pseudo labels', 1);('maximizingrepresentation similarity', 1);('different views samearxiv230100725v1 cscv', 1);('jan', 1);('factors person', 1);('idunrelatedcloth', 1);('color pose viewpointhair color texture illumination camera stylebody shape backgroundpseudo identity model attracts', 1);('view toits', 1);('original view', 1);('view fromimages', 1);('different identities contrastive module', 1);('identity encoder extract viewinvariant identityfeatures', 1);('improves generation qualityin', 1);('common practice', 1);('modifying', 1);('allowsfor learning identity', 1);('variations paper explore possibilityof', 1);('augmentation idrelatedfeatures', 1);('inspiredby mixup', 1);('asmoother decision boundary', 1);('insidethe generative module', 1);('disentangled mixup dmixup', 1);('p1andp2respectively', 1);('red yellow clothes inbetween identity', 1);('05p2however dataset person', 1);('different identity', 1);('p3', 1);('whichhinders network learning', 1);('accurate relationshipbetween', 1);('different identities', 1);('traditional imagelevel', 1);('proposeddmixup generates', 1);('accurate inbetween identity images', 1);('reidin dmixup', 1);('idunrelatedfeatures pose viewpoint', 1);('idrelatedfeatures cloth colorto summarize contributions', 1);('generator disentangle representations', 1);('novel data augmentation techniquesare', 1);('rotation contrast mixup contrastmodules', 1);('joint generative contrastive learning framework comprehensivelyinvestigate generative contrastive modules', 1);('performance\x0fextensive experiments validate superiority', 1);('augmentation traditionalaugmentation', 1);('reid ourmethod', 1);('performance mainstream', 1);('market1501 dukemtmcreid msmt17table', 1);('2interpolation results', 1);('random persons', 1);('p1andp2withimagelevel mixup', 1);('mixup dmixup', 1);('visualize results fromfmixup', 1);('amr', 1);('vaegan', 1);('identityfeatures generation alleviates noise', 1);('mixup fmixup dmixupimageimagelabel10p1', 1);('05p2\x0four method', 1);('r elated work21 contrastive', 1);('learningcontrastive learning', 1);('impressive performance', 1);('contrastive methods targetat learning representations invariant differentdistortions', 1);('negative pairs image', 1);('positive pair constitutedby', 1);('views whereas images adataset', 1);('negative samples', 1);('learning methods benet', 1);('data augmentation techniques mimic realworld imagedistortions example', 1);('moco', 1);('random croppingcolor', 1);('grayscale conversionto', 1);('positive view pairs', 1);('mocov2', 1);('color distorsionwhich', 1);('original method', 1);('ofdata augmentation settings contrastive learning methodswere', 1);('general image classication datasets egimagenet', 1);('traditional augmentation techniquesare', 1);('suitable colorsensitive person', 1);('reidespecially', 1);('strong color distorsion22', 1);('augmentationas technique constitute', 1);('positive pairs data augmentation plays', 1);('important role contrastive learning', 1);('recently gan mixup', 1);('new approaches fordata augmentation person', 1);('reid221 ganbased', 1);('person images', 1);('dcgan', 1);('reid following ganbased', 1);('pose', 1);('guidance 2d posesfdgan', 1);('pngan', 1);('target person', 1);('new poses', 1);('poseirrelevant representationsfor singledomain', 1);('similar pose transfer21', 1);('dataset', 1);('style illumination adataset', 1);('uniform illumination condition', 1);('ptgan', 1);('syri', 1);('cyclegan', 1);('minimize domain gap', 1);('different datasets', 1);('person images style target domain', 1);('camerastyle', 1);('general dataset style', 1);('camstyle', 1);('camera styleof', 1);('camera order', 1);('intercamera stylegaps', 1);('similar method', 1);('sbsgan', 1);('background ofa person image mitigate background inuence', 1);('udareid', 1);('general structure', 1);('global locallevel', 1);('disentangleda representation', 1);('image contains', 1);('multiple idunrelatedfactors person image', 1);('pose backgroundand', 1);('personimages color distribution images', 1);('identityrepresentations invariant structure factors proposed3d mesh', 1);('generator shares', 1);('certain similarity withpose transfers', 1);('pose transfersand', 1);('body shape information', 1);('3d meshes', 1);('style crossdomain mannerwhich', 1);('source domain222', 1);('mixupmixup', 1);('effective data augmentationtechnique interpolates', 1);('samples labels intoone', 1);('new inbetween sample encourages smootherdecision boundary', 1);('classes interpolationcan', 1);('twofeature representations', 1);('portions differentimages', 1);('image classication', 1);('novel class discovery', 1);('augmix', 1);('versions imageinto', 1);('image proves technique canenhance robustness', 1);('source domain image atarget domain image', 1);('betweendomain personimage facilitates crossdomain knowledge transferin', 1);('whole images', 1);('person structures', 1);('toreduce', 1);('person structures proposeto interpolate', 1);('gan23 unsupervised', 1);('reiddepending', 1);('necessity largescale', 1);('fall setting', 1);('uda reid severalworks', 1);('semantic attributes facilitatethe domain adaptation', 1);('prominent approach todo', 1);('pseudo label learning', 1);('algorithms eg', 1);('kmeans', 1);('56since performance', 1);('correlatedto scale quality source domain', 1);('pure pseudo label learning', 1);('ourprevious', 1);('andpseudo label learning method compatible withboth', 1);('settings proposea', 1);('enhancesour framework', 1);('new stateoftheart performanceunder', 1);('ethodin', 1);('generativeand contrastive learning gcl', 1);('personreid dene', 1);('problem learning invariance', 1);('variance illustratedin', 1);('modulesa generative module', 1);('contrastive module learns invariancefrom', 1);('identity encoder joint training', 1);('toboth modules facilitate reading', 1);('list ofabbreviations', 1);('c31 generative moduleour', 1);('estra', 1);('xfx1x2x ng', 1);('theprominent algorithm', 1);('hmr', 1);('generate corresponding3d meshes', 1);('structure guidance inthe generative module', 1);('specic 3d meshto reconstruct', 1);('real image person representation canbe', 1);('identity structure', 1);('weconduct', 1);('meshes otherone identity', 1);('dmixup311 meshguided rotation', 1);('2d projection themesh', 1);('original structure sori mimic realworld camera4a', 1);('architecture gcl contrastive moduleb generative module id', 1);('module', 1);('mix c', 1);('generative module id', 1);('identity encoderstructure encoderdecoder', 1);('lossmix mixupd contrastive module rotation contrastmemory', 1);('contrastive module mixup contrast123', 1);('mixpseudo label123123fig', 1);('general architecture', 1);('generative module b c contrastive module e whichare', 1);('eidb mesh', 1);('gcombines', 1);('estrto', 1);('view x0newwith cycle consistency c', 1);('ggenerates', 1);('view x0mixwith', 1);('rotation contrast viewpointinvariance', 1);('eidx', 1);('eidx0newand', 1);('memory fposrepresentations e', 1);('decision boundary learnt x0mixand', 1);('pseudo labelviewpoint', 1);('rotate 3d meshby4590135180225270and 315and randomlytake', 1);('2d projection', 1);('meshes anew structure snew', 1);('eidxfidwhile', 1);('original new structures', 1);('estrsorifstrorisnewfstrnew combining', 1);('identity andstructure', 1);('decoder generates', 1);('imagesg fidfstrorix0orifidfstrnewx0newwhere', 1);('new structures paireddata cycle consistency reconstruction', 1);('indispensable generative module encode', 1);('new structure x0new decodeonce', 1);('original structuresgeidx0newsorix00ori double primes', 1);('images calculate 1image reconstruction loss', 1);('original image x', 1);('ekx\x00x00orik1', 1);('1to enhance disentanglement cycle consistencyreconstruction', 1);('calculate 1feature reconstructionlosslfeatekfid\x00eidx0newk1ekfid\x00eidx00orik12the discriminator', 1);('dattempts', 1);('distinguish betweenreal', 1);('images adversarial lossesladvelogdx log1\x00dx0orielogdx log1\x00dx0newelogdx log1\x00dx00ori3remark', 1);('switch 2d grayimages', 1);('switch meshes random personsor rotate ones mesh introduce', 1);('new structures asgeneration guidance', 1);('pose viewpoint variances', 1);('generation random5table 3examples 3d mesh', 1);('dataseteach mesh', 1);('hinders conservation body shape informationafter', 1);('appropriate way topreserve body shape generate', 1);('meshrotation', 1);('random person images xiandxjin minibatch encode images identityfeatureseidxifidiandeidxjfidj followthe', 1);('distribution ahyperparameter', 1);('coefcient\x15\x15beta \x15\x03max\x151\x00\x15fidmix\x15\x03\x01fidi 1\x00\x15\x03\x01fidj4where\x15\x03renders', 1);('similar xi', 1);('toconserve', 1);('corresponding body shape information usethe', 1);('original structure xi', 1);('xjas generation guidance', 1);('original structure featuresgfidmixsoriix0mix discriminator', 1);('dattemptsto', 1);('images theadversarial lossladvmixelogdx log1\x00dx0mix 5more discussion', 1);('regularization losses', 1);('a313 overall', 1);('generative lossthe overall', 1);('coefcient \x15recon', 1);('lgan\x15recon limglfeat ladvladvmix', 1);('6mesh switch', 1);('rotation 2d', 1);('gray image switchfig', 1);('different', 1);('structural variance 2d', 1);('gray imageswitch', 1);('rotation generationtable 4performance comparison', 1);('tworandom meshes generationmethoddukemarket', 1);('marketdukemap rank1', 1);('rank12d', 1);('gray image switch', 1);('762mesh switch', 1);('769mesh rotation', 1);('contrastive modulethe', 1);('generative module generates augmentedviews person image form', 1);('positive view pairsfor contrastive module', 1);('robust representations invariant distortions', 1);('positiveimages dataset', 1);('different posescamera styles backgrounds', 1);('similaritybetween image', 1);('tosuboptimal performance', 1);('previous methods', 1);('negative samples contrastive learningin order mine positives', 1);('large number ofnegatives generate pseudo labels memory bank 30that stores representations', 1);('mcorresponding', 1);('representation ftin', 1);('current epochthe', 1);('corresponding memory bank representation', 1);('miisupdated', 1);('momentum hyperparameter', 1);('mit', 1);('\x01mit\x001 1\x00 \x01ft', 1);('memorybank representations tandt\x001epochs memory bank stores', 1);('representations whichstabilize pseudo label generation enhancethe pseudo label quality compute kreciprocal rerankedjaccard distance', 1);('memory bank representationswhich', 1);('63to generate pseudo labels', 1);('yfy1y2y ng', 1);('beginning ofeach epoch design', 1);('rotation contrast mixupcontrast', 1);('original image xand', 1);('image x0new', 1);('eidxfandeidx0newf0new', 1);('representation fwith pseudolabelyi', 1);('positive representation fpos61 2fig', 1);('linear', 1);('market1501 dukemtmcreidof', 1);('pseudo label yiandknegative representationsof pseudo labels', 1);('different yifrom memory bankthree', 1);('ie ffposff0newandfposf0new', 1);('thef0new', 1);('representations memory bank', 1);('pairs dene', 1);('viewinvariant losses toattract', 1);('f0new\x01ki exp f\x01fpos 8l0vielog', 1);('f0new\x01ki exp f0new\x01f 9l00vielog', 1);('f0new\x01ki exp f0new\x01fpos 10where\x01denotes cosine similarity twofeature vectors', 1);('temperature hyperparameter tosharpen cosine similarity kidenotes', 1);('negative representations', 1);('memory bank', 1);('presented', 1);('enable contrastive module maximize thesimilarity', 1);('original view f', 1);('view f0newand', 1);('positive memory view fpos time thesimilarity', 1);('view f0new andknegativememory', 1);('encourages generative module rene', 1);('view f0new shouldbe', 1);('different large number', 1);('negative samples322', 1);('image x0mix', 1);('eidx0mixf0mix', 1);('certain instances ina cluster', 1);('close decision boundary twoprototype061042041062fig', 1);('targets learning', 1);('decision boundarybetween', 1);('p1andp2by', 1);('inbetween samples withinbetween prototypesclusters whereas others', 1);('prototype clusterpa1naxmi2yami 11wherenais number instances', 1);('clusteragiven random image representation f use softmax crossentropy loss', 1);('lproto', 1);('makefconverge thecluster prototype encourages compactness aclusterlproto', 1);('elog', 1);('pjyj\x001i1exp', 1);('f\x01piexp f\x01p 12wherepis', 1);('corresponding prototype fandpidenotesother cluster prototypes jyjis number clusters', 1);('giventhat', 1);('certain clusters', 1);('instances areclose decision boundaries clusters compactclusters', 1);('pseudo labels dene', 1);('clusters iandjpmix\x15\x03\x01pi 1\x00\x15\x03\x01pj 13where\x15\x03is', 1);('representation f0mix use', 1);('softmax crossentropy loss maximize similarity', 1);('prototype pmix minimize similarity withjyj\x00 2negative prototypes', 1);('pjyj\x002i1exp', 1);('f0mix\x01piexp f0mix\x01pmix 14as', 1);('cosine similarity', 1);('donot compute', 1);('similarity average operationfor', 1);('prototype vectors performs normalization323', 1);('overall', 1);('contrastive lossthe overall contrastive loss', 1);('14lcontrast \x15vilvil0vil00vi\x15mixlprotolmix15733', 1);('joint trainingour', 1);('framework incorporates generative moduleand contrastive module generative module disentangles person image representation identity structure', 1);('identityfeatures person', 1);('contrastive module learnsinvariance', 1);('images replacethe', 1);('traditional data augmentation techniques modules', 1);('separate training', 1);('suboptimalperformance address issue wecouple', 1);('identity encoder ajoint training framework setting joint training bothmodules work', 1);('discriminality identity representations', 1);('insidegcl', 1);('augmentations contrastive moduleon hand contrastive module maximizes thesimilarity', 1);('positive views', 1);('renes identity representations fora', 1);('generation quality modules', 1);('promoteeach others performance joint training', 1);('framework aforward propagation', 1);('abackward', 1);('lganlcontrast', 1);('e xperiment41 datasets evaluation protocolswe', 1);('mainstream person', 1);('front supermarket', 1);('tsinghua universityfrom', 1);('images 751identities training', 1);('duke', 1);('university contains 16522images', 1);('persons training', 1);('query images and17661 gallery images', 1);('isa largescale', 1);('images 3060identities', 1);('indoorand outdoor scenes', 1);('largescale videobasedperson', 1);('dataset dataset contains', 1);('dukemtmc', 1);('datasetdukemtmcvideoreid contains', 1);('training tracklets of702 identities', 1);('identitiesas method', 1);('contrastivemodule report results', 1);('personreid generation quality evaluations unsupervisedperson', 1);('domain adaptation', 1);('cumulative', 1);('characteristics cmc rank1 rank5 rank10', 1);('accuracies wellas', 1);('average precision', 1);('generation quality evaluation conduct qualitativecomparison method stateoftheart methods', 1);('images42 implementation detailswe introduce implementation details', 1);('networkdesign general training congurations', 1);('threestep optimizationnetwork design network design', 1);('theidentity encoder', 1);('estr', 1);('dhas', 1);('maps channel \x02height\x02width 1eidisan', 1);('imagenet', 1);('resnet50', 1);('layer replacedby batch normalization layer', 1);('layer outputs identity representations fin512\x021\x021 contrastive module parallel', 1);('outputs identity', 1);('fidin2048\x024\x021 generative module 2estris composedof', 1);('residual layers outputstructure', 1);('fstrin 128\x0264\x02323gcontains fourresidual', 1);('convolutional layers', 1);('residual layercontains', 1);('adaptive instance normalization layers 18that transform fidinto scale bias parameters 4dis amultiscale', 1);('patchgan', 1);('\x0232 128\x0264and 256\x02128general training congurations framework', 1);('pytorch', 1);('nvidiav100 gpu', 1);('large weight \x15recon', 1);('reconstruction ineq', 1);('batch size', 1);('eidand adam', 1);('optimizer train', 1);('estrgandd learning', 1);('adam', 1);('01after 10epochs', 1);('maximalneighborhood distance', 1);('05and minimal samplenumber', 1);('number negatives', 1);('kis', 1);('eidoutputs', 1);('representations fof dimension 512for', 1);('gpu', 1);('tracklet onmars', 1);('dukemtmcvideoreidfor', 1);('frames trackletare', 1);('tracklet representation forsimilarity', 1);('settingsthreestage optimization', 1);('noise fromimperfect', 1);('early epochs train thefour modules', 1);('eidestrganddin', 1);('threestage optimization stage 1eidwarmup use', 1);('stage 2estrganddwarmup', 1);('estrg', 1);('withthe overall', 1);('epochs stage', 1);('memory bank pseudolabels', 1);('whole framework overallloss', 1);('mixup coefcient ondukemarket', 1);('memory momentum forcontrastive temperature', 1);('unsupervised reid evaluationto', 1);('validate effectiveness component conduct parameter analysis ablation experiments ajvtc', 1);('version ofjvtc camera temporal distribution postprocessingthe performance boost', 1);('ablation experiments', 1);('similar variance', 1);('jvtc jvtc', 1);('baselines compareour method stateoftheart', 1);('reidwith', 1);('different baselines', 1);('generalizability ofour method896', 1);('coefcients \x15recon forreconstruction weight \x15vifor rotation contrast weight \x15mix formixup contrast weight', 1);('tasktable 5performance', 1);('neighborhood distancethreshold', 1);('approximate number pseudoidentitiesthresholddukemarket', 1);('marketduken', 1);('rank1 n', 1);('rank104\x18642', 1);('parameter', 1);('coefcient memorymomentum', 1);('viewinvariant contrastive loss temperature play', 1);('important roles', 1);('gclframework', 1);('values analyze sensitivityof hyperparameter', 1);('possibility \x15gets', 1);('performance bothdukemarket', 1);('tasks reference', 1);('tasks optimal performanceis', 1);('frameworkthe value', 1);('speedthe value amplies cosine similarity contrastive', 1);('introduces noise contrastive learningwe report performance variation reference', 1);('dukemarket', 1);('nd theperformance', 1);('sensitive similarity temperature', 1);('004the number', 1);('possible pseudoidentities', 1);('nis', 1);('hyperparameters maximal neighborhood distance threshold minimal cluster samplenumber distance threshold', 1);('inthe neighborhood', 1);('distance thresholdenlarges radius cluster making samples', 1);('nbecomes', 1);('asshown', 1);('threshold value', 1);('affectsreid performanceas framework', 1);('optimize generative andcontrastive modules', 1);('weight coefcients balancedifferent loss functions', 1);('coefcients \x15recon \x15viand\x15mix', 1);('corresponding results', 1);('different values', 1);('range slightlyinuence nal results', 1);('results set\x15recon 5\x15vi', 1);('ablation', 1);('studycontrastive learning methods', 1);('traditional contrastive learning methods', 1);('traditional data augmentation techniques', 1);('augmentation techniques validate effectiveness', 1);('augmentation techniques contrastive losses weconduct ablation experiments', 1);('anddukemtmcreid datasetsdata augmentation', 1);('augmentation techniques canbe', 1);('augmentation creates intraimage visual distortions contrast', 1);('augmentation creates interimage visual distortions affects imageidentities', 1);('traditional generative data augmentation', 1);('settingand domain adaptation setting', 1);('traditionaldata augmentation use', 1);('multiple popular person', 1);('reid9table', 1);('6ablation study', 1);('traditional wo', 1);('generative w', 1);('data augmentation contrastivemodule', 1);('data augmentation techniques person', 1);('image level', 1);('fmixup', 1);('idrelated market dukemulti rotation mixup fmixup dmixup', 1);('idrelated dukemarket marketdukemulti rotation mixup fmixup dmixup', 1);('891table 7ablation study', 1);('viewinvariant losses', 1);('andtwo prototype losses', 1);('mixup contrastlvil0vil00vilprotolmixdukemarket marketdukemap r1', 1);('r1x', 1);('x x', 1);('x x x', 1);('x x x x', 1);('normalized', 1);('joint trainingepochs', 1);('market1501 trad', 1);('traditional data augmentationtechniques', 1);('rot', 1);('full refersto', 1);('dmixupdata', 1);('augmentation techniques', 1);('evenwith', 1);('traditional data augmentation contrastivemodule', 1);('outperforms baseline wereplace', 1);('traditional data augmentation generative dataaugmentation', 1);('data augmentation techniques', 1);('achievesbetter performance imagelevel', 1);('augmentationeffects pseudo labels', 1);('robust', 1);('identity representations', 1);('intraclass compactness interclass separability', 1);('pseudo label qualitywe', 1);('pseudo label quality', 1);('ourpseudo labels ground truth labels', 1);('trad', 1);('thattraditional data augmentation', 1);('undesirabledistortions identity', 1);('idsensitive tasks', 1);('deviating ganbased', 1);('augmentation introduces noise beginninghowever', 1);('nal training epochs', 1);('inaddition', 1);('full conducts', 1);('ganbasedidunrelated', 1);('augmentation achievesbetter pseudo label quality', 1);('rotcontrastive', 1);('maximal invariance', 1);('image memory', 1);('image formedthree', 1);('10our objective', 1);('identity representations areinvariant instancelevel pose viewpoint backgroundvariance', 1);('identity prototypes mixedprototypes', 1);('classleveldecision boundary', 1);('conrmthe contribution contrastive losses graduallyadd framework report correspondingresults', 1);('proposedcontrastive losses', 1);('contribute learning robustrepresentations', 1);('reid433 comparison', 1);('unsuperviseddomain adaptation evaluation protocols', 1);('different baselines includingmmcl', 1);('setting report', 1);('market1501 dukemtmcreid', 1);('andmsmt17 dataset', 1);('results ofstateoftheart methods', 1);('thethree datasets', 1);('performance from10table 8comparison', 1);('method onseveral baselines', 1);('referencemarket1501 dukemtmcreid msmt17map r1 r5 r10', 1);('r1 r5 r10buc', 1);('aaai19', 1);('gclmmcl', 1);('645gclmmcl paper', 1);('614gcljvtc paper', 1);('671table 9comparison', 1);('referencedukemarket marketduke marketmsmt17 dukemsmt17map r1 r5 r10', 1);('r1 r5 r10ecn', 1);('cvpr19', 1);('ssg', 1);('tpami20', 1);('iclr20', 1);('gclact', 1);('742gclact paper', 1);('702gcljvtc paper', 1);('mmcl jvtc jvtc', 1);('dmixup mixup contrast', 1);('gclconsistently', 1);('surpasses performance previouswork', 1);('different baselines strongbaseline', 1);('stateoftheart performance', 1);('domain adaptation setting wereport', 1);('mainstream benchmarks', 1);('dukemarket marketduke marketmsmt17and dukemsmt17', 1);('performance stateoftheart methods', 1);('ecn', 1);('pda', 1);('crgan41 ssg', 1);('jvtc60 ecn', 1);('mmt', 1);('amongthese', 1);('share certainsimilarity', 1);('pda dgnet', 1);('usedeither 2d skeleton random', 1);('body shape informationfurther', 1);('generate inbetween identity imagescail', 1);('introduce noise identityfeatures', 1);('structures addition crossdomain', 1);('mixupinterpolates', 1);('domains proposeddmixup interpolates intradomain images moreexible', 1);('reidvideobased', 1);('reidmethods mars dukemtmcvideoreid', 1);('video trackletper identity initialize models', 1);('utilizecamera labels tracklet', 1);('associate tracklets ofa person', 1);('different cameras', 1);('reidmethods', 1);('asour baseline', 1);('methodsgcl viewpoint augmentation', 1);('viewpoint andinbetween identity augmentation', 1);('methods11table 10comparison stateoftheart methods', 1);('reid datasets', 1);('mars dukemtmcvideoreid labels', 1);('columnindicates labels', 1);('denotes oneexample annotation', 1);('identity camera refers camera annotationbaseline', 1);('labelsmars dukemtmcvideoreidmap r1 r5 r10', 1);('r1 r5 r10race', 1);('baseline buc', 1);('generation quality evaluation441 ablation', 1);('studywe conduct qualitative ablation study', 1);('contrastive modulecan', 1);('generative quality person image generationunconditional', 1);('data distribution', 1);('reconstruction adversarial training image whichthen generate', 1);('new images', 1);('distributionhowever unconditional', 1);('asingle image neglect', 1);('person class', 1);('conditional gans', 1);('identity labels', 1);('viewinvariant classlevel', 1);('person image generation', 1);('positive viewswe', 1);('tovalidate effectiveness', 1);('contrastive module person image generation', 1);('target person arobust identity representation', 1);('majority observations differentviewpoints poses case', 1);('trainedwithoutlcontrast generative module tends', 1);('original image', 1);('black backpackfor rst example', 1);('blue jacket', 1);('images sameperson', 1);('yellow tshirt rst example', 1);('red backpackfor', 1);('example contrastive module ensures theconsistency identity', 1);('generation differentposes viewpoints442', 1);('stateoftheart methodswe conduct qualitative comparison', 1);('publishedsource code generate', 1);('real image ofthe', 1);('fdganisgan dgnet', 1);('methods relyon', 1);('robust identitylevelfeatures observe images', 1);('andisgan suffer evident visual blur', 1);('identity information generation', 1);('wo w', 1);('id', 1);('qualitative', 1);('ablation study effectiveness contrastiveloss', 1);('generation quality', 1);('lcontrast', 1);('yellow tshirt rst exampleand', 1);('red backpack', 1);('example identity representationsfor generation', 1);('different poses viewpointstable 11examples 3d mesh', 1);('gclours isgan dgnet real dgnetfig', 1);('examples fdgan isgan dgnet dgnet gcl', 1);('gure note', 1);('dgnet gcl', 1);('methodstable 12examples 3d mesh', 1);('generate sharperimages', 1);('prone result incoherent body shapeand', 1);('comparison generative qualitybetween', 1);('section b', 1);('udamethod dgnet', 1);('uses crossdomain', 1);('imagesas guidance', 1);('shares problems generation', 1);('dgnet different dgnet', 1);('method directlyaugments data diversity target domain', 1);('mesh whichhelps', 1);('body shape information addextra', 1);('gclhave', 1);('quality similarity', 1);('real images othermethods validate generative quality', 1);('dukemtmcreid msmt17', 1);('consistency', 1);('spaceand variance', 1);('space validate puritydisentanglement quality identity representations ourframework', 1);('tracklet examplesbefore viewpoint rotation videobasedperson', 1);('reid fig', 1);('reid443', 1);('failure case analysiswe show failure cases rotation generativemodel', 1);('exists inconsistentfrontside backside patterns', 1);('large rotationrotaterotatemars trackletdukemtmc', 1);('videoreid', 1);('examples', 1);('tracklet frames viewpoint rotation', 1);('tracklets', 1);('datasetsfor example model', 1);('visual patterns onlyin', 1);('side backpack rst row', 1);('row aswholebody appearance', 1);('possible solution use 3d humanobject arrangement meshgenerator', 1);('generative model distinguishhumans objects5 c', 1);('onclusionin', 1);('joint generative andcontrastive learning', 1);('framework unsupervisedperson', 1);('generativemodule data augmentation', 1);('learning invariance', 1);('3d meshes generation guidance', 1);('identity representations contrastive130', 1);('failure cases', 1);('row backpack', 1);('row carryingobject', 1);('sidemodule design', 1);('contrast', 1);('data augmentation techniques learnrobust identity representations', 1);('extensive', 1);('validate superiority', 1);('traditional augmentation techniques contrastive representation learning generative module benets', 1);('robust identity representations', 1);('identity information forbetter generation quality', 1);('outperforms stateoftheartmethods', 1);('unsuperviseddomain adaptation settings', 1);('contrastive discriminator', 1);('ganwhich', 1);('person image generationacknowledgmentsthis work', 1);('french governmentthrough 3ia c ote dazur', 1);('investments futureproject', 1);('national research agency', 1);('anrwith', 1);('reference number', 1);('anr19p3ia0002', 1);('opal', 1);('resources supportreferences1', 1);('ye j shen g lin xiang', 1);('shao', 1);('h hoi deeplearning', 1);('person reidentication survey outlook', 1);('ieeetpami', 1);('karanam gou z wu ratesborras camps', 1);('radke', 1);('systematic evaluation benchmark person reidentication', 1);('features', 1);('metrics datasets', 1);('sun', 1);('zheng yang q tian wang', 1);('partmodels person retrieval', 1);('strongconvolutional baseline', 1);('h chen', 1);('bremond learning', 1);('generalizable representations spatialchannel partition forperson reidentication', 1);('wacv', 1);('yang yz', 1);('xiang hospedales', 1);('generalizable person reidentication domaininvariant mappingnetwork', 1);('cvpr june', 1);('x jin', 1);('lan', 1);('zeng z chen', 1);('zhang style', 1);('normalization restitution', 1);('generalizable person reidentication incvpr', 1);('june', 1);('zheng z luo li yang invariance', 1);('mattersexemplar memory domain adaptive person reidenticationincvpr', 1);('ge chen h li', 1);('label renery', 1);('domain adaptation person reidentication', 1);('h chen wang', 1);('lagadec dantcheva', 1);('bremondjoint', 1);('generative contrastive learning', 1);('chen kornblith norouzi g hinton', 1);('simpleframework contrastive learning visual representations inicml', 1);('k h fan wu xie r girshick momentum', 1);('visual representation learning', 1);('zheng g kang li yang', 1);('random erasingdata augmentation', 1);('goodfellow j pougetabadie mirza', 1);('xu wardefarleys ozair courville bengio generative', 1);('wei zhang', 1);('gao q tian', 1);('gan tobridge domain gap person reidentication', 1);('bak p carr jf lalonde domain', 1);('adaptation throughsynthesis', 1);('zheng li yang generalizing', 1);('personretrieval model hetero', 1);('zou x yang z yu', 1);('v k v kumar j kautzjoint', 1);('adaptation crossdomain person reidentication', 1);('x huang belongie arbitrary', 1);('realtimewith adaptive instance normalization', 1);('p isola jy zhu zhou efros imagetoimagetranslation', 1);('conditional adversarial networks', 1);('ge z li h zhao g yin yi x wang h li fdgan poseguided', 1);('gan robust person reidentication', 1);('yj li cs lin yb lin yc', 1);('wang crossdatasetperson', 1);('pose disentanglementand adaptation', 1);('z cao simon', 1);('wei sheikh realtime', 1);('multiperson2d pose estimation', 1);('part afnity elds', 1);('kanazawa j black', 1);('jacobs j malik endtoendrecovery', 1);('human shape pose', 1);('zheng z zheng li yang', 1);('camera styleadaptation person reidentication', 1);('z zheng x yang z yu', 1);('zheng yang j kautzjoint', 1);('discriminative generative learning person reidentication', 1);('h zhang cisse n dauphin lopezpaz', 1);('mixupbeyond empirical risk minimization', 1);('v verma lamb', 1);('beckham naja mitliagkas lopezpaz bengio manifold', 1);('icml', 1);('beckham honari v verma lamb', 1);('ghadiri r dhjelm bengio', 1);('pal', 1);('adversarial mixup resynthesisneurips', 1);('r hadsell chopra lecun dimensionality', 1);('reductionby learning invariant', 1);('z wu xiong x yu lin unsupervised', 1);('nonparametric instance discrimination', 1);('caron misra j mairal p goyal p bojanowski joulinunsupervised', 1);('learning visual', 1);('jb grill', 1);('strub', 1);('altch', 1);('e c', 1);('tallec p h richemonde buchatskaya', 1);('doersch', 1);('pires z guo g azaret', 1);('bootstrap', 1);('new approach', 1);('x chen k exploring', 1);('simple siamese', 1);('x chen h fan r girshick k improved', 1);('baselines withmomentum contrastive learning arxiv preprint arxiv200304297', 1);('russakovsky j deng h su j krause satheesh maz huang karpathy khosla bernstein berg', 1);('feifei imagenet', 1);('large scale visual recognition challengeijcv', 1);('z zheng', 1);('zheng yang unlabeled', 1);('samples generatedby gan', 1);('person reidentication baseline vitro iniccv', 1);('radford', 1);('metz chintala unsupervised', 1);('convolutional generative adversarialnetworks', 1);('x qian fu xiang', 1);('wang j qiu wu yg jiangand x xue posenormalized', 1);('image generation person reidentication', 1);('jy zhu', 1);('p isola efros unpaired', 1);('imagetoimage translation', 1);('cycleconsistent adversarial networks incvpr', 1);('huang q wu j xu zhong sbsgan suppressionof', 1);('interdomain background', 1);('person reidentication iniccv', 1);('chen x zhu gong instanceguided', 1);('context renderingfor crossdomain person reidentication', 1);('eom', 1);('ham learning', 1);('representation forrobust person reidentication', 1);('tokozume ushiku harada betweenclass', 1);('learningfor image classication', 1);('yun han j oh chun j choe yoo cutmixregularization', 1);('strategy train', 1);('strong classiers localizablefeatures', 1);('berthelot n carlini goodfellow n papernot oliverand', 1);('raffel mixmatch', 1);('holistic approach', 1);('berthelot n carlini e cubuk kurakin k sohnh zhang', 1);('raffel remixmatch semisupervised', 1);('learning distribution', 1);('xu j zhang', 1);('ni li', 1);('wang q tian', 1);('zhangadversarial', 1);('domain adaptation domain mixup', 1);('zhu z luo li yang n sebe openmixreviving', 1);('novel visual categories', 1);('hendrycks n mu e cubuk', 1);('zoph j gilmer', 1);('lakshminarayanan augmix', 1);('simple data processing method toimprove robustness uncertainty', 1);('luo', 1);('c song', 1);('z zhang generalizing', 1);('person reidentication cameraaware invariance learning crossdomain mixup', 1);('j wang x zhu gong', 1);('li', 1);('transferable joint attributeidentity', 1);('person reidenticationcvpr', 1);('lin h li ct li', 1);('kot multitask', 1);('midlevelfeature alignment network', 1);('crossdataset personreidentication', 1);('hx yu', 1);('zheng wu x guo gong j lai unsupervised', 1);('soft multilabel learning incvpr', 1);('fu wei g wang zhou h shi huangselfsimilarity', 1);('cross domainadaptation approach person reidentication', 1);('yang k li z zhong z luo x sun h cheng x guof huang r ji li asymmetric', 1);('crossdomain person reidentication', 1);('zheng z luo li yang learning', 1);('adaptinvariance memory person reidentication', 1);('lin x dong', 1);('zheng yan yang', 1);('person reidentication inaaai', 1);('lin', 1);('xie wu', 1);('yan q tian unsupervised', 1);('similarity learning', 1);('wang zhang unsupervised', 1);('person reidentication viamultilabel classication', 1);('j li zhang joint', 1);('visual temporal consistency', 1);('domain adaptive person reidentication', 1);('g wu x zhu gong tracklet', 1);('zheng cao li reranking', 1);('person reidentication kreciprocal', 1);('ester hp kriegel j sander x xu', 1);('large spatial databases withnoise', 1);('kdd', 1);('zheng', 1);('shen', 1);('tian wang j wang q tian scalableperson', 1);('reidentication benchmark', 1);('e ristani', 1);('solera r zou r cucchiara', 1);('tomasi performance', 1);('measures data', 1);('eccvw', 1);('zheng z bie sun j wang', 1);('su wang', 1);('tian mars', 1);('video benchmark largescale person reidentication', 1);('wu lin x dong yan', 1);('ouyang yang exploit', 1);('oneshot', 1);('person reidentication stepwise learning', 1);('k x zhang ren j sun deep', 1);('residual learning forimage recognition', 1);('paszke gross', 1);('massa lerer j bradbury g chanant killeen z lin n gimelshein', 1);('antiga desmaisona k', 1);('e yang z devito raison tejani chilamkurthyb steiner', 1);('fang j bai chintala pytorch', 1);('imperativestyle highperformance', 1);('learning library', 1);('yang z zhong z luo cai li nicu joint', 1);('noisetolerant learning meta camera', 1);('strehl j ghosh cluster', 1);('ensembles knowledge reuseframework', 1);('multiple partitions', 1);('jmlr', 1);('ye x lan p', 1);('yuen robust', 1);('chen x zhu gong deep', 1);('association learning', 1);('li x zhu gong unsupervised', 1);('learning tracklet association', 1);('unsupervised', 1);('tracklet person reidentication', 1);('ieee', 1);('transactions pattern analysis machine intelligence', 1);('xiao li', 1);('lin x wang joint', 1);('detection andidentication', 1);('learning person search', 1);('j zhang pepose h joo ramanan j malik', 1);('kanazawa perceiving', 1);('3d humanobject spatial arrangementsfrom single image', 1);('chen', 1);('wuhanuniversity', 1);('degree fromcentralesup elec', 1);('paris saclay', 1);('phdat inria sophia antipolis universit', 1);('research interests', 1);('homepage', 1);('degree fromxidian university', 1);('ensiie universit', 1);('paris saclayin', 1);('inria sophia antipolis stars teamand universit', 1);('cote', 1);('current researchfocuses image video synthesis activityrecognition representation learningbenoit', 1);('engineer', 1);('video analysis solutions basedon abnormal human behavior', 1);('previously', 1);('public research', 1);('ifremer', 1);('image processing algorithms', 1);('dantcheva', 1);('scientistcrcn stars', 1);('inria sophiaantipolis france previously mariecurie', 1);('inria postdoctoral fellowat michigan', 1);('state university', 1);('westvirginia', 1);('usa', 1);('phddegree', 1);('paristecheurecom', 1);('image processing biometrics', 1);('research computer vision', 1);('suitablerepresentations human', 1);('interpretation generationfrancois', 1);('bremond', 1);('inria', 1);('video understanding', 1);('research work post doctorate university', 1);('californiausc', 1);('interpretation videos', 1);('airborne vehicle uav', 1);('hdr', 1);('habilitation dirigerdes recherches nice', 1);('sceneunderstanding', 1);('stars', 1);('team onthe 1st', 1);('january', 1);('inria sophia antipolis france hehas', 1);('research work video understanding', 1);('antipolis', 1);('author coauthor', 1);('scientic papers', 1);('international journals conferences', 1);('mva', 1);('reviewer forseveral', 1);('international journals', 1);('cviu ijprai ijhcs pami aij eurasipjasp', 1);('cvpr iccv avss vs icvs', 1);('ec infso', 1);('anr expertfor', 1);