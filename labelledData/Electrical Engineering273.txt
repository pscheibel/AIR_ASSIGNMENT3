('slu', 28);('asr', 13);('ssl', 7);('fsc', 7);('skits2i', 6);('slurp', 5);('hubert', 5);('figure', 3);('dataset rst', 2);('indianaccented slu', 2);('pipeline methods', 2);('s2idataset', 2);('telephone calls', 2);('whisperasr xlmr', 2);('slu wav2vec2slu', 2);('slu hubertslu', 2);('slu whisperbaseenslu', 2);('slu whispersmallenslu', 2);('based', 2);('fsc slurp', 2);('speech', 2);('accented speech intent', 1);('rajaa swaraj dalmia kumarmanas nethilskitaibengaluru indiashangethrajaaskitaiabstractconventional', 1);('conversation assistants extract text transcriptsfrom speech signal', 1);('automatic speech recognitionasr', 1);('intent transcriptions', 1);('usingendtoend', 1);('language understanding', 1);('intentsof speaker', 1);('speech signalwithout', 1);('intermediate text transcripts result themodel optimize', 1);('intent classication', 1);('system alsohelps', 1);('latency intent prediction model', 1);('texttointenttasks availability', 1);('speechtointent datasets', 1);('available indian accentin paper release', 1);('domain conversational tonality experiment multiplebaselines', 1);('speech encoders representations nd', 1);('speechtointent classication', 1);('thedataset', 1);('baseline code', 1);('available httpsgithubcomskitaispeechtointentdatasetindex', 1);('terms', 1);('language understanding speech intentvoice assistant', 1);('introductionearlier', 1);('intent classication pipeline systems transcribe thespeech signal', 1);('model train', 1);('natual language understandingnlu', 1);('intents usingthe text transcripts pipeline methods', 1);('prone error propagation', 1);('transcript errors texttointentnlu models', 1);('semantic meaning thespeech ignore paralinguistic information speechwhich', 1);('speakers intention', 1);('andnlu models', 1);('different metrics', 1);('approach intent classication taskthis pipeline method', 1);('increases computational requirement latency intent classication building pipelinemethod', 1);('complex involves training', 1);('twodifferent models collection', 1);('corpus fortrainingendtoend', 1);('methods attempt', 1);('speech signal single model', 1);('transcripts contrast', 1);('advantage acoustic', 1);('speech signals', 1);('target metric intent classication', 1);('advantageof lesser computational requirements', 1);('latency duringdeployment lack', 1);('large audio dataset', 1);('research need anslu dataset', 1);('languages accents', 1);('multiple domainsto', 1);('models robust paper release theskits2i dataset rst', 1);('indianaccented', 1);('speech corpus intent classication tasks', 1);('telephony conversational tone', 1);('experimental comparison', 1);('speech encoders', 1);('methods speech featureswith', 1);('prosody information', 1);('performance ofthe', 1);('intent classication model', 1);('diagnosethe errors dataset datamaps 1figure', 1);('example', 1);('utterances intentclass2', 1);('related workair travel information', 1);('atis', 1);('audio datasetwith semantic labels', 1);('air travel planning', 1);('snips slu dataset english', 1);('french languages 29k 12k samplesin voice assistant domain', 1);('previous studies usedtransfer learning', 1);('acoustic model', 1);('intent classication slot prediction', 1);('datasets forendtoend', 1);('stop', 1);('7however datasets', 1);('personal assistant domain', 1);('indianaccented english', 1);('domain paper introduce', 1);('speech corpus endtoend', 1);('multiple speakers', 1);('overthe telephony conversational tonalityarxiv221213015v1 cscl', 1);('dec', 1);('2022split utterance hourstrain', 1);('data', 1);('s2idataset3 skits2i dataset31 data collectionthe skits2i', 1);('voice assistants inthe', 1);('domain dataset', 1);('multiple', 1);('intent class', 1);('possible variations human speech audio utterances recordedby speakers', 1);('templates variations dataset', 1);('descriptions foreach intent', 1);('shows example', 1);('multiple templatesfor intent variations speakers utterances average number templates', 1);('background', 1);('noise prevalent inrealworld scenarios speakers', 1);('environment audio signals', 1);('of8 khz', 1);('dataset statisticsa', 1);('males speakers native', 1);('indianswith', 1);('different native languages', 1);('different parts country', 1);('samples dataset dividedinto train test', 1);('model test', 1);('samples forevaluation', 1);('datasetthe train test', 1);('intent data speakersthe speakers', 1);('train test', 1);('intent dataset', 1);('anonymizedspeaker information gender native language languagesspoken speakers places', 1);('indianstates', 1);('compares statistics', 1);('sludatasetss2i slurp fsc snipsdomain banking', 1);('assistant assistant', 1);('assistantspeaker', 1);('files', 1);('118k 72k 30k 58kdurationhrs', 1);('55avg lengths', 1);('statistics', 1);('audio corpus', 1);('experimentswe', 1);('baselines cascadedpipelineasrnlu endtoend', 1);('pipeline extract', 1);('model accuracy f1pipeline wav2vec2asr xlmr', 1);('baseline models', 1);('model', 1);('wav2vec2asr xlmr', 1);('315m 278mpipeline', 1);('244m 278me2e', 1);('number', 1);('parameters baseline modelvoice dataset', 1);('small model', 1);('xlmr', 1);('transcripts topredict intentsfor endtoend', 1);('speech encoders intents predictedwith linear classier average', 1);('learning tasks', 1);('sizes whisper encoder base andsmall', 1);('models encode audio encoders ofthe', 1);('models models', 1);('learningrate 1e\x005with', 1);('adam optimizer5', 1);('pipeline endtoend', 1);('baseline results', 1);('xlmr nlu', 1);('asrtranscripts', 1);('different test accuracy', 1);('f1', 1);('scores error', 1);('asrpredicted', 1);('nlu', 1);('model models', 1);('togetherfor intent classicationthe', 1);('hubertbased', 1);('betterthan wav2vec2 model whisper models', 1);('wav2vec models pipeline endtoend', 1);('baselines whisper model outperforms otherbaselines whisper model robust performsbetter zeroshot tasks models', 1);('comparesthe number parameters', 1);('different baseline models', 1);('thepipeline', 1);('number parameters thepipeline', 1);('different models endtoendslu models', 1);('lesser computation', 1);('whisperbased slu', 1);('number ofparameters model input', 1);('melspectrograms', 1);('lesser computation wav2vec2', 1);('models input', 1);('raw waveformmost endtoend', 1);('intent classication use distillation methods13', 1);('text encoders', 1);('asrrepresentations', 1);('force model use linguisticsemantic information speech signal ignore otherimportant information prosody', 1);('stressing', 1);('differentsyllables word lead', 1);('different meanings overall intonation contour contributes speakers intention soprosodic', 1);('intent classicationtaskwe', 1);('versions wav2vec2', 1);('models intent classication tasks', 1);('models slightlyimprove test metrics', 1);('models 14also shows', 1);('ssltrained', 1);('models cangeneralize', 1);('learning prosody semantic', 1);('speech signal', 1);('thesemodels lead loss prosodic information learnedrepresentations', 1);('results observationswe hypothesize performance', 1);('model representation', 1);('model contains prosodic informationmodel', 1);('pretraining accuracy f1wav2vec2 ssl', 1);('ssl asr', 1);('representations forintent classicationwe', 1);('model thefsc', 1);('datasets analyze dataset benchmarkfrom', 1);('accuracy scoreof', 1);('slurp skits2i', 1);('intent classicationbenchmarks', 1);('simple baselinesdataset', 1);('accuracy f1s2i', 1);('dataset analysiswe', 1);('dataset cartography', 1);('analysis thes2idataset assess quality diagnose datasetdataset', 1);('cartography', 1);('leverage training dynamics', 1);('distinct regions easytolearn', 1);('ambiguous andhardtolearn', 1);('ambiguous samples dataset contributeto outofdistribution generalization easytolearn samples', 1);('essential role optimization hardtolearnsamples', 1);('showsthe datamap', 1);('training dataset', 1);('whispersmallen', 1);('datamaps foundthat data points hardtolearn samples hadlabel noise speechless audio les', 1);('short speech utteranceswhich', 1);('telephony noise', 1);('figures', 1);('datamaps analysis skits2i', 1);('datamaps skits2i', 1);('dataset speakers', 1);('dataset easytolearn region whereas', 1);('dataset good', 1);('ofdata samples', 1);('dataset canact', 1);('fscwe', 1);('datamaps speaker thedataset identify speakers audio samples aboveissues', 1);('datamaps speakers', 1);('dataset errors samples', 1);('shows datamaps generatedfor speakers', 1);('hardtolearn samples whereas speakers', 1);('hardtolearn samples data errors hardtolearn samplesare data errors', 1);('chance erfigure', 1);('datamaps analysis fsc', 1);('datamaps analysis slurp', 1);('check hardtolearn samples andchangeremove', 1);('dataset errorfree', 1);('onthe dataset cartography analysis', 1);('errors inthe', 1);('future version', 1);('conclusionsin', 1);('domain trainedand', 1);('endtoendslu baselines', 1);('different models', 1);('asr ssl', 1);('prosodic informationwe', 1);('intentclassication model', 1);('thatthe baseline model', 1);('good performanceon', 1);('skits2i slurp', 1);('references1 swayamdipta r schwartz n lourie wang h hajishirzi n smith choi dataset', 1);('mappingand', 1);('datasets training dynamics arxiv preprintarxiv200910795', 1);('hemphill j j godfrey g r doddington theatis', 1);('language systems pilot corpus', 1);('language proceedings', 1);('hiddenvalley pennsylvania june', 1);('online availablehttpsaclanthologyorgh9010213 n tomashenko caubri', 1);('est', 1);('investigatingadaptation transfer learning endtoend spoken language understanding speech proc interspeech', 1);('lugosch ravanelli p ignoto v tomar bengiospeech model pretraining endtoend spoken languageunderstanding proc interspeech', 1);('arxiv preprint arxiv190403670', 1);('e bastianelli vanzo p swietojanski v rieser slurpa', 1);('language understanding resource package 2020online', 1);('available httpsarxivorgabs2011132057', 1);('p tomasello shrivastava lazar pc hsu lea sagar elkahky j copet wn hsu adi r algayrest nguyen e dupoux', 1);('zettlemoyer mohamedstop', 1);('semantic parsing2022', 1);('online', 1);('available httpsarxivorgabs2207106438', 1);('baevski zhou mohamed auli', 1);('wav2vec20 framework', 1);('learning speech representations', 1);('advances neural information processing systems', 1);('ravanelli parcollet p plantinga rouhe cornelll lugosch', 1);('subakan n dawalatabad heba j zhongjc chou sl yeh', 1);('fu cf liao e rastorguevaf grondin', 1);('aris h na gao r mori bengio speechbrain', 1);('generalpurpose speech toolkit 2021arxiv21060462410', 1);('radford j', 1);('kim xu g brockman', 1);('mcleavey', 1);('sutskever robust', 1);('speech recognition', 1);('largescale weak supervision', 1);('openai blog', 1);('conneau k khandelwal n goyal v chaudhary g wenzekf guzm e grave ott', 1);('zettlemoyer v stoyanovunsupervised', 1);('crosslingual representation learning scalearxiv preprint arxiv191102116', 1);('wn hsu', 1);('bolte h h tsai k lakhotia r salakhutdinov mohamed hubert selfsupervised', 1);('speech representation learning', 1);('transactions audio speech language processing', 1);('jiang', 1);('sharma madhavi h li knowledge', 1);('distillation bert transformer speech transformer intent classication arxiv preprint arxiv210802598', 1);('wang boumadane heba', 1);('wav2vec20hubert benchmark speech emotion recognition speakerverication', 1);('language understanding arxiv preprintarxiv211102735', 1);