('r epdib', 63);('rl', 29);('vq', 18);('protorl', 17);('returnswalkerwalk', 16);('figure', 16);('international conference', 14);('returnscheetahrun', 14);('proceedings', 11);('learning deep rl', 10);('pmlr', 9);('vib', 8);('proceedings machine learning', 7);('dqn', 7);('information bottleneck', 7);('research pages', 6);('mmact', 6);('urlb', 6);('driml', 5);('neurips', 5);('december', 5);('neural information processing systems', 5);('rgb', 5);('f1score', 5);('expert datasetacstate', 5);('expert datasetinverse', 5);('decision transformer', 5);('atari', 5);('representation learning', 5);('openreviewnet', 4);('corr', 4);('advances', 4);('virtual event', 4);('july', 4);('virtual pages', 4);('unimodal representations', 4);('keyless', 4);('repdib', 4);('ema', 3);('adamlearning', 3);('reconstructed image', 3);('cnn', 3);('reach', 3);('ablation', 3);('repdibacstate dibacstate vib00', 3);('present observations', 3);('advances neural information processing systems', 3);('proceedings aaai', 3);('different factors', 3);('hamlet', 3);('mutual information', 3);('r epdibwith', 3);('tasks', 3);('different domains', 3);('experiment setup', 3);('experiment', 3);('gridworld', 3);('learning', 3);('robust representations', 3);('r epdibcan', 3);('frames 4000discount 099optimizer', 2);('layers resnet block', 2);('groups discrete codes', 2);('loopworld', 2);('gpus', 2);('fusion', 2);('r epdibfigure', 2);('jaco arm', 2);('r epdibbottleneck', 2);('repdibinverse dibinverse vibfigure', 2);('visual', 2);('distractor1stepinverse repdib factor41stepinverse repdib factor81stepinverse repdib factor161stepinverse repdib factor321stepinverse baseline02', 2);('distractormultistep inverse repdib factor4multistep inverse repdib factor8multistep inverse repdib factor16multistep inverse repdib factor32multistep inverse baseline02', 2);('changing video distractor1stepinverse repdib factor41stepinverse repdib factor81stepinverse repdib factor161stepinverse repdib factor321stepinverse baseline02', 2);('changing video distractormultistep inverse repdib factor4multistep inverse repdib factor8multistep inverse repdib factor16multistep inverse repdib factor32multistep inverse baseline02', 2);('dib', 2);('discrete information bottleneck', 2);('top learnt representations', 2);('correlated background distractor1stepinverse repdib factor41stepinverse repdib factor81stepinverse repdib factor161stepinverse repdib factor321stepinverse baseline02', 2);('correlated background distractormultistep inverse repdib factor4multistep inverse repdib factor8multistep inverse repdib factor16multistep inverse repdib factor32multistep inverse baseline02', 2);('additional results', 2);('episode data collection', 2);('cifar', 2);('setup details', 2);('machine learning icml', 2);('august', 2);('machine learning icml2017 sydney nsw australia', 2);('whye teh', 2);('doina precup', 2);('neuralinformation processing systems', 2);('34annual conference', 2);('marcaurelioranzato alina beygelzimer yann n dauphin percyliang jennifer wortman vaughan', 2);('ieee', 2);('conference track', 2);('learning representationsiclr', 2);('articial intelligence', 2);('learning representations iclr', 2);('jun', 2);('machine learning', 2);('curran associates inc', 2);('information processing systems', 2);('internationalconference machine learning icml', 2);('annual', 2);('performance comparison', 2);('models eg', 2);('ways incorporate', 2);('baseline multimodal models', 2);('changing', 2);('following', 2);('expert datasetdriml', 2);('repdibacstate dibacstate dynamic bottleneckacstate vibacstate svibacstate mine00', 2);('repdibinverse dibinverse dynamic bottleneckinverse vibinverse svibinverse mine00', 2);('discrete information bottleneck02', 2);('r epdibto', 2);('video background', 2);('r epdibis', 2);('adam', 2);('variational information bottleneck', 2);('learnt representation', 2);('state art', 2);('r epdibon', 2);('islam hongyu zang manan tomar aniket didolkarfigure', 2);('state representations', 2);('maze', 2);('additional exogenous information', 2);('details', 2);('gaussian', 2);('information bottlenecks', 2);('sample efciency', 2);('latent states', 2);('ofine tasks', 1);('frames 1\x02105number discrete codes 512number groups 481632vib coefcient', 1);('frames 1\x02105number', 1);('001features dim 256hidden dim 1024number', 1);('rate 3\x0210\x014critic target', 1);('returns 3minibatch size', 1);('valuenstep', 1);('continuous control taskscommon hyperparameter', 1);('frames 2\x02106number discrete codes 50number groups 81632vib coefcient', 1);('frames 2\x02106number', 1);('001features dim 1024hidden dim 1024exploration stddev clip 03exploration stddev value 02number', 1);('rate 10\x014agent update frequency 2critic target', 1);('frames 4000nstep returns 3minibatch size', 1);('buffer capacity', 1);('valuereplay', 1);('maze navigation taskscommon hyperparameter', 1);('frames 1\x02104number discrete codes 50number groups 81632vib coefcient', 1);('001features dim 128hidden dim 128number', 1);('rate 3\x0210\x013critic target', 1);('6\x026minibatch size 128discount 099optimizer', 1);('discrete information bottleneckhyperparameter valuesize maze', 1);('hyperparameter detailsrepresentation learning deep rl', 1);('value purple11', 1);('state values', 1);('right tsneafter training', 1);('r epdib vib', 1);('middle tsne', 1);('jacoreachtopright', 1);('bottleneck representations tsne latent spaces', 1);('comparing visualizations', 1);('nd use variational information bottleneck', 1);('visualizationin', 1);('additionalrepresentation learning module10', 1);('relevant latent representation', 1);('key role', 1);('information bottleneckwhich captures factorial compositional representations', 1);('discard exogenous information', 1);('top representation learning objectives', 1);('new moreover', 1);('past literature use discreteinformation bottleneck', 1);('top oflearnt representationswe', 1);('representation learning objectives', 1);('benchmarks demonstratethat', 1);('tasks suchas human activity recognition experiments', 1);('range experiments', 1);('learnt representation needs discard exogenous irrelevant information theobservations', 1);('evenmore impactful', 1);('learning representations', 1);('bottlenecks signicant', 1);('discrete information', 1);('anynew representation learning objective', 1);('clarication signicance work work', 1);('explanation signicance r epdibwe', 1);('captures brightness ofelephants skin', 1);('captures shadow picture factor', 1);('column factor', 1);('similar observation canbe', 1);('specic details elephant', 1);('brightness factor', 1);('shape ofthe elephant', 1);('elephants image input factor', 1);('27a elephant top elephant thebottommiddle brighter', 1);('elephants fth column', 1);('different semantic information example obviousto', 1);('2factor representation nd', 1);('islam hongyu zang manan tomar aniket didolkaras', 1);('images totalriashat', 1);('group discrete codes consequence', 1);('group discrete codes', 1);('zero vector substitute', 1);('imagefor purpose', 1);('different semantic meaning', 1);('different groups', 1);('reconstructionof images', 1);('pictures dataset pass images network', 1);('semantic meaning differentgroups', 1);('loss vector quantization train network', 1);('mseloss', 1);('reconstruction loss', 1);('decoder network', 1);('groups discrete codes thecodebook size', 1);('latent representation', 1);('latent representation dimension', 1);('input sizeof', 1);('training evaluation purpose', 1);('elephant categoryis', 1);('pacs', 1);('semantic factorial representation withrepdib use cartoon domain images benchmark dataset', 1);('agent ability', 1);('details followexperiment details', 1);('real world data', 1);('capable learning factorial representations', 1);('discrete factorial information bottleneck agent', 1);('demonstrating factorial representationwe', 1);('byzero vectors8', 1);('zero vectors', 1);('groups discretecodes', 1);('original imagesecond', 1);('top', 1);('dataset example', 1);('pacscartoonelephant', 1);('brightness detailsb different', 1);('blue lines', 1);('environments maze navigation tasks', 1);('spiralworldfigure', 1);('discrete information bottlenecka gridworld', 1);('maze navigation tasksrepresentation', 1);('goal center maze evaluation', 1);('traininggoals agent', 1);('small nite', 1);('stage agent', 1);('data collectedby random policy', 1);('directions travel eachtimestep reward function', 1);('wall task', 1);('agent pass vacancy inthe bottom', 1);('spiralworld', 1);('spiral grid', 1);('path agent agent onlynavigate', 1);('wantsspiralworld hardest', 1);('walls agent', 1);('easiest task', 1);('action space state space dynamicsare', 1);('gridworld spiralworld loopworld', 1);('kinds environments maze navigation tasks', 1);('tasksmaze', 1);('extract salient multimodalrepresentation', 1);('multimodal models', 1);('activity recognition 8496andoutperforms', 1);('r epdib\x00mmprepdib\x00uniqimproves f1score', 1);('unimodal andmultimodal representations', 1);('model applies', 1);('multimodal representations examplerepdib\x00mmprepdib\x00uniqmodel uses', 1);('thevq bottleneck unimodal multimodal representations improves performance models', 1);('activity recognition', 1);('models ensure reproducibility', 1);('pytorchand pytorchlightning', 1);('cluster environment node contains', 1);('tmult', 1);('cycle multiplier', 1);('t0', 1);('cycle length', 1);('3e\x014 train learning model themmact dataset', 1);('initial learning rate', 1);('warm restarts learning scheduler', 1);('optimizer weight decay regularization', 1);('crossentropy loss use', 1);('data thesame human subjectswe train models', 1);('crosssession evaluation setting training', 1);('activityrecognition task', 1);('dataset crosssession evaluation setting', 1);('weevaluated', 1);('wearable sensors acceleration gyroscope orientation', 1);('task representations activity recognition baselines usedve modalities', 1);('extract unimodal representationsand', 1);('repdibmmr epdibuni', 1);('multimodal representations', 1);('extract multimodal representations', 1);('repdibmm', 1);('models extract salient representation', 1);('stateoftheart multimodal', 1);('human activities', 1);('learning taskthe model uses multimodal sensor data', 1);('setup multimodal model evaluation crosssession setting', 1);('multimodal learning methods', 1);('crosssession', 1);('8389repdibmmkeyless 7135repdibmmrepdibuni', 1);('opticalflow', 1);('islam hongyu zang manan tomar aniket didolkarmethod f1score svmhog', 1);('human activity sample data', 1);('approaches realworldsettings', 1);('har', 1);('data samples', 1);('acceleration gyroscope orientation modalities train test', 1);('data fromtwo', 1);('views acceleration gyroscope orientation', 1);('37kdata samples activities', 1);('activity times', 1);('twenty', 1);('pcs', 1);('objects fall kicking', 1);('activities eg', 1);('dataset contains', 1);('activity recognition taskdataset mmact', 1);('gyroscopeorientation acceleration74 multimodal representation learning', 1);('dataset modalities', 1);('sample data human activities', 1);('exogenous noise show importance learning robust representations', 1);('side environmentobservations', 1);('games exogenous images', 1);('example', 1);('qbertc seaquest breakoutfigure', 1);('discrete information bottlenecka pong', 1);('game domainrepresentation', 1);('check theeffect number discretization factors model performance effect number factors overallperformance', 1);('shows effect', 1);('multistep inverseobjectivefigure', 1);('predicts action', 1);('mlp', 1);('valuesofk feed', 1);('nal loss', 1);('different valuesforkand calculate objective value k', 1);('multistep inverse objective sample', 1);('atari frames', 1);('considerone observation stack', 1);('seaquest breakout', 1);('context length use context length', 1);('length training', 1);('hyperparameter details', 1);('top multistep inverse dynamics objective learning robust representations28', 1);('example observations atari games exogenous noise', 1);('side environment observations exogenousnoise', 1);('observations anexogenous noise side use', 1);('addition environment observations', 1);('experiment setup decision transformers', 1);('r epdib73 atari benchmark exogenous observationsexperiment setup', 1);('available dataset use ametric classication accuracy', 1);('cross entropy loss ground truth actions', 1);('future representation pxkq model', 1);('current representation pxqand', 1);('latent state representation multistep inversedynamics model ppa pxq pxkqq predicts actions', 1);('estimate pxqofthe imagesx addition', 1);('small convolutional neural network', 1);('outperforms factors learning representations withfactorial structurefor learning representation', 1);('benchmark nd factor', 1);('atarigames ale', 1);('effect number discretization factors model performance', 1);('breakoutfigure', 1);('factors0102030405060returns', 1);('factors02004006008001000returnsa seaquest1', 1);('background information robot arm part collecteddataset1', 1);('different images', 1);('setup robot data collection presence exogenous irrelevant background informationfigure shows', 1);('random uniform policy fora total 6hours', 1);('500steps recalibrate robot arm dataset', 1);('ie robotarm', 1);('current state use episodic length', 1);('image action', 1);('front side robotand top view', 1);('images dataset', 1);('robot arm experiments moves ina grid 9different positions', 1);('robot arm experimentrobot arm experiment background video exogenous distractors', 1);('performanceon generalization task72', 1);('vital role', 1);('number factors', 1);('thatthe factorization representation', 1);('different factorizations discrete bottleneck experiment results', 1);('urlb benchmark continuous', 1);('returnsjacoreachtopleftprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baselinefigure', 1);('returnsjacoreachbottomrightprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnsjacoreachbottomleftprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnsquadrupedwalkprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnsquadrupedstandprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnsquadrupedrunprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnsquadrupedjumpprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnswalkerrunprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('returnswalkerflipprotorl repdib factor8protorl repdib factor16protorl repdib factor32protorl baseline000', 1);('factors representation000', 1);('baseline results gure', 1);('summarizes ablation studies ofrepdib', 1);('tasks bottleneck', 1);('task helpsin', 1);('factorial nature compression', 1);('different factors learning representations goal experiments', 1);('top theencoders', 1);('open source code', 1);('benchmark details experiment setup comparisons', 1);('impressive performance', 1);('existing', 1);('algorithm encoder differentenvironment', 1);('experiments representations', 1);('different environments', 1);('continuous control tasks test generalization', 1);('continuous control tasksexperiment', 1);('present set hyperparameters usedin', 1);('manipulation tasks', 1);('discrete information bottlenecksimple', 1);('6dof robotic arm threenger gripper tests ability control robot arm performrepresentation', 1);('jaco arm reach', 1);('due highdimensionalstate action spaces 3d environment', 1);('similar walker', 1);('3d spacethe reward function', 1);('run', 1);('quadruped stand walk', 1);('relative angular velocity', 1);('velocity whileinflip task', 1);('andrun tasks reward proportional', 1);('walk', 1);('encouraging uprighttorso minimal torso height', 1);('task reward combination terms', 1);('stand', 1);('walker stand walk fliprun', 1);('easiest hardest domains tasks', 1);('domains walker', 1);('urlb benchmarkfigure', 1);('generalization continuous', 1);('exogenous distractors theobservations ofine datasets', 1);('background video', 1);('exogenous distractors observations ofofine datasets', 1);('repdibdriml dibdriml vib00', 1);('bottlenecks lead expectedperformance improvements00', 1);('r epdibcanprimarily', 1);('signicance performance improvement', 1);('experimental', 1);('representation objectivesas', 1);('islam hongyu zang manan tomar aniket didolkartoonly', 1);('representations wouldalways outperform baselines', 1);('observations consist exogenous information', 1);('objective validates', 1);('alwaysoutperform baselines', 1);('exogenous noiseas gures', 1);('robust robust representations presence', 1);('additional exogenous distractors', 1);('ofine datasets vd4rl benchmark', 1);('distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baselinefigure', 1);('distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baseline02', 1);('improves sample efciency overall performance methods usedon visual ofine data learning robust representations plays key role02', 1);('thebackground show', 1);('exogenous information', 1);('hard ofine setting', 1);('background video distractors consideredto', 1);('particular multistep onestep inverse models learnsmore robust representations', 1);('different representation objectives nd', 1);('top learnt representations fromthe', 1);('setting backgroundvideo distractors changes', 1);('video exogenous noise ofine datasets', 1);('changing video distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baselinefigure', 1);('changing video distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baseline02', 1);('weinclude ablation studies', 1);('r epdibobjective', 1);('ablation studies', 1);('signicance vib dib r epdibin', 1);('exogenous distractors7', 1);('factorial representations', 1);('lead improvedperformance', 1);('overall degradation performance contrast addition', 1);('state art representation learning methods cansuffer', 1);('exogenous noise', 1);('temporal contrastive learning', 1);('multistep inversedynamics objective', 1);('1step inverse dynamics objective', 1);('visual observationswe', 1);('overall performance', 1);('avoidingthe distractors', 1);('bottleneck representations', 1);('distractors contrast addingrepdib top learnt representations nd', 1);('representation learning methods suffer presence ofthis exogenous noise', 1);('robust exogenous ofine datasetsexperiment', 1);('ability methods', 1);('groupsof factors', 1);('different factorial representations', 1);('onestep inverse', 1);('multistep inverse', 1);('different representation learningobjectives', 1);('learning ofrobust representations invariant exogenous images', 1);('data collection procedure setting', 1);('background image distractors backgroundthe background exogenous noise', 1);('ofine data', 1);('settingwhere observations pixel', 1);('background image exogenous noise ofine datasets', 1);('correlated background distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baselinefigure', 1);('correlated background distractordriml repdib factor4driml repdib factor8driml repdib factor16driml repdib factor32driml baseline02', 1);('shows sample observations theofine dataset02', 1);('figures', 1);('background data collection', 1);('background images changingvideo distractors', 1);('different types distractors inthe ofine datasets exogenous information', 1);('effective robust especiallywhen', 1);('factorial bottlenecks', 1);('compresses thelearnt latent representations', 1);('objective show', 1);('1step inverse dynamics 48and temporal contrastive learning', 1);('top multistep inverse dynamics objective', 1);('rlsetting', 1);('top learnt representations visual pixel', 1);('state art performance ofine control taskswe', 1);('td3 bc', 1);('ne tune downstreampolicy learning algorithms', 1);('learnt representations', 1);('train encoders representation learning objective pretrain encoderswith', 1);('major difference', 1);('experiment pipeline', 1);('baseline policy optimization', 1);('islam hongyu zang manan tomar aniket didolkarfor', 1);('video data', 1);('observations addition', 1);('settingsince agent', 1);('episodewe video distractor changes', 1);('images changes', 1);('important role policy learning 2we', 1);('dataset image changesper episode data collection introduce learning robust representations', 1);('additional background image', 1);('environment observation', 1);('exogenous noise setting data collection episode theagent', 1);('1we rst', 1);('variations exogenous noise', 1);('data collection', 1);('samedata collection procedure vd4rl', 1);('additional exogenous noise', 1);('vd4rlbenchmark recollect data', 1);('datacollection', 1);('visual ofine datasets vd4rl benchmark', 1);('episode ofine data collectionexperiment', 1);('background video distractor changes', 1);('theexogenous', 1);('sample observations visual ofine datasets exogenous', 1);('episode ofine data collectionfigure', 1);('images backgroundthe exogenous background image changes', 1);('sample observations visual ofine datasets exogenous time', 1);('details61 visual ofine rl exogenous observations datasetsfigure', 1);('discrete information bottlenecksupplementary materialsappendix6 additional experiment', 1);('stein variational approach 2021representation', 1);('pei yingjun hou xinwen li jian lei wangoptimizing', 1);('virtual event austria may', 1);('deepreinforcement learning pixels', 1);('regularizing', 1);('augmentation need', 1);('pmlr202166 denis yarats ilya kostrikov rob fergus image', 1);('conferenceon machine learning', 1);('learning prototypical representations', 1);('pinto reinforcement', 1);('denis yarats rob fergus alessandro lazaric', 1);('research pages 1178411794pmlr', 1);('july2021 virtual event', 1);('marina meila tong zhang', 1);('mengjiao yang nachum representationmatters ofine', 1);('exploration nearoptimal tabular mdparxiv preprint arxiv210209703', 1);('randomized', 1);('zhihan xiong ruoqi shen simon', 1);('eccv', 1);('good practices fordeep action recognition', 1);('towards', 1);('segment networks', 1);('limin wang yuanjun xiong zhe wang yu qiaodahua lin xiaoou tang luc van gool temporal', 1);('proceedings ieeecvfconference computer vision pattern recognition', 1);('minimal sufcient representation incontrastive learning', 1);('haoqing wang xun guo zhihong deng yanlu rethinking', 1);('neuraldiscrete', 1);('aaron van den oord oriol vinyals', 1);('keyvalue bottleneck', 1);('discrete', 1);('anirudh goyal nasim rahamanmichael mozer kenji kawaguchi yoshua bengioand bernhard sch', 1);('ieee201559 frederik tr', 1);('ieeeinformation theory workshop itw pages', 1);('learningand information bottleneck principle', 1);('naftali tishby noga zaslavsky deep', 1);('information bottleneck method arxivpreprint physics0004057', 1);('pereira williambialek', 1);('naftali tishby fernando', 1);('mit', 1);('learning introduction', 1);('richard sutton andrew g barto reinforcement', 1);('intelligence', 1);('conference onarticial', 1);('learning variational information bottleneck', 1);('qingyun sun jianxin li hao peng jia wuxingcheng fu cheng ji yu philip graphstructure', 1);('zhang', 1);('marina meila', 1);('representation learningfrom reinforcement learning', 1);('laskin decoupling', 1);('adam stooke kimin lee pieter abbeel', 1);('informationarxiv preprint arxiv170300810', 1);('neural networks', 1);('theblack box', 1);('ravid shwartzziv naftali tishby opening', 1);('representations dataefcient reinforcement learning', 1);('max schwarzer nitarshan rajkumar michaelnoukhovitch ankesh anand laurent charlinr devon hjelm philip bachman aaron ccourville pretraining', 1);('event austria may', 1);('reinforcement learning selfpredictive representations', 1);('courville philip bachman dataefcient', 1);('max schwarzer ankesh anand rishab goel r devon hjelm aaron', 1);('representations reinforcement learning information bottleneck approach', 1);('yingjun pei xinwen hou learning', 1);('islam hongyu zang manan tomar aniket didolkar49 deepak pathak pulkit agrawal alexei efrosand trevor darrell curiositydriven', 1);('international conference onmachine learning pages', 1);('darrell curiositydriven', 1);('deepak pathak pulkit agrawal alexei efros', 1);('frontiers neurorobotics', 1);('isintrinsic motivation typology computationalapproaches', 1);('kaplan', 1);('pierreyves oudeyer fr', 1);('explorationwith neural density models', 1);('munos countbased', 1);('aron van denoord', 1);('georg ostrovski marc g bellemare', 1);('j mach learn res', 1);('wen deep', 1);('ian osband benjamin van roy daniel j russo', 1);('inwacv', 1);('comprehensive multimodal human action database', 1);('ruzena bajcsy berkeley', 1);('ferda oi rizwan chaudhry gregorij kurillo ren', 1);('provable representation learning imitation contrastive fourierfeatures', 1);('nachum mengjiao yang', 1);('reinforcement learning', 1);('information maximisation', 1);('shakir mohamed danilo jimenez rezende variational', 1);('reinforcement learning arxiv preprint arxiv13125602', 1);('mnih koray kavukcuoglu david silveralex graves ioannis antonoglou daan wierstraand martin riedmiller playing', 1);('international conference machine learning pages', 1);('efcient richobservation reinforcement learning', 1);('state abstraction', 1);('dipendra misra mikael henaff akshay krishnamurthy john langford kinematic', 1);('neural information processing systems33 annual', 1);('hugolarochelle marcaurelio ranzato raia hadsellmariaflorina balcan hsuantien lin', 1);('infomax learning', 1);('combes thangdoan philip bachman r devon hjelm deepreinforcement', 1);('bogdan mazoure remi tachet', 1);('opportunities ofine reinforcement learning visual observations', 1);('cong lu philip j ball tim g j rudner jackparkerholder michael osborne yee whyeteh challenges', 1);('keyless attention fusion video classication', 1);('chuang gan gerard de melo xiao liuyandong li fu li shilei wen multimodal', 1);('xiang', 1);('hao liu pieter abbeel behavior', 1);('ranzatoa beygelzimer dauphin ps liang j wortman vaughan', 1);('neural communication', 1);('mozer yoshua bengio discretevalued', 1);('dianbo liu alex lamb kenji kawaguchianirudh goyal alias parth goyal chen sunmichael', 1);('dynamic vector quantization arxivpreprint arxiv220201334', 1);('discrete communication bottlenecks', 1);('dianbo liu alex lamb xu ji pascal notsawo mike mozer yoshua bengio kenjikawaguchi adaptive', 1);('san juanpuerto rico may', 1);('conferenceon learning representations iclr', 1);('lecun', 1);('yoshua bengio', 1);('control withdeep reinforcement learning', 1);('timothy p lillicrap jonathan j hunt alexanderpritzel nicolas heess tom erez yuval tassa davidsilver daan wierstra continuous', 1);('andopen questions arxiv preprint arxiv220903430', 1);('principles', 1);('recent trends multimodal machine learning', 1);('ieee computer society201732 paul pu liang amir zadeh louisphilippemorency foundations', 1);('venice italy october', 1);('computer vision iccv', 1);('broader artier domain generalization', 1);('timothy mhospedales deeper', 1);('discrete information bottleneck31 da li yongxin yang yizhe', 1);('virtual 2021representation', 1);('neurips datasets benchmarks2021 december', 1);('datasets', 1);('proceedings neural information processing systems', 1);('yeung', 1);('joaquin vanschoren', 1);('reinforcement learning benchmark', 1);('michael laskin denis yarats hao liu kimin leealbert zhan kevin lu catherine cang lerrel pintoand pieter abbeel urlb', 1);('research pages56395650', 1);('volume 119ofproceedings', 1);('machine learning icml2020', 1);('representations forreinforcement learning', 1);('michael laskin aravind srinivas pieter abbeelcurl', 1);('controllable latentstates multistep inverse models arxiv preprintarxiv220708229', 1);('toronto toronto ontario200928 alex lamb riashat islam yonathan efroni aniketdidolkar dipendra misra dylan foster lekan molurajan chari akshay krishnamurthy john langford guaranteed', 1);('technicalreport', 1);('tiny images', 1);('multiple layers', 1);('alex krizhevsky geoffrey hinton learning', 1);('machine learningicml', 1);('marinameila tong zhang', 1);('reinforcement learning withsher divergence critic regularization', 1);('nachum ofine', 1);('ilya kostrikov rob fergus jonathan tompson', 1);('iccv', 1);('largescale dataset cross modal humanaction understanding', 1);('quan kong ziming wu ziwei deng martinklinkigt bin tong tomokazu murakamimmact', 1);('virtual event austriamay', 1);('learningrepresentations iclr', 1);('representation noiserobust exploration', 1);('kim dropbottleneck learning', 1);('jaekyeom kim minjung kim dongyeon woo', 1);('conferenceon machine learning icml', 1);('emi explorationwith', 1);('hyoungseok kim jaekyeom kim yeonwoo jeongsergey levine hyun oh', 1);('collegelondon', 1);('thesis university', 1);('phd', 1);('sample complexity reinforcement learning', 1);('sham kakade', 1);('proceedings openreviewnet', 1);('toulon france april', 1);('auxiliary tasks 5th', 1);('mnih wojciech marianczarnecki tom schaul joel z leibo david silver koray kavukcuoglu reinforcement', 1);('max jaderberg v', 1);('ieee transaction multimedia', 1);('recurrent approach multimodal fusion', 1);('iqbal ven', 1);('md mojul islam mohammad samin yasar', 1);('multimodal fusion', 1);('md mojul islam tariq iqbal mumu cooperative', 1);('intelligent robots systemsiros', 1);('ieeersj', 1);('human activityrecognition algorithm', 1);('hierarchical multimodal', 1);('md mojul islam tariq iqbal hamlet', 1);('annualconference neural information processing systems', 1);('marcaurelio ranzatoalina beygelzimer yann n dauphin percy liangand jennifer wortman vaughan', 1);('sample efcient neuralfunction approximation', 1);('baihe huang kaixuan huang sham kakade jason lee qi lei runzhe wang jiaqi yanggoing', 1);('knowledge neural network', 1);('geoffrey hinton oriol vinyals jeff dean distilling', 1);('stockholm sweden july', 1);('stockholmsm', 1);('jennifer g dy andreaskrause', 1);('reinforcement learning astochastic actor', 1);('maximum entropy', 1);('offpolicy', 1);('levine soft', 1);('tuomas haarnoja aurick zhou pieter abbeel', 1);('primitives arxiv preprintarxiv190610667', 1);('competitive ensemblesof', 1);('anirudh goyal shagun sodhani jonathan binasxue bin peng sergey levine yoshua bengioreinforcement', 1);('orleans la usa may', 1);('inriashat islam hongyu zang manan tomar aniket didolkar7th', 1);('anirudh goyal riashat islam daniel strouse zafarali ahmed hugo larochelle matthew botvinickyoshua bengio sergey levine infobot transfer', 1);('evaluation information budgetarxiv preprint arxiv200411935', 1);('stochastic', 1);('variational bandwidth bottleneck', 1);('anirudh goyal yoshua bengio matthew botvinickand sergey levine', 1);('statistical complexity interactive decision making', 1);('rakhlin', 1);('dylan j foster sham kakade jian qian', 1);('arxiv', 1);('multistepinverse dynamics', 1);('langfordprovable rl exogenous distractors', 1);('yonathan efroni dipendra kumar misra akshaykrishnamurthy alekh agarwal john', 1);('learningtheory pmlr', 1);('reinforcement learning presence ofexogenous information conference', 1);('yonathan efroni dylan foster dipendra misra akshay krishnamurthy john langford sampleefcient', 1);('kamalika chaudhuri ruslansalakhutdinov', 1);('rich observations', 1);('akshay krishnamurthy nan jiang alekhagarwal miroslav dudik john langford provably', 1);('simon', 1);('volume 34pages', 1);('ranzato beygelzimer dauphin psliang j wortman vaughan', 1);('reinforcement', 1);('lili chen kevin lu aravind rajeswaran kiminlee aditya grover misha laskin pieter abbeel aravind srinivas igor mordatch decision', 1);('random network distillation arxiv preprint arxiv181012894', 1);('klimov exploration', 1);('yuri burda harrison edwards amos storkey', 1);('spain', 1);('garnetteditors advances neural information processingsystems', 1);('daniel lee masashi sugiyama ulrikevon luxburg isabelle guyon', 1);('exploration intrinsic motivation', 1);('munosunifying', 1);('marc g bellemare sriram srinivasan georg ostrovski tom schaul david saxton r', 1);('research pages 619629pmlr', 1);('marina meila tongzhang', 1);('world models facilitate zeroshot dynamics generalization single ofine environment', 1);('j roberts augmented', 1);('philip j ball cong lu jack parkerholder', 1);('neurips2021 december', 1);('advances neural informationprocessing systems', 1);('marcaurelio ranzato alina beygelzimeryann n dauphin percy liang jennifer wortmanvaughan', 1);('bottleneck robust', 1);('chenjia bai lingxiao wang lei han animeshgarg jianye hao peng liu zhaoran wangdynamic', 1);('variational information bottleneck arxiv preprint arxiv161200410', 1);('murphy deep', 1);('alexander alemi ian fischer joshua v dillon', 1);('international conference onmachine', 1);('optimistic perspective ofine reinforcement learning', 1);('rishabh agarwal dale schuurmans mohammadnorouzi', 1);('nsfc grant', 1);('hongyu zang xin liwere', 1);('forvaluable feedback', 1);('remi tachet des combesromain laroche harm van seijen doina precup', 1);('empiricallyacknowledgementsthe authors', 1);('interesting questionboth', 1);('agents toachieve leverage compositional representation spacefor', 1);('generalization capabilities', 1);('compositional structure shape path', 1);('actual factorization structure data', 1);('theoreticalproof corresponds', 1);('discrete factorization', 1);('whilewe', 1);('future work', 1);('interesting avenue', 1);('different factors observations', 1);('compositional representation space disentangle', 1);('whether', 1);('experimental resultslimitations', 1);('space work shows discrete bottleneck representations compresses relevant information observations lead substantialimprovements', 1);('learns robust representations', 1);('discrete information bottleneckthat', 1);('r epdibrepresentation learning deep rl', 1);('vital end', 1);('exogenous information need learning robust representations', 1);('recent past', 1);('learning methods', 1);('discussionconclusion representation', 1);('salient multimodal representations5', 1);('crucial future avenue research utilize', 1);('experimental results', 1);('model performance', 1);('appropriatevalue hyperparameters', 1);('bottleneck impact model performance number ofgroups number embeddings', 1);('unimodal representationsmoreover couple hyperparameters', 1);('room improvement', 1);('impact performance downstreamtask', 1);('fuse unimodal representations', 1);('works multimodal', 1);('hamlet r epdib\x00mmprepdib\x00uniqfuses', 1);('improves theperformance', 1);('model appliesrepdib unimodal multimodal', 1);('r epdib\x00mmprepdib\x00uniqmodel', 1);('multimodal representations example', 1);('models notuse', 1);('bottleneck unimodal multimodal representations improves performance models', 1);('salient representations task learningon hand', 1);('multimodal representation ensure', 1);('multimodal representation results', 1);('from6935 models', 1);('degrades thef1score activity recognition task', 1);('bottleneck multimodal representations', 1);('bottleneck multimodal representationsdegrades performance multimodal models theactivity recognition task example', 1);('activity recognition task 25experiment', 1);('dataset crosssubjectevaluation setting', 1);('wearable sensorsacceleration gyroscope orientation evaluatedall baselines', 1);('modalitiestwo viewpoints', 1);('task representations activity recognition baselines', 1);('thorough avq bottleneck', 1);('bottleneck toproduce', 1);('extract unimodal representations', 1);('repdibmmr epdibuniwe', 1);('datasetmodal representations', 1);('multimodal learning model', 1);('crosssubject', 1);('epdibuni', 1);('7183repdibmmhamlet 5747repdibmmkeyless 6322repdibmmr', 1);('f1score smd', 1);('true state robotmethod', 1);('able removenoise representation', 1);('various types bottlenecks', 1);('representation quality', 1);('various distractors tv', 1);('real robotic arm', 1);('representations', 1);('estimation relative error', 1);('noise relative error', 1);('r epdibno vib r epdibtemporal noise relative error', 1);('islam hongyu zang manan tomar aniket didolkarbottleneck', 1);('hamlet18', 1);('bottleneckrepdibmm extract multimodal', 1);('learning multimodal representations human activity recognition task', 1);('bottleneckexperiment details', 1);('multimodal representation learning', 1);('predictthe ground truth state robot45', 1);('noise therepresentation', 1);('helpsimprove ability', 1);('irrelevant information observations', 1);('time step', 1);('temporalnoise', 1);('effectiveness ofrepdib timestep indicator backgroundnoise', 1);('additional metric', 1);('timestep observation', 1);('withthe learnt model', 1);('furthermore', 1);('ground states ignoringthe irrelevant background information', 1);('learnt representation needs', 1);('observations aclassication task', 1);('accuracy', 1);('ground truth states', 1);('ability ofrepdib', 1);('multistep inverse dynamics model', 1);('baseline agent learns representation learning latent representations', 1);('representation learning objectivescompare', 1);('video distractors background', 1);('video distractors exogenous noise background', 1);('repdibinverse dibinverse dynamic bottleneckinverse vibinverse svibinverse minefigure', 1);('representation learning objectives00', 1);('different bottleneck', 1);('main wenow', 1);('previous results', 1);('approximations ofine', 1);('approaches basedon information bottleneck', 1);('comparison r epdibwith', 1);('exogenous images background', 1);('repdibdriml dibdriml dynamic bottleneckdriml vibdriml svibdriml minefigure', 1);('similar insettings', 1);('contrast performance', 1);('ofine visual control setup', 1);('due information bottleneck presence backgroundexogenous distractors', 1);('returnswalkerwalk background distractormultistep inverse repdib factor1multistep inverse repdib factor4multistep inverse repdib factor8multistep inversefigure', 1);('returnscheetahrun background distractormultistep inverse repdib factor1multistep inverse repdib factor4multistep inverse repdib factor8multistep inverse02', 1);('returnswalkerwalk distractormultistep inverse repdib factor1multistep inverse repdib factor4multistep inverse repdib factor8multistep inverse02', 1);('image noise', 1);('reconstruct image learning latentstate representation', 1);('r epdibexperiment', 1);('ground truth state position learning latent representations', 1);('background goal experiment topredict', 1);('due video', 1);('action background distractors changes', 1);('right samplepoint image', 1);('highlevel actions', 1);('samples arm', 1);('6hours ofrobot data', 1);('nearby ofine dataset', 1);('setup robot task thereis tv', 1);('exogenous noiseinformation setup', 1);('inspired', 1);('thebackground distractors', 1);('observations onlywhere images consist robot arm', 1);('wecollect', 1);('true states', 1);('9different positions', 1);('top grid layout', 1);('information discretizationbottleneck learnt representation task therobot arm', 1);('multistep inverse model', 1);('learning latent state representation theimages', 1);('rich temporal backgroundnoise', 1);('high resolution videoof robot arm presence', 1);('challenging real robot dataset', 1);('robot arm experiment presence irrelevantbackground informationexperiment details', 1);('basedfactorization variational information bottleneck44', 1);('vqv ae', 1);('svgd weemphasize', 1);('faircomparison bottlenecks update networks', 1);('steinvariational gradient descent svgd notably', 1);('standard loss function', 1);('utilizes mutualinformation observation correspondingrepresentation', 1);('svib', 1);('current action', 1);('current stateand', 1);('latent representation ofpstatqstatcorrespond', 1);('mutual informationiprstatsztq whereztis', 1);('mutual informationipztst\x001qwhile', 1);('dynamicsrelevant representation', 1);('db', 1);('estimatedlower bounds', 1);('maximize mutualinformation state', 1);('specically emi', 1);('r epdibcompares', 1);('show gures', 1);('svib67', 1);('emiwith mineobjectives23 dbdynamic bottleneck', 1);('mi', 1);('r epdibdoes', 1);('objectivein contrast', 1);('basedon approximations', 1);('r epdibbottlnecknote', 1);('different baselinesalong comparisons variations', 1);('step inverse dynamics', 1);('acstate', 1);('information bottleneck approacheson top', 1);('otherbottleneck baselines pixel', 1);('information bottleneck approaches', 1);('additionalexogenous distractorscomparisons', 1);('similar setting', 1);('learnmore robust representations', 1);('summarizes results nd presence exogenous image distractors', 1);('exogenous image distractors background', 1);('settings visual background distractors', 1);('ulti step inversemodel', 1);('control wherewe', 1);('ofine dataset', 1);('considerthe visual', 1);('visual ofine rl', 1);('effect number ofdiscretization factors', 1);('factors gamesadditional results', 1);('bottleneck use discretization module', 1);('showingthe effectiveness', 1);('ulti step inverse', 1);('atariresults ulti step inverse r epdib', 1);('applyingmultistep inverse objectiveexperiment', 1);('method section', 1);('approach discretize output theencoder', 1);('convolutional encoder xedfor', 1);('foraction prediction', 1);('episodes rst pretrain convolutional encoder multistep inverse objective', 1);('different image', 1);('episode usea', 1);('cifar image', 1);('image eachframe', 1);('exogenous information observation spacewe append', 1);('statesactions returnstogoto', 1);('approach outperforms baseline inall cases', 1);('setup cansee', 1);('4atari game', 1);('ulti stepinverse r epdib ulti stepinverse', 1);('islam hongyu zang manan tomar aniket didolkargame multi stepinverse multi stepinverse r epdibpong', 1);('sequence modelriashat', 1);('ofine dataset 1for training model', 1);('breakout seaquest qbert', 1);('representations ignore noisyor background information relevant task usingrepdib', 1);('wherethe goal', 1);('setup decision transformers', 1);('ofine experiments exogenous distractorsexperiment setup atari', 1);('thatrepdiballeviates problem', 1);('phenomenon prototypicalrl baseline', 1);('steps counterintuitive failure modeis', 1);('performance function pretrainedunsupervised representation steps downstream', 1);('klweightings appendix', 1);('signicance information bottleneck', 1);('algorithmwe nd use information bottleneck', 1);('demonstrates signicance', 1);('bottleneck rewardfree setting test', 1);('discretization bottleneck denotedas', 1);('r epdibwhich', 1);('protorlbaseline', 1);('apt', 1);('icm', 1);('drq', 1);('isshown outperform', 1);('free representationexperiment', 1);('learnt representation study effectiveness reward', 1);('compositional structure', 1);('sac', 1);('soft actor critic', 1);('standard state', 1);('dataset whichis', 1);('weuse', 1);('new tasks test generalization capability', 1);('phase agent netunedto', 1);('discrete factorial embeddings efcient', 1);('computes intrinsic', 1);('utilize factorizationstructure representation space use ofthe information bottleneck', 1);('case ofrepdib', 1);('agent bottom row entropy latent state distribution', 1);('steps whena', 1);('degrade function', 1);('discretiztion bottleneck gradual improvement inperformance top row', 1);('xaxis', 1);('steps 100k500kor1mtimesteps', 1);('downstream', 1);('representations learnt', 1);('finetuning', 1);('returnswalkerrunprotorlprotorl repdib vibprotorl repdibfigure', 1);('returnswalkerflipprotorlprotorl repdib vibprotorl repdib000', 1);('returnsquadrupedwalkprotorlprotorl repdib vibprotorl repdib000', 1);('returnsquadrupedrunprotorlprotorl repdib vibprotorl repdib000', 1);('discrete information bottleneck000', 1);('approximation torepresentation', 1);('agent trainedto maximize coverage', 1);('asimilar procedure', 1);('unseen regions tocollect diverse data helpin learning', 1);('thegoal', 1);('free setting', 1);('phase trainrepdib agent task agnostic reward', 1);('thenevaluate adaptation ability method adaptingthe', 1);('checkpoint agent 100k500k 1m 2m timesteps', 1);('experiment pipeline inurlb benchmark', 1);('domainand adapts', 1);('specic task', 1);('arm theagent', 1);('walker quadruped', 1);('different downstreamtasks', 1);('continuous control tasks varyingdifculty', 1);('factorial structure embeddingswe use total', 1);('exploits theuse information bottleneck vector quantization', 1);('ensure factorizedstructure learnt latent representation', 1);('key approach learningdiscret prototypese', 1);('incontrast protorl', 1);('phase task agnostic rewardfree setting', 1);('learnt prototypical representations form basis intrinsic reward function ensures sufcient coverage', 1);('prototypes ensure exploration latent state entropy distribution', 1);('aset prototypical vectors prototypes', 1);('outperform baselines learning', 1);('good representations', 1);('continuous control tasks visual observations', 1);('generalization continuous controlrepdib', 1);('state spacecoverage rewardfree exploration42', 1);('factorizedrepresentations r epdib', 1);('coverage', 1);('state space', 1);('different group factors discretizationbottleneck', 1);('results gure', 1);('top encoder', 1);('rewardfree representation learning', 1);('objective learning representations usedriml', 1);('topology maze inrepresentation space', 1);('coverage state space demonstratedin', 1);('representation structureleads', 1);('observationswe nd', 1);('update representations', 1);('representations emptygridworld', 1);('discrete codes parsimonious', 1);('explorationleft information bottleneck', 1);('generalization capability incontinuous control tasks', 1);('summary r epdib', 1);('agent neriashat', 1);('study spiral loop world mazenavigation task baseline', 1);('endtask policyexperiment', 1);('representations thesethree tasks', 1);('random policyand adapt', 1);('r epdib gridworld spiralworld loopworld', 1);('effectiveness learning parsimonious representations', 1);('kinds maze navigation tasks', 1);('tasksexperiment details', 1);('similar representation point center41', 1);('position showshow', 1);('darkness', 1);('topology theagent', 1);('learns representationsthat', 1);('withrepdib show', 1);('left baseline dqn agent right dqn agent', 1);('relative distance representation', 1);('existingbaselines information bottleneck multimodal representations activity recognition tasksfigure', 1);('helpsachieve performance improvements', 1);('multimodal representation', 1);('modality information bottleneck', 1);('weshow', 1);('dataset multimodal learning setting', 1);('human activity recognition', 1);('information bottleneck extract unimodal fuse multimodal representationswe study', 1);('distractorswhat impact', 1);('benchmark environment observations consist', 1);('problem ofine datasets evaluaterepdib ofine', 1);('relevant factors variation ignore irrelevant distractors throughthe use information discretization bottleneckdoes bottleneck representations', 1);('real robot arm collecteddata temporal background structure isbackground noise lightnings tv video', 1);('background distractors', 1);('relevant representations areal robot arm task', 1);('stepsdoes information bottleneck', 1);('tasks importantlywe show sample efciency', 1);('generalization capabilities settingwe pretrain representations rewardfree approach ona', 1);('complex control tasks', 1);('generalizaton capabilities', 1);('task agnostic', 1);('r epdibhelplearn', 1);('betterexploration maze tasks', 1);('discrete latent states', 1);('discrete information bottlenecks wecan', 1);('effective exploration', 1);('structure lead', 1);('simple toytasks learning representations', 1);('structure representation space helpwith exploration rst', 1);('objective experiments weanswer', 1);('framework learns representations', 1);('plugin approach top ofany', 1);('effectiveness information compression representations', 1);('bottleneckwe', 1);('vqv ae4 experiments representations', 1);('agentvector quantization', 1);('different factors 81632in learnt representation', 1);('different maze navigation tasks', 1);('performance', 1);('returnsgridworlddqn repdib factor8dqn repdib factor16dqn repdib factor32dqn baselinefigure', 1);('returnsloopworlddqn repdib factor8dqn repdib factor16dqn repdib factor32dqn baseline10', 1);('returnsspiralworlddqn repdib factor8dqn repdib factor16dqn repdib factor32dqn baseline10', 1);('discrete information bottleneck10', 1);('continuous representation information bottleneck discrete latent variables generalizingrepresentation', 1);('reparameterization uniform', 1);('encoder mapsobservations oto latent representation p\x04q rst usea variational information bottleneck', 1);('vector quantizationdiscretization bottleneck top encoder learnsa latent state representation', 1);('enable factorial structure representation space', 1);('reinforcement learning objective', 1);('technical details approach', 1);('zq\x10concatenate pdiscretizepc1q\x04\x04\x04discretizepcgqqthis process results compositionality latent representation information bottleneckrepdib implementation', 1);('variable concatenate allsegments', 1);('lway', 1);('oi\x10argminjpt1luci\x01ej wherelis sizeof discrete latent space ie', 1);('discretizepciqwhere', 1);('neighbourlookup eoi\x10', 1);('adiscrete vector', 1);('continuous state representation intogdifferent groups ze\x10concatpc1c2\x04\x04\x04cgqthen', 1);('discrete vectorwe rst', 1);('zeto single', 1);('concretely', 1);('discretization bottleneck quantizethe output projector layer', 1);('different groupingfactors', 1);('thevq discretization bottleneck', 1);('learnt embeddings', 1);('apparent structure existsin latent space baseline', 1);('shows learntcompositional structure latent', 1);('discrete codes', 1);('sufcient representationsmeans', 1);('aninformation bottleneck', 1);('adding', 1);('discrete information bottlenecksmore parsimonious discrete representations', 1);('structure representationspace', 1);('\x00repdib learns', 1);('latent representations', 1);('factorized', 1);('discrete prototypesright', 1);('protorl left latent', 1);('topof learnt representations', 1);('continuous control', 1);('setup learning representations', 1);('representation embeddings', 1);('tsne', 1);('discretization function encouragefigure', 1);('achievedthrough discretization bottleneck additionallyadd gaussian information bottleneck', 1);('representationwhile compositional structure', 1);('discretization bottleneck preserves size', 1);('rm rm', 1);('z\x10 pzqwith', 1);('factors canconcatenate single', 1);('lgwe', 1);('total number discrete states express', 1);('gfactors lcodes', 1);('vector quantization discretizationbottleneck', 1);('compositional structure learnt representation space', 1);('representationzprmfor richobservation x zcould theoutput convolutional neural network recurrent neuralnetwork transformer expressive neural modelwe', 1);('learning section webriey describe approach learning robust representations information bottlenecksthe', 1);('representation spacevia use discrete information bottlenecks', 1);('r epdiblearns', 1);('performance downstreamtasks range experiments section', 1);('effective robustrepresentations', 1);('simple bottlenecks lead learning', 1);('irrelevant information additionof', 1);('goal work study effectiveness variational discrete information bottlenecks representation learning', 1);('discrete factorial informationbottlenecks representation learningthe', 1);('zoomedoutperspective efcacy bottlenecks learning representations reinforcement learning3', 1);('learning paper', 1);('andsimilar variants', 1);('dreamerv2', 1);('workin reinforcement learning', 1);('previous', 1);('particular variational ones', 1);('combinesboth kinds bottlenecks ie architectural discrete bottlenecks', 1);('inverse model targets', 1);('dqntargets', 1);('repdibapplies', 1);('informationbottleneck dynamics system whereas', 1);('chenjia', 1);('architectural choices suchas', 1);('avariational approach', 1);('various ways', 1);('minimal sufcient representations', 1);('related', 1);('anyform structure representation spacecomparisons', 1);('complex high dimensional tasks', 1);('islam hongyu zang manan tomar aniket didolkaralgorithms', 1);('exploration prediction errors', 1);('random network distillation6', 1);('intrinsic motivation', 1);('optimismdriven exploration', 1);('large observation spaces', 1);('works exploration proposedwith', 1);('rich observation environmentsseveral', 1);('grounds representation learning exploration theoretical guarantees', 1);('theoretical side', 1);('explicit representation selfsupervisedobjective', 1);('latent bottleneck states donot', 1);('problem representation learning exploration', 1);('ourwork learning prototypical representations 65which studies', 1);('improvingdownstream task performance', 1);('recent workshave', 1);('latent structure worldensures agent learns unseen frontiers inobservation space', 1);('representation learning problemsince', 1);('exploration problem', 1);('bottleneck exploration deep reinforcement learning', 1);('neural networksinformation', 1);('mutual information objective information bottleneck', 1);('alemi', 1);('discrete representation bottlenecks 59most', 1);('learning models variational bottlenecks', 1);('design information bottlenecks', 1);('relevant information betweenxandythat parsimonious', 1);('optimal', 1);('sufcient information', 1);('advocates learningminimal sufcient representations ie', 1);('presence exogenous information informationbottleneck principle', 1);('rlin', 1);('effective approach learning robust representatons', 1);('minimal representations informationbottleneck', 1);('exploratory objectives', 1);('representations itleads', 1);('52while learning', 1);('achievetremendous performance improvements', 1);('self', 1);('objectives learning robust representations', 1);('empirically', 1);('learning exogenous information show bottlenecks lter irrelevantinformation observations', 1);('representation learning thiswork show effectiveness information bottleneckswith', 1);('theoreticalrl community', 1);('learning irrelevant exogenous information', 1);('learning representations highdimensional observations', 1);('mostof', 1);('environment dynamics', 1);('online ofine settings', 1);('representation learning contextof', 1);('related workself supervised representation learning rl severalprior', 1);('efciency androbustness', 1);('learns compressedrepresentations', 1);('robustness ofinerl presence exogenous distractors rangeof experiments', 1);('continuous control c bottleneck representations', 1);('improved', 1);('practical robot arm task b', 1);('robustness learning factorial representations ignoreirrelevant information', 1);('thesalient attributes environment', 1);('downstreamperformance settings irrelevant background information work', 1);('aneasy use approach', 1);('agents actions', 1);('observations consist irrelevant exogenous informationtains exogenous noise', 1);('representations discrete information bottleneck r epdib', 1);('representations variational discretefactorial bottlenecks', 1);('generic approach', 1);('illustration', 1);('discrete information bottleneckrl finetuningpretrainingdiscretebottleneckvariationalbottleneckfigure', 1);('dec', 1);('settings observation conarxiv221213835v1 cslg', 1);('learnmore robust representations improvement', 1);('information bottleneck induces factorial structure', 1);('continuous representationsthis work studies effectiveness learning compressedrepresentations reinforcement learning nd thatby', 1);('encouraging beparsimonious gaussian variational informationbottleneck', 1);('representationsdiscrete factorial', 1);('figure1 representations rl discrete informationbottleneck r epdib', 1);('expressiveness factorial representations', 1);('small tabularmdpsand representations', 1);('small number discrete stateswe explore intersection', 1);('strong theoretical guarantees9 planning', 1);('countswhile algorithms', 1);('frontier pairs thediscrete latent states actions', 1);('algorithm40 explores', 1);('homer', 1);('representations discrete latentstate setting', 1);('theory literature', 1);('new samplesfrom environmentapproaches', 1);('extraneous information', 1);('intuitivelylearning', 1);('state difcult', 1);('desirable state', 1);('quality representations', 1);('setting credit assignment exploration andgeneralization', 1);('highlongterm reward', 1);('setting anagent', 1);('general reinforcement learning', 1);('introductionin', 1);('irrelevant information1', 1);('relevant state', 1);('strong performance improvements asthe learnt bottlenecks', 1);('real robot arm task ndthat', 1);('online ofine', 1);('effective bottleneck', 1);('representations introduce', 1);('exploiting', 1);('architecturesthat utilize variational discrete informationbottlenecks', 1);('presence task irrelevant information', 1);('construct latent states', 1);('irrelevant exogenous information work study information bottlenecks', 1);('sensory inputs', 1);('rich observations realworld applications', 1);('representation learningmethods', 1);('nycabstractseveral', 1);('technologyanirudh goyal nicolas heess alex lambgoogle deepmind google deepmind microsoft', 1);('virginia beijing', 1);('university university', 1);('montrealmd mojul islam samin yeasar arnob tariq iqbal xin liuniversity virginia mila mcgill', 1);('montrealmila', 1);('albertamicrosoft', 1);('amii', 1);('institute technology', 1);('montrealbeijing', 1);('discrete information bottleneckriashat islam hongyu zang manan tomar aniket didolkarmila mcgill universitymicrosoft', 1);('representation learning deep rl', 1);