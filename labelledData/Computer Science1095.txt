('rama vt', 24);('fig', 10);('mha', 9);('active visual', 8);('conv', 7);('international conference', 6);('fov', 4);('frame', 4);('sncoat', 3);('active visualtrackers', 3);('active visual tracker', 3);('pomdp', 3);('normse layer', 3);('vt', 3);('vtp', 3);('ael', 3);('deep reinforcement learning', 3);('acta astronautica', 3);('deep recurrent reinforcement learning', 2);('deep', 2);('preliminary work', 2);('wu', 2);('space noncooperative object', 2);('squeezeandexcitation', 2);('s1max poolbatch', 2);('s2max poolbatch', 2);('iii', 2);('recent years', 2);('pbvs', 2);('active visual trackers', 2);('drla vt', 2);('partiallyobservable problem', 2);('deep recurrentreinforcement learning', 2);('qnetwork', 2);('drqn', 2);('input', 2);('interpretability research', 2);('actaastronautica', 2);('feb', 2);('active spacedebris removal mission removedebris part', 2);('reinforcement learning', 2);('nature', 2);('zhong p sun', 2);('intelligence', 2);('p tiritiris n passalis tefas temporal difference rewardsfor endtoend visionbased active robot tracking', 2);('deep recurrent reinforcement learning active visual trackingof', 1);('noncooperative objectsdong zhou1 guanghui sun1\x03 zhao zhang1and ligang wu1abstract active', 1);('space noncooperative objectthat', 1);('relies vision camera', 1);('signicant forautonomous rendezvous debris removal', 1);('markov decision process pomdp', 1);('property paper', 1);('novel tracker', 1);('arbitrary space noncooperativeobject highfrequency nearoptimal velocity controlcommands', 1);('performance introduce', 1);('multihead attention mha', 1);('module andsqueezeandexcitation se layer', 1);('representative ability neural networkwith', 1);('extra computational cost', 1);('extensive', 1);('experimentsand ablation study', 1);('benchmark showthe effectiveness robustness method', 1);('withother stateoftheart algorithm source codes availableonhttpsgithubcomdongzhou1996ramavt', 1);('index terms active', 1);('recurrent reinforcement learning space noncooperative object', 1);('multiheadattentioni introductionwith', 1);('rapid development aerospace technologyspace noncooperative object', 1);('spacecraft space manipulator pursue anyspecic noncooperative target', 1);('vision camerahas', 1);('extensive attentions', 1);('essential intelligentonorbit service autonomous rendezvous 13space debris removal', 1);('powerful deep reinforcement learningdrl', 1);('eldslike video game', 1);('12and robotic manipulation', 1);('global optimal policy trainingwith millions trialanderrors experiencesin', 1);('sncoatbenchmark', 1);('drla vtin', 1);('aerospace domain', 1);('performance velocity control mode', 1);('multiple framesas input', 1);('mechanism onlydecreases control bandwidth', 1);('makesactive tracker', 1);('vulnerable perturbations eg imageblur actuator noise computational delaythis work', 1);('key rd program', 1);('ofchina grant 2019yfb13120011d', 1);('zhou g sun z zhao', 1);('department ofcontrol science', 1);('engineering harbin', 1);('institute technology', 1);('harbinchina', 1);('g sun', 1);('velocity controlmdp problem pomdp problemtargetchaserfig', 1);('active visual trackingto end', 1);('property space noncooperative object', 1);('consideration novel activevisual tracker', 1);('paper drivethe', 1);('spacecraft pursue arbitrary target highfrequency nearoptimal velocity control commands', 1);('ourmethod', 1);('accurate perception target positionand velocity', 1);('image input', 1);('timewhich benets recurrent neural network', 1);('rnnin rama vt', 1);('architecture establishes relationshipbetween longterm temporal', 1);('active visual trackerthat focus attention partial regions partial channelsof', 1);('information space noncooperative target end', 1);('multiheadattention module', 1);('layer 25in', 1);('small number modelparameters', 1);('representative ability neural network addition data augmentationmethods', 1);('enhance efciency', 1);('process generalization ability', 1);('active trackerthe contributions work paper', 1);('ondeep recurrent reinforcement learning', 1);('excellent performance', 1);('stateoftheart methodsarxiv221214304v1 csro', 1);('dec', 1);('normconv', 1);('excitation layer1x1xcmulti headattentionqy xqwsoftmaxomulti head attention modulefkwvwfffqqqkqvadd normfc1action', 1);('valueslstm 512fc2', 1);('fc3fig', 1);('maps image optimal velocity control command', 1);('thelstm module', 1);('longterm relationship temporal sequence', 1);('selayer', 1);('representative ability neural network\x0fmultihead attention module se layer adoptedinto', 1);('data augmentation ofwhich effectiveness', 1);('ablation studythis work proceeds', 1);('ii', 1);('works space noncooperative object', 1);('method indetail experiments analysis', 1);('sectioniv', 1);('conclusion section', 1);('vii r elated workvisual', 1);('hot topic computer visionsociety', 1);('wide applications', 1);('civil military andaerospace elds', 1);('passive methods', 1);('eld viewfov vision camera', 1);('limits possibilityto', 1);('visual object', 1);('aerospace applications thetarget', 1);('maneuvers 6degreesoffreedom', 1);('dof', 1);('andthe lowresolution camera', 1);('spacecraft hassmall', 1);('identiesthe target', 1);('changes pose chaser realtimeto', 1);('view contact target', 1);('traditional', 1);('pbvs ibvs', 1);('framework whichmodules eg keypoints detection', 1);('poseestimation controller design', 1);('separatelyin paper', 1);('spacerobotic manipulator grasp noncooperative target', 1);('photogrammetry adaptive extendedkalman lter', 1);('6dof pose target', 1);('unadaptable complex space environmentas', 1);('traditional active visual trackers', 1);('preliminary work 3that adapts stateoftheart 2d monocular', 1);('good active trackingperformance', 1);('concessionin realtime capabilitydeep reinforcement learning learns optimal actionpolicy endtoend manner millions trialanderrors experiences', 1);('great contributions manyelds video game', 1);('autonomous driving12 robotic manipulation', 1);('1422most aim terrestrial targets deploy', 1);('ground vehicle', 1);('ugvluo', 1);('rst endtoend activevisual tracker', 1);('a3c', 1);('pursuetwo person models', 1);('trajectory twotypes environments addition training progresstakes', 1);('performanceeven lowresolution image', 1);('\x0284\x023 paper37', 1);('ppo', 1);('learning framework', 1);('effectivelydecreases distance error', 1);('singletarget simulation environment', 1);('impossible track', 1);('target realworld scenarioin contrast method', 1);('types spacenoncooperative objects', 1);('space stations satellitesasteroids rockets return capsules successfullyguarantees generalization ability', 1);('rama vtthose', 1);('initialposition target', 1);('active trackers', 1);('real application endjeong', 1);('navigation exploration insight', 1);('target network', 1);('attn', 1);('policy track agile anomalous objectwith', 1);('target model method', 1);('egocentric maps visit frequencyto convolutional neural network', 1);('cnn', 1);('markov decision processmdp', 1);('dionigi', 1);('drlbased ev', 1);('targetdetection networkand', 1);('network explore theenvironment track target', 1);('terrestrial targets', 1);('active visual trackingtasks space noncooperative objects challenging1', 1);('complex6dof trajectory', 1);('available suchas geometry texture kinematic', 1);('dynamic parameters 3the images', 1);('vision camera spacecraft oftenlowquality', 1);('low resolution', 1);('cameramotion illumination variancein', 1);('rst activetracker', 1);('aerospace domain performance', 1);('large room', 1);('avoidedby framestack mechanism', 1);('decreasescontrol bandwidth', 1);('performance end wepropose novel', 1);('image tooptimal velocity control command', 1);('longtermtemporal relationship', 1);('rnn', 1);('addition themha module se layer', 1);('improvenetwork representative abilityiii', 1);('p roposed methodin', 1);('section formulate', 1);('active visual trackingproblem space noncooperative object describe ourrama', 1);('algorithm thoroughlya', 1);('problem formulationthe', 1);('task space noncooperative object', 1);('involves chaser', 1);('vision cameraand', 1);('information theprevious', 1);('images toreduce error etwhich', 1);('followset rbtt\x00r\x03 21in whichrbttis 3d position target thebodyframe chaser tth timestep r\x03denotesthe', 1);('distance chaser target thisworkr\x03is', 1);('complete task', 1);('drlbased', 1);('method befurther', 1);('problem tth timestep thestate target st2s', 1);('ot2o agent withvision camera agent', 1);('action at2a followinga policy greedy policy maxa2aqotathatis', 1);('article agent', 1);('receivea rewardrtfrom environment', 1);('bya reward function denition reward functionis', 1);('visibletermrvisand distance penalty term rdist', 1);('ot6st agent', 1);('actual state target', 1);('forthe velocityb', 1);('ramavt algorithmthe pomdp', 1);('active visual tracker difcult approximate optimalaction value function', 1);('q\x03otat', 1);('end proposea', 1);('longtermrelationship temporal sequence', 1);('map oneimage optimal velocity control commandmeanwhile', 1);('additional se layers', 1);('multihead', 1);('attention module', 1);('improvethe representative ability', 1);('approximatebetter action value function', 1);('qotat', 1);('se layer featuresthe', 1);('channelwise interdependencies', 1);('low computational cost schematicis', 1);('middle part', 1);('weplace', 1);('se layer', 1);('convolutional layer', 1);('convnetbackbonein', 1);('recent years selfattention mechanism', 1);('fromnatural language processing', 1);('appliedto computer vision', 1);('increases representation neural network images', 1);('moduleshown bottom', 1);('famousselfattention method', 1);('interrelationship ofdifferent positions', 1);('dotproduct attention algorithmyisoftmax\x12qiktipdk\x13vi 2whereqiwq\x01xikiwk\x01xi andviwv\x01xiare thethree', 1);('different fullconnectedfc layers', 1);('input xi anddkdenotes thedimension', 1);('ki based mha', 1);('asowo\x01concatfy1y2\x01\x01\x01yng 3in whichnis number heads', 1);('different representation subspaces', 1);('different positionsin parallel', 1);('heads worktable', 1);('active tracking performance comparisonnameinput format episode length episode reward speedrgbd depth color avg min max avg min max hzrandom', 1);('ii training congurationsparams value notereplay', 1);('size replay poolinitial buffer 10000the number initialexperiencesepisode num 300the number', 1);('qnetworkmax', 1);('episode len 1000the max length oneepisode target islost episode overupdate interval 10the update interval oftarget networkgamma', 1);('rewards', 1);('model loss', 1);('eoaro0\x18uh\x02y\x00qoa\x122\x034where', 1);('training data oaro0is', 1);('fromthe hierarchical memory pool', 1);('hproposed', 1);('moresuitable deep recurrent reinforcement learning methodsyr maxa02aqo0a0\x12\x00is', 1);('temporaldifference tdtarget', 1);('target network \x12\x00iv', 1);('e xperimentin', 1);('section rst validate', 1);('evaluation toolkit', 1);('sufcient ablationstudies', 1);('show theeffectiveness method', 1);('active visual trackers trackersfollows training congurations', 1);('iithe', 1);('experimental platform', 1);('hpc', 1);('intelxeone5', 1);('cpu nvidia tesla p100 gpua ramavt performancewe', 1);('train agent', 1);('types space noncooperativeobjects', 1);('different targets includingasteroids satellite rockets space station return capsule50', 1);('training curves', 1);('different active visual trackerstable', 1);('iii robustness evaluation differentperturbationsnameperturbations metricsactuatornoisetimedelayimageblurael aerdrla vtp', 1);('p p4563 7586rama', 1);('p7933 8101p p p5808', 1);('redsome data augmentations', 1);('crop ip cutoutand rotation', 1);('generalization abilitywhen trains', 1);('performance episodelength episode reward work utilize agentthat', 1);('action random baseline', 1);('drla vtalgorithm', 1);('comparisonall training curves', 1);('active visual trackers withuni0000003buni00000010uni00000015uni00000018uni00000003uni00000050uni00000010uni00000015uni00000013uni00000003uni00000050uni00000010uni00000014uni00000018uni00000003uni00000050uni00000010uni00000014uni00000013uni00000003uni00000050uni00000010uni00000018uni00000003uni00000050uni00000013uni00000003uni00000050uni0000003cuni00000013uni00000003uni00000050uni00000018uni00000003uni00000050uni00000014uni00000013uni00000003uni00000050uni00000014uni00000018uni00000003uni00000050uni00000015uni00000013uni00000003uni00000050uni0000003duni00000013uni00000003uni00000050uni00000018uni00000003uni00000050uni00000014uni00000013uni00000003uni00000050uni00000014uni00000018uni00000003uni00000050uni00000015uni00000013uni00000003uni00000050uni00000016uni00000027uni00000003uni00000057uni00000055uni00000044uni0000004duni00000048uni00000046uni00000057uni00000052uni00000055uni0000004cuni00000048uni00000056uni00000003uni00000053uni0000004funi00000052uni00000057uni00000056uni00000057uni00000044uni00000055uni0000004auni00000048uni00000057uni00000046uni0000004buni00000044uni00000056uni00000048uni00000055uni00000056uni00000057uni00000044uni00000055uni00000057uni00000003uni00000053uni00000052uni0000004cuni00000051uni00000057uni00000048uni00000051uni00000047uni00000003uni00000053uni00000052uni0000004cuni00000051uni00000057uni0000003buni00000013uni00000003uni00000050uni00000018uni00000003uni00000050uni00000014uni00000013uni00000003uni00000050uni00000014uni00000018uni00000003uni00000050uni00000015uni00000013uni00000003uni00000050uni00000015uni00000018uni00000003uni00000050uni0000003cuni00000010uni00000017uni00000013uni00000003uni00000050uni00000010uni00000016uni00000018uni00000003uni00000050uni00000010uni00000016uni00000013uni00000003uni00000050uni00000010uni00000015uni00000018uni00000003uni00000050uni00000010uni00000015uni00000013uni00000003uni00000050uni00000010uni00000014uni00000018uni00000003uni00000050uni00000010uni00000014uni00000013uni00000003uni00000050uni00000010uni00000018uni00000003uni00000050uni00000013uni00000003uni00000050uni0000003duni00000013uni00000003uni00000050uni00000015uni00000003uni00000050uni00000018uni00000003uni00000050uni0000001auni00000003uni00000050uni00000014uni00000013uni00000003uni00000050uni00000014uni00000015uni00000003uni00000050uni00000014uni00000018uni00000003uni00000050uni00000014uni0000001auni00000003uni00000050uni00000015uni00000013uni00000003uni00000050uni00000016uni00000027uni00000003uni00000057uni00000055uni00000044uni0000004duni00000048uni00000046uni00000057uni00000052uni00000055uni0000004cuni00000048uni00000056uni00000003uni00000053uni0000004funi00000052uni00000057uni00000056uni00000057uni00000044uni00000055uni0000004auni00000048uni00000057uni00000046uni0000004buni00000044uni00000056uni00000048uni00000055uni00000056uni00000057uni00000044uni00000055uni00000057uni00000003uni00000053uni00000052uni0000004cuni00000051uni00000057uni00000048uni00000051uni00000047uni00000003uni00000053uni00000052uni0000004cuni00000051uni00000057a', 1);('trajectoriesuni00000013 uni00000015uni00000013uni00000013 uni00000017uni00000013uni00000013 uni00000019uni00000013uni00000013 uni0000001buni00000013uni00000013 uni00000014uni00000013uni00000013uni00000013uni00000057uni0000004cuni00000050uni00000048uni00000056uni00000057uni00000048uni00000053uni00000056uni00000014uni00000011uni00000013uni00000013uni00000011uni00000018uni00000013uni00000011uni00000013uni00000013uni00000011uni00000018uni00000014uni00000011uni00000013uni00000048uni00000055uni00000055uni00000052uni00000055uni0000003buni00000013 uni00000015uni00000013uni00000013 uni00000017uni00000013uni00000013 uni00000019uni00000013uni00000013 uni0000001buni00000013uni00000013 uni00000014uni00000013uni00000013uni00000013uni00000057uni0000004cuni00000050uni00000048uni00000056uni00000057uni00000048uni00000053uni00000056uni00000016uni00000015uni00000014uni00000013uni00000048uni00000055uni00000055uni00000052uni00000055uni0000003cuni00000013 uni00000015uni00000013uni00000013 uni00000017uni00000013uni00000013 uni00000019uni00000013uni00000013 uni0000001buni00000013uni00000013 uni00000014uni00000013uni00000013uni00000013uni00000057uni0000004cuni00000050uni00000048uni00000056uni00000057uni00000048uni00000053uni00000056uni00000015uni00000017uni00000019uni00000048uni00000055uni00000055uni00000052uni00000055uni0000003duni00000016uni00000027uni00000003uni00000048uni00000055uni00000055uni00000052uni00000055uni00000003uni00000053uni0000004funi00000052uni00000057uni00000056b', 1);('depth maps', 1);('rama vt depth', 1);('imagedifferent inputs', 1);('nd learning progresses', 1);('drla vts', 1);('rama vtswhatever', 1);('input format', 1);('qnetworkarchitecture', 1);('observable state addition depthinformation', 1);('inputs signicant activevisual trackers', 1);('episode length', 1);('depth map color image', 1);('whole evaluation results', 1);('tablei', 1);('depth map asinput', 1);('average episode length 9591score', 1);('realtime performance', 1);('thatour method', 1);('track target', 1);('minimum episode length', 1);('provesthe stability', 1);('accuracyie average episode reward', 1);('drla vtwe', 1);('results inaccurate targets states astarget position velocity', 1);('basedon recurrent neural network problem', 1);('whenthe agent', 1);('color images', 1);('inthe nal row', 1);('iwe', 1);('rama vt fig', 1);('itcan', 1);('4a method', 1);('trackthe target', 1);('whole episodes', 1);('particular trackingerrors', 1);('x z', 1);('small range', 1);('4b noncooperativetarget', 1);('fast highspeedrotationfurthermore', 1);('tracker underthree types perturbations', 1);('actuator noise timedelay image blur show robustness methodthe experiment results', 1);('perturbations inuences activevisual', 1);('performance terms', 1);('period andaccuracy', 1);('time delay decreases the50', 1);('training curves ablation modelstable', 1);('iv ablation', 1);('rama vt rgbd', 1);('ael aer speedorigin', 1);('2027average episode length', 1);('isbecause inconsistency target velocity', 1);('random time delayin training stage target velocity', 1);('types perturbationswork', 1);('robuster thedrla', 1);('b 1st', 1);('g 1st', 1);('drla vt rama vt', 1);('rows worthwhile', 1);('rst frame', 1);('ablation studyto', 1);('show effectiveness', 1);('data augmentations se layer', 1);('scratch trainingcongurations training curves', 1);('accelerates learning progress agent', 1);('improves episode length advancementattributes attention', 1);('sensitive accurate themovement targetthe nal evaluation results ablation models', 1);('iv', 1);('module achievesthe', 1);('ael aer', 1);('otherswhich decreases', 1);('speed se layer alsoincreases', 1);('times almostno realtime performance loss addition data augmentation algorithms', 1);('crop cutoutip rotation work', 1);('notinduce computational burden evaluation stagein word', 1);('excellent active visual', 1);('performance lesscomputational cost', 1);('spatialwise andchannelwise attention mechanism', 1);('mhamodule', 1);('se layersc', 1);('interpretability researchwe', 1);('utilize neural network interpretability method40 summarizes squares activation values alongchannelwise axis', 1);('softmax', 1);('operationto explore', 1);('layer neuralnetwork', 1);('6a6e illustrates', 1);('different levels', 1);('architecture contains 4convolutional blocks convolutional block involves aconvolutional layer batchnormalization layer', 1);('reluactivation', 1);('function worthwhile', 1);('drla vtstacks', 1);('consecutive frames channelwise', 1);('inputhowever rst frame', 1);('weclearly', 1);('rst convolutional block extracts allthe edges target generates', 1);('value tothe', 1);('white body noncooperative target', 1);('convolutional block enhances reactions parts ofedges', 1);('subsequent convolutional blocks highlevel', 1);('specic implications', 1);('thenal', 1);('convnet', 1);('point lightsource', 1);('gaussian', 1);('distributionin comparison visualization', 1);('signicant differences thebackbone', 1);('rama vt drla vt', 1);('se layer addedinto rst', 1);('convolutional blocks', 1);('convnetbackbone', 1);('rstconvolutional block', 1);('focus object color', 1);('fig6b', 1);('convolutional block', 1);('contour noncooperative target', 1);('furthermorethe', 1);('distribution nal output', 1);('compact causedby', 1);('estimate accurateaction valuev c', 1);('onclusionin', 1);('paper formulate', 1);('active visual trackingtask space noncooperative object', 1);('active tracker', 1);('multiheadattention', 1);('spacecraft toapproach arbitrary space noncooperative target optimaland', 1);('velocity control commands advancement', 1);('sufcient experiments', 1);('stateoftheart method', 1);('drla vtto', 1);('show effectiveness method', 1);('ablation study', 1);('architecture additionwe', 1);('activevisual trackers explore', 1);('k hovell ulrich deep reinforcement learning spacecraftproximity operations guidance', 1);('spacecraft rockets jan', 1);('x zhao r emami zhang imagebased', 1);('control forrendezvous synchronization', 1);('space debris', 1);('zhou g sun', 1);('lei', 1);('space noncooperative objectactive', 1);('ieee transactionson aerospace electronic systems', 1);('p huang', 1);('zhang j cai wang z meng j guo dexteroustethered', 1);('robot', 1);('measurement', 1);('experiment ieee transactions aerospace electronic systems', 1);('june', 1);('forshaw g aglietti fellowes salmon retat hallt chabot pisseloup tye', 1);('bernal', 1);('concept launchacta', 1);('astronautica', 1);('g aglietti', 1);('taylor fellowes salmon retat hallt chabot pisseloup', 1);('cox mafcini', 1);('orbit operations', 1);('floresabad k pham ulrich', 1);('review spacerobotics technologies onorbit', 1);('aerospacesciences', 1);('july', 1);('fourie', 1);('e tweddle ulrich saenzotero', 1);('flight results', 1);('navigation autonomous spacecraft inspectionof', 1);('unknown objects journal spacecraft rockets vol', 1);('wj li dy cheng xg liu', 1);('wang wh shi zx tangf gao fm zeng hy chai wb luo', 1);('onorbit', 1);('serviceoos spacecraft review engineering developments', 1);('progressin aerospace', 1);('v mnih k kavukcuoglu silver', 1);('humanlevel', 1);('silver huang', 1);('j maddison guez', 1);('masteringthe', 1);('deep neural networks tree search', 1);('jan', 1);('r kiran sobh v talpaert p mannion al sallab yogamani p p', 1);('ieee transactions intelligent transportationsystems', 1);('singh r kumar v p singh reinforcement', 1);('learning inrobotic applications', 1);('comprehensive survey', 1);('articial intelligencereview', 1);('luo p sun', 1);('zhong', 1);('liu zhang wang endtoendactive object tracking', 1);('reinforcement learning internationalconference machine learning july', 1);('g cruciata', 1);('lo presti', 1);('cascia', 1);('deepreinforcement learning visual tracking survey ieee access', 1);('devo dionigi g costante enhancing', 1);('continuous controlof', 1);('mobile robots endtoend visual', 1);('robotics', 1);('systems', 1);('luo yan wang adv anasymmetric dueling mechanism learning understandingvisual active tracking ieee transactions pattern analysis', 1);('may', 1);('heejin jeong h hassani morari lee g j pappasdeep reinforcement learning active target tracking', 1);('robotics automation icra', 1);('luo yan wang towards', 1);('machinelearning', 1);('emergingtechniques computational intelligence icetci', 1);('dionigi devo', 1);('guiducci g costante ev anasymmetric endtoend approach visual active exploration', 1);('ieee robotics automation', 1);('letters vol', 1);('xi zhou z chen', 1);('zhou h li antidistractor activeobject tracking', 1);('environments ieee transactions circuitsand systems video', 1);('technology vol', 1);('zhou', 1);('vaswani n shazeer n parmar j uszkoreit', 1);('jones ngomez kaiser polosukhin attention', 1);('needadvances neural information processing systems vol', 1);('j hu', 1);('shen albanie g sun e wu squeezeandexcitation', 1);('ieee transactions pattern analysis', 1);('laskin k lee stooke', 1);('pinto p abbeel srinivasreinforcement', 1);('advances', 1);('neuralinformation processing systems vol', 1);('x chen', 1);('yan j zhu wang x yang h lu transformertracking proceedings ieeecvf', 1);('computervision pattern recognition', 1);('ondra', 1);('p tar', 1);('siamese visual object tracking asurvey ieee access', 1);('name ieee access29 zhou g sun j', 1);('song w', 1);('yao', 1);('algorithm general space noncooperative objects', 1);('nov', 1);('hu x zhao', 1);('huang k huang global', 1);('ieee transactions patternanalysis machine intelligence', 1);('dunnhofer furnari g farinella', 1);('micheloni visual', 1);('rst person vision', 1);('international journal ofcomputer', 1);('vision', 1);('g dong z h zhu autonomous', 1);('noncooperative target adaptive', 1);('kalman lter', 1);('sun z zheng adaptive', 1);('relative pose control spacecraftwith model couplings uncertainties', 1);('vol 143pp', 1);('j liu h li luo j zhang robust', 1);('relative positionand attitude', 1);('uncontrolled tumblingspacecraft', 1);('proceedings institution mechanical engineerspart g', 1);('aerospace engineering', 1);('li j yan', 1);('wu z zhu x hu', 1);('high performance', 1);('siamese region proposal network', 1);('proceedings', 1);('theieee conference computer vision pattern recognition 2018pp', 1);('v mnih p badia mirza graves', 1);('asynchronousmethods deep reinforcement learning', 1);('machine learning pmlr june', 1);('emerging techniques computational intelligence icetci', 1);('virtual india202138 j schulman', 1);('wolski p dhariwal radford klimovproximal policy optimization algorithms', 1);('arxiv170706347 cs', 1);('aug', 1);('hausknecht p stone deep', 1);('partiallyobservable mdps', 1);('aaai fall symposium series', 1);('zagoruyko n komodakis paying', 1);('performance convolutional neural networks viaattention', 1);('learning representations', 1);