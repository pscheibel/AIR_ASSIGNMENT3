('vits', 61);('fig', 20);('beitl', 20);('vitl', 19);('lsbs', 18);('august', 17);('latex class files vol', 15);('cityscapes', 14);('r101', 13);('lhfs', 10);('computer vision', 10);('swinl', 10);('sasm', 9);('ade20k', 8);('ablation', 8);('semantic segmentation', 7);('twopathway network', 7);('cnns', 7);('vitb', 7);('proceedings', 7);('segmenter', 6);('vit', 6);('visualized', 6);('pascal context', 5);('cnn', 5);('lsb', 5);('lmb', 5);('gflops', 5);('vitly', 5);('computer vision pattern recognition', 5);('proceedings ieeecvf', 5);('specially', 4);('segmentation results', 4);('huang', 4);('sasms', 4);('vitaugreg', 4);('beitb', 4);('cswins', 4);('10\x02lr af', 4);('segmentation maps', 4);('springer', 4);('decoupledtwopathway network', 3);('vits cityscapes', 3);('longrange context', 3);('mlp', 3);('inspired', 3);('cnns vits', 3);('small thin objects', 3);('small objects', 3);('encoder', 3);('mitb5', 3);('stateoftheart', 3);('proceedings ieee', 3);('theieeecvf conference', 3);('eccv', 3);('ieee', 3);('international conference', 3);('adaptive separation module', 2);('dosovitskiy', 2);('different categories', 2);('deit', 2);('imagenet', 2);('imagenet1k', 2);('dense prediction', 2);('following', 2);('cnnbased', 2);('comparisons', 2);('local information', 2);('previous methods', 2);('natural corruptions', 2);('challenging scene', 2);('mask transformer', 2);('upernet', 2);('representational capacity', 2);('semantic segmentation methods', 2);('softmax', 2);('patch embeddings', 2);('output rst', 2);('oplocal', 2);('l2normalized', 2);('corresponding region', 2);('loss patchtoregion', 2);('coco', 2);('mmsegmentation', 2);('cswin', 2);('beit', 2);('crop size', 2);('pascalcontext', 2);('cocostuff10k', 2);('rssegvitb', 2);('performance gain', 2);('rscswint', 2);('flops', 2);('rssegvitl', 2);('previous stateoftheart methodby', 2);('edge loss', 2);('performance', 2);('singescale', 2);('setrpup', 2);('mask2former', 2);('test resolution', 2);('ms', 2);('segformerb5', 2);('segvit', 2);('vitadapterupernet', 2);('vitadapterupernet beitl', 2);('convnextl', 2);('strong robustness', 2);('gscnn', 2);('val setthe gures', 2);('top input images groundtruths segmentation maps', 2);('vision', 2);('vision transformer', 2);('ieeecvf', 2);('proceedings ieeecvfconference computer vision pattern recognition', 2);('ieee transactions patternanalysis machine intelligence', 2);('j gu h kwon wang', 2);('ye li yh chen', 2);('conference computer vision patternrecognition pp', 2);('huang kang', 2);('jia x', 2);('yu j wang', 2);('deep', 2);('proceedings ieeecvf conferenceon computer vision pattern recognition', 2);('proceedings ieeeconference', 2);('computer vision pattern recognition pp', 2);('journal latex class files vol', 1);('separation semanticsegmentation vision transformersyuanduo hong huihui pan member ieee weichao sun senior member ieee xinghu yu huijungao fellow ieeeabstract vision', 1);('image sequence patches', 1);('new paradigms semantic segmentationwe', 1);('present efcient framework representation separation localpatch level globalregion level semantic segmentationwith', 1);('peculiar oversmoothness', 1);('current popularparadigms context', 1);('advantage attention rst', 1);('pathway enhances passes localpatch discrepancy', 1);('complementary globalrepresentations transformers', 1);('separate deeprepresentations discriminative crossattention yields discriminative region representations novel auxiliarysupervisions', 1);('impressive results', 1);('new stateoftheart performances', 1);('new record', 1);('representations framework', 1);('favorable transferabilityin images', 1);('natural corruptions codes', 1);('terms semantic', 1);('segmentation vision transformer representation separationf1', 1);('ntroductionsemantic', 1);('image understanding indispensablefor', 1);('promising technologies applications', 1);('medical image processing environment perceptionof autonomous vehicles robots key semanticsegmentation', 1);('labels pixels', 1);('fcn', 1);('seminal workutilizes convolutional neural networks', 1);('dense labels pixels farreachinginuence followup', 1);('previous', 1);('multiscalecontext plays signicant role highaccuracy semanticsegmentation', 1);('deeplab', 1);('introducesdilation convolutions semantic segmentation', 1);('receptive elds vanilla convolutions withoutextra computation', 1);('larger', 1);('convolutional kernels', 1);('powerful tools establishlongrange', 1);('selfattention mechanism', 1);('global dependencies', 1);('captures thecontextual information semantic segmentation', 1);('works introduce transformer', 1);('selfattention modules', 1);('layersfor vision tasks shows', 1);('great potential', 1);('intact encoder module image classication', 1);('pure transformerarchitecture mass training data rst', 1);('theimage patches generate', 1);('token embeddings', 1);('atrainable linear projection', 1);('position', 1);('embeddings learn\x0fthe authors research institute', 1);('intelligent', 1);('systems harbin', 1);('institute technology', 1);('harbin', 1);('china', 1);('emailhjgaohiteducncnnvitpixel embeddings pixel embeddingspatch embeddings patch embeddingsmask embeddings mask embeddingsfig', 1);('comparison representation separation', 1);('cnns therepresentations', 1);('dispersive dueto', 1);('receptive elds context', 1);('discriminative representations reducingthe intraclass variances', 1);('compared cnns', 1);('closeto distinguish', 1);('methodsseparate representations', 1);('small intraclass variancesarxiv221213764v1 cscv', 1);('dec', 1);('positional informationand generate classication results', 1);('impressive accuracy', 1);('ontop', 1);('fundamental architecture improvementslike pyramid', 1);('windows proposed13', 1);('powerfulvit backbones semantic segmentation', 1);('impressive performances image classicationand intrinsic', 1);('fancy decodersalthough vision transformers', 1);('excellenttransferability semantic segmentation essentialdifferences image classication', 1);('routine extra components', 1);('withmultiscale representations attention variants', 1);('performance transformer basedsemantic segmentation', 1);('thatvision transformers', 1);('rethink segmentation transformers', 1);('new perspective', 1);('works analyzethe', 1);('maps transformers image classicationtasks', 1);('light lowpass characteristic selfattention high similarity patch embeddings', 1);('semantic segmentation models transformerssuffer', 1);('smooth segmentation', 1);('corresponding results', 1);('insection 31in paper explore efcient solutions theviewpoint representational discrimination', 1);('throughthe', 1);('representational discrepancy', 1);('signicant semanticsegmentation', 1);('due blurry', 1);('maps andsuppose discrepancy', 1);('data downstreamtasks', 1);('efcient utilization', 1);('vision transformers', 1);('transformer backbone design fromdownstream tasks', 1);('general architectureof', 1);('reasons thehigh similarity patch embeddings lowresolution', 1);('maps rst layer', 1);('global lters end weintroduce representation separation framework consist ofthree novel components extract local discrepancy ofpatch embeddings', 1);('twopathwaynetwork contains', 1);('local separation path enhanceand pass localpatch discrepancy', 1);('local separation blocks', 1);('thelearnable highpass lters', 1);('separate local patchembeddings', 1);('local discrepancyinto', 1);('rich representations', 1);('fusion af', 1);('local information fromthe', 1);('global representations yields enhancedglobal representations', 1);('local details', 1);('adaptiveseparation module', 1);('guides representationseparation nal output local information of8215834555255986536748503519950115104cityscapes', 1);('ade20k pascal context cocostuff10k cocostuff164k5060708090previous sotaour', 1);('previous stateoftheart methodson benchmarks results', 1);('vitl26', 1);('multiscale testthe', 1);('convertthe output local separation path', 1);('patch embeddings expandthe resolution pixel shufe discrepancy patchembeddings', 1);('due guidanceof', 1);('learnable queries', 1);('dynamic mask embeddings extraplain', 1);('layers nal segmentation masks', 1);('simple matrix multiplication mask embeddings patch embeddings', 1);('proposethe discriminative crossattention', 1);('querypay attention', 1);('corresponding region keysthrough', 1);('novel auxiliary supervisions', 1);('mask embeddings', 1);('loss lets query vector', 1);('loss ensures discrimination keys', 1);('finallythe', 1);('framework incorporates', 1);('local representationseparation patch embeddings', 1);('global representationseparation mask embeddings', 1);('representation separationframework largescale', 1);('rssegvitand', 1);('benchmarks iecityscapes', 1);('ade20k pascal context cocostuff10k', 1);('experimental results', 1);('new stateoftheart accuracy vedatasets', 1);('powerfulselfattention baselines', 1);('distinct segmentation maps', 1);('knowledge performsbetter', 1);('muchmore cumbersome models', 1);('previous stateoftheart results', 1);('natural corruptions proposedmethod', 1);('pure attention networksour contributions', 1);('follows\x0fwe rethink semantic segmentation', 1);('adifferent perspective', 1);('efcient framework representation separation localpatchjournal', 1);('3level globalregion level', 1);('knowledgewe rst', 1);('study representationseparation semantic segmentation', 1);('vits\x0fthe', 1);('toenhance localpatch discrepancy relativelysmooth', 1);('maps incorporates', 1);('novellearnable highpass lters', 1);('fusion mechanism\x0fthe', 1);('separate deep representationsit utilizes localpatch discrepancy', 1);('therepresentation separation output lasttransformer layer\x0fto', 1);('discriminative mask embeddingsdiscriminative crossattention', 1);('ensurethe discriminative', 1);('queries keysby', 1);('novel auxiliary', 1);('new stateoftheart accuracy onve benchmarks', 1);('backbone weachieve', 1);('numerous smallthin objects\x0fthe robustness', 1);('vitsis', 1);('representation separation framework', 1);('pureattention networks2', 1);('r elated work21 vision transformersvit', 1);('great success', 1);('original transformersto vision tasks whereas', 1);('huge model complexity andneeds', 1);('hundreds millions imagesdeit', 1);('alleviates problem', 1);('wang', 1);('liu', 1);('thehierarchical vision transformers', 1);('various pixellevel', 1);('dense prediction tasks', 1);('numerous', 1);('architectural improvements', 1);('introduce locality', 1);('global attention', 1);('inspired hrnet yuan', 1);('32propose highresolution multibranch transformers', 1);('guet', 1);('efcient variants achievethe stateoftheart performance', 1);('inthe', 1);('training recipes', 1);('scalable vision learners', 1);('35these improvements training recipes learning patternsgive birth', 1);('big transferability tosemantic segmentation example', 1);('extra bells whistlesour method', 1);('remarkable performance gains uponstrong baselines addition designs', 1);('cost methodmay substitute methods', 1);('imagenet22 semantic segmentation vitszheng', 1);('rst explore', 1);('setr', 1);('stateoftheart performance', 1);('tasks thattime', 1);('ranftl', 1);('ushaped', 1);('dense visiontransformers encoders', 1);('vits vithybrid', 1);('convolutional layers', 1);('segmenter18', 1);('input theoutput', 1);('learnable class embeddings', 1);('segmentation masks', 1);('xie', 1);('convolutional embeddings efcient selfattention', 1);('\x023 depthwiseconvolutions feed', 1);('ffn benetting', 1);('representational capacity longrange', 1);('process vision transformers stateoftheart methods', 1);('directlyconcatenate multiresolution', 1);('asimple decoder', 1);('specic methods forsemantic segmentation', 1);('selfattention crossattention module design extractingricher contextual information utilize multiscale featuresto', 1);('inspired detr37', 1);('classication maskprediction', 1);('semantic instance segmentationare', 1);('stateoftheart results', 1);('outwhat semantic segmentation', 1);('otherthan', 1);('aforementioned works', 1);('oversmoothness transformer backbones', 1);('simple andeffective methods', 1);('different perspective', 1);('representation separation', 1);('context modeling23', 1);('semantic segmentation cnnsahead', 1);('vision transformers accuracy semanticsegmentation', 1);('architectures training settings', 1);('cnnsfrom', 1);('early encoderdecoder structure', 1);('thedilation backbone', 1);('modulesare helpful supplements', 1);('due locality convolutionoperations', 1);('pyramid', 1);('atrousspatial pyramid pooling aspp', 1);('large', 1);('kernel convolution rst', 1);('due largecomplexity', 1);('selfattention modules theirvariants', 1);('addition context', 1);('lowresolutionfeatures class efcient methods', 1);('rening', 1);('segmentation boundary', 1);('ofspecic supervision', 1);('effective ne segmentation scenarios', 1);('hand vision transformers', 1);('capacity hand', 1);('fusion methods boundary renement methods', 1);('valid highjournal', 1);('vitsare', 1);('differsfrom methods', 1);('coherent representations', 1);('enhance theconsistency', 1);('highresolution representations24', 1);('representation separationas', 1);('recent works focus', 1);('high similarity ofpatch embeddings', 1);('highfrequency information', 1);('appliedto image classication task improvements semantic segmentation', 1);('backbones example', 1);('gong', 1);('reducethe similarity patch embeddings possiblyimpairs intraclass consistency', 1);('threeloss functions', 1);('intraclass variance maximizeinterclass separation semantic segmentation workdiffers work terms motivations methodsand implementation technologies', 1);('aim useclasslevel information', 1);('signicance ofrepresentation separation semantic segmentation withvits addition ignore', 1);('discrepancy oflocal regions framework', 1);('account thediscrepancy local patch embeddings', 1);('global regionembeddings', 1);('theinterclass similarity', 1);('direct supervision', 1);('isvery difcult dene interclass similarity', 1);('onthe', 1);('effective architectures', 1);('ethodsince', 1);('backbones werst review', 1);('current vision transformers analyze theimmanent', 1);('introducethe details', 1);('framework representation separation context vision transformers', 1);('components respectively31', 1);('review vision transformersthe', 1);('introduction vision transformers basicmodule multihead selfattention', 1);('msa', 1);('new opportunities theeld', 1);('preactivationtransformer layer', 1);('lnxin', 1);('gelu mlp lnz', 1);('ln', 1);('layer normalization', 1);('geluis', 1);('gaussian error linear', 1);('unit 54among multihead selfattention mechanism isthe key point', 1);('1d embeddingsequence', 1);('xand', 1);('position encodings input 2d featuremaps', 1);('1d sequence rstlytable', 1);('segmentation results smallthin objects', 1);('valsetmiou sis average accuracy', 1);('small objectsall model weights', 1);('open sourcetoolbox', 1);('segformerb2 cswint', 1);('whichwe train crop size', 1);('\x02768modelmioupoletlightsignpersonridermotorbikemiou spspnetr50', 1);('qk v2rbncqxw q kxw k vxw v', 1);('wqwk wvare', 1);('learnable parameters linearprojection layers', 1);('multihead', 1);('q k v', 1);('qktpdkv', 1);('3where dkis dimension', 1);('memory cost andcomputational complexity process', 1);('n2', 1);('sequence patch', 1);('convolutional layerwe', 1);('patch similarity', 1);('architectural characteristics drasticreduction', 1);('resolution rst layer completelyglobal', 1);('lowpass attention weights', 1);('positive attention', 1);('memory cost computational complexity efcient selfattention variants', 1);('k v', 1);('patch embeddingsinto', 1);('multiple small sequences', 1);('based', 1);('vitsgradually', 1);('aggregate spatial tokens selfattentionblocks utilize convolutional operations', 1);('location information', 1);('maps inthe', 1);('stage locality', 1);('performance plainvits', 1);('oversmoothness possiblystill exists locality', 1);('posterior selfattention blocksgiven', 1);('smooth representations', 1);('smoothness existingsemantic segmentation methods', 1);('plainvits pyramid', 1);('datasets ie', 1);('cityscapes ade20k', 1);('mediatelyreects degree smoothness', 1);('inuence model capability andcritical training settings', 1);('principles 1the overall accuracy models', 1);('allthe', 1);('model weights', 1);('open sourcetoolbox 55modelmiouvaseclockshowerlightstreetlightsconceashcanmiou sdlv3r101', 1);('414a b c efig', 1);('layer oncityscapes', 1);('image', 1);('pspnetr50', 1);('setrpupld dlv3r101', 1);('segformerb2 zoom', 1);('crop sizes consistent', 1);('previous works andfor', 1);('objects accordingto average sizes', 1);('entire dataset', 1);('bad small objectssegmentation', 1);('itindicates vit', 1);('3in addition', 1);('interesting discovery', 1);('representation separation frameworksince', 1);('oftensuffer oversmooth segmentation maps introduce anovel framework incorporates localpatch representation separation globalregion representation', 1);('byselfattention crossattention321', 1);('localpatch', 1);('representation separationwe dene patchlevel representational discrepancy thediscrepancy', 1);('local regionit', 1);('fact pixels', 1);('local region nearthe semantic boundary need', 1);('differentcategories patchlevel representation separation shouldbe', 1);('local patch embeddingsand source localpatch discrepancy', 1);('rich texturesof shallow', 1);('certainamount noise', 1);('local information fromsmooth', 1);('maps transformers suppress thenoise', 1);('twopathway networkas', 1);('layer rst generate', 1);('sequence ofpatch embeddings', 1);('layer initializationas vanilla patch', 1);('layer outputs', 1);('\x02longersequence upsample outputs transformer layers bilinear interpolation', 1);('fusion ina', 1);('addition topdown enhancementpath', 1);('representations bottomup way', 1);('different', 1);('rich semantics spatial cues sametime', 1);('adaptive separationmodule utilizes shallow local discrepancy toguide localpatch separation', 1);('separate patch embeddings ina local region', 1);('adaptive weights formulatedby output', 1);('maps 14image resolutionin addition', 1);('twopathway network pyramid', 1);('output rst stage input thelocal separation path upsample output thesecond stage', 1);('maps thirdstage', 1);('subsequent fusion', 1);('mapsof pyramid resolutions', 1);('thenal segmentation predictions', 1);('mlplayers', 1);('binary boundary supervision', 1);('lsbs322 globalregion', 1);('representation separationfor', 1);('learnable queries paradigm nal segmentationmasks', 1);('matrix multiplication patchembeddings mask embeddings', 1);('learnable queries interact patchembeddings', 1);('mask embeddings canbe', 1);('regionlevel representations becauseeach contains', 1);('global information', 1);('semantic region discrepancy region representationsis', 1);('important nal mask predictions canbe', 1);('patch embeddingsand mask embeddings suppose discrepancyis', 1);('maps andglobal', 1);('problem wepropose discriminative crossattention', 1);('thevanilla crossattention transformer decoder utilizesextra optimization objectives', 1);('discriminative mask embeddings323', 1);('architectural', 1);('congurations architecturalhyperparameters', 1);('input dimensionjournal', 1);('6afaf af', 1);('afa representation', 1);('local patch separation pyramid', 1);('vitsaf18116141418116132af afsasm sasmtransformer', 1);('decoderqueriesmask embeddingsmlpmlp18 14bsconcat14afbs', 1);('boundary supervisionfig', 1);('overview methods', 1);('blue blocks', 1);('yellow blocksdenote', 1);('transformer layers', 1);('box denotes module', 1);('congurations architecture hyperparameters', 1);('layers', 1);('depth conguration thebackbone', 1);('sample outputs transformer blocks forsimplicitybackbone', 1);('layers sampling', 1);('input', 1);('expand', 1);('ratio group number group dimcswint', 1);('cswinb', 1);('group number group dimof', 1);('indices intermediate layersnote netune hyperparametersand use', 1);('common congurations33', 1);('decoupled twopathway network331', 1);('local separation blockwe dene process local separation block followingthe inverse residual block', 1);('normalization andactivation layers', 1);('conv', 1);('1\x021oplocalconv 1\x021x x 4where', 1);('depthwise local operatorsin patch', 1);('theabove formulas', 1);('plays signicant role enhancingthe localpatch discrepancy', 1);('vanilla depthwiseconvolutions', 1);('local similarity', 1);('edge extraction lters', 1);('learnablehighpass lters', 1);('enhance local discrepancyby', 1);('sum kernel weights zero', 1);('aconvolution kernel arbitrary weights rst applythesoftmax function kernel dimension makethese weights', 1);('zerosum weightskernel high\x00passsoftmax kernel \x0010kernel size5where kernel size denotes size convolution kernel paper use', 1);('\x025 convolution whichkernel sizeis', 1);('batchnorm layernorm', 1);('highpass lters offset thelimitation kernel weight values', 1);('softmax function332', 1);('attentionguided', 1);('fusionthe enhancement local discrepancy', 1);('producesundesirable noise', 1);('receptive eldsto suppress noise', 1);('attentionguidedfeature fusion mechanism', 1);('fuses localdiscrepancy', 1);('gpxgi\x03xliupxgi8attn\x01 sigmoid bnconv', 1);('bn\x019where xlidenotes', 1);('map ith', 1);('lmbxgidenotes', 1);('map fromthe transformer backbone', 1);('gp', 1);('relationship', 1);('twopathway methodsthere twopathway methods', 1);('cnnera', 1);('appealingin realtime semantic segmentation', 1);('performances methods', 1);('fall behindmethods', 1);('dilation backbones', 1);('hrnets differentfrom', 1);('method centers', 1);('thelocal discrepancy', 1);('textural informationgatedscnn', 1);('work utilizes', 1);('focus onlyon', 1);('maps middle shapestream attempts', 1);('semantic boundary byglobal operations contrary', 1);('mergefeature maps selfattention backbones', 1);('mechanism enhance', 1);('information local highpass lters', 1);('local features', 1);('rich features', 1);('enhances localpatchdiscrepancy', 1);('smooth representations differentfrom', 1);('gatedscnn', 1);('local pathbetter focus itself34', 1);('spatially adaptive separation modulethe', 1);('linear projection patch', 1);('layer actuallyencodes structural information image patches intothe channel dimension patch embeddings localseparation block outputs', 1);('oftransformers incorporate local information anddiscrepancy', 1);('thechannel dimension', 1);('patch embeddings ofmlpmlppixel shuffleconvolution operationsoftmaxreshapeflocalfglobalfig', 1);('adaptive separation modulelsbs spatial lters', 1);('corresponding local patch embeddings', 1);('global representationsas', 1);('mlplayer', 1);('dimension reshape', 1);('function spatiallter constrain weight valuessafb433hw', 1);('softmax reshape mlp flocal10where saf', 1);('adaptive lter', 1);('flocal', 1);('common interpolation methods generate', 1);('new pixels', 1);('pixelswe use', 1);('spatial lters', 1);('\x023 local region togenerate', 1);('new patch embeddings', 1);('red box', 1);('double featureresolution pixel shufefbc 2h2wglobal 2\x02', 1);('pixelshuffle fglobalsaf', 1);('11wheredenotes convolution operation', 1);('fglobal2rbchwis', 1);('global representation newpatch embeddings', 1);('due tothe guidance local information', 1);('resolution increase representational capacity furthergroup', 1);('channel dimension learnthe spatial lters', 1);('asshown fig', 1);('utilizes outputof', 1);('nal output ofthe transformer', 1);('guidancefeature resolution', 1);('convolution stride', 1);('sasmthen', 1);('secondsasm output penultimate', 1);('asthe guidance', 1);('nal patch embeddings tocalculate similarity mask embeddingszhou', 1);('dynamic joint', 1);('thatutilizes highresolution', 1);('guidance generate thespatial lters', 1);('lowresolution featureswhich', 1);('theyuse highresolution', 1);('rgb', 1);('images upsample lowresolution depth maps harvest discriminative', 1);('rich local information upsample smoothjournal', 1);('8cross attentionlayer', 1);('normalizationq k vnormlized qnormlized kvgtregion', 1);('embeddingsquery toregion', 1);('losstransformer decoderlayer', 1);('normalizationffnlayer normalizationlayer normalizationpatch', 1);('details discriminative crossattentionbut', 1);('rich features source addition utilize guidance', 1);('applysoftmax function generate', 1);('positive lters theyobtain spatial lters', 1);('complex decoupledmethod method', 1);('aligns lowresolution', 1);('maps wouldlike', 1);('separate local representations35', 1);('discriminative crossattentionthe', 1);('vanilla crossattention transformer decoders notensure mask', 1);('proposethe discriminative crossattention utilizes theauxiliary supervisions generate discriminative maskembeddings', 1);('inference cost shownin', 1);('q k v softmax qnormktnormsv', 1);('qnorm2rbn', 1);('l2normalized qandkacross', 1);('channel dimensionandsdenotes', 1);('learnable scale factor restore therepresentational capacity', 1);('crossattention eachquery needs calculate similarity', 1);('h\x02wpatch', 1);('embeddings increases', 1);('aggregationof patch embeddings', 1);('smooth featuremaps', 1);('purpose query search allthe embeddings specic regions wholefeature maps', 1);('capacityof query', 1);('corresponding semantic region inthe regionlevel space', 1);('construct querytoregion', 1);('task query matchesthe', 1);('fromthe region embeddings region', 1);('whole information semantic regionwhich', 1);('average patch', 1);('category querytoregion', 1);('task reduces number keys', 1);('h\x02wto', 1);('thenumber categories', 1);('nclass', 1);('contributes morediscriminative', 1);('rst utilize downsampledonehot ground truth generate region', 1);('reupon knorm', 1);('calculate similarity betweentheqnorm', 1);('region embeddings likethe formation attention matrixreflatten', 1);('gtknorm', 1);('13sim query\x00to\x00region', 1);('softmax qnormretnorms14where flatten', 1);('hw gt2rbn', 1);('classhwdenotes onehot ground truthandrenorm2rbn classnclass denotes', 1);('l2normalizedregion', 1);('query closesto', 1);('awayfrom region embeddings ground truth ofsim query\x00to\x00region', 1);('diagonal matrix ofnclass\x02nclass', 1);('zero vectors', 1);('region embeddings', 1);('due inexistence ofsome classes', 1);('corresponding queries', 1);('region embeddings ignore thematch queries', 1);('moreoverto', 1);('ensure region embeddings', 1);('capable representingthe', 1);('whole region', 1);('interclass centertopixel lossin', 1);('loss tomake', 1);('knorm', 1);('compact discriminative ideais', 1);('patch embeddings category closeto region', 1);('theother region embeddings', 1);('optimize softmaxsimilarity', 1);('region embeddingssim patch\x00to\x00region softmax', 1);('knormretnorms15the', 1);('ground truth', 1);('sim', 1);('onehot segmentation label', 1);('crossentropy function', 1);('weinitialize', 1);('learnable scale factor 1sin', 1);('equation', 1);('loss functionwe', 1);('upsample nal segmentation maps imagesize bilinear interpolation use', 1);('common crossentropy function measure differences thesegmentation results ground truths simplicitywe', 1);('deep supervision 5online', 1);('hard example mining', 1);('class balance loss', 1);('theoverall', 1);('lconsists', 1);('partsllseglquery\x00to\x00region lpatch\x00to\x00region 16for pyramid', 1);('boundary loss', 1);('weight auxiliary loss', 1);('followingprevious works', 1);('total loss isllseg 04lboundary', 1);('e xperiments41 datasetscityscapes', 1);('training images', 1);('test images image resolution isjournal', 1);('challenging computation memory usage addition', 1);('labeledimages useade20k', 1);('semantic classes', 1);('and3352 images training validation testingpascal', 1);('context', 1);('images trainingand', 1);('images validation', 1);('previous workswe', 1);('semantic labels 1background labelcocostuff10k', 1);('datasetfor semantic segmentation', 1);('118k training images and5k validation images', 1);('categories42 implementation', 1);('detailswe', 1);('toolbox experiments', 1);('powerful capacity', 1);('role representation separation methods encoders', 1);('imagenet22k', 1);('defaultdata augmentation', 1);('random horizontal', 1);('respective previous training settingsin general fair comparison models', 1);('beitbackbones', 1);('training protocols originalpaper addition', 1);('parametersof transformer decoders', 1);('learnable queries themodels', 1);('backbones employ', 1);('weight decay', 1);('batch size', 1);('\x02512 forade20k', 1);('\x02640 forcocostuff164k', 1);('corresponding training iterations are80k 80k 30k 30k 80k models', 1);('cswinbackbones', 1);('segformer', 1);('cityscapesduring', 1);('inference phase', 1);('window inference window size', 1);('models pyramidvits models', 1);('window inference forcityscapes', 1);('multiscale results weperform multiscale test', 1);('ablation studythe', 1);('ablation experiments', 1);('various datasetsade20k', 1);('pascal context cityscapes', 1);('vitbbeitb cswin', 1);('wetrain models', 1);('\x02512 crop size 80k iterations fortable', 1);('study representation separationmodel miou', 1);('gflops paramsade20kvitlinearb', 1);('866m transformer decoder', 1);('998m discriminative crossattention', 1);('contextbeitlinearb', 1);('862m transformer decoder', 1);('995m discriminative crossattention', 1);('sasmmodel', 1);('gflops params2 sasm', 1);('norm', 1);('998mgroup number', 1);('crop size 30k iterations', 1);('crop size 80k iterations', 1);('cityscapesall', 1);('study representation separationour baseline', 1);('linear decoderwhich', 1);('singlescale test improvement', 1);('miou from493to', 1);('transformer decoder generate', 1);('dynamic mask embeddings', 1);('twopathway network framework', 1);('4m parametersthe performance gain', 1);('thediscriminative crossattention accuracy', 1);('extra parameters computation', 1);('discriminative crossattention improves performance', 1);('extraparameters computation432', 1);('sasmas', 1);('maps performance dropsby', 1);('replacing', 1);('filter normproposed', 1);('performance drop', 1);('weight values stabilize', 1);('reducingthe group number', 1);('defaultgroup number', 1);('multihead attention', 1);('sucha setting', 1);('theperformance', 1);('study discriminative crossattentionwe conduct ablation experiments discriminativecrossattention', 1);('study discriminative crossattentionmethod mioudiscriminative crossattention 531querytoregion', 1);('loss 526patchtoregion', 1);('loss 528wo', 1);('l2', 1);('normalization 519a b c dfig', 1);('attention maps transformer decoder', 1);('top downare ground truths attention maps', 1);('withoutdiscriminative crossattention attention maps', 1);('select attention maps', 1);('typical small objects aclock b streetlight c vase sconceregion', 1);('loss willdecrease performance', 1);('similarity dramaticdrop performance', 1);('different region embeddings', 1);('difcult vanilla crossattention locatethe', 1);('small object', 1);('whole image discriminative crossattention', 1);('b vanilla crossattentionpays attention irrelevant background moreextensive object', 1);('discriminative crossattention', 1);('c andd vanilla crossattention focuses adjacent objector', 1);('similar object', 1);('method centers onthe', 1);('targets existence', 1);('mighty interferencenote', 1);('attention maps withperpixel segmentation labels434', 1);('twopathway networkthe ablation study', 1);('twopathway networkis', 1);('cswint cswinsas', 1);('segformeras', 1);('9blocks improves miou', 1);('enlargingthe', 1);('learning rate', 1);('sufcient training', 1);('lsbsleading', 1);('performance gain attentionguidedfeature fusion improves performance', 1);('lasta b cd e ffig', 1);('ainput image segmentation map b', 1);('result ofthe output', 1);('result ofthe input', 1);('result theoutput', 1);('result theoutput vanilla convolutions', 1);('f visualizedresult', 1);('vanilla convolutions e', 1);('lhfsusing', 1);('edge supervisionimproves miou', 1);('conclusionthe localpatch separation improves performances ofcswint', 1);('different convolutional variants', 1);('largekernel convolutionsor dilation convolutions', 1);('performancewhich demonstrates', 1);('local operations', 1);('tobetter', 1);('local separation capacity', 1);('lhfswe', 1);('clear boundaryfrom', 1);('8d show', 1);('maps shallow layers', 1);('agnostic edge information methodreduces noises', 1);('distinct semantic boundary', 1);('f show comparison resultsof vanilla convolutions', 1);('lhfscapture', 1);('thinner boundary vanilla convolutions44', 1);('comparisons stateoftheart methodsin', 1);('efciency methodby', 1);('accuracy parameters', 1);('withprevious startoftheart methods benchmarks', 1);('forthe', 1);('sake fairness', 1);('methods basedon perpixel classication paradigm mark grey themethods', 1);('classication mask prediction', 1);('source toocumbersome', 1);('cityscapesas', 1);('miou outperforms', 1);('twopathway network 10\x02lr denotes impose', 1);('increase number', 1);('cswint', 1);('lsbs5 lsbs', 1);('intervalis 4model', 1);('different convolutionalvariantsmethod miou3\x023 convolutions 827depthwise largekernel convolutions', 1);('826multidilation convolutions', 1);('convolutions boundary loss 828lhfs boundary loss 830table', 1);('val setthe', 1);('gflops cnns', 1);('\x02768 resolution faircomparison', 1);('line obtainedfrom', 1);('model zoo', 1);('original papers cases ydenotes pretrain weights', 1);('26model mioussms', 1);('gflops paramsfcn', 1);('ocr', 1);('3332mstructtokenpwel y21', 1);('previous methods538614682657672727756762811795803835613607666674687707753759793pole tlight', 1);('person rider motor bike405060708090setrnaivelsetrpuplrssegvitlfig', 1);('segmentation results smallthin objectson', 1);('val setwith', 1);('extra attention', 1);('segmenter structtoken', 1);('itcan', 1);('improves average accuracyof', 1);('whileour method', 1);('substantial improvements smallobjects addition', 1);('vitsbased', 1);('ourmethod', 1);('generate sharper results canbe', 1);('stateoftheart performanceswith', 1);('parameters computation example', 1);('similar performance lawinl', 1);('parameters thelatter', 1);('semasklmask2', 1);('swinlas', 1);('backbone utilizes', 1);('train biggermodels', 1);('cswint cswins', 1);('rscswins', 1);('hrvitb3', 1);('contains series improvements', 1);('network architecture needs retrainedon', 1);('localpatch separation enoughfor ne segmentation scenariosscales multiscale test', 1);('normal circumstancessmaller test resolution', 1);('intraclass consistencyand', 1);('sharper semantic boundary', 1);('rich context', 1);('theintraclass consistency', 1);('predictionswhich hampers ensemble performance', 1);('images multiscaletest', 1);('numerous smallthinobjects reects difference betweensemantic segmentation', 1);('vits cnns442 ade20kon', 1);('segmenter vitljournal latex class files vol', 1);('multiscale', 1);('test results', 1);('different scale factors stride', 1);('models weightscan', 1);('open source toolbox', 1);('ss', 1);('list stateoftheart methods', 1);('\x02512 640\x02640resolution', 1);('test crop size \x03denotes resultis', 1);('ydenotes pretrain weightsare', 1);('gflopspspnet', 1);('psanet', 1);('ocrnet', 1);('ccnet', 1);('cpnet', 1);('stlnet', 1);('cnextl', 1);('cswinl', 1);('vitby', 1);('6703963947539526243744557545943956623123230642742350545467486vase clock shower', 1);('light streetlight sconce ashcan010203040506070vitlinearlsegmenterlrssegvitlfig', 1);('small objects onade20k val setby', 1);('multiscale test accuracy', 1);('previous stateoftheart method', 1);('backbone achieve584miou result', 1);('whileour method needs', 1);('computation requirements ofit intuitive representation validness ofthe', 1);('method train', 1);('vitl beitl', 1);('witha linear decoder', 1);('identical training settings whichis', 1);('simple effective baseline', 1);('method andsegmenter', 1);('method improves performance by37miou', 1);('strong baselineswhile', 1);('select theseven', 1);('segmentation resultsin', 1);('extra transformer layers evena', 1);('slight drop segmentation accuracy', 1);('small objectsfor', 1);('contrast method', 1);('achievesremarkable performance gains', 1);('challenging scenarios', 1);('separates smoothrepresentations', 1);('small objects443', 1);('pascal contextsince', 1);('original paper', 1);('reports theresults', 1);('classes retrain models 40k iterations', 1);('adamw', 1);('miou higherthan', 1);('usingthe backbone method', 1);('vitadaptermask2', 1);('vitadapterupernetand vitadaptermask2', 1);('cumbersome thanour methods444', 1);('shows results', 1);('rssegvit', 1);('beitl rssegvit', 1);('cocostuff164kwe', 1);('segmentation models', 1);('vitson cocostuff164k', 1);('semantic segmentationjournal', 1);('pascal contextdataset', 1);('report miou', 1);('\x03denotes result', 1);('ourselvesydenotes pretrain weights', 1);('vitaugreg26model encoder', 1);('hrw48', 1);('efcientnetb7', 1);('vithybridl', 1);('cocostuff10kdatasetydenotes', 1);('pretrain weights', 1);('26zdenotes result', 1);('cocostuff164kdataset', 1);('models pyramid', 1);('trainedwith crop size', 1);('\x02640ydenotes pretrain weightsuse', 1);('22k zdenotes model', 1);('with320k iterations default 80k \x03denotes result', 1);('swinb', 1);('beitly', 1);('robustness', 1);('andade20k report average results', 1);('blur noisedigital weather', 1);('typesof corruptions', 1);('corr', 1);('denotes average result 16types corruptions', 1);('rete', 1);('denotes retention', 1);('corr clean', 1);('ydenotes resultis', 1);('clean corr rete blur noise digit weathcityscapesgscnny47', 1);('vitlinear segmenter vitadapterupernetwith', 1);('different backbones method', 1);('results trainingcrop size', 1);('robustness evaluationmodel', 1);('safetycritical taskssuch autonomous', 1);('recent', 1);('works shownthat', 1);('robust representations', 1);('cnns16', 1);('image classication semanticsegmentation', 1);('vits84', 1);('open vast perspective', 1);('semantic segmentation notbeen', 1);('separate suchcoherent representations', 1);('robustness ourmethod', 1);('effect robustness', 1);('theresults', 1);('vitlinearb', 1);('similar encoder sizewith', 1);('retention indicatesthat', 1);('mlpsare', 1);('robust learners', 1);('natural corruptions semanticsegmentation improvements robustness reallycome selfattention', 1);('performance gainof', 1);('twopathway network transferfrom', 1);('clean images', 1);('dueto fact highresolution representations withrich local information', 1);('method notlead', 1);('severe degradation', 1);('14a b cfig', 1);('setrnaive', 1);('segmentation maps ourmethod methods', 1);('backbonewe frame', 1);('parts gures groundtruthsour method robust', 1);('ourrepresentation separation', 1);('robust thepure attention baselines', 1);('cityscapes rssegvitb', 1);('fanlhybrid', 1);('fullyattentional network', 1);('robustness similarencoder size', 1);('model capacity', 1);('unprecedented robustness', 1);('interesting properties representation separation framework whichmaintain', 1);('enhance robustness', 1);('therepresentational discrepancy46', 1);('visualized resultswe', 1);('cityscapes ade20kand pascal context', 1);('method generates sharper segmentation maps', 1);('different methods', 1);('substantial improvements', 1);('multiple challenging scenarios', 1);('thegenerality robustness method5 c', 1);('onclusionsin', 1);('paper introduce efcient framework ofrepresentation separation semantic segmentation withtransformers', 1);('novel components', 1);('theoriginal local discrepancy', 1);('adaptive separation module utilizes', 1);('separate deepest representations discriminative crossattention generates morediscriminative mask embeddings classify nal patcha b cfig', 1);('segmentation maps method methods', 1);('vitlas', 1);('backbone frame', 1);('parts thegures ground truthsa b cfig', 1);('pascal contextval', 1);('top input imagesground truths segmentation maps', 1);('andsegmentation maps method methods', 1);('thevitl backbone frame', 1);('partsin gures ground truthsjournal', 1);('integrated', 1);('stateoftheart accuracy popularbenchmarks', 1);('computational efciency', 1);('thevisualized', 1);('method learns morediscriminative representations yields sharper segmentation maps', 1);('method evensurpasses', 1);('highresolution transformerson ne segmentation scenariosfor', 1);('long time', 1);('contextual information', 1);('intraclass consistency focus semanticsegmentation hope methods results caninspire', 1);('future works', 1);('attention representationseparation', 1);('coherent representationsof', 1);('dense predictiontasks addition method', 1);('feasible solution thatgenerates sharper segmentation maps timemaintains', 1);('tomake effort', 1);('powerful practical semantic segmentation models', 1);('segmentation boundary andsmall objects', 1);('e shelhamer darrell fully', 1);('convolutional networks semantic segmentation', 1);('proceedings ieeeconference computer vision pattern recognition', 1);('lc chen g papandreou kokkinos k murphy lyuille deeplab semantic', 1);('image segmentation', 1);('convolutional nets atrous convolution', 1);('ieeetransactions pattern analysis machine intelligence', 1);('vol 40no', 1);('lc chen g papandreou', 1);('schroff h adam rethinking', 1);('atrous convolution semantic image segmentation arxivpreprint arxiv170605587', 1);('liu rabinovich', 1);('berg parsenet looking', 1);('arxiv preprint arxiv150604579', 1);('h zhao j shi x qi x wang j jia pyramid', 1);('scene parsingnetwork', 1);('computer visionand pattern recognition', 1);('peng x zhang g yu g luo j sun large', 1);('kernelmattersimprove semantic segmentation', 1);('global convolutionalnetwork', 1);('conference computer visionand pattern recognition pp', 1);('j fu j liu h tian li bao z fang h lu dualattention', 1);('network scene segmentation', 1);('yuan', 1);('huang j guo', 1);('zhang x chen j wang ocnetobject', 1);('context semantic segmentation', 1);('international journal ofcomputer', 1);('yin z yao cao x li z zhang lin h hudisentangled', 1);('nonlocal neural networks', 1);('conferenceon computer vision', 1);('vaswani n shazeer n parmar j uszkoreit', 1);('jones ngomez', 1);('kaiser polosukhin attention', 1);('needarxiv preprint arxiv170603762', 1);('beyer kolesnikov weissenborn x zhait unterthiner dehghani minderer g heigold gellyet', 1);('transformers', 1);('imagerecognition scale arxiv preprint arxiv201011929', 1);('h touvron cord douze', 1);('massa sablayrolles', 1);('training', 1);('dataefcient image transformers distillation attention arxiv preprint arxiv201212877', 1);('wang e xie x li dp fan k', 1);('liang lu p luoand', 1);('shao pyramid', 1);('versatile backbone', 1);('convolutions arxiv preprintarxiv210212122', 1);('z liu lin cao h hu wei z zhang lin', 1);('guoswin', 1);('hierarchical', 1);('shiftedwindows arxiv preprint arxiv210314030', 1);('zheng j lu h zhao x zhu z luo wang fu j fengt xiang p h torr', 1);('rethinking', 1);('semantic segmentationfrom sequencetosequence perspective transformers inproceedings', 1);('recognition', 1);('e xie', 1);('wang z yu anandkumar j alvarez p luosegformer simple', 1);('efcient design semantic segmentationwith transformers arxiv preprint arxiv210515203', 1);('r ranftl bochkovskiy v koltun vision', 1);('transformers fordense prediction arxiv preprint arxiv210313413', 1);('r strudel r garcia laptev', 1);('schmid segmenter transformer', 1);('semantic segmentation arxiv preprintarxiv210505633', 1);('h yan', 1);('zhang wu lawin', 1);('improving', 1);('semantic segmentation transformer multiscale representationsvia', 1);('large window attention arxiv preprint arxiv220101615', 1);('j jain singh n orlov z huang j li walton h shisemask semantically', 1);('transformers semantic segmentation arxiv preprint arxiv211212782', 1);('lin z liang j zheng tian k chen structtoken rethinking', 1);('semantic segmentation structural priorarxiv preprint arxiv220312612', 1);('z chen duan', 1);('wang j lu j dai qiaovision', 1);('transformer adapter', 1);('dense predictions arxiv preprintarxiv220508534', 1);('kim', 1);('vision transformers work ininternational conference', 1);('learning representations', 1);('gong wang li v chandra q liu vision', 1);('transformers patch diversication arxiv preprintarxiv210412753', 1);('h bao', 1);('dong', 1);('wei beit bert', 1);('imagetransformers arxiv preprint arxiv210608254', 1);('steiner kolesnikov x zhai r wightman j uszkoreit', 1);('beyer', 1);('train vit data augmentation regularization vision transformers arxiv preprint arxiv210610270', 1);('x chu z tian', 1);('zhang x wang x wei h xia', 1);('shenconditional', 1);('positional encodings vision transformers arxivpreprint arxiv210210882', 1);('x chu z tian wang', 1);('zhang h ren x wei h xia', 1);('shen', 1);('revisiting', 1);('design spatial attention visiontransformers arxiv preprint arxiv210413840', 1);('z dai h liu q v', 1);('tan coatnet marryingconvolution', 1);('attention data sizes arxiv preprintarxiv210604803', 1);('x dong j bao chen', 1);('zhang n yu', 1);('yuan chen', 1);('guo cswin', 1);('transformer general vision transformer backbone', 1);('yuan q hou z jiang j feng yan volo visionoutlooker', 1);('visual recognition', 1);('yuan r fu', 1);('lin', 1);('zhang x chen j wanghrformer highresolution', 1);('dense predictionarxiv preprint arxiv211009408', 1);('lai v chandra z pan multiscale', 1);('highresolution vision transformerfor semantic segmentation arxiv preprint arxiv211101236', 1);('h touvron cord h j', 1);('revenge', 1);('vitarxiv preprint arxiv220407118', 1);('k x chen xie li p doll', 1);('r girshickmasked', 1);('scalable vision learners arxiv preprintarxiv211106377', 1);('xiao liu', 1);('zhou jiang j sun unied', 1);('scene understanding', 1);('proceedings europeanconference', 1);('n carion', 1);('massa g synnaeve n usunier kirillov', 1);('zagoruyko endtoend', 1);('object detection transformersineuropean conference', 1);('springer202038', 1);('cheng schwing kirillov perpixel', 1);('classication isnot need semantic segmentation', 1);('advances neuralinformation processing systems', 1);('cheng misra g schwing kirillov r girdharmaskedattention', 1);('universal image segmenjournal', 1);('computervision pattern recognition', 1);('ronneberger p fischer brox unet convolutionalnetworks', 1);('biomedical image segmentation', 1);('internationalconference', 1);('medical image', 1);('intervention pp', 1);('z huang x wang wei', 1);('huang h shi', 1);('liu shuang ccnet crisscross', 1);('attention semantic segmentationieee', 1);('transactions pattern analysis machine intelligence', 1);('liu chen p lasang q sun covariance', 1);('attention forsemantic segmentation', 1);('ieee transactions pattern analysis', 1);('intelligence', 1);('z li sun', 1);('zhang j tang ctnet contextbased', 1);('tandemnetwork semantic segmentation', 1);('g lin milan', 1);('shen reid renenet multipathrenement', 1);('networks highresolution semantic segmentationinproceedings', 1);('kirillov r girshick k p doll', 1);('panoptic', 1);('featurepyramid networks', 1);('conference oncomputer vision pattern recognition pp', 1);('x li z zhu h zhao yang k yang tan', 1);('tong semantic', 1);('fast accurate scene parsingineuropean conference', 1);('springer202047 takikawa acuna v jampani fidler gatedscnngated', 1);('shape cnns semantic segmentation', 1);('international conference computer vision pp', 1);('x li x li', 1);('zhang g cheng j shi z lin tan tongimproving', 1);('body edgesupervision arxiv preprint arxiv200710035', 1);('wang zhang cui j liu p ren yang x xiex hua h bao', 1);('xu active', 1);('boundary loss semanticsegmentation arxiv preprint arxiv210202696', 1);('yuan j xie x chen j wang segx modelagnosticboundary', 1);('renement segmentation', 1);('european conference oncomputer', 1);('j bai', 1);('yuan st xia yan z li', 1);('liu improvingvision', 1);('highfrequency componentsarxiv preprint arxiv220400993', 1);('chen x zhe', 1);('baocar classaware', 1);('regularizations semantic segmentationarxiv preprint arxiv220307160', 1);('ba j r kiros g e hinton layer', 1);('normalization arxivpreprint arxiv160706450', 1);('hendrycks k gimpel gaussian', 1);('error linear unitsgelus arxiv preprint arxiv160608415', 1);('contributors mmsegmentation openmmlab', 1);('semantic segmentation toolbox benchmark', 1);('lc chen zhu g papandreou', 1);('schroff h adamencoderdecoder', 1);('separable convolution semanticimage segmentation', 1);('european conference oncomputer vision', 1);('z liu h mao cy wu', 1);('feichtenhofer darrell xiea', 1);('convnet 2020s', 1);('peng', 1);('gao g yu n sang bisenet bilateral', 1);('segmentation network realtime semantic segmentationinproceedings', 1);('european conference computer vision', 1);('yu', 1);('gao j wang g yu', 1);('shen n sang bisenet', 1);('v2bilateral network', 1);('aggregation realtime semanticsegmentation', 1);('international journal', 1);('vol 129no', 1);('hong h pan', 1);('sun jia', 1);('dualresolutionnetworks realtime', 1);('accurate semantic segmentation ofroad scenes arxiv preprint arxiv210106085', 1);('pang li j shen', 1);('shao towards', 1);('z huang wei x wang', 1);('liu huang h shialignseg featurealigned', 1);('segmentation networks', 1);('ieee transactions pattern analysis machine intelligence', 1);('j zhou v jampani z pi q liu mh yang decoupleddynamic', 1);('lter networks', 1);('mazzini guided', 1);('network realtime semanticsegmentation arxiv preprint arxiv180707466', 1);('fan lai j huang x wei z chai j luo x weirethinking', 1);('bisenet realtime semantic segmentation', 1);('yuan x chen j wang objectcontextual', 1);('representationsfor semantic segmentation', 1);('computer visioneccv', 1);('16theuropean conference', 1);('glasgow uk august', 1);('proceedingspart vi', 1);('cordts omran ramos rehfeld enzweilerr benenson u franke roth', 1);('schiele', 1);('cityscapesdataset semantic', 1);('urban scene understanding', 1);('proceedingsof ieee', 1);('zhou h zhao x puig fidler barriuso torralbascene', 1);('ade20k dataset', 1);('r mottaghi x chen x liu ng cho', 1);('lee fidlerr urtasun yuille', 1);('role context object detectionand semantic segmentation', 1);('h caesar j uijlings v ferrari cocostuff thing', 1);('stuffclasses context', 1);('conference computervision pattern recognition pp', 1);('j deng', 1);('dong r socher lj li k li', 1);('feifei imagenet', 1);('largescale hierarchical image database', 1);('ieeeconference', 1);('computer vision pattern recognition pp 248255ieee', 1);('h zhang k dana j shi z zhang x wang tyagi', 1);('agrawal context', 1);('semantic segmentation inproceedings', 1);('computer vision patternrecognition', 1);('j wang k sun cheng', 1);('jiang', 1);('deng zhao liuy mu tan x wang', 1);('highresolution representation learning visual recognition', 1);('transactions patternanalysis machine intelligence vol', 1);('laiv chandra z pan hrvit multiscale', 1);('highresolutionvision transformer arxiv preprint arxiv211101236', 1);('h zhao zhang liu j shi', 1);('c c', 1);('loy lin j jiapsanet pointwise', 1);('spatial attention network scene parsinginproceedings', 1);('european conference', 1);('computer vision eccv', 1);('gao g yu', 1);('shen n sang context', 1);('priorfor scene segmentation', 1);('zhu ji zhu', 1);('gan', 1);('wu j yan learningstatistical', 1);('texture semantic segmentation', 1);('bousselham g thibault', 1);('pagano machireddy j grayy h chang x', 1);('efcient', 1);('selfensemble framework forsemantic segmentation arxiv preprint arxiv211113280', 1);('zhang z tian q tang x chu x wei', 1);('shen liusegvit semantic', 1);('plain vision transformersarxiv preprint arxiv221005844', 1);('h yuan x yue h hu rankseg adaptive', 1);('pixelclassication image category', 1);('segmentation ineuropean conference', 1);('springer202281 j cui yuan z zhong z tian h hu lin j jia regionrebalance', 1);('semantic segmentation arxiv preprintarxiv220401969', 1);('liu channelized', 1);('axialattention semantic', 1);('channel relationwithin spatial attention semantic segmentation arxiv preprintarxiv210107434 2021journal', 1);('kamann', 1);('rother benchmarking', 1);('robustness ofsemantic segmentation models', 1);('zhou z yu e xie', 1);('xiao anandkumar j feng j malvarez understanding', 1);('robustness vision transformersininternational conference', 1);('machine learning', 1);('pp 2737827394pmlr', 1);('bhojanapalli chakrabarti glasner li unterthinerand veit understanding', 1);('robustness transformers imageclassication', 1);('k mahmood r mahmood van dijk', 1);('robustnessof vision transformers adversarial examples', 1);('paul p chen vision', 1);('transformers robust learnersinproceedings', 1);('aaai', 1);('articial intelligence', 1);('vol 36pp', 1);('x mao g qi chen x li r duan ye', 1);('xue towards', 1);('robust vision transformer', 1);