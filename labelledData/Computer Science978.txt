('lipgan', 19);('l1wgangp', 16);('grid', 14);('gan', 6);('lrs2', 6);('model traininggridsmallgridfulla', 5);('psnr', 5);('well fids well', 4);('gridsmall gridfull', 4);('model traininggridsmallgridfull b', 4);('ssim', 4);('losses', 3);('lipgan l1wgangp', 3);('wgan', 3);('training iterations', 3);('gridsmall', 3);('gridfull', 3);('proceedings', 3);('lip motion', 2);('similarly', 2);('train', 2);('wasserstein gan', 2);('generator', 2);('lg0', 2);('critic', 2);('ldfigure', 2);('generator loss', 2);('discriminator loss', 2);('additionally', 2);('truth0', 2);('truth10', 2);('sfrom', 2);('true faces training', 2);('ssim0', 2);('psnrfigure', 2);('gz', 2);('gradient penalty term', 2);('summary statistics models', 2);('gridfull outliers', 2);('gridtrain', 2);('example', 2);('ieee', 2);('proceedings ieee', 2);('acm transactions graphics tog', 2);('alls well fids wellresult quality metric scores gan models forlipsychronization taskscarina geldhauser johan liljegren pontus nordqvistabstract', 1);('test performance', 1);('models lipsynchronization wereimplement', 1);('lipgan pytorch', 1);('train dataset', 1);('grid1introductionfacial', 1);('important element', 1);('computer generated imagery humans', 1);('variety information character scene facial expressions emotionsto situations joy tension danger', 1);('human perception', 1);('sensitive anomaliesin facial motion dissynchronization audio visual information', 1);('realistic videoclips', 1);('challenging requireshighquality', 1);('lip movements', 1);('audio plausible facial expressionstraditional approaches facial synthesis', 1);('computer generated imagery', 1);('producefaces exhibit high level realism', 1);('traditional approaches mouthshapes', 1);('3d meshes speakerspeci c', 1);('huge amount video footage target person training modelingor', 1);('expensive equipment high', 1);('specialist work suchprojects', 1);('large studiosin order drive cost time', 1);('quality computer', 1);('audiovisual sceneries researchers', 1);('automatic face synthesis', 1);('lipsychronization', 1);('particular interest', 1);('speech acoustics', 1);('facial movements', 1);('applications', 1);('lm animation processes', 1);('steps postproduction scope', 1);('visual telecommunications', 1);('entire visual content', 1);('frames preciselyour motivation work pipeline visual content creation', 1);('gure 1in', 1);('exploratory work', 1);('machine learning model', 1);('speechinformation arbitrary photo', 1);('image use', 1);('trainedgan generate', 1);('short video clip', 1);('speech information', 1);('throughan audio', 1);('lipgan wgangp', 1);('somecommon metrics visual quality nonagreeance human eye', 1);('workthe', 1);('classical computer vision computer graphicswhere plethora', 1);('faces videos', 1);('famous recent example', 1);('power oftheir', 1);('traditional computer vision technique photorealistic', 1);('videoclips formerpresident', 1);('barack obama', 1);('problem creatinga credible fake video', 1);('human attentiveness details mouth area extensionobamanet', 1);('integrates texttovoice', 1);('model uses recurrentneural networks audio processing', 1);('unets', 1);('video processingin', 1);('recent years models', 1);('neural networks', 1);('popular particulardue potential generate arbitraryidentity', 1);('recent ganbased', 1);('approaches1arxiv221213810v1 cscv', 1);('dec', 1);('carina geldhauser johan liljegren pontus nordqvistfigure', 1);('sketch vision pipeline', 1);('video messageservice work focuses lipsynchronization', 1);('phoneme search approach', 1);('words videos', 1);('learning approach23 uses', 1);('audio video di erent persons', 1);('audio video embeddingswhich', 1);('implementations datadriven', 1);('uses encoders audio video separatelywhich', 1);('uses encoder decoders manner witha', 1);('pipeline uses networks work', 1);('model aimingto', 1);('translation videos', 1);('combination autoencodersand', 1);('wasserstein gans3datsetsin', 1);('brief description', 1);('main dataset', 1);('lrs2the', 1);('sample images', 1);('respective datasets', 1);('corpus tasks speech perceptionand speech recognition', 1);('unique speakers', 1);('word sequences inseparate videos', 1);('long total length', 1);('video material about275 hours', 1);('video resolution', 1);('\x02288 bitrate', 1);('outof', 1);('male speakers', 1);('english', 1);('rstlanguage videos', 1);('lab environment green screen background', 1);('aclinic setting videos speakers', 1);('camerathe authors', 1);('train model', 1);('lrs2consists', 1);('news recordings', 1);('bbc', 1);('di erent', 1);('poses andpeople di erent origins', 1);('inthewild dataset capturesreal', 1);('video frames crop', 1);('image andrescale', 1);('audio audio segments melspectrogram representationto', 1);('preprocess audio code', 1);('training data', 1);('inputs shiftedframes0', 1);('\x0296\x023 ieh', 1);('furthermore', 1);('s0were', 1);('time step \x06', 1);('random size 126as audio data', 1);('melfrequency channelsand time window', 1);('time window equivalates', 1);('ms total audiowhich', 1);('resulting', 1);('data attributes summarizedin table 1alls', 1);('samples', 1);('speakers datasets', 1);('notethat', 1);('samples representative', 1);('data', 1);('attributes training datadata attributesinput image horizontalvertical dimension', 1);('96frameshift time step 126melfrequency channels 80melspectrogram time window', 1);('frames faces', 1);('gridsmall gridfulland gridtest', 1);('speakers name suggests', 1);('test models', 1);('intersection data thetwo', 1);('training test', 1);('image samples speci', 1);('matches sample', 1);('calculate speci c', 1);('comparison articles', 1);('information', 1);('data subsets', 1);('type', 1);('videos', 1);('test', 1);('204experiment overviewin series experiments', 1);('task lipsynchronizationwith', 1);('dataset training data', 1);('pytorch', 1);('gradient penalty', 1);('choiceto use', 1);('empirical study', 1);('thatwgangp performs', 1);('test it4', 1);('carina geldhauser johan liljegren pontus nordqvist0', 1);('iteration000000250050007501000125015001750200gg lipgan', 1);('iteration025030035040045050055060065dd lipgan', 1);('modelto aim rst analyze implementations', 1);('convergence inspect sample images', 1);('training ensure', 1);('satisfying perceptual quality', 1);('di erent quantitativemetrics', 1);('qualitative assessment models', 1);('epochs abatch size', 1);('initial random seed numpyrandomseed10 batchnormalization', 1);('discriminator problem', 1);('trainable parameters', 1);('37087763are generator', 1);('adam', 1);('optimizer bothnetworks', 1);('initial learning rate \x11 10\x004and decay parameters', 1);('keras', 1);('original implementation modelbuilds pipeline inputs video source language', 1);('target languagewith', 1);('lips target language', 1);('inputs frames audio andinput distribution', 1);('pzand', 1);('frame output distributionpgthe', 1);('datasets 20epochs', 1);('systems training di erentlipgan losses', 1);('600th training iteration datasets', 1);('lgconverges', 1);('minimum loss', 1);('ldconverges', 1);('045however outliers', 1);('search potential errors trainingsamples', 1);('lfacewith', 1);('input fake', 1);('swith', 1);('real audio losslaudio input', 1);('real face', 1);('sbut', 1);('contribute discriminator loss', 1);('ldfor', 1);('speci c iteration losses', 1);('outliers losslaudio losses', 1);('laudio', 1);('thanlfacesample inspection', 1);('good quality rst epoch', 1);('howeverif', 1);('small di erences', 1);('select samples', 1);('example thesample epoch', 1);('open mouth whilethe mouth', 1);('ground truth', 1);('notice thatthe beard blurry appearance ground truth counterpart', 1);('lastly ssim', 1);('generators samples', 1);('ground truth counterpartevery 600th training iteration', 1);('gure 6quality metrics convenience plot', 1);('ssim psnr', 1);('gridsmall gridfull ssim', 1);('db datasets endat', 1);('gridfullalls well fids well', 1);('iteration141516171819202122faceface lipgan', 1);('faked', 1);('audio losslface0', 1);('iteration105104103102101100log10audioaudio lipgan', 1);('model traininggridsmallgridfullb', 1);('real', 1);('a0', 1);('number denotes epoch0', 1);('iteration0204060810ssimssim lipgan', 1);('iteration152025303540psnr', 1);('ssim psnr lipgan', 1);('model trainingthe metrics', 1);('600th training iteration42l1wgangp', 1);('round experiments', 1);('generative adversarial network gradient penalty', 1);('l1reconstruction6 carina geldhauser johan liljegren pontus nordqvist0', 1);('iteration00000025005000750100012501500175gg l1wgangp', 1);('iteration102100102104106log10dd l1wgangp', 1);('wgangp', 1);('iteration103101101103105log10gpgp l1wgangp', 1);('model traininggridsmallgridfullfigure', 1);('gradient', 1);('penalty term', 1);('rgpfor l1wgangp', 1);('lreg', 1);('1nnxi1ks\x00gs0ak1in generatorthe gradient penalty regularization', 1);('rgpex\x18px\x14\x00krxdxk2\x001\x012\x15where', 1);('xis output generator ie', 1);('introducing', 1);('term yields totalloss function of3', 1);('lwgangp gd ex\x18pg\x14dx\x15\x00ex\x18pr\x14dx\x15\x15rgpwhere\x15is', 1);('penalty coe\x0ecient xthe output generator ie', 1);('xz\x18pzthe motivation', 1);('penalize gradients normsdi', 1);('penalty terms discriminator input xare', 1);('individuallybatch normalization', 1);('major di erence', 1);('model thelipgan model training process training step', 1);('step generator', 1);('5th step', 1);('in105000 training iterations', 1);('check convergence', 1);('lgand', 1);('ldat', 1);('600th training iteration visualizedin gure', 1);('rgp', 1);('sample inspectionsamples', 1);('sand', 1);('corresponding ground truth part', 1);('onceper epoch training', 1);('realistic look butalls', 1);('model usinggridfull epoch samples', 1);('number eachsample0', 1);('iteration0204060810ssimssim l1wgangp', 1);('iteration1520253035psnr', 1);('ssim psnr l1wgangp', 1);('600th training iterationtend', 1);('blurry times', 1);('early epochs', 1);('upon', 1);('separate frame', 1);('mode collapse couldbe observedquality metrics', 1);('db datasets', 1);('gridfull5resultsin', 1);('section summarize results experiments motivation work wasthe animation image', 1);('person good backgroundinto', 1);('short video message', 1);('audio task', 1);('setting b', 1);('audio transcription makingit', 1);('implementation texttospeech feature51dataset impact', 1);('surprising outcome', 1);('poor generalization', 1);('pytorch lipgan', 1);('grayscale images', 1);('keraslipgan', 1);('satisfactory visual results inference', 1);('pytorchlipgan', 1);('manage adapt', 1);('new color scheme', 1);('carina geldhauser johan liljegren pontus nordqvista lipgan', 1);('lrs2figure', 1);('inference lipgan', 1);('di erent datasets', 1);('manage adapt color schemeof target image', 1);('image', 1);('fidscore', 1);('gridfullmodel fidscorelipgan', 1);('itshould conclude outcome inference', 1);('properties ofthe', 1);('target data problem', 1);('17whose model performance', 1);('frontal facessuch', 1);('gridfurther', 1);('additional grayscale images shouldbe', 1);('grid52fid ssim psnr', 1);('terms ofthree quantitative metrics', 1);('fid ssim psnr', 1);('unseen test data form ofthe', 1);('gridtest', 1);('dataset scores', 1);('points reference data', 1);('testgrid ssimand psnr', 1);('boxplots outliers', 1);('visibility results ofthe', 1);('fid', 1);('model outperforms reimplementation', 1);('data distributionis', 1);('reference data distributionin terms', 1);('ssim lipgan l1wgangp', 1);('maximum possiblevalue', 1);('terms medianand', 1);('summarizes numeric properties', 1);('gridfullmodel meanmedianmaxminlipgan', 1);('di erent phenomenon rst', 1);('around15 db', 1);('terms median meanalls', 1);('l1wgangp08750900092509500975ssimssimmedianmeanfigure', 1);('box plotlipgan', 1);('l1wgangp20253035psnr', 1);('gridfullmodel mean', 1);('dbmedian dbmax dbmin dblipgan', 1);('128153qualitative comparison', 1);('qualitative aspects', 1);('input rst remark itshould', 1);('task lipsynchronization', 1);('good ina subjective manner note', 1);('inspection data', 1);('inference modelsa', 1);('certain discrepancy', 1);('avisible box', 1);('hadvisual artifacts', 1);('examples gure', 1);('data producedby', 1);('eyes target', 1);('variety ways', 1);('likely originate fact', 1);('di erentiate background', 1);('certain areas', 1);('di\x0ecult todetermine artefacts', 1);('unavoidable facial expressions need generatedas', 1);('deviations ground truth', 1);('training hours', 1);('fth iteration', 1);('howeverthis', 1);('quick convergence losses', 1);('similar metric performance', 1);('carina geldhauser johan liljegren pontus nordqvista inference', 1);('inference', 1);('l1wgangpfigure', 1);('visual box', 1);('inferencethis phenomenon', 1);('visible artifacts images', 1);('thel1wgangp model', 1);('input6conclusion outlookto summarize quantitative metrics', 1);('cases results', 1);('whilesample inspection', 1);('large number artifacts', 1);('inthe images', 1);('largerdiscrepancy quantitative metric scores guess', 1);('entire pictures', 1);('small artifact', 1);('large di erence metricsin contrast applications lipsynchronization task focusses', 1);('smallregion image', 1);('small artefacts ruin', 1);('image qualityfurthermore focus quantitative metrics image quality congruence theground truth', 1);('unsatisfactory animation tasks', 1);('byseveral authorswhile', 1);('consensus adequat quantitative metrics', 1);('gans', 1);('proper quantitative', 1);('systemto measure quality video outputin researcherss attempts', 1);('humaneye qualitative assessment standardizedlargescale versions', 1);('turing', 1);('tests17 meanopinionscore', 1);('years warnings', 1);('mosactually', 1);('measures dimensions output quality standardization tester scores isensuredwe conclude', 1);('appropriate alternative human inspection availableto', 1);('measure quality lipsynchronization', 1);('beresearch multidimensional quality measurement alternatives', 1);('sophisticated analysisalls', 1);('jl', 1);('michael truong simon akesson pieter buteneers', 1);('helpful discussionsand', 1);('sinch ab malm\x7f', 1);('computational resourcesreferences1', 1);('triantafyllos afouras joon', 1);('chung andrew senior oriol vinyals andrew zisserman deep', 1);('audiovisual speech recognition', 1);('ieee transactions pattern analysis machine intelligence', 1);('lele chen zhiheng li ross k maddox zhiyao duan chenliang xu lip', 1);('movements generation aglance', 1);('european conference', 1);('computer vision eccv', 1);('min jin chong david forsyth e', 1);('d inception score nd', 1);('joon', 1);('chung amir jamaludin andrew zisserman', 1);('corr', 1);('martin cooke jon barker stuart cunningham xu shao', 1);('audiovisual corpus speech perceptionand', 1);('automatic speech recognition journal', 1);('acoustical', 1);('america', 1);('bo fan lijuan wang frank k soong lei xie photoreal', 1);('bidirectional lstmin2015', 1);('international conference', 1);('acoustics speech', 1);('processing icassp', 1);('ishaan gulrajani faruk ahmed martin arjovsky vincent dumoulin aaron', 1);('courville improvedtraining', 1);('wasserstein gans', 1);('advances', 1);('neural information processing systems', 1);('rithesh kumar jose sotelo kundan kumar alexandre', 1);('brebisson yoshua bengio obamanetphotorealistic', 1);('lipsync text', 1);('karol kurach mario lucic xiaohua zhai marcin michalski sylvain gelly', 1);('largescale study onregularization normalization gans', 1);('ziwei liu raymond yeh xiaoou tang yiming liu aseem agarwala video', 1);('frame synthesis usingdeep voxel ow', 1);('international conference computer vision pages', 1);('k r prajwal rudrabha mukhopadhyay philip jerin jha abhishek vinay namboodiri', 1);('v jawahartowards', 1);('automatic facetoface translation', 1);('acm', 1);('international conference onmultimedia', 1);('mm', 1);('york ny usa', 1);('acm12 ad simons sj cox generation', 1);('mouthshape synthetic', 1);('proc', 1);('institute ofacoustics', 1);('robert', 1);('streijl stefan winkler david hands mean', 1);('opinion score mos', 1);('methods andapplications limitations alternatives', 1);('multimedia systems', 1);('supasorn suwajanakorn steven seitz ira kemelmachershlizerman synthesizing', 1);('obama learninglip sync audio', 1);('justus thies michael zollhofer marc stamminger', 1);('theobalt matthias nie\x19ner face2facerealtime', 1);('reenactment rgb videos', 1);('conference computervision pattern recognition pages', 1);('mahesh viswanathan madhubalan viswanathan measuring', 1);('speech quality texttospeech systemsdevelopment assessment modi', 1);('opinion score mos scale', 1);('computer speech language', 1);('konstantinos vougioukas stavros petridis maja pantic realistic', 1);('speechdriven facial animation withgans', 1);('international journal', 1);('computer vision', 1);('lijuan wang xiaojun qian wei han frank k soong synthesizing', 1);('sample selection', 1);('eleventh annual', 1);('speech communication', 1);('olivia wiles koepke andrew zisserman x2face', 1);('generation usingimages audio pose codes', 1);('european conference computer vision', 1);('eccv', 1);('lei xie zhiqiang liu realistic', 1);('ieee transactions multimedia', 1);('qiantong xu gao huang yang yuan chuan guo yu sun felix wu kilian weinberger', 1);('empiricalstudy evaluation metrics generative adversarial networks arxiv preprint arxiv180607755', 1);('xinwei yao ohad fried kayvon fatahalian maneesh agrawala iterative', 1);('editing talkingheads', 1);('hang zhou yu liu ziwei liu ping luo xiaogang wang', 1);('audiovisual representation', 1);('proceedings aaai', 1);('conference arti cial intelligence volume', 1);('2019lund university', 1);('centre mathematical', 1);('lund swedenemail', 1);('address carinageldhausermathlthseemail address tna15jlistudentluseemail address tna15pnostudentluse', 1);