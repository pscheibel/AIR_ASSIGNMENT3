('hubert', 17);('corr', 14);('flops', 12);('bit', 11);('quantops', 11);('asr', 10);('sqwq', 8);('superb', 7);('qat', 7);('knowledge distillation', 7);('bit-l-w1a1', 6);('distillhubert', 5);('ks', 5);('ste', 5);('model parameters', 5);('mbs', 4);('bit-l', 4);('bit-la', 4);('sqwq-w8', 4);('mod- els', 4);('bit-la-w1a1', 4);('computational complexity', 3);('word error rate', 3);('edge devices', 3);('recently', 3);('individual tasks', 3);('transformer', 3);('@ y @', 3);('weight quantization', 3);('sf', 3);('pr', 3);('qbe', 3);('ic', 3);('asv', 3);('sd', 3);('er', 3);('linear', 3);('model weights', 3);('similar trends', 3);('sqwq-w2', 3);('sqwq-w1', 3);('attention operations', 3);('speech', 3);('icassp', 3);('wei-ning hsu', 2);('machine learning', 2);('quantization techniques', 2);('] benchmark', 2);('representation learning', 2);('model ef- ciency', 2);('model performance', 2);('speech representation learning', 2);('automatic speech recognition', 2);('speech signals', 2);('quan- tization techniques', 2);('weight quantization [', 2);('resource consumption', 2);('quantization strategies', 2);('quantization errors', 2);('model training', 2);('linear operations', 2);('precious bits', 2);('x\x00', 2);('elastic quantization', 2);('storage size', 2);('quantization error', 2);('uniform distributions', 2);('loss function', 2);('gs', 2);('gbits', 2);('runtime', 2);('base', 2);('] fp16', 2);('+fastconv [', 2);('superb tasks', 2);('proling', 2);('teacher model', 2);('intermediate outputs', 2);('mse', 2);('librispeech', 2);('word error rates', 2);('deepspeed', 2);('comparison', 2);('loss functions', 2);('quantized model training', 2);('sqwq-w4', 2);('bit-l-w8a8', 2);('ta-', 2);('one-step', 2);('bit-la-w2a2', 2);('intermediate layer outputs', 2);('speech rep- resentation learning', 2);('one-step quantization', 2);('performance degrada- tion', 2);('zechun liu', 2);('barlas oguz', 2);('meta ai', 2);('zhaoheng ni', 2);('kushal lakhotia', 2);('shu-wen yang', 2);('abdelrahman mohamed', 2);('hung-yi lee', 2);('speech processing', 2);('international conference', 2);('acoustics', 2);('processing', 2);('bert', 2);('myle ott', 2);('angela fan', 2);('quantization', 2);('alexei baevski', 2);('michael auli', 2);('proceedings', 2);('efficient speech representation learning with low-bit quantization ching-feng yeh', 1);('paden tomasello', 1);('abdelrahman mohamed meta ai', 1);('abdo g @ meta.com', 1);('abstract', 1);('ef- ciency', 1);('recent quantization techniques [', 1);('speech representation learn-', 1);('models [', 1);('aggressive quantization', 1);('% stor- age reduction', 1);('runtime reduction', 1);('model compression', 1);('2-bit congura- tion', 1);('index terms quantization', 1);('introduction', 1);('modern machine learning technology', 1);('daily lives', 1);('performances improves', 1);('resource consump- tion', 1);('energy usage', 1);('de- velopment', 1);('wearable devices', 1);('machine learning applications', 1);('device side', 1);('heavy interests', 1);('numerous directions', 1);('quantization aims', 1);('original model architecture', 1);('lower-precision alternatives', 1);('computation reduction', 1);('casts parameters', 1);('lower-precision data types', 1);('integer operations', 1);('devices [', 1);('nature converts numbers', 1);('continuous domains', 1);('discrete domains', 1);('introduces quantization errors', 1);('minimal performance loss', 1);('maximal efciency gain', 1);('high potential', 1);('common components', 1);('different speech tasks', 1);('key- word', 1);('traditionally', 1);('ex- ists', 1);('major redundancy', 1);('similar purposes', 1);('higher-level embeddings', 1);('separate ones', 1);('redun- dancy', 1);('speech representation learning aims', 1);('generate embeddings', 1);('] model', 1);('experimental results', 1);('signicant storage reduction', 1);('runtime improvement', 1);('extreme 1-bit quantization', 1);('word error rate degradation', 1);('recent compres- sion approaches', 1);('efficient low-bit quantization quantization', 1);('converts tensors', 1);('high-precision domains', 1);('oating-point numbers', 1);('arxiv:2301.00652v1 [ eess.as ]', 1);('dec', 1);('minimal perfor- mance degradation', 1);('original high-precision models', 1);('good trade-off', 1);('quantization aware training', 1);('straight-', 1);('estimator', 1);('wide variety', 1);('quanti- zation', 1);('aware training', 1);('performance gap', 1);('different', 1);('in- corporates quantization operations', 1);('gradient computation', 1);('simulate quantization', 1);('stages [', 1);('major challenge', 1);('gra- dients', 1);('model parameters wont', 1);('straight-through es- timator', 1);('gradi- ent updates', 1);('discrete domain', 1);('backward pass', 1);('chain rule', 1);('approxi- mation', 1);('w=', 1);('\x03 @', 1);('wste\x19', 1);('robustly binarized transformer', 1);('conventionally', 1);('n-bit quantization', 1);('discrete counterparts', 1);('2n\x00 1gfor asymmetric cases', 1);('2n\x001\x001gfor symmetric cases', 1);('new quantization techniques', 1);('simple formulation [', 1);('] demonstrates', 1);('quan- tization errors', 1);('efcient model inference', 1);('activations.the core idea', 1);('two-set elastic quantization', 1);('different formulations', 1);('different numeri- cal', 1);('softmax operations', 1);('quantization scenario', 1);('factor 2r+and', 1);('threshold 2r', 1);('xcan', 1);('additional model parame- ters', 1);('xq=', 1);('ifx2r+ \x03clip', 1);('two-set', 1);('generic way', 1);('op- erations', 1);('high- computation operations', 1);('multi-head attention', 1);('major computations', 1);('intermediate activations', 1);('quantizing', 1);('such activations', 1);('computational efciency', 1);('squashed weight quantization', 1);('squashed', 1);('weight quantization aims', 1);('gain factor', 1);('additional regulariza- tion losslqis', 1);('equa- tion', 1);('regularization loss', 1);('standard deviation', 1);('lq=\x15q\x03', 1);('great performance', 1);('lower-bit models.base', 1);('model quant precisionsuperb tasks storage', 1);('est', 1);('] w8', 1);('evaluation', 1);('quantization-aware training', 1);('quanti- zation errors', 1);('back-propagation [', 1);('miti- gate', 1);('gradient degradation', 1);('knowledge distillation [', 1);('student model aims', 1);('original loss function', 1);('different strategies', 1);('different scenarios', 1);('quan- tization', 1);('model architecture', 1);('model shares', 1);('tensor shapes', 1);('nal output', 1);('attention weights', 1);('square error operator', 1);('ytandysare model outputs', 1);('iand os', 1);('iare intermediate outputs', 1);('layer i', 1);('iare attention weights', 1);('layer iin teacher', 1);('student models', 1);('lfinal', 1);('llayers', 1);('=p i', 1);('experiments', 1);('experimental setup', 1);('baseline model', 1);('] challenge', 1);('phoneme recogni- tion', 1);('intent classication', 1);('automatic speaker verication', 1);('speaker diarization', 1);('emotion recognition', 1);('up/down arrows', 1);('wers', 1);('speech representation extractor', 1);('fairseq [', 1);('torchaudio [', 1);('] tool', 1);('on-disk storage', 1);('point operations', 1);('quantization operations', 1);('storage', 1);('model parame- ters', 1);('parameters', 1);('pa- rameters', 1);('weight bits', 1);('bi- nary', 1);('num- ber', 1);('8-bit integer', 1);('2-bit integer', 1);('multiplica- tion', 1);('relative proportion', 1);('execution speeds', 1);('hardware [', 1);('hardware-agnostic fashion', 1);('anchor point', 1);('conversion rate', 1);('as- sume', 1);('model runs', 1);('fp16 counterpart', 1);('= 28:55gs', 1);('model quant loss precisionsuperb tasks asr', 1);('] w8a8', 1);('knowledge distillationw8a8', 1);('runtime estimation', 1);('experimental', 1);('model pro-', 1);('model [', 1);('rst baseline', 1);('similar storage size com-', 1);('alternative version', 1);('ef- cient conguration', 1);('efcient version', 1);('hu- bert', 1);('new baseline', 1);('quantiza- tion', 1);('w4a2 refers', 1);('setups fw8', 1);('based', 1);('different quantization strategies', 1);('lin-', 1);('linear+attention', 1);('different num- ber', 1);('main metric', 1);('re- sults', 1);('quan-', 1);('trend applies', 1);('degradation in- creases', 1);('fp16 baseline', 1);('exam- ple', 1);('addi- tion', 1);('applies quantization', 1);('signicant portion', 1);('run- time', 1);('lin- ear', 1);('similar bits', 1);('quantization ad-', 1);('slight degradation', 1);('bit-la-w8a8', 1);('major benet', 1);('compar-', 1);('attention operators', 1);('quantization domains', 1);('low bits', 1);('neu- ral architecture search', 1);('wide interest', 1);('comparable models', 1);('quantization strate-fig', 1);('scheduled quan-', 1);('superb-asr', 1);('bit-l-w2a2', 1);('word er- ror rates', 1);('quantization error accumulates', 1);('knowledge distilla- tion', 1);('square error', 1);('model outputs', 1);('atten- tion weights', 1);('knowledge distil- lation', 1);('quantization congurations', 1);('baseline fp16 models', 1);('loss [', 1);('baseline fp16 model', 1);('mitigate ac-', 1);('scheduled quantization', 1);('section 4.2.1', 1);('original model', 1);('target precision', 1);('multi-step quantization', 1);('in- termediate precisions', 1);('endless combinations', 1);('multi-step distillation', 1);('simpler setup', 1);('quantization schedules', 1);('one-step results', 1);('fp16 w8a8w4a4w2a2w1a1', 1);('fp16 w1a2w1a1', 1);('figure', 1);('x-axis', 1);('y-axis', 1);('similar performance', 1);('one-step counterparts', 1);('target precision w1a1', 1);('preliminary conclusion', 1);('signicant improvement', 1);('conclusion', 1);('novel quantization tech- niques', 1);('] models', 1);('speech representation learning tasks', 1);('] bench- mark', 1);('signicant savings', 1);('comparable congura- tions', 1);('2-bit models', 1);('word rates', 1);('estimate runtime', 1);('modern mod- els', 1);('acknowledgement', 1);('sincere gratitude', 1);('technical details', 1);('ro-', 1);('binarized transformer', 1);('xiaohui zhang', 1);('techincal discussions', 1);('im- plementation', 1);('anuj diwan', 1);('texas', 1);('austin', 1);('technical discussions', 1);('references', 1);('aasish pappu', 1);('lin xiao', 1);('scott yih', 1);('meng li', 1);('raghuraman krishnamoorthi', 1);('yashar mehdad', 1);('robustly', 1);('nikko strom', 1);('haidar khan', 1);('wael hamza', 1);('squashed weight distribution', 1);('low bit quantiza-', 1);('deep', 1);('proc', 1);('interspeech', 1);('benjamin bolte', 1);('yao-hung hubert tsai', 1);('ruslan salakhutdinov', 1);('abdelrah-', 1);('mohamed', 1);('self-supervised', 1);('po-han chi', 1);('yung-sung chuang', 1);('cheng-i jeff lai', 1);('yist y', 1);('lin', 1);('andy t. liu', 1);('jiatong shi', 1);('xuankai chang', 1);('guan-ting lin', 1);('tzu- hsien huang', 1);('wei-cheng tseng', 1);('ko-tik lee', 1);('da-rong liu', 1);('zili huang', 1);('shuyan dong', 1);('shang-wen li', 1);('shinji watanabe', 1);('universal performance benchmark', 1);('heng-jui chang', 1);('distilhubert', 1);('layer- wise distillation', 1);('hidden-unit bert', 1);('ieee', 1);('ashish vaswani', 1);('noam shazeer', 1);('niki parmar', 1);('jakob uszkoreit', 1);('llion jones', 1);('aidan n. gomez', 1);('lukasz kaiser', 1);('illia polosukhin', 1);('attention', 1);('tom', 1);('brown', 1);('benjamin mann', 1);('nick ryder', 1);('melanie subbiah', 1);('jared kaplan', 1);('prafulla dhariwal', 1);('arvind neelakantan', 1);('pranav shyam', 1);('girish sastry', 1);('amanda askell', 1);('sandhini agarwal', 1);('ariel herbert-v', 1);('gretchen krueger', 1);('tom henighan', 1);('rewon child', 1);('aditya ramesh', 1);('daniel m. ziegler', 1);('jeffrey wu', 1);('clemens winter', 1);('christopher hesse', 1);('mark chen', 1);('eric sigler', 1);('mateusz litwin', 1);('scott', 1);('benjamin chess', 1);('jack clark', 1);('christopher berner', 1);('sam mccandlish', 1);('alec radford', 1);('ilya sutskever', 1);('dario amodei', 1);('language', 1);('few-shot learners', 1);('jacob devlin', 1);('ming-wei chang', 1);('kenton lee', 1);('kristina toutanova', 1);('deep bidirectional transformers', 1);('language understanding', 1);('yinhan liu', 1);('naman goyal', 1);('jingfei', 1);('man-', 1);('joshi', 1);('danqi chen', 1);('omer levy', 1);('mike lewis', 1);('luke zettlemoyer', 1);('veselin stoyanov', 1);('roberta', 1);('mohammad rastegari', 1);('vicente ordonez', 1);('joseph red-', 1);('ali farhadi', 1);('xnor-net', 1);('imagenet', 1);('classi- cation', 1);('binary convolutional neural networks', 1);('tailin liang', 1);('john glossner', 1);('lei wang', 1);('shaobo shi', 1);('pruning', 1);('deep neural network acceleration', 1);('pierre', 1);('benjamin graham', 1);('edouard grave', 1);('gribonval', 1);('herv', 1);('jegou', 1);('armand joulin', 1);('training', 1);('quantization noise', 1);('extreme model compression', 1);('srivatsan krishnan', 1);('max lam', 1);('sharad chitlangia', 1);('zishen wan', 1);('gabriel barth-maron', 1);('aleksandra faust', 1);('vijay janapa reddi', 1);('quarl', 1);('sustainable reinforcement learn-', 1);('transactions', 1);('benoit jacob', 1);('skirmantas kligys', 1);('bo chen', 1);('meng-', 1);('zhu', 1);('matthew tang', 1);('andrew g. howard', 1);('hartwig adam', 1);('dmitry kalenichenko', 1);('neural networks', 1);('efcient integer-', 1);('jangho kim', 1);('yash bhalgat', 1);('jinwon lee', 1);('chirag patel', 1);('nojun kwak', 1);('qkd', 1);('quantization-aware knowl- edge distillation', 1);('yoshua bengio', 1);('nicholas', 1);('l eonard', 1);('aaron c. courville', 1);('estimating', 1);('stochastic neurons', 1);('conditional computation', 1);('felix wu', 1);('kwangyoun kim', 1);('jing pan', 1);('kyu j. han', 1);('kil-', 1);('q. weinberger', 1);('yoav artzi', 1);('performance-', 1);('efciency trade-offs', 1);('speech recognition', 1);('geoffrey hinton', 1);('oriol vinyals', 1);('jeff dean', 1);('distill-', 1);('neural network', 1);('vassil panayotov', 1);('guoguo chen', 1);('daniel povey', 1);('san-', 1);('khudanpur', 1);('asr corpus', 1);('public domain audio books', 1);('ieee inter-', 1);('national conference', 1);('sergey edunov', 1);('sam gross', 1);('nathan ng', 1);('david grangier', 1);('extensible toolkit', 1);('naacl-hlt', 1);('demonstrations', 1);('yao-yuan yang', 1);('moto hira', 1);('anjali chourdia', 1);('artyom astafurov', 1);('caroline chen', 1);('ching- feng yeh', 1);('puhrsch', 1);('david pollack', 1);('dmitriy genzel', 1);('donny greenberg', 1);('edward z. yang', 1);('jason lian', 1);('jay mahadeokar', 1);('jeff hwang', 1);('ji chen', 1);('peter goldsbor-', 1);('prabhat roy', 1);('sean narenthiran', 1);('shinji watan-', 1);('soumith chintala', 1);('vincent quenneville-b', 1);('yangyang shi', 1);('torchaudio', 1);('building blocks', 1);('arxiv preprint arxiv:2110.15018', 1);('jeff rasley', 1);('samyam rajbhandari', 1);('olatunji ruwase', 1);('yuxiong', 1);('system optimizations', 1);('enable training', 1);('learning models', 1);('bil- lion parameters', 1);('acm sigkdd', 1);('knowledge dis-', 1);('data mining', 1);('york', 1);('ny', 1);('usa', 1);('kdd', 1);('computing machinery', 1);('henry zhou', 1);('speech representations', 1);