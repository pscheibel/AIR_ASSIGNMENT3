('lm', 17);('asr', 12);('transformer lm', 9);('librispeech', 9);('transformer', 8);('ngram', 8);('eq', 6);('lookup dictionary', 5);('english', 5);('cer', 4);('ieee', 4);('international conference', 4);('overall', 3);('ids', 3);('tail tokens', 3);('acoustics speech', 3);('speech recognition', 2);('language', 2);('rare words', 2);('bert', 2);('initialize dictionary', 2);('current tokens', 2);('lm asr', 2);('uis', 2);('dictionary size', 2);('bernoulli', 2);('token', 2);('input search', 2);('asr lm', 2);('pg19', 2);('espnet', 2);('conformer', 2);('search', 2);('transformerlm', 2);('online', 2);('arxiv', 2);('processing icassp', 2);('memory augmented lookup dictionary based language modeling forautomatic speech recognitionyukun feng1\x03 ming tu2y rui xia2 chuanzeng huang2 yuxuan wang2johns hopkins university1speech', 1);('intelligence sami bytedance2yfeng55jhuedu', 1);('fmingtu ruixia huangchuanzeng wangyuxuan11 gbytedancecomabstractrecent studies', 1);('language modellm', 1);('benets endtoend', 1);('automatic speech recognition asrhowever', 1);('challenging longtail prediction problems havebeen', 1);('applications addressedby studies', 1);('asr lms', 1);('lookup dictionary incorporatesrich contextual information training', 1);('vital correctlypredict longtail tokens intensive experiments', 1);('chinese andenglish data', 1);('outperform thebaseline', 1);('wordcharactererror rate tail tokens error rate', 1);('longtail tokensindex', 1);('terms automatic', 1);('rare words recognition longtail recognition1', 1);('introductionwhile', 1);('lot studies', 1);('superiority endtoend', 1);('e2e automatic speech recognition asr', 1);('andthe effectiveness', 1);('recognition prediction words thatappear zero times training data', 1);('e2e asr', 1);('onlyon text training datasome studies', 1);('longtail problem', 1);('e2easr', 1);('large corpora oftextual data', 1);('distribution head tail words inlm training', 1);('ability tail words', 1);('8the authors', 1);('prediction tail words withthe', 1);('lms bert', 1);('computational cost', 1);('lineof research', 1);('training loss', 1);('extra loss termsto regularize', 1);('training results', 1);('scale upthe', 1);('rnn lm', 1);('ngramcontext', 1);('frequency informationof words', 1);('ngrams', 1);('reply input', 1);('contextual information', 1);('rare words\x03work', 1);('bytedanceycorresponding', 1);('transformer lms', 1);('performance thanrnn', 1);('lms asr', 1);('transformerlms', 1);('lookup dictionary maps', 1);('current context candidate tokens', 1);('inspired', 1);('14which focuses', 1);('effective training', 1);('current token askeys utilize multivector array values', 1);('enable memorization', 1);('rich context information', 1);('dictionarysvalues memory', 1);('specifically', 1);('contextual memory', 1);('token occurs training corpus key thefrequency', 1);('multivector value', 1);('anattention module', 1);('layer transformer blocks mapthe dictionary memory', 1);('current token current context query relevantvectors', 1);('corresponding multivector memorywe', 1);('mandarin asr', 1);('character error rate cer', 1);('lm notably', 1);('method show', 1);('reduction 1gram 2gram tail tokens', 1);('weachieve word', 1);('error rate wer', 1);('test setsof', 1);('success method', 1);('prediction tail tokens', 1);('mandarin english', 1);('different aspects', 1);('contributions asthe following1', 1);('equippedwith lookup dictionary', 1);('multivector memorythat builds', 1);('current context', 1);('candidate tokens2 incorporate', 1);('context information', 1);('token frequency training data lookup dictionary toimprove prediction', 1);('rare words3', 1);('outperforms baseline', 1);('lmin mandarin english asr', 1);('sameinference efciency2', 1);('proposed approachin figure', 1);('eachmodule', 1);('subsectionsarxiv230100066v1 cscl', 1);('dec', 1);('tmtm tmtmc0c1 c2e1e2w0w1w2attentionm idw0 idw1', 1);('overview', 1);('transformer lm wkrepresents', 1);('input tokens', 1);('ekis', 1);('token embeddingtm', 1);('blocks autoregressive manner', 1);('ckis', 1);('corresponding theinput tokens', 1);('input', 1);('lm21 dictionary', 1);('indexingwe', 1);('ddd2ru\x02m\x02demb', 1);('onevector value key', 1);('scale dictionarysize', 1);('extra hyperparameter', 1);('mto', 1);('form keyvaluepair idiwheredi2rm\x02demb thekthtoken inputsequence', 1);('corresponding dictionary index iis', 1);('amodular hash', 1);('idtoken', 1);('k mod', 1);('id', 1);('refers vocabulary id input', 1);('token believewith', 1);('multiple vectors', 1);('context dictionary', 1);('equation', 1);('dictionary indexiis', 1);('followsi kxnk\x00n1idtoken n mod', 1);('2wherenindicates number', 1);('aggregate example ifn', 1);('current token itsprevious', 1);('token modulo operationto trade information redundancy memory capacity collision', 1);('unandmcan', 1);('utilize dictionarymemory', 1);('show inuence changingthe', 1);('hyperparameters performance results part22', 1);('dictionary updateas', 1);('dictionary memory', 1);('dithroughequation', 1);('memory vector dmiis', 1);('token ek1', 1);('asfdmidmi\x03 ek1\x031\x00 ifxk1 1dmi ifxk1 03where', 1);('experiments dene', 1);('xk1\x18bernp', 1);('k1 whichdecides', 1);('dipk1indicates', 1);('update ratio', 1);('occurrenceof thek 1thtoken training datapk11logcount', 1);('k1 4in case embeddings', 1);('low frequency tokens', 1);('able contribute', 1);('corresponding memory', 1);('high frequency tokens', 1);('training textand', 1);('corresponding text tokenizer', 1);('effectof update ratio', 1);('context selectionwe', 1);('attention module relate output representation ofthe', 1);('current token corresponding dictionary memory', 1);('attentionperforms', 1);('function input query', 1);('kv', 1);('pairs asattention', 1);('qkv softmax qktpdembv', 1);('input output', 1);('dictionary memory stores candidate', 1);('attention module couldhelp', 1);('select useful information memory', 1);('current token kthtoken dene', 1);('model ckand', 1);('corresponding dictionary memory', 1);('di', 1);('new output representationfckis', 1);('attention', 1);('ckdidi 6which', 1);('calculate output', 1);('token distributionmodel', 1);('input searchoverall tail1 tail2 overall tail1 tail2cerser cer cer cerser cer cerconformer', 1);('language model lm', 1);('lml', 1);('1227ours l', 1);('evaluation cer ser', 1);('voice input voice searchdomain test', 1);('lrefers lm', 1);('training inferenceduring', 1);('training context selection operation', 1);('thedictionary update reason update information', 1);('eq3', 1);('current input sentence', 1);('current contextselection stabilize training', 1);('dictionary update rst', 1);('training steps warmup', 1);('distribution inference dictionaryupdate', 1);('information leakage autoregressive prediction', 1);('shallow fusion', 1);('weight \x15sf', 1);('internal language model estimationilme', 1);('lm e2e asrand', 1);('advocate contribution external', 1);('domain mismatch textual distribution', 1);('training data weightof', 1);('ilme', 1);('nbestoutput', 1);('beam search weight', 1);('experiment31 datasetswe', 1);('hours data trainingand', 1);('clean test', 1);('11gb indomain text', 1);('project gutenberg', 1);('sentence length', 1);('intoa sentencelevel corpus', 1);('unigram tokenizer', 1);('vocabulary size', 1);('internal chinese videodatasets 10k hours', 1);('audio dataset generalasr training', 1);('voice input domain 5103utterances voice search domain', 1);('different domains', 1);('training setas', 1);('training 60gb text corpus voiceinput domain 2gb corpus voice search domain process', 1);('chinese text character level vocabulary size of11k', 1);('chinese characters', 1);('subword tokensbesides', 1);('overall performance', 1);('metrics tail tokens', 1);('tailtokens', 1);('frequency inthe training corpus', 1);('5ie frequency ratio head tail tokens', 1);('1gramtail1 2gram', 1);('tail2', 1);('teset ses extracted1gram wordlevel tail tokens32', 1);('experimental', 1);('settingswe train', 1);('english asr', 1);('las', 1);('architecture use 12layer', 1);('encoder and6layer', 1);('librispeech espnet', 1);('encoder 4layer', 1);('decoder forthe 10k hours', 1);('chinese datasetfor', 1);('transformerblocks', 1);('onpg19 sentencelevel language', 1);('dropout rate of03', 1);('effective token number', 1);('adamwith', 1);('weight decay', 1);('theoptimization 10k warmup steps', 1);('lookup dictionary use 2gram dictionary', 1);('setto 5kmis', 1);('chinese datasets', 1);('small large conguration respectively1 lookup dictionaryuis', 1);('10k hyperparameters withthe', 1);('inference paper', 1);('inputsearchgrespectively', 1);('performance beamsize', 1);('weuse', 1);('error rate wer asr', 1);('test setsand', 1);('character error rate cer sentence error rate ser', 1);('forchinese test', 1);('calculate tail tokenerror rate', 1);('errors tail tokens', 1);('errorson tokens', 1);('resultswe', 1);('astwo baselines', 1);('singlevector memory', 1);('ser', 1);('method shows signicant improvement itand', 1);('baseline methods', 1);('cerimprovement', 1);('lm cer', 1);('improvement tail tokens even1we', 1);('settings impact decodingefciencymodel', 1);('clean otheroverall tail1 overall tail1conformer', 1);('evaluation wer librispeech', 1);('test setsfig', 1);('cer search', 1);('withdifferent dictionary size', 1);('2gram tail tokens increase', 1);('lms', 1);('cerin', 1);('shows consistent improvementon', 1);('improvement tail word errorrate', 1);('wer', 1);('chinese test sets4', 1);('analysisin', 1);('section analyze', 1);('different hyperparameters', 1);('unin ngram', 1);('memory update ratio memory size entry', 1);('performanceall experiments', 1);('memory augmentedlookup dictionary', 1);('figure', 1);('axiswith increase dictionary size', 1);('settings isclear', 1);('dictionary size willboost performance 2gram', 1);('performancesince degree collision elevates', 1);('uandn', 1);('largernmeans collision', 1);('4gram performs', 1);('1gram case dictionary size', 1);('theextra space', 1);('large dictionary size wo', 1);('2gramwith 10k dictionary sizein', 1);('performance overall', 1);('cerand cer', 1);('different memory update settings', 1);('theratios', 1);('probability alltokens', 1);('xk1in eq', 1);('update memory freq', 1);('different tokens', 1);('frequency trainingset results', 1);('large update ratio tends improvethe performance', 1);('memory updatestrategy', 1);('large memory size', 1);('mwould', 1);('selection overall performance use', 1);('information gainig', 1);('difference attention entropyas', 1);('dictionary anda', 1);('overall tail1 tail202', 1);('overall tail tokens', 1);('differentmemory update options16', 1);('size000204060810information gain gradients825830835840845cerig gradients cerfig', 1);('overall cer gradients information gain ig', 1);('increase memory size', 1);('mmaps', 1);('current token fck21 results', 1);('ig', 1);('gradient attribution', 1);('address dictionary memorys contribution computes', 1);('gradient model variables reect contributionto output prediction shows gradients', 1);('contribution model predictionhowever', 1);('small relative gain high computationalcost increase memory size', 1);('thememory size', 1);('model size', 1);('additional computation method', 1);('context selection', 1);('o1time', 1);('cost contextselection', 1);('constant time cost', 1);('om', 1);('wheremis memory size dictionary', 1);('real timefactor rtf search', 1);('nvidia a100 gpu', 1);('withbeam size batch size equals', 1);('rtf', 1);('additional operations', 1);('speed practice', 1);('themodel size increases', 1);('lookup dictionary5', 1);('conclusionsin', 1);('asrespecially', 1);('long tail tokens', 1);('terms overall', 1);('metrics tail words error rate', 1);('analyze ourmethod', 1);('different hyperparameter settings', 1);('resultsprove superiority method baseline', 1);('inference speed', 1);('domain mismatchcondition', 1);('method generallanguage', 1);('references1 graves sequence', 1);('transduction recurrent neural networks arxiv preprint arxiv12113711', 1);('chan n jaitly q v', 1);('vinyals listen', 1);('arxiv preprint arxiv150801211', 1);('toshniwal kannan cc chiu wu n sainathand k livescu', 1);('comparison techniques languagemodel integration encoderdecoder speech recognitionin2018', 1);('language technology workshop', 1);('slt ieee', 1);('kannan wu p nguyen n sainath z chen', 1);('prabhavalkar', 1);('externallanguage model sequencetosequence model 2018ieee', 1);('processing icassp ieee', 1);('peyser n sainath g pundak improving', 1);('propernoun recognition endtoend asr customization themwer loss criterion', 1);('icassp', 1);('processingicassp ieee', 1);('peyser mavandadi n sainath j apfel r pangand kumar improving', 1);('tail performance deliberation e2e asr model', 1);('large text corpus arxiv preprintarxiv200810491', 1);('g winata g wang', 1);('xiong hoi adaptandadjust overcoming', 1);('longtail problem multilingualspeech recognition', 1);('available httpsopenreviewnetforumid34kaz9hbjco8', 1);('k deng g cheng r yang yan alleviating', 1);('learning representation andclassication', 1);('ieeeacm transactions audio speech', 1);('processing', 1);('r huang', 1);('peyser n sainath r pang strohmanand kumar sentenceselect largescale', 1);('language modeldata selection rareword speech recognition', 1);('r huang n sainath', 1);('peyser kumar rybachand strohman', 1);('lookuptable recurrent language modelsfor', 1);('long tail speech recognition', 1);('vol abs210404552202111', 1);('ch h yang', 1);('liu gandhe gu raju filimonov bulyko multitask', 1);('ieeeautomatic speech recognition understanding workshopasru ieee', 1);('j devlin mw chang k lee k toutanova bertpretraining', 1);('deep bidirectional transformers', 1);('proceedings', 1);('conference thenorth', 1);('american chapter association', 1);('computationallinguistics', 1);('language technologies', 1);('longand short papers minneapolis minnesota associationfor computational linguistics jun', 1);('pp 41714186online', 1);('available httpsaclanthologyorgn19142313', 1);('k irie zeyer r schl', 1);('h ney language', 1);('interspeech', 1);('q wu', 1);('xing li g ke ty liu', 1);('iclr', 1);('available httpsopenreviewnetforumidlu5rs wcwen15', 1);('z meng n kanda gaur parthasarathy e sun', 1);('lux chen j li gong internal', 1);('domainadaptive endtoend speech recognitionicassp', 1);('v panayotov g chen povey khudanpur librispeech', 1);('asr corpus', 1);('public domain audio booksin2015', 1);('acoustics speechand', 1);('rae potapenko jayakumar', 1);('hillierand p lillicrap compressive', 1);('transformers longrange sequence', 1);('arxiv preprint', 1);('onlineavailable httpsarxivorgabs19110550718', 1);('kudo subword', 1);('improving', 1);('neural network translation models', 1);('multiple subword candidatesinproceedings 56th', 1);('annual meeting', 1);('computational linguistics', 1);('longpapers melbourne australia', 1);('computational linguistics jul', 1);('online availablehttpsaclanthologyorgp18100719 watanabe hori karita hayashi j nishitobay unno n enrique yalta soplin j heymann wiesnern chen renduchintala ochiai espnet endtoend speech processing toolkit proc interspeech', 1);('gulati j qin cc chiu n parmar zhang j yuw han wang z zhang wu r pang conformerconvolutionaugmented', 1);('transformer speech recognition10', 1);('feng', 1);('li z', 1);('song b', 1);('zheng p koehnlearn', 1);('recurrent memoryfor documentlevel machine translation', 1);('findings', 1);('ofthe association', 1);('computational linguistics naacl2022 seattle', 1);('computationallinguistics jul', 1);('online availablehttpsaclanthologyorg2022ndingsnaacl10522 ancona e ceolini', 1);('oztireli gross towardsbetter', 1);('attribution methodsfor', 1);('neural networks', 1);('conferenceon learning representations', 1);('online availablehttpsopenreviewnetforumidsy21r9jaw23 g qin feng', 1);('van durme', 1);('nlp taskeffectiveness longrange transformers', 1);('onlineavailable httpsarxivorgabs220207856', 1);