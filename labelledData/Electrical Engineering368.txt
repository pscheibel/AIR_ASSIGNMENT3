('hsv', 11);('places2', 11);('cswin', 7);('fig', 6);('celeba', 6);('cnn', 5);('masked', 5);('proceedings ieeecvf', 5);('zoomin', 4);('\x02256 results', 4);('canny', 3);('hifill', 3);('tfill', 3);('rdb', 3);('aotgan', 3);('crfill', 3);('quantitative', 3);('proceedings', 3);('eccv', 3);('top bottom', 3);('texture structure', 2);('whole image', 2);('global information', 2);('furthermore', 2);('color consistency', 2);('yu', 2);('receptive eld', 2);('joint attention', 2);('different receptive elds', 2);('global layer', 2);('theamount calculation', 2);('lepe', 2);('edge', 2);('styleloss', 2);('contextual transformations', 2);('lama', 2);('psnr ssim', 2);('dataset image size', 2);('hence', 2);('irregular masks', 2);('dataset report', 2);('peak', 2);('signaltonoise ratio', 2);('psnr', 2);('ssim', 2);('ndenotes', 2);('hdenotes', 2);('lesser parameters', 2);('underline', 2);('italics', 2);('ssimparametersx106mask5o1010o2020o3030o4040o5050o605o1010o2020o3030o4040o5050o60pm', 2);('iconv', 2);('ltotalhsv', 2);('ablation', 2);('conference oncomputer', 2);('vision pattern recognition', 2);('proceedings ieee', 2);('computer vision pattern recognition', 2);('european conference computer vision', 2);('ieee', 2);('rw deepfill', 2);('lightweight image inpainting stripe window transformer withjoint attention cnnbowei chentsungjung liukuanhsien liuydepartment electrical engineering', 1);('graduate institute', 1);('communication engineering', 1);('chung hsing', 1);('taiwanydepartment computer', 1);('information engineering', 1);('taichung', 1);('university science technology', 1);('taiwanabstractimage', 1);('important task computer vision', 1);('asadmirable methods', 1);('onhuman vision', 1);('models havebeen', 1);('advancement computer hardware', 1);('suitable model forpersonal use', 1);('proposea lightweight model', 1);('special transformer andthe', 1);('traditional convolutional neural network', 1);('cnn furthermore', 1);('primary colors', 1);('rgb', 1);('new loss function intensify color details', 1);('extensive', 1);('places2 celeba', 1);('validate efcacy', 1);('stateoftheart methodsindex', 1);('terms hsv', 1);('color space image', 1);('jointattention mechanism stripe window vision transformer1', 1);('introductionimage', 1);('researchers forseveral years', 1);('main goal image', 1);('realistic pixels', 1);('region image andthis', 1);('object removal photo restorationto', 1);('realistic results need', 1);('important points', 1);('continuity adjacent textures', 1);('reasonable structure', 1);('methods target', 1);('problem suchas', 1);('traditional diffusion method patch', 1);('current methods', 1);('cnn gan', 1);('stillface difculties', 1);('narrow receptive eld', 1);('hard repair key edgeand lines scene researchers', 1);('methodsthat utilize auxiliary information structure recovery egedges', 1);('hand researcher', 1);('attention scores', 1);('suvorov', 1);('etal2 utilize', 1);('fast fourier convolution ffc', 1);('encodefeatures frequency domain', 1);('global receptive eldsfor resolutionrobust', 1);('overall repair result', 1);('huge computational cost', 1);('recent years transformerhas', 1);('eld advantageof', 1);('receptive elds', 1);('cnns', 1);('atlow resolutions', 1);('lot ofcomputer memorytherefore inspires', 1);('design lightweight transformer block', 1);('stable repair', 1);('specically', 1);('stripe window selfattention', 1);('traditional full selfattention', 1);('stripewindow', 1);('selfattention mechanism computes selfattentionparallel horizontal vertical stripe crosswindows', 1);('eachstripe', 1);('constantwidth stripes way', 1);('global attentionwith', 1);('computational cost redesign transformer block', 1);('repair performancethe consistency color', 1);('important factor tojudge quality image', 1);('easy discern difference', 1);('original image humanvision color deviation researchers dealwith', 1);('basic primary colors', 1);('ifwe', 1);('repair performance', 1);('thereforewe', 1);('color space andcompare input image followup experimentsour method', 1);('effectivethe rest paper', 1);('section2', 1);('previous stateoftheart inpaintingmethods', 1);('method lossfunction section', 1);('exhibit trainingdetails experiment results', 1);('images ablationstudies', 1);('dueto', 1);('page limit qualitative quantitative results', 1);('celebadataset', 1);('object removal experiments', 1);('appendix', 1);('supplementary materialarxiv230100553v1', 1);('jan', 1);('related worktraditional', 1);('traditional', 1);('categories rst', 1);('diffusion method', 1);('diffusion', 1);('methods disseminate texturecontent', 1);('multicurve information knownregion', 1);('patch', 1);('approximatenearestneighbor nd nearestneighbor region', 1);('similar nearestneighbor region', 1);('complete image inpaintingthe', 1);('easy blur', 1);('results largemasks', 1);('method cost lot calculationsdeep learning', 1);('advancementof hardware technology', 1);('deep learning model hasbecome mainstream', 1);('gradually', 1);('novelcnn models', 1);('different modules proposedeg models utilize edge auxiliaries information asnazeri', 1);('edgeconnect', 1);('edge generate edge images methods', 1);('additional auxiliaries informationto', 1);('complex structure building', 1);('interior space', 1);('need stagesor parameters training methods', 1);('edgeinformation mask', 1);('input proposedapproach enhance edge structureon hand researchers', 1);('contextual attention enhance texture', 1);('zhu', 1);('madf', 1);('yi', 1);('8they calculate', 1);('attention scores nd mostsimilar texture', 1);('type methods', 1);('others interms texture', 1);('method redesign theattention module', 1);('wide attention local', 1);('attention sharingvision transformer', 1);('recently', 1);('vision', 1);('vit', 1);('transformer', 1);('nlp', 1);('usable computer vision', 1);('methodas novel transformers', 1);('dong', 1);('scswin transformer', 1);('theeld image', 1);('zheng', 1);('huge mask transformer inpaint plausible textures bytheir', 1);('special attention addition transformer', 1);('traditional convolution', 1);('costs convolution', 1);('basic transformer', 1);('stripe window', 1);('amount calculation andobtain', 1);('repair effectsto summarize paper', 1);('special transformer framework image', 1);('joint attention local', 1);('layers model focuses', 1);('local layer process', 1);('global local layerin parallel share attention information end use', 1);('simple upsamples getthe', 1);('result major contributions work areas', 1);('stripe window selfattention transformerwith efcient local enhancement position encodingthen redesign transformer block', 1);('original method', 1);('global layers locallayers', 1);('layers enhance overallconsistency repair results', 1);('common dataset', 1);('conductextensive experiments conrm proposedmodel', 1);('methodologyoverview', 1);('whole model', 1);('approach isshown', 1);('im', 1);('mboth', 1);('concatenate input themto', 1);('layers downsample input image', 1);('global layer iecswin transformer local residual residual', 1);('dense blockrrdb', 1);('layer use joint attention', 1);('block inrrdb', 1);('convrelu', 1);('threeupsample layers', 1);('iout31', 1);('cswin transformerthe', 1);('cswin transformer', 1);('map withsize', 1);('h\x02w\x02c handware', 1);('fourcswin transformer blocks', 1);('global layer blockhas multihead stripe window sw', 1);('multihead 24816andswto481632for', 1);('blocks default rst threeblocks', 1);('transformer block willsplit channel horizontal vertical stripes andthen', 1);('channel multihead', 1);('theswwill', 1);('horwchosen', 1);('horizontal stripes verticalstripes', 1);('different', 1);('general multihead selfattentionmhsa stripe window multihead selfattention', 1);('swmhsa', 1);('multihead swto', 1);('lowresolution image thefig', 1);('whole model structure shows framework', 1);('model andthe details joint attention', 1);('global', 1);('local layer input images', 1);('imandm', 1);('right side shows', 1);('cswintransformer block', 1);('normalization factor softmax', 1);('similarity pixels', 1);('residual dense block', 1);('local layer', 1);('top right corner', 1);('whole modelselfattention', 1);('qquery kkeys vvalues', 1);('transformer thefull attention swin', 1);('whichmeans stripe window', 1);('cswin block', 1);('cswinblock', 1);('rst feedforward beginningbecause hope selfattention block', 1);('swmhsa stripe window selfattention', 1);('selfattention', 1);('different receptiveelds', 1);('residual link', 1);('wealso', 1);('thetransformer block', 1);('end transformer blockbut middle', 1);('right side', 1);('wefound', 1);('selfattention needs', 1);('multiple timesto', 1);('attention information', 1);('nito', 1);('denotethe number repetitions32', 1);('joint', 1);('attentionwe concatenate', 1);('global local layers', 1);('focus onthe information', 1);('different receptive elds expectour', 1);('results admixture', 1);('local receptive eldsso', 1);('cswintransformer', 1);('rdbblocks', 1);('sameas attention need reshape', 1);('conform attention', 1);('values inqkv', 1);('mixedreceptive elds', 1);('block thetwo layers', 1);('joint attention33', 1);('loss functionmost', 1);('loss functions', 1);('andwe', 1);('l1', 1);('l1jiout\x00igtjwhereioutigtindicate', 1);('images ground truth respectivelyin addition', 1);('enhance edge inpaintingimage', 1);('loss ledge 1npni1jjiout', 1);('medge\x00igt medgejj22wherenrepresents', 1);('number ofpixels image', 1);('medge', 1);('1\x00iedge 10\x03iedgewhich', 1);('edge mask accentuate edgestructure', 1);('iedge', 1);('edgedetection 11in order', 1);('model weuse', 1);('perceptual', 1);('loss measure similarity imageswe', 1);('perceptualloss', 1);('visible regions', 1);('vggbased', 1);('model generate images semanticallycloser ground truth notice', 1);('resultshave checkerboard artifacts', 1);('according', 1);('total lossbesides', 1);('loss tomeasure similarity colors', 1);('followslhsv 1nnxi1jjhsv out\x00hsv', 1);('gtjj22lhsv', 1);('edge 1nnxi1jjhsv', 1);('medge\x00hsv gt medgejj22ltotalhsv', 1);('\x15hsv\x03lhsv \x15hsv edge\x03lhsv edge1where\x15hsv', 1);('and\x15hsv edge', 1);('herehsv', 1);('color spacebut use', 1);('value hsv', 1);('loss brightnessintensity', 1);('losses stilluse thevalue', 1);('ablation experimentsthe adversarial loss', 1);('discriminator loss', 1);('ldand', 1);('generator loss', 1);('lg', 1);('adversarial loss', 1);('asld\x00eigtlogdigt\x00eioutmlogdiout 1\x00m\x00eioutmlog1\x00diout', 1);('mlg\x00eioutlogdioutladvldlg\x15gplgp2where patchgan', 1);('dand', 1);('g thelgpeigtjj5igtdigtjj2is', 1);('gradient penalty and\x15gp 1e\x003', 1);('losses total lossltotal', 1);('ltotal', 1);('\x15l1l1\x15edgeledge \x15perclperc\x15stylelstyle \x15totalhsvltotalhsv \x15advladv3where\x15l1', 1);('\x15perc 01\x15style', 1);('loss weights', 1);('experiments41 datasetsto', 1);('modelwe conduct experiments', 1);('20k images', 1);('original dataset', 1);('dataset 5k images validation use about4k images test use', 1);('data lightweightmodel show', 1);('robustnessthan stateoftheart hugeparameters models allof images', 1);('dataset train test themwith image size', 1);('\x02256 comparison methods weuse', 1);('test thesame dataset did42', 1);('reference stateoftheartwe', 1);('model stateoftheartmethods', 1);('patchmatch pm', 1);('contextual attention ca', 1);('shiftnet sn', 1);('partial convolutionspc', 1);('regionwise rw', 1);('gated convolution deepfill', 1);('contextual residual aggregation hifill', 1);('imputed convolution iconv', 1);('aggregated', 1);('maskaware dynamic filtering madf', 1);('auxiliary contextual', 1);('bridging global context interactions tfill', 1);('large mask', 1);('quantitative comparisonsin', 1);('assess theperformance', 1);('\x02256 withirregular masks', 1);('method results', 1);('method defeat', 1);('methods terms', 1);('evaluation metrics', 1);('onthe', 1);('hand training images steps', 1);('thanmost methods', 1);('model surpass themif', 1);('similar resources doin', 1);('lpips', 1);('assess perceptualsimilarity', 1);('dataset inimage size', 1);('thelpips metric fair', 1);('eld themain point', 1);('images reconstruct imageclose', 1);('perceptual similarity likewhat human vision', 1);('model canachieve', 1);('thismeans', 1);('qualitative comparisonswe', 1);('show qualitative', 1);('places2 fig2 compared', 1);('model canreconstruct', 1);('clear textures notice', 1);('focus onthe transformer', 1);('future setrestrictions', 1);('local layers', 1);('local information willnot', 1);('architecture lightweightmodel', 1);('need lots parameters butstill', 1);('similar results', 1);('training data steps', 1);('thanother methods45', 1);('ablation studyto', 1);('new loss function areuseful', 1);('test themin ablation experiments test stability thecswin transformer redesign', 1);('original transformer', 1);('07431deepfill v2', 1);('qualitative', 1);('rw', 1);('deepfillv2', 1);('learned', 1);('perceptual image patch similarity', 1);('lpipslpipsrw', 1);('deepfill', 1);('01156cswin transformer results', 1);('psnr ssimwe', 1);('conduct experiments', 1);('table 3we', 1);('value v hsv', 1);('l1and', 1);('v lhsv', 1);('inuence balance', 1);('thetable show color deviation withoutltotalhsv', 1);('training steps', 1);('cansee color', 1);('training steps shows', 1);('closeto ground truth', 1);('region consistent', 1);('specialcswin transformer size', 1);('\x02256 images', 1);('places2psnrssimlpipsoriginal', 1);('01221ours wo', 1);('01212ours w', 1);('01184ours w', 1);('cswinand hsv', 1);('loss wo', 1);('v265801', 1);('study color deviation', 1);('images wo', 1);('totalhsv', 1);('loss andtotalhsv loss wo', 1);('vltotalhsv', 1);('conclusionin', 1);('lightweight joint attention transformer architecture use', 1);('architecture toget', 1);('wide receptive eld information', 1);('rrdb', 1);('loss stabilize colors', 1);('early training stepsand', 1);('performancewe use', 1);('transformer redesign transformerblock confuse', 1);('signicant improvements experiments', 1);('small amount parameters stillgenerate', 1);('results otherstateoftheart methods', 1);('large models advantage details', 1);('hardware support', 1);('small models', 1);('large models6', 1);('references1 k nazeri e ng joseph', 1);('z qureshi', 1);('ebrahimi edgeconnect generative', 1);('adversarial edge learning arxiv preprintarxiv190100212', 1);('r suvorov e logacheva mashikhin remizova ashukha silvestrov n kong h gokak', 1);('v lempitsky resolutionrobust', 1);('fourier convolutions', 1);('proceedings ieeecvf winter', 1);('applications computer vision', 1);('x dong j bao chen', 1);('zhang n yu', 1);('yuand chen', 1);('guo cswin', 1);('transformer generalvision transformer backbone', 1);('barnes e shechtman finkelstein bgoldman patchmatch', 1);('correspondence algorithm structural image editing', 1);('acmtrans graph', 1);('j yu z lin j yang x shen x lu huangfreeform', 1);('ieeecvf', 1);('international conference computer vision pp', 1);('j yu z lin j yang x shen x lu huanggenerative', 1);('contextual attention', 1);('conference computer vision pattern recognition pp', 1);('zhu x li', 1);('li', 1);('li x liu e ding', 1);('zhang image', 1);('endtoend cascadedrenement mask awareness', 1);('ieee transactionson image processing', 1);('z yi q tang azizi jang z xu contextual', 1);('residual aggregation ultra highresolution image', 1);('k x chen xie li p doll', 1);('r girshick masked', 1);('scalable vision learners', 1);('zheng tj cham j cai phung bridging', 1);('global context interactions highdelity imagecompletion', 1);('ding goshtasby', 1);('canny edge', 1);('pattern', 1);('recognition vol', 1);('x wang k yu wu j gu liu', 1);('dongy qiao', 1);('loy esrgan enhanced', 1);('superresolution generative adversarial networks', 1);('workshops pp', 1);('q dong', 1);('cao fu incremental', 1);('proceedings ieeecvfconference computer vision pattern recognition', 1);('g liu', 1);('reda k j shih tc wang tao', 1);('catanzaro image', 1);('irregular holes', 1);('partial convolutions', 1);('p isola jy zhu zhou efros imagetoimage', 1);('translation conditional adversarial networks', 1);('conference oncomputer vision pattern recognition pp', 1);('z yan x li li', 1);('zuo shiftnetimage', 1);('rearrangement inproceedings', 1);('european conference computervision', 1);('x liu bai', 1);('wang liu tao', 1);('r hancock regionwise', 1);('generative adversarial image', 1);('ieee transactions cybernetics', 1);('h hukkel', 1);('lindseth r mester image', 1);('dagmgerman', 1);('pattern recognition', 1);('springer', 1);('zeng j fu h chao', 1);('guo aggregatedcontextual', 1);('transformations highresolution', 1);('ieee transactions visualization', 1);('graphics', 1);('zeng z lin h lu v patel crll generative', 1);('auxiliary contextual reconstruction', 1);('international conference', 1);('computer vision', 1);('z wang', 1);('bovik h r sheikh e p simoncelli image', 1);('quality assessment error visibilityto structural similarity', 1);('r zhang p isola efros e shechtman', 1);('wang', 1);('unreasonable effectiveness deepfeatures perceptual metric', 1);('conference computer vision patternrecognition pp', 1);('appendix71 qualitative quantitative', 1);('celebadatasetdatasets celeba', 1);('whole dataset ofceleba', 1);('trainvalidation test datasets images inceleba dataset train test imagesize', 1);('comparison methods', 1);('test samedataset didreference', 1);('stateoftheart', 1);('proposedmodel stateoftheart methods includepatchmatch', 1);('pm contextual attention ca shiftnetsn partial convolutions pc regionwise rw gatedconvolution deepfill', 1);('imputed convolution iconvaggregated', 1);('aotgan auxiliary contextual', 1);('crfill bridging globalcontext interactions tfillresult', 1);('show qualitative comparison', 1);('table 4we utilize', 1);('assess performance ofall', 1);('method resultsare', 1);('tiny masks', 1);('huge masks hand', 1);('model surpass', 1);('similar resources', 1);('celeba fig', 1);('different groundtruth image', 1);('global information nolimitation local information lling72', 1);('places2and fig', 1);('small masks tothe', 1);('huge masks', 1);('object removalwe', 1);('conduct object removal experiments', 1);('fig4', 1);('target removal andbackground repair background', 1);('grid background meansour model needs enhance structure', 1);('future research codes releasedin httpsgithubcombobo0303lightweightimageinpaintingbystripewindowtransformerwithjointattentiontocnnfig', 1);('object', 1);('removal size', 1);('original', 1);('image mask object removal resultfig', 1);('inpainting', 1);('rwdeepfill', 1);('iconv aotgan crfill tfill zoomin', 1);('07140deepfill v2', 1);('iconv aotgan crfill tfill', 1);('aotgan crfill tfill', 1);